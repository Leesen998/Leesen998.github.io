<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>QJun</title>
  
  <subtitle>QJun&#39;s Homepage</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://leesen998.github.io/"/>
  <updated>2019-03-22T08:28:17.071Z</updated>
  <id>https://leesen998.github.io/</id>
  
  <author>
    <name>QJun</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>推荐系统--神经协同过滤NCF原理及实战</title>
    <link href="https://leesen998.github.io/2018/11/19/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F--%E7%A5%9E%E7%BB%8F%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4NCF%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E6%88%98/"/>
    <id>https://leesen998.github.io/2018/11/19/推荐系统--神经协同过滤NCF原理及实战/</id>
    <published>2018-11-19T11:48:29.000Z</published>
    <updated>2019-03-22T08:28:17.071Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0B/0F/ChMlWlyAyIiIQH8pABv6qMmlUWEAAIp0AAv7LcAG_rA821.jpg" alt="" style="width:100%"></p><a id="more"></a><h1 id="推荐系统–神经协同过滤NCF原理及实战"><a href="#推荐系统–神经协同过滤NCF原理及实战" class="headerlink" title="推荐系统–神经协同过滤NCF原理及实战"></a>推荐系统–神经协同过滤NCF原理及实战</h1><p>论文地址：<a href="https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf" target="_blank" rel="noopener">https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf</a></p><h1 id="1、Neural-Collaborative-Filtering"><a href="#1、Neural-Collaborative-Filtering" class="headerlink" title="1、Neural Collaborative Filtering"></a>1、Neural Collaborative Filtering</h1><h2 id="1-1-背景"><a href="#1-1-背景" class="headerlink" title="1.1 背景"></a>1.1 背景</h2><p>本文讨论的主要是隐性反馈协同过滤解决方案，先来明确两个概念：显性反馈和隐性反馈：</p><p><strong>显性反馈</strong>行为包括用户明确表示对物品喜好的行为<br><strong>隐性反馈</strong>行为指的是那些不能明确反应用户喜好</p><p>举例来说：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-9cab8ff893c16d2a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/702/format/webp" alt="img"></p><p>很多应用场景，并没有显性反馈的存在。因为大部分用户是沉默的用户，并不会明确给系统反馈“我对这个物品的偏好值是多少”。因此，推荐系统可以根据大量的隐性反馈来推断用户的偏好值。</p><p>根据已得到的隐性反馈数据，我们将用户-条目交互矩阵Y定义为：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-4cf5e3db52a1c7d3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/352/format/webp" alt="img"></p><p>但是，Yui为1仅代表二者有交互记录，并不代表用户u真的喜欢项目i，同理，u和i没有交互记录也不能代表u不喜欢i。这对隐性反馈的学习提出了挑战，因为它提供了关于用户偏好的噪声信号。虽然观察到的条目至少反映了用户对项目的兴趣，但是未查看的条目可能只是丢失数据，并且这其中存在自然稀疏的负反馈。</p><p>在隐性反馈上的推荐问题可以表达为估算矩阵 Y中未观察到的条目的分数问题（这个分数被用来评估项目的排名）。形式上它可以被抽象为学习函数：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-875ca45170bf6cf9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/105/format/webp" alt="img"></p><p>为了处理缺失数据，有两种常见的做法：要么将所有未观察到的条目视作负反馈，要么从没有观察到条目中抽样作为负反馈实例。</p><h2 id="1-2-矩阵分解及其缺陷"><a href="#1-2-矩阵分解及其缺陷" class="headerlink" title="1.2 矩阵分解及其缺陷"></a>1.2 矩阵分解及其缺陷</h2><p>传统的求解方法是矩阵分解(MF,Matrix Factorization)，为每个user和item找到一个隐向量，问题变为：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-4603109b9e326aa7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/361/format/webp" alt="img"></p><p>这里的 K表示隐式空间（latent space）的维度。正如我们所看到的，MF模型是用户和项目的潜在因素的双向互动，它假设潜在空间的每一维都是相互独立的并且用相同的权重将它们线性结合。因此，MF可视为隐向量（latent factor）的线性模型。</p><p>论文中给出了一个例子来说明这种算法的局限性：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-b381c43ffb45efad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/471/format/webp" alt="img"></p><p>1(a)是user-item交互矩阵，1(b)是用户的隐式空间，论文中强调了两点来理解这张图片：<br>1）MF将user和item分布到同样的隐式空间中，那么两个用户之间的相似性也可以用二者在隐式空间中的向量夹角来确定。<br>2）使用Jaccard系数来作为真实的用户相似性。<br>通过MF计算的相似性与Jaccard系数计算的相似性也可以用来评判MF的性能。我们先来看看Jaccard系数</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-c104fa23f3d69c0b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/780/format/webp" alt="img"></p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-7448a3708977e2ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/883/format/webp" alt="img"></p><p>上面的示例显示了MF因为使用一个简单的和固定的内积，来估计在低维潜在空间中用户-项目的复杂交互，从而所可能造成的限制。解决该问题的方法之一是使用大量的潜在因子 K (就是隐式空间向量的维度)。然而这可能对模型的泛化能力产生不利的影响（e.g. 数据的过拟合问题），特别是在稀疏的集合上。论文通过使用DNNs从数据中学习交互函数，突破了这个限制。</p><h2 id="1-3-NCF"><a href="#1-3-NCF" class="headerlink" title="1.3 NCF"></a>1.3 NCF</h2><p>本文先提出了一种通用框架：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-9c075241d934afaa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/651/format/webp" alt="img"></p><p>针对这个通用框架，论文提出了三种不同的实现，三种实现可以用一张图来说明：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-0cc3550bf20a608c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/699/format/webp" alt="img"></p><p><strong>GMF</strong>：<br>上图中仅使用GMF layer，就得到了第一种实现方式GMF，GMF被称为广义矩阵分解，输出层的计算公式为：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-f33f0e781fce1331.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/316/format/webp" alt="img"></p><p><strong>MLP</strong><br>上图中仅使用右侧的MLP Layers，就得到了第二种学习方式，通过多层神经网络来学习user和item的隐向量。这样，输出层的计算公式为：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-cd8744d945dab6c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/301/format/webp" alt="img"></p><p><strong>NeuMF</strong><br>结合GMF和MLP，得到的就是第三种实现方式，上图是该方式的完整实现，输出层的计算公式为：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-4f43b020b149514f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/477/format/webp" alt="img"></p><h2 id="1-4-模型实验"><a href="#1-4-模型实验" class="headerlink" title="1.4 模型实验"></a>1.4 模型实验</h2><p>论文通过三个角度进行了试验：</p><p><strong>RQ1</strong> 我们提出的NCF方法是否胜过 state-of-the-art 的隐性协同过滤方法？<br><strong>RQ2</strong> 我们提出的优化框架（消极样本抽样的logloss）怎样为推荐任务服务？<br><strong>RQ3</strong> 更深的隐藏单元是不是有助于对用户项目交互数据的学习？</p><p><strong>使用的数据集</strong>：MovieLens 和 Pinterest 两个数据集</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-c5c67c9c159e7820.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/696/format/webp" alt="img"></p><p><strong>评估方案</strong>：为了评价项目推荐的性能，论文采用了leave-one-out方法评估，即：对于每个用户，我们将其<strong>最近的一次交互作为测试集</strong>（数据集一般都有时间戳），并利用余下的培训作为训练集。由于在评估过程中为每个用户排列所有项目花费的时间太多，所以遵循一般的策略，随机抽取100个不与用户进行交互的项目，将测试项目排列在这100个项目中。排名列表的性能由<strong>命中率（HR）</strong>和<strong>归一化折扣累积增益（NDCG）</strong>来衡量。同时，论文将这两个指标的排名列表截断为10。如此一来，HR直观地衡量测试项目是否存在于前10名列表中，而NDCG通过将较高分数指定为顶级排名来计算命中的位置。本文计算每个测试用户的这两个指标，并求取了平均分。</p><p><strong>Baselines</strong>，论文将NCF方法与下列方法进行了比较：ItemPop，ItemKNN，BPR，eALS。</p><p>以下是三个结果的贴图，关于试验结果的解读，由于篇幅的原因，大家可以查看原论文。</p><p><strong>RQ1试验结果</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-f625ccafecdd8070.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/883/format/webp" alt="img"></p><p>简单的结论，即NCF效果好于BaseLine模型，如果不好的话论文也不用写了，哈哈。</p><p><strong>RQ2试验结果</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-619cfe110711228a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/858/format/webp" alt="img"></p><p>Figure 6 表示将模型看作一个二分类任务并使用logloss作为损失函数时的训练效果。<br>Figure7 表示采样率对模型性能的影响（横轴是采样率，即负样本与正样本的比例）。</p><p><strong>RQ3试验结果</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-fc499022ad1423cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/608/format/webp" alt="img"></p><p>上面的表格设置了两个变量，分别是Embedding的长度K和神经网络的层数，使用类似网格搜索的方式展示了在两个数据集上的结果。增加Embedding的长度和神经网络的层数是可以提升训练效果的。</p><h1 id="2、NCF实战"><a href="#2、NCF实战" class="headerlink" title="2、NCF实战"></a>2、NCF实战</h1><p>项目结构如下：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-abf4284380169268.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/187/format/webp" alt="img"></p><p><strong>数据输入</strong><br>本文使用了一种新的数据处理方式，不过我们的输入就是三个：userid，itemid以及label，对训练集来说，label是0-1值，对测试集来说，是具体的itemid</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(self)</span>:</span></span><br><span class="line">    sample = self.iterator.get_next()</span><br><span class="line">    self.user = sample[<span class="string">'user'</span>]</span><br><span class="line">    self.item = sample[<span class="string">'item'</span>]</span><br><span class="line">    self.label = tf.cast(sample[<span class="string">'label'</span>],tf.float32)</span><br></pre></td></tr></table></figure><p><strong>定义初始化方式、损失函数、优化器</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">""" Initialize important settings """</span></span><br><span class="line">    self.regularizer = tf.contrib.layers.l2_regularizer(self.regularizer_rate)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.initializer == <span class="string">'Normal'</span>:</span><br><span class="line">        self.initializer = tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>)</span><br><span class="line">    <span class="keyword">elif</span> self.initializer == <span class="string">'Xavier_Normal'</span>:</span><br><span class="line">        self.initializer = tf.contrib.layers.xavier_initializer()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.initializer = tf.glorot_uniform_initializer()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.activation_func == <span class="string">'ReLU'</span>:</span><br><span class="line">        self.activation_func = tf.nn.relu</span><br><span class="line">    <span class="keyword">elif</span> self.activation_func == <span class="string">'Leaky_ReLU'</span>:</span><br><span class="line">        self.activation_func = tf.nn.leaky_relu</span><br><span class="line">    <span class="keyword">elif</span> self.activation_func == <span class="string">'ELU'</span>:</span><br><span class="line">        self.activation_func = tf.nn.elu</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.loss_func == <span class="string">'cross_entropy'</span>:</span><br><span class="line">        <span class="comment"># self.loss_func = lambda labels, logits: -tf.reduce_sum(</span></span><br><span class="line">        <span class="comment">#       (labels * tf.log(logits) + (</span></span><br><span class="line">        <span class="comment">#       tf.ones_like(labels, dtype=tf.float32) - labels) *</span></span><br><span class="line">        <span class="comment">#       tf.log(tf.ones_like(logits, dtype=tf.float32) - logits)), 1)</span></span><br><span class="line">        self.loss_func = tf.nn.sigmoid_cross_entropy_with_logits</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.optim == <span class="string">'SGD'</span>:</span><br><span class="line">        self.optim = tf.train.GradientDescentOptimizer(self.lr,</span><br><span class="line">                                                       name=<span class="string">'SGD'</span>)</span><br><span class="line">    <span class="keyword">elif</span> self.optim == <span class="string">'RMSProp'</span>:</span><br><span class="line">        self.optim = tf.train.RMSPropOptimizer(self.lr, decay=<span class="number">0.9</span>,</span><br><span class="line">                                               momentum=<span class="number">0.0</span>, name=<span class="string">'RMSProp'</span>)</span><br><span class="line">    <span class="keyword">elif</span> self.optim == <span class="string">'Adam'</span>:</span><br><span class="line">        self.optim = tf.train.AdamOptimizer(self.lr, name=<span class="string">'Adam'</span>)</span><br></pre></td></tr></table></figure><p><strong>得到embedding值</strong><br>分别得到GMF和MLP的embedding向量，当然也可以使用embedding_lookup方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</span><br><span class="line">    self.user_onehot = tf.one_hot(self.user,self.user_size,name=<span class="string">'user_onehot'</span>)</span><br><span class="line">    self.item_onehot = tf.one_hot(self.item,self.item_size,name=<span class="string">'item_onehot'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'embed'</span>):</span><br><span class="line">    self.user_embed_GMF = tf.layers.dense(inputs = self.user_onehot,</span><br><span class="line">                                          units = self.embed_size,</span><br><span class="line">                                          activation = self.activation_func,</span><br><span class="line">                                          kernel_initializer=self.initializer,</span><br><span class="line">                                          kernel_regularizer=self.regularizer,</span><br><span class="line">                                          name=<span class="string">'user_embed_GMF'</span>)</span><br><span class="line"></span><br><span class="line">    self.item_embed_GMF = tf.layers.dense(inputs=self.item_onehot,</span><br><span class="line">                                          units=self.embed_size,</span><br><span class="line">                                          activation=self.activation_func,</span><br><span class="line">                                          kernel_initializer=self.initializer,</span><br><span class="line">                                          kernel_regularizer=self.regularizer,</span><br><span class="line">                                          name=<span class="string">'item_embed_GMF'</span>)</span><br><span class="line"></span><br><span class="line">    self.user_embed_MLP = tf.layers.dense(inputs=self.user_onehot,</span><br><span class="line">                                          units=self.embed_size,</span><br><span class="line">                                          activation=self.activation_func,</span><br><span class="line">                                          kernel_initializer=self.initializer,</span><br><span class="line">                                          kernel_regularizer=self.regularizer,</span><br><span class="line">                                          name=<span class="string">'user_embed_MLP'</span>)</span><br><span class="line">    self.item_embed_MLP = tf.layers.dense(inputs=self.item_onehot,</span><br><span class="line">                                          units=self.embed_size,</span><br><span class="line">                                          activation=self.activation_func,</span><br><span class="line">                                          kernel_initializer=self.initializer,</span><br><span class="line">                                          kernel_regularizer=self.regularizer,</span><br><span class="line">                                          name=<span class="string">'item_embed_MLP'</span>)</span><br></pre></td></tr></table></figure><p><strong>GMF</strong><br>GMF部分就是求两个embedding的内积：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"GMF"</span>):</span><br><span class="line">    self.GMF = tf.multiply(self.user_embed_GMF,self.item_embed_GMF,name=<span class="string">'GMF'</span>)</span><br></pre></td></tr></table></figure><p><strong>MLP</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"MLP"</span>):</span><br><span class="line">    self.interaction = tf.concat([self.user_embed_MLP, self.item_embed_MLP],</span><br><span class="line">                                 axis=<span class="number">-1</span>, name=<span class="string">'interaction'</span>)</span><br><span class="line"></span><br><span class="line">    self.layer1_MLP = tf.layers.dense(inputs=self.interaction,</span><br><span class="line">                                      units=self.embed_size * <span class="number">2</span>,</span><br><span class="line">                                      activation=self.activation_func,</span><br><span class="line">                                      kernel_initializer=self.initializer,</span><br><span class="line">                                      kernel_regularizer=self.regularizer,</span><br><span class="line">                                      name=<span class="string">'layer1_MLP'</span>)</span><br><span class="line">    self.layer1_MLP = tf.layers.dropout(self.layer1_MLP, rate=self.dropout)</span><br><span class="line"></span><br><span class="line">    self.layer2_MLP = tf.layers.dense(inputs=self.layer1_MLP,</span><br><span class="line">                                      units=self.embed_size,</span><br><span class="line">                                      activation=self.activation_func,</span><br><span class="line">                                      kernel_initializer=self.initializer,</span><br><span class="line">                                      kernel_regularizer=self.regularizer,</span><br><span class="line">                                      name=<span class="string">'layer2_MLP'</span>)</span><br><span class="line">    self.layer2_MLP = tf.layers.dropout(self.layer2_MLP, rate=self.dropout)</span><br><span class="line"></span><br><span class="line">    self.layer3_MLP = tf.layers.dense(inputs=self.layer2_MLP,</span><br><span class="line">                                      units=self.embed_size // <span class="number">2</span>,</span><br><span class="line">                                      activation=self.activation_func,</span><br><span class="line">                                      kernel_initializer=self.initializer,</span><br><span class="line">                                      kernel_regularizer=self.regularizer,</span><br><span class="line">                                      name=<span class="string">'layer3_MLP'</span>)</span><br><span class="line">    self.layer3_MLP = tf.layers.dropout(self.layer3_MLP, rate=self.dropout)</span><br></pre></td></tr></table></figure><p><strong>得到预测值</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'concatenation'</span>):</span><br><span class="line">    self.concatenation = tf.concat([self.GMF,self.layer3_MLP],axis=<span class="number">-1</span>,name=<span class="string">'concatenation'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    self.logits = tf.layers.dense(inputs= self.concatenation,</span><br><span class="line">                                  units = <span class="number">1</span>,</span><br><span class="line">                                  activation=<span class="keyword">None</span>,</span><br><span class="line">                                  kernel_initializer=self.initializer,</span><br><span class="line">                                  kernel_regularizer=self.regularizer,</span><br><span class="line">                                  name=<span class="string">'predict'</span>)</span><br><span class="line"></span><br><span class="line">    self.logits_dense = tf.reshape(self.logits,[<span class="number">-1</span>])</span><br></pre></td></tr></table></figure><p><strong>测试集构建</strong><br>这里只介绍几行关键的测试集构建代码，整个流程希望大家可以看一下完整的代码。<br>需要明确的一点是，对于测试集，我们的评价不只是对错，还要关注排名，所以测试集的label不是0-1，而是具体的itemid<br>首先，对每个user取最后一行作为测试集的正样本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">split_train_test = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(user_set)):</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(user_length[i] - <span class="number">1</span>):</span><br><span class="line">        split_train_test.append(<span class="string">'train'</span>)</span><br><span class="line">    split_train_test.append(<span class="string">'test'</span>)</span><br><span class="line"></span><br><span class="line">full_data[<span class="string">'split'</span>] = split_train_test</span><br><span class="line"></span><br><span class="line">train_data = full_data[full_data[<span class="string">'split'</span>] == <span class="string">'train'</span>].reset_index(drop=<span class="keyword">True</span>)</span><br><span class="line">test_data = full_data[full_data[<span class="string">'split'</span>] == <span class="string">'test'</span>].reset_index(drop=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>添加一些负采样的样本， 这里顺序是，1正样本-n负样本-1正样本-n负样本….，每个用户有n+1条数据，便于计算HR和NDCG：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">feature_user.append(user)</span><br><span class="line">feature_item.append(item)</span><br><span class="line">labels_add.append(label)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> neg_samples:</span><br><span class="line">    feature_user.append(user)</span><br><span class="line">    feature_item.append(k)</span><br><span class="line">    labels_add.append(k)</span><br></pre></td></tr></table></figure><p>不打乱测试集的顺序，设置batch的大小为1+n:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.Dataset.from_tensor_slices(data)</span><br><span class="line">dataset = dataset.batch(test_neg + <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><strong>计算HR和NDCG</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hr</span><span class="params">(gt_item, pred_items)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> gt_item <span class="keyword">in</span> pred_items:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ndcg</span><span class="params">(gt_item, pred_items)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> gt_item <span class="keyword">in</span> pred_items:</span><br><span class="line">        index = np.where(pred_items == gt_item)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> np.reciprocal(np.log2(index + <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0B/0F/ChMlWlyAyIiIQH8pABv6qMmlUWEAAIp0AAv7LcAG_rA821.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="推荐系统" scheme="https://leesen998.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统实践" scheme="https://leesen998.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统--DeepFM模型理论和实践</title>
    <link href="https://leesen998.github.io/2018/10/08/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F--DeepFM%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5/"/>
    <id>https://leesen998.github.io/2018/10/08/推荐系统--DeepFM模型理论和实践/</id>
    <published>2018-10-08T11:48:29.000Z</published>
    <updated>2019-03-22T08:28:37.901Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0B/0F/ChMlWlyAyIiIQH8pABv6qMmlUWEAAIp0AAv7LcAG_rA821.jpg" alt="" style="width:100%"></p><a id="more"></a><h1 id="推荐系统–DeepFM模型理论和实践"><a href="#推荐系统–DeepFM模型理论和实践" class="headerlink" title="推荐系统–DeepFM模型理论和实践"></a>推荐系统–DeepFM模型理论和实践</h1><h1 id="1、背景"><a href="#1、背景" class="headerlink" title="1、背景"></a>1、背景</h1><p><strong>特征组合的挑战</strong><br>对于一个基于CTR预估的推荐系统，最重要的是学习到用户点击行为背后隐含的特征组合。在不同的推荐场景中，低阶组合特征或者高阶组合特征可能都会对最终的CTR产生影响。</p><p>之前介绍的因子分解机(Factorization Machines, FM)通过对于每一维特征的隐变量内积来提取特征组合。最终的结果也非常好。但是，虽然理论上来讲FM可以对高阶特征组合进行建模，但实际上因为计算复杂度的原因一般都只用到了二阶特征组合。</p><p>那么对于高阶的特征组合来说，我们很自然的想法，通过多层的神经网络即DNN去解决。</p><p><strong>DNN的局限</strong><br>下面的图片来自于张俊林教授在AI大会上所使用的PPT。</p><p>我们之前也介绍过了，对于离散特征的处理，我们使用的是将特征转换成为one-hot的形式，但是将One-hot类型的特征输入到DNN中，会导致网络参数太多：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-f4363ca2be689dbb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>如何解决这个问题呢，类似于FFM中的思想，将特征分为不同的field：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-5f476d2c5b616232.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>再加两层的全链接层，让Dense Vector进行组合，那么高阶特征的组合就出来了</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-12f3119df69b7b5b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>但是低阶和高阶特征组合隐含地体现在隐藏层中，如果我们希望把低阶特征组合单独建模，然后融合高阶特征组合。</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-7e036f56982d323b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>即将DNN与FM进行一个合理的融合：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-2b8d2e22017ad339.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>二者的融合总的来说有两种形式，一是串行结构，二是并行结构</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-cd51e0bd97ab285d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-1118724d47e2c65e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>而我们今天要讲到的DeepFM，就是并行结构中的一种典型代表。</p><h1 id="2、DeepFM模型"><a href="#2、DeepFM模型" class="headerlink" title="2、DeepFM模型"></a>2、DeepFM模型</h1><p>我们先来看一下DeepFM的模型结构：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-21fa429e42108e99.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/535/format/webp" alt="img"></p><p>DeepFM包含两部分：神经网络部分与因子分解机部分，分别负责低阶特征的提取和高阶特征的提取。这两部分<strong>共享同样的输入</strong>。DeepFM的预测结果可以写为：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-7984bc2c7474d6ea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/646/format/webp" alt="img"></p><p><strong>FM部分</strong></p><p>FM部分的详细结构如下：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-d144aba541c68a34.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/582/format/webp" alt="img"></p><p>FM部分是一个因子分解机。关于因子分解机可以参阅文章[Rendle, 2010] Steffen Rendle. Factorization machines. In ICDM, 2010.。因为引入了隐变量的原因，对于几乎不出现或者很少出现的隐变量，FM也可以很好的学习。</p><p>FM的输出公式为：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-f9af97ad7e0f5b88.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/558/format/webp" alt="img"></p><p><strong>深度部分</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-366d825a661466a3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/538/format/webp" alt="img"></p><p>深度部分是一个前馈神经网络。与图像或者语音这类输入不同，图像语音的输入一般是连续而且密集的，然而用于CTR的输入一般是及其稀疏的。因此需要重新设计网络结构。具体实现中为，在第一层隐含层之前，引入一个嵌入层来完成将输入向量压缩到低维稠密向量。</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-cc075cd266bf2d5f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/467/format/webp" alt="img"></p><p>嵌入层(embedding layer)的结构如上图所示。当前网络结构有两个有趣的特性，1）尽管不同field的输入长度不同，但是embedding之后向量的长度均为K。2)在FM里得到的隐变量Vik现在作为了嵌入层网络的权重。</p><p>这里的第二点如何理解呢，假设我们的k=5，首先，对于输入的一条记录，同一个field 只有一个位置是1，那么在由输入得到dense vector的过程中，输入层只有一个神经元起作用，得到的dense vector其实就是输入层到embedding层该神经元相连的五条线的权重，即vi1，vi2，vi3，vi4，vi5。这五个值组合起来就是我们在FM中所提到的Vi。在FM部分和DNN部分，这一块是共享权重的，对同一个特征来说，得到的Vi是相同的。</p><p>有关模型具体如何操作，我们可以通过代码来进一步加深认识。</p><h1 id="3、相关知识"><a href="#3、相关知识" class="headerlink" title="3、相关知识"></a>3、相关知识</h1><p>我们先来讲两个代码中会用到的相关知识吧，代码是参考的github上星数最多的DeepFM实现代码。</p><p><strong>Gini Normalization</strong><br>代码中将CTR预估问题设定为一个二分类问题，绘制了Gini Normalization来评价不同模型的效果。这个是什么东西，不太懂，百度了很多，发现了一个比较通俗易懂的介绍。</p><p>假设我们有下面两组结果，分别表示预测值和实际值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predictions = [0.9, 0.3, 0.8, 0.75, 0.65, 0.6, 0.78, 0.7, 0.05, 0.4, 0.4, 0.05, 0.5, 0.1, 0.1]</span><br><span class="line">actual = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</span><br></pre></td></tr></table></figure><p>然后我们将预测值按照从小到大排列，并根据索引序对实际值进行排序：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sorted Actual Values [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1]</span><br></pre></td></tr></table></figure><p>然后，我们可以画出如下的图片：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-295f18796ee0030e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/903/format/webp" alt="img"></p><p>接下来我们将数据Normalization到0，1之间。并画出45度线。</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-b8943ac16560285b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/908/format/webp" alt="img"></p><p>橙色区域的面积，就是我们得到的Normalization的Gini系数。</p><p>这里，由于我们是将预测概率从小到大排的，所以我们希望实际值中的0尽可能出现在前面，因此Normalization的Gini系数越大，分类效果越好。</p><p><strong>embedding_lookup</strong><br>在tensorflow中有个embedding_lookup函数，我们可以直接根据一个序号来得到一个词或者一个特征的embedding值，那么他内部其实是包含一个网络结构的，如下图所示：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-53a1ed7584a8bb71.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/978/format/webp" alt="img"></p><p>假设我们想要找到2的embedding值，这个值其实是输入层第二个神经元与embedding层连线的权重值。</p><p>之前有大佬跟我探讨word2vec输入的问题，现在也算是有个比较明确的答案，输入其实就是one-hot Embedding，而word2vec要学习的是new Embedding。</p><h1 id="4、代码解析"><a href="#4、代码解析" class="headerlink" title="4、代码解析"></a>4、代码解析</h1><p>好，一贯的风格，先来介绍几个地址：<br>原代码地址：<a href="https://github.com/ChenglongChen/tensorflow-DeepFM" target="_blank" rel="noopener">https://github.com/ChenglongChen/tensorflow-DeepFM</a></p><p><strong>项目结构</strong><br>项目结构如下：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-55ff1b9e36979f20.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/326/format/webp" alt="img"></p><p>其实还应该有一个存放data的路径。config.py保存了我们模型的一些配置。DataReader对数据进行处理，得到模型可以使用的输入。DeepFM是我们构建的模型。main是项目的入口。metrics是计算normalized gini系数的代码。</p><p><strong>模型输入</strong></p><p>模型的输入主要有下面几个部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">self.feat_index = tf.placeholder(tf.int32,</span><br><span class="line">                                 shape=[<span class="keyword">None</span>,<span class="keyword">None</span>],</span><br><span class="line">                                 name=<span class="string">'feat_index'</span>)</span><br><span class="line">self.feat_value = tf.placeholder(tf.float32,</span><br><span class="line">                               shape=[<span class="keyword">None</span>,<span class="keyword">None</span>],</span><br><span class="line">                               name=<span class="string">'feat_value'</span>)</span><br><span class="line"></span><br><span class="line">self.label = tf.placeholder(tf.float32,shape=[<span class="keyword">None</span>,<span class="number">1</span>],name=<span class="string">'label'</span>)</span><br><span class="line">self.dropout_keep_fm = tf.placeholder(tf.float32,shape=[<span class="keyword">None</span>],name=<span class="string">'dropout_keep_fm'</span>)</span><br><span class="line">self.dropout_keep_deep = tf.placeholder(tf.float32,shape=[<span class="keyword">None</span>],name=<span class="string">'dropout_deep_deep'</span>)</span><br></pre></td></tr></table></figure><p><strong>feat_index</strong>是特征的一个序号，主要用于通过embedding_lookup选择我们的embedding。<strong>feat_value</strong>是对应的特征值，如果是离散特征的话，就是1，如果不是离散特征的话，就保留原来的特征值。<strong>label</strong>是实际值。还定义了两个dropout来防止过拟合。</p><p><strong>权重构建</strong><br>权重的设定主要有两部分，第一部分是从输入到embedding中的权重，其实也就是我们的dense vector。另一部分就是深度神经网络每一层的权重。第二部分很好理解，我们主要来看看第一部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#embeddings</span></span><br><span class="line">weights[<span class="string">'feature_embeddings'</span>] = tf.Variable(</span><br><span class="line">    tf.random_normal([self.feature_size,self.embedding_size],<span class="number">0.0</span>,<span class="number">0.01</span>),</span><br><span class="line">    name=<span class="string">'feature_embeddings'</span>)</span><br><span class="line">weights[<span class="string">'feature_bias'</span>] = tf.Variable(tf.random_normal([self.feature_size,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">1.0</span>),name=<span class="string">'feature_bias'</span>)</span><br></pre></td></tr></table></figure><p>weights[‘feature_embeddings’] 存放的每一个值其实就是FM中的vik，所以它是F * K的。其中，F代表feture的大小(将离散特征转换成one-hot之后的特征总量),K代表dense vector的大小。</p><p>weights[‘feature_bias’]是FM中的一次项的权重。</p><p><strong>Embedding part</strong><br>这个部分很简单啦，是根据feat_index选择对应的weights[‘feature_embeddings’]中的embedding值，然后再与对应的feat_value相乘就可以了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model</span></span><br><span class="line">self.embeddings = tf.nn.embedding_lookup(self.weights[<span class="string">'feature_embeddings'</span>],self.feat_index) <span class="comment"># N * F * K</span></span><br><span class="line">feat_value = tf.reshape(self.feat_value,shape=[<span class="number">-1</span>,self.field_size,<span class="number">1</span>])</span><br><span class="line">self.embeddings = tf.multiply(self.embeddings,feat_value)</span><br></pre></td></tr></table></figure><p><strong>FM part</strong><br>首先来回顾一下我们之前对FM的化简公式，之前去今日头条面试还问到过公式的推导。</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-a9ead5ad8ff9d2d3?imageMogr2/auto-orient/strip%7CimageView2/2/w/413/format/webp" alt="img"></p><p>所以我们的二次项可以根据化简公式轻松的得到，再加上我们的一次项，FM的part就算完了。同时更为方便的是，由于权重共享，我们这里可以直接用<strong>Embedding part</strong>计算出的embeddings来得到我们的二次项：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># first order term</span></span><br><span class="line">self.y_first_order = tf.nn.embedding_lookup(self.weights[<span class="string">'feature_bias'</span>],self.feat_index)</span><br><span class="line">self.y_first_order = tf.reduce_sum(tf.multiply(self.y_first_order,feat_value),<span class="number">2</span>)</span><br><span class="line">self.y_first_order = tf.nn.dropout(self.y_first_order,self.dropout_keep_fm[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># second order term</span></span><br><span class="line"><span class="comment"># sum-square-part</span></span><br><span class="line">self.summed_features_emb = tf.reduce_sum(self.embeddings,<span class="number">1</span>) <span class="comment"># None * k</span></span><br><span class="line">self.summed_features_emb_square = tf.square(self.summed_features_emb) <span class="comment"># None * K</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># squre-sum-part</span></span><br><span class="line">self.squared_features_emb = tf.square(self.embeddings)</span><br><span class="line">self.squared_sum_features_emb = tf.reduce_sum(self.squared_features_emb, <span class="number">1</span>)  <span class="comment"># None * K</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#second order</span></span><br><span class="line">self.y_second_order = <span class="number">0.5</span> * tf.subtract(self.summed_features_emb_square,self.squared_sum_features_emb)</span><br><span class="line">self.y_second_order = tf.nn.dropout(self.y_second_order,self.dropout_keep_fm[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p><strong>DNN part</strong><br>DNNpart的话，就是将<strong>Embedding part</strong>的输出再经过几层全链接层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Deep component</span></span><br><span class="line">self.y_deep = tf.reshape(self.embeddings,shape=[<span class="number">-1</span>,self.field_size * self.embedding_size])</span><br><span class="line">self.y_deep = tf.nn.dropout(self.y_deep,self.dropout_keep_deep[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(self.deep_layers)):</span><br><span class="line">    self.y_deep = tf.add(tf.matmul(self.y_deep,self.weights[<span class="string">"layer_%d"</span> %i]), self.weights[<span class="string">"bias_%d"</span>%I])</span><br><span class="line">    self.y_deep = self.deep_layers_activation(self.y_deep)</span><br><span class="line">    self.y_deep = tf.nn.dropout(self.y_deep,self.dropout_keep_deep[i+<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p>最后，我们要将DNN和FM两部分的输出进行结合：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">concat_input = tf.concat([self.y_first_order, self.y_second_order, self.y_deep], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><strong>损失及优化器</strong><br>我们可以使用logloss(如果定义为分类问题)，或者mse(如果定义为预测问题)，以及多种的优化器去进行尝试，这些根据不同的参数设定得到：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># loss</span></span><br><span class="line"><span class="keyword">if</span> self.loss_type == <span class="string">"logloss"</span>:</span><br><span class="line">    self.out = tf.nn.sigmoid(self.out)</span><br><span class="line">    self.loss = tf.losses.log_loss(self.label, self.out)</span><br><span class="line"><span class="keyword">elif</span> self.loss_type == <span class="string">"mse"</span>:</span><br><span class="line">    self.loss = tf.nn.l2_loss(tf.subtract(self.label, self.out))</span><br><span class="line"><span class="comment"># l2 regularization on weights</span></span><br><span class="line"><span class="keyword">if</span> self.l2_reg &gt; <span class="number">0</span>:</span><br><span class="line">    self.loss += tf.contrib.layers.l2_regularizer(</span><br><span class="line">        self.l2_reg)(self.weights[<span class="string">"concat_projection"</span>])</span><br><span class="line">    <span class="keyword">if</span> self.use_deep:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.deep_layers)):</span><br><span class="line">            self.loss += tf.contrib.layers.l2_regularizer(</span><br><span class="line">                self.l2_reg)(self.weights[<span class="string">"layer_%d"</span> % I])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> self.optimizer_type == <span class="string">"adam"</span>:</span><br><span class="line">    self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=<span class="number">0.9</span>, beta2=<span class="number">0.999</span>,</span><br><span class="line">                                            epsilon=<span class="number">1e-8</span>).minimize(self.loss)</span><br><span class="line"><span class="keyword">elif</span> self.optimizer_type == <span class="string">"adagrad"</span>:</span><br><span class="line">    self.optimizer = tf.train.AdagradOptimizer(learning_rate=self.learning_rate,</span><br><span class="line">                                               initial_accumulator_value=<span class="number">1e-8</span>).minimize(self.loss)</span><br><span class="line"><span class="keyword">elif</span> self.optimizer_type == <span class="string">"gd"</span>:</span><br><span class="line">    self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate).minimize(self.loss)</span><br><span class="line"><span class="keyword">elif</span> self.optimizer_type == <span class="string">"momentum"</span>:</span><br><span class="line">    self.optimizer = tf.train.MomentumOptimizer(learning_rate=self.learning_rate, momentum=<span class="number">0.95</span>).minimize(</span><br><span class="line">        self.loss)</span><br></pre></td></tr></table></figure><p><strong>模型效果</strong><br>前面提到了，我们用logloss作为损失函数去进行模型的参数更新，但是代码中输出了模型的 Normalization 的 Gini值来进行模型评价，我们可以对比一下(记住，Gini值越大越好呦)：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-908ee89d46240580.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0B/0F/ChMlWlyAyIiIQH8pABv6qMmlUWEAAIp0AAv7LcAG_rA821.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="推荐系统" scheme="https://leesen998.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统实践" scheme="https://leesen998.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统--FFM模型理论和实践</title>
    <link href="https://leesen998.github.io/2018/09/15/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F--FFM%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5/"/>
    <id>https://leesen998.github.io/2018/09/15/推荐系统--FFM模型理论和实践/</id>
    <published>2018-09-15T11:48:29.000Z</published>
    <updated>2019-03-22T08:27:29.442Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1541167132/samples/java%20files/photo-1539452851739-c57dee0c0859.jpg" alt="" style="width:100%"></p><a id="more"></a><h1 id="推荐系统–FFM模型理论和实践"><a href="#推荐系统–FFM模型理论和实践" class="headerlink" title="推荐系统–FFM模型理论和实践"></a>推荐系统–FFM模型理论和实践</h1><h1 id="1、FFM理论"><a href="#1、FFM理论" class="headerlink" title="1、FFM理论"></a>1、FFM理论</h1><p>在CTR预估中，经常会遇到one-hot类型的变量，one-hot类型变量会导致严重的数据特征稀疏的情况，为了解决这一问题，在上一讲中，我们介绍了FM算法。这一讲我们介绍一种在FM基础上发展出来的算法-FFM（Field-aware Factorization Machine）。</p><p>FFM模型中引入了类别的概念，即field。还是拿上一讲中的数据来讲，先看下图：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-3723a0992d59f0e9?imageMogr2/auto-orient/strip%7CimageView2/2/w/275/format/webp" alt="img"></p><p>在上面的广告点击案例中，“Day=26/11/15”、“Day=1/7/14”、“Day=19/2/15”这三个特征都是代表日期的，可以放到同一个field中。同理，Country也可以放到一个field中。简单来说，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个field，包括用户国籍，广告类型，日期等等。</p><p>在FFM中，每一维特征 xi，针对其它特征的每一种field fj，都会学习一个隐向量 v_i,fj。因此，隐向量不仅与特征相关，也与field相关。也就是说，“Day=26/11/15”这个特征与“Country”特征和“Ad_type”特征进行关联的时候使用不同的隐向量，这与“Country”和“Ad_type”的内在差异相符，也是FFM中“field-aware”的由来。</p><p>假设样本的 n个特征属于 f个field，那么FFM的二次项有 nf个隐向量。而在FM模型中，每一维特征的隐向量只有一个。FM可以看作FFM的特例，是把所有特征都归属到一个field时的FFM模型。根据FFM的field敏感特性，可以导出其模型方程。</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-d04fed8047209d53.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/764/format/webp" alt="img"></p><p>可以看到，如果隐向量的长度为 k，那么FFM的二次参数有 nfk 个，远多于FM模型的 nk个。此外，由于隐向量与field相关，FFM二次项并不能够化简，其预测复杂度是 O(kn^2)。</p><p>下面以一个例子简单说明FFM的特征组合方式。输入记录如下：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-659e8f0e43d6310d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/570/format/webp" alt="img"></p><p>这条记录可以编码成5个特征，其中“Genre=Comedy”和“Genre=Drama”属于同一个field，“Price”是数值型，不用One-Hot编码转换。为了方便说明FFM的样本格式，我们将所有的特征和对应的field映射成整数编号。</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-d0f6963eb0505c31.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/784/format/webp" alt="img"></p><p>那么，FFM的组合特征有10项，如下图所示。</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-e3da4d35478d62b3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>其中，红色是field编号，蓝色是特征编号。</p><h1 id="2、FFM实现细节"><a href="#2、FFM实现细节" class="headerlink" title="2、FFM实现细节"></a>2、FFM实现细节</h1><p>这里讲得只是一种FFM的实现方式，并不是唯一的。</p><p><strong>损失函数</strong><br>FFM将问题定义为分类问题，使用的是logistic loss，同时加入了正则项</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-c2df975e6e6a7847.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/716/format/webp" alt="img"></p><p>什么，这是logisitc loss？第一眼看到我是懵逼的，逻辑回归的损失函数我很熟悉啊，不是长这样的啊？其实是我目光太短浅了。逻辑回归其实是有两种表述方式的损失函数的，取决于你将类别定义为0和1还是1和-1。大家可以参考下下面的文章：<a href="https://link.jianshu.com/?t=https%3A%2F%2Fwww.cnblogs.com%2Fljygoodgoodstudydaydayup%2Fp%2F6340129.html" target="_blank" rel="noopener">https://www.cnblogs.com/ljygoodgoodstudydaydayup/p/6340129.html</a>。当我们将类别设定为1和-1的时候，逻辑回归的损失函数就是上面的样子。</p><p><strong>随机梯度下降</strong></p><p>训练FFM使用的是随机梯度下降方法，即每次只选一条数据进行训练，这里还有必要补一补梯度下降的知识，梯度下降是有三种方式的，截图取自参考文献3：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-142f546cdaef9e42.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><h1 id="3、tensorflow实现代码"><a href="#3、tensorflow实现代码" class="headerlink" title="3、tensorflow实现代码"></a>3、tensorflow实现代码</h1><p><strong>生成数据</strong><br>这里我没有找到合适的数据，就自己产生了一点数据，数据涉及20维特征，前十维特征是一个field，后十维是一个field:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_data</span><span class="params">()</span>:</span></span><br><span class="line">    labels = [<span class="number">-1</span>,<span class="number">1</span>]</span><br><span class="line">    y = [np.random.choice(labels,<span class="number">1</span>)[<span class="number">0</span>] <span class="keyword">for</span> _ <span class="keyword">in</span> range(all_data_size)]</span><br><span class="line">    x_field = [i // <span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(input_x_size)]</span><br><span class="line">    x = np.random.randint(<span class="number">0</span>,<span class="number">2</span>,size=(all_data_size,input_x_size))</span><br><span class="line">    <span class="keyword">return</span> x,y,x_field</span><br></pre></td></tr></table></figure><p><strong>定义权重项</strong><br>在ffm中，有三个权重项，首先是bias，然后是一维特征的权重，最后是交叉特征的权重：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTwoDimensionWeight</span><span class="params">(input_x_size,field_size,vector_dimension)</span>:</span></span><br><span class="line">    weights = tf.truncated_normal([input_x_size,field_size,vector_dimension])</span><br><span class="line"></span><br><span class="line">    tf_weights = tf.Variable(weights)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf_weights</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createOneDimensionWeight</span><span class="params">(input_x_size)</span>:</span></span><br><span class="line">    weights = tf.truncated_normal([input_x_size])</span><br><span class="line">    tf_weights = tf.Variable(weights)</span><br><span class="line">    <span class="keyword">return</span> tf_weights</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createZeroDimensionWeight</span><span class="params">()</span>:</span></span><br><span class="line">    weights = tf.truncated_normal([<span class="number">1</span>])</span><br><span class="line">    tf_weights = tf.Variable(weights)</span><br><span class="line">    <span class="keyword">return</span> tf_weights</span><br></pre></td></tr></table></figure><p><strong>计算估计值</strong><br>估计值的计算这里不能项FM一样先将公式化简再来做，对于交叉特征，只能写两重循环，所以对于特别多的特征的情况下，真的计算要爆炸呀！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span><span class="params">(input_x,input_x_field,zeroWeights,oneDimWeights,thirdWeight)</span>:</span></span><br><span class="line">    <span class="string">"""计算回归模型输出的值"""</span></span><br><span class="line"></span><br><span class="line">    secondValue = tf.reduce_sum(tf.multiply(oneDimWeights,input_x,name=<span class="string">'secondValue'</span>))</span><br><span class="line"></span><br><span class="line">    firstTwoValue = tf.add(zeroWeights, secondValue, name=<span class="string">"firstTwoValue"</span>)</span><br><span class="line"></span><br><span class="line">    thirdValue = tf.Variable(<span class="number">0.0</span>,dtype=tf.float32)</span><br><span class="line">    input_shape = input_x_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(input_shape):</span><br><span class="line">        featureIndex1 = I</span><br><span class="line">        fieldIndex1 = int(input_x_field[I])</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>,input_shape):</span><br><span class="line">            featureIndex2 = j</span><br><span class="line">            fieldIndex2 = int(input_x_field[j])</span><br><span class="line">            vectorLeft = tf.convert_to_tensor([[featureIndex1,fieldIndex2,i] <span class="keyword">for</span> i <span class="keyword">in</span> range(vector_dimension)])</span><br><span class="line">            weightLeft = tf.gather_nd(thirdWeight,vectorLeft)</span><br><span class="line">            weightLeftAfterCut = tf.squeeze(weightLeft)</span><br><span class="line"></span><br><span class="line">            vectorRight = tf.convert_to_tensor([[featureIndex2,fieldIndex1,i] <span class="keyword">for</span> i <span class="keyword">in</span> range(vector_dimension)])</span><br><span class="line">            weightRight = tf.gather_nd(thirdWeight,vectorRight)</span><br><span class="line">            weightRightAfterCut = tf.squeeze(weightRight)</span><br><span class="line"></span><br><span class="line">            tempValue = tf.reduce_sum(tf.multiply(weightLeftAfterCut,weightRightAfterCut))</span><br><span class="line"></span><br><span class="line">            indices2 = [I]</span><br><span class="line">            indices3 = [j]</span><br><span class="line"></span><br><span class="line">            xi = tf.squeeze(tf.gather_nd(input_x, indices2))</span><br><span class="line">            xj = tf.squeeze(tf.gather_nd(input_x, indices3))</span><br><span class="line"></span><br><span class="line">            product = tf.reduce_sum(tf.multiply(xi, xj))</span><br><span class="line"></span><br><span class="line">            secondItemVal = tf.multiply(tempValue, product)</span><br><span class="line"></span><br><span class="line">            tf.assign(thirdValue, tf.add(thirdValue, secondItemVal))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.add(firstTwoValue,thirdValue)</span><br></pre></td></tr></table></figure><p><strong>定义损失函数</strong><br>损失函数我们就用逻辑回归损失函数来算，同时加入正则项：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">lambda_w = tf.constant(<span class="number">0.001</span>, name=<span class="string">'lambda_w'</span>)</span><br><span class="line">lambda_v = tf.constant(<span class="number">0.001</span>, name=<span class="string">'lambda_v'</span>)</span><br><span class="line"></span><br><span class="line">zeroWeights = createZeroDimensionWeight()</span><br><span class="line"></span><br><span class="line">oneDimWeights = createOneDimensionWeight(input_x_size)</span><br><span class="line"></span><br><span class="line">thirdWeight = createTwoDimensionWeight(input_x_size,  <span class="comment"># 创建二次项的权重变量</span></span><br><span class="line">                                       field_size,</span><br><span class="line">                                       vector_dimension)  <span class="comment"># n * f * k</span></span><br><span class="line"></span><br><span class="line">y_ = inference(input_x, trainx_field,zeroWeights,oneDimWeights,thirdWeight)</span><br><span class="line"></span><br><span class="line">l2_norm = tf.reduce_sum(</span><br><span class="line">    tf.add(</span><br><span class="line">        tf.multiply(lambda_w, tf.pow(oneDimWeights, <span class="number">2</span>)),</span><br><span class="line">        tf.reduce_sum(tf.multiply(lambda_v, tf.pow(thirdWeight, <span class="number">2</span>)),axis=[<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">loss = tf.log(<span class="number">1</span> + tf.exp(input_y * y_)) + l2_norm</span><br><span class="line"></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(loss)</span><br></pre></td></tr></table></figure><p><strong>训练</strong><br>接下来就是训练了，每次只用喂一个数据就好：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">input_x_batch = trainx[t]</span><br><span class="line">input_y_batch = trainy[t]</span><br><span class="line">predict_loss,_, steps = sess.run([loss,train_step, global_step],</span><br><span class="line">                         feed_dict=&#123;input_x: input_x_batch, input_y: input_y_batch&#125;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1541167132/samples/java%20files/photo-1539452851739-c57dee0c0859.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="推荐系统" scheme="https://leesen998.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统实践" scheme="https://leesen998.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>强化学习-MADDPG算法原理及简单实现</title>
    <link href="https://leesen998.github.io/2018/06/19/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-MADDPG%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8A%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/"/>
    <id>https://leesen998.github.io/2018/06/19/强化学习-MADDPG算法原理及简单实现/</id>
    <published>2018-06-19T11:48:29.000Z</published>
    <updated>2019-03-22T04:03:06.742Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0B/0F/ChMlWlyAyIiIQH8pABv6qMmlUWEAAIp0AAv7LcAG_rA821.jpg" alt="" style="width:100%"></p><a id="more"></a><h1 id="强化学习-MADDPG算法原理及简单实现"><a href="#强化学习-MADDPG算法原理及简单实现" class="headerlink" title="强化学习-MADDPG算法原理及简单实现"></a>强化学习-MADDPG算法原理及简单实现</h1><p>之前接触的强化学习算法都是单个智能体的强化学习算法，但是也有很多重要的应用场景牵涉到多个智能体之间的交互，比如说，多个机器人的控制，语言的交流，多玩家的游戏等等。本文，就带你简单了解一下Open-AI的<strong>MADDPG(Multi-Agent Deep Deterministic Policy Gradient)</strong>算法，来共同体验一下多智能体强化学习的魅力。</p><p>论文全称：Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments<br>下载地址：<a href="https://arxiv.org/pdf/1706.02275.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1706.02275.pdf</a></p><h1 id="1、引言"><a href="#1、引言" class="headerlink" title="1、引言"></a>1、引言</h1><p>强化学习中很多场景涉及多个智能体的交互，比如多个机器人的控制，语言的交流，多玩家的游戏等等。不过传统的RL方法，比如Q-Learning或者policy gradient都不适用于多智能体环境。主要的问题是，在训练过程中，每个智能体的策略都在变化，因此从每个智能体的角度来看，环境变得十分不稳定(其他智能体的行动带来环境变化)。对DQN来说，经验重放的方法变的不再适用(如果不知道其他智能体的状态，那么不同情况下自身的状态转移会不同），而对PG的方法来说，环境的不断变化导致了学习的方差进一步增大。</p><p>因此，本文提出了<strong>MADDPG(Multi-Agent Deep Deterministic Policy Gradient)</strong>方法。为什么要使用DDPG方法作为基准模型呢？主要是<strong>集中训练和分散执行的策略</strong>。</p><p>本文提出的方法框架是集中训练，分散执行的。我们先回顾一下DDPG的方式，DDPG本质上是一个AC方法。训练时，Actor根据当前的state选择一个action，然后Critic可以根据state-action计算一个Q值，作为对Actor动作的反馈。Critic根据估计的Q值和实际的Q值来进行训练，Actor根据Critic的反馈来更新策略。测试时，我们只需要Actor就可以完成，此时不需要Critic的反馈。因此，在训练时，我们可以在Critic阶段加上一些额外的信息来得到更准确的Q值，比如其他智能体的状态和动作等，这也就是集中训练的意思，即每个智能体不仅仅根据自身的情况，还根据其他智能体的行为来评估当前动作的价值。分散执行指的是，当每个Agent都训练充分之后，每个Actor就可以自己根据状态采取合适的动作，此时是不需要其他智能体的状态或者动作的。DQN不适合这么做，因为DQN训练和预测是同一个网络，二者的输入信息必须保持一致，我们不能只在训练阶段加入其他智能体的信息。</p><h1 id="2、DDPG算法的简单回顾"><a href="#2、DDPG算法的简单回顾" class="headerlink" title="2、DDPG算法的简单回顾"></a>2、DDPG算法的简单回顾</h1><p><strong>什么是DDPG</strong><br>什么是DDPG呢？一句话描述，它是Actor-Critic 和 DQN 算法的结合体。</p><p>DDPG的全称是Deep Deterministic Policy Gradient。</p><p>我们首先来看Deep，正如Q-learning加上一个Deep就变成了DQN一样，这里的Deep即同样使用DQN中的经验池和双网络结构来促进神经网络能够有效学习。</p><p>再来看Deterministic，即我们的Actor不再输出每个动作的概率，而是一个具体的动作，这更有助于我们连续动作空间中进行学习。</p><p><strong>DDPG的网络结构</strong><br>盗用莫烦老师的一张图片来形象的表示DDPG的网络结构，同图片里一样，我们称Actor里面的两个网络分别是动作估计网络和动作现实网络，我们称Critic中的两个网络分别是状态现实网络和状态估计网络：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-d1bfab0264feea59?imageMogr2/auto-orient/strip%7CimageView2/2/w/638/format/webp" alt="img"></p><p>image</p><p>我们采用了类似DQN的双网络结构，而且Actor和Critic都有target-net和eval-net。我们需要强调一点的事，我们只需要训练动作估计网络和状态估计网络的参数，而动作现实网络和状态现实网络的参数是由前面两个网络每隔一定的时间复制过去的。</p><p>我们先来说说Critic这边，Critic这边的学习过程跟DQN类似，我们都知道DQN根据下面的损失函数来进行网络学习，即现实的Q值和估计的Q值的平方损失：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-271e1b4fa039af90?imageMogr2/auto-orient/strip%7CimageView2/2/w/506/format/webp" alt="img"></p><p>上面式子中Q(S,A)是根据状态估计网络得到的，A是动作估计网络传过来的动作。而前面部分R + gamma * maxQ(S’,A’)是现实的Q值，这里不一样的是，我们计算现实的Q值，不在使用贪心算法，来选择动作A’,而是动作现实网络得到这里的A’。总的来说，Critic的状态估计网络的训练还是基于现实的Q值和估计的Q值的平方损失，估计的Q值根据当前的状态S和动作估计网络输出的动作A输入状态估计网络得到，而现实的Q值根据现实的奖励R，以及将下一时刻的状态S’和动作现实网络得到的动作A’ 输入到状态现实网络 而得到的Q值的折现值加和得到(这里运用的是贝尔曼方程)。</p><p>我们再来说一下Actor这边，论文中，我们基于下面的式子进行动作估计网络的参数：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-587e0300af3b40ee?imageMogr2/auto-orient/strip%7CimageView2/2/w/698/format/webp" alt="img"></p><p>这个式子看上去很吓人，但是其实理解起来很简单。假如对同一个状态，我们输出了两个不同的动作a1和a2，从状态估计网络得到了两个反馈的Q值，分别是Q1和Q2，假设Q1&gt;Q2,即采取动作1可以得到更多的奖励，那么Policy gradient的思想是什么呢，就是增加a1的概率，降低a2的概率，也就是说，Actor想要尽可能的得到更大的Q值。所以我们的Actor的损失可以简单的理解为得到的反馈Q值越大损失越小，得到的反馈Q值越小损失越大，因此只要对状态估计网络返回的Q值取个负号就好啦。是不是很简单。</p><p><strong>DDPG学习中的小trick</strong></p><p>与传统的DQN不同的是，传统的DQN采用的是一种被称为’hard’模式的target-net网络参数更新，即每隔一定的步数就将eval-net中的网络参数赋值过去，而在DDPG中，采用的是一种’soft’模式的target-net网络参数更新，即每一步都对target-net网络中的参数更新一点点，这种参数更新方式经过试验表明可以大大的提高学习的稳定性。’soft’模式到底是如何更新网络的？我们可以通过代码更好的理解。</p><p>论文中提到的另一个小trick是对采取的动作增加一定的噪声：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-a7d13457262f5430?imageMogr2/auto-orient/strip%7CimageView2/2/w/700/format/webp" alt="img"></p><p><strong>DDPG的完整流程</strong></p><p>介绍了这么多，我们也就能顺利理解原文中的DDPG算法的流程：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-d81f7a8bd9a5e382?imageMogr2/auto-orient/strip%7CimageView2/2/w/700/format/webp" alt="img"></p><h1 id="3、MADDPG算法简介"><a href="#3、MADDPG算法简介" class="headerlink" title="3、MADDPG算法简介"></a>3、MADDPG算法简介</h1><p><strong>算法流程</strong></p><p>理解了DDPG的算法过程，那么MADDPG的过程也是不难理解的，我们一起来看一下吧。</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-9e4407a715d94b0a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>每个Agent的训练同单个DDPG算法的训练过程类似，不同的地方主要体现在<strong>Critic的输入</strong>上：在单个Agent的DDPG算法中，Critic的输入是一个state-action对信息，但是在MADDPG中，每个Agent的Critic输入除自身的state-action信息外，还可以有额外的信息，比如其他Agent的动作。</p><p><strong>多Agent之间的关系形式</strong></p><p>不同的Agent之间的关系大体可以分为三种，合作型，对抗性，半合作半对抗型。我们可以根据不同的合作关系来设计我们的奖励函数。</p><h1 id="4、模型实验"><a href="#4、模型实验" class="headerlink" title="4、模型实验"></a>4、模型实验</h1><p>文章中设置了多组实验环境，有合作型的，有对抗型的也有半合作半对抗型的。如下图所示：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-95ae63a6d0aa3057.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>这里只重点讲我们后面代码中实现的实验。</p><p>实验的名称为Predator-prey。其英文解释为Good agents (green) are faster and want to avoid being hit by adversaries (red). Adversaries are slower and want to hit good agents. Obstacles (large black circles) block the way.</p><p>不过我们在代码中只实现了三个Adversaries，而Good agents处于随机游走状态。</p><p>在合作交流的环境下，论文中将MADDPG与传统的算法进行了对比，得到的结果如下：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-090bb37270692cd4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-b97d1c907335a35d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/982/format/webp" alt="img"></p><p>可以看到，MADDPG与传统的RL算法相比，在多智能体的环境下，能够取得更加突出的效果。</p><h1 id="5、MADDPG算法的简单实现"><a href="#5、MADDPG算法的简单实现" class="headerlink" title="5、MADDPG算法的简单实现"></a>5、MADDPG算法的简单实现</h1><p>本文实践了Predator-prey这一环境，如下图所示：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-fe12dd703e1f8bde.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/868/format/webp" alt="img"></p><p>绿色的球为目标，在二维空间中随机游走，躲避红色的球的攻击。三个红色的球是我们定义的Agent，它们处在互相对抗的环境中，想要击中绿色的球，从而获得奖励。黑色的地方时障碍。</p><p><strong>实验环境安装</strong></p><p>下载<a href="https://github.com/openai/multiagent-particle-envs" target="_blank" rel="noopener">https://github.com/openai/multiagent-particle-envs</a>中的代码。</p><p>进入到代码主路径中，执行命令安装所需的环境</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -e .</span><br></pre></td></tr></table></figure><p><strong>代码结构</strong><br>本项目的代码结构如下：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-c39c33fe58d97910.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/550/format/webp" alt="img"></p><p><strong>model_agent_maddpg.py</strong>:该文件定义了单个Agent的DDPG结构，及一些函数<br><strong>replay_buffer.py</strong>：定义了两种不同的经验池，一种是普通的经验池，一种是优先采样经验池<br><strong>segment_tree.py</strong> :只有在使用优先采样经验池的时候才用到。定义一种树结构根据经验的优先级进行采样<br><strong>test_three_agent_maddpg.py</strong>:对训练好的模型进行测试<br><strong>three_agent_maddpg.py</strong>:模型训练的主代码</p><p><strong>DDPG-Actor实现</strong><br>我们首先来实现单个的DDPG结构<br>Actor的输入是一个具体的状态，经过两层的全链接网络输出选择的Action。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">actor_network</span><span class="params">(name)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(name) <span class="keyword">as</span> scope:</span><br><span class="line">        x = state_input</span><br><span class="line">        x = tf.layers.dense(x, <span class="number">64</span>)</span><br><span class="line">        <span class="keyword">if</span> self.layer_norm:</span><br><span class="line">            x = tc.layers.layer_norm(x, center=<span class="keyword">True</span>, scale=<span class="keyword">True</span>)</span><br><span class="line">        x = tf.nn.relu(x)</span><br><span class="line"></span><br><span class="line">        x = tf.layers.dense(x, <span class="number">64</span>)</span><br><span class="line">        <span class="keyword">if</span> self.layer_norm:</span><br><span class="line">            x = tc.layers.layer_norm(x, center=<span class="keyword">True</span>, scale=<span class="keyword">True</span>)</span><br><span class="line">        x = tf.nn.relu(x)</span><br><span class="line"></span><br><span class="line">        x = tf.layers.dense(x, self.nb_actions,</span><br><span class="line">                            kernel_initializer=tf.random_uniform_initializer(minval=<span class="number">-3e-3</span>, maxval=<span class="number">3e-3</span>))</span><br><span class="line">        x = tf.nn.tanh(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><strong>DDPG-Critic实现</strong></p><p>Critic的输入是state，以及所有Agent当前的action信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">critic_network</span><span class="params">(name, action_input, reuse=False)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(name) <span class="keyword">as</span> scope:</span><br><span class="line">        <span class="keyword">if</span> reuse:</span><br><span class="line">            scope.reuse_variables()</span><br><span class="line"></span><br><span class="line">        x = state_input</span><br><span class="line">        x = tf.layers.dense(x, <span class="number">64</span>)</span><br><span class="line">        <span class="keyword">if</span> self.layer_norm:</span><br><span class="line">            x = tc.layers.layer_norm(x, center=<span class="keyword">True</span>, scale=<span class="keyword">True</span>)</span><br><span class="line">        x = tf.nn.relu(x)</span><br><span class="line"></span><br><span class="line">        x = tf.concat([x, action_input], axis=<span class="number">-1</span>)</span><br><span class="line">        x = tf.layers.dense(x, <span class="number">64</span>)</span><br><span class="line">        <span class="keyword">if</span> self.layer_norm:</span><br><span class="line">            x = tc.layers.layer_norm(x, center=<span class="keyword">True</span>, scale=<span class="keyword">True</span>)</span><br><span class="line">        x = tf.nn.relu(x)</span><br><span class="line"></span><br><span class="line">        x = tf.layers.dense(x, <span class="number">1</span>, kernel_initializer=tf.random_uniform_initializer(minval=<span class="number">-3e-3</span>, maxval=<span class="number">3e-3</span>))</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><strong>训练Actor和Critic</strong></p><p>Actor的训练目标是Q值的最大化，而Critic的训练目标是最小化Q估计值和Q实际值之间的差距：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">self.actor_optimizer = tf.train.AdamOptimizer(<span class="number">1e-4</span>)</span><br><span class="line">self.critic_optimizer = tf.train.AdamOptimizer(<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最大化Q值</span></span><br><span class="line">self.actor_loss = -tf.reduce_mean(</span><br><span class="line">    critic_network(name + <span class="string">'_critic'</span>, action_input=tf.concat([self.action_output, other_action_input], axis=<span class="number">1</span>),</span><br><span class="line">                   reuse=<span class="keyword">True</span>))</span><br><span class="line">self.actor_train = self.actor_optimizer.minimize(self.actor_loss)</span><br><span class="line"></span><br><span class="line">self.target_Q = tf.placeholder(shape=[<span class="keyword">None</span>, <span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">self.critic_loss = tf.reduce_mean(tf.square(self.target_Q - self.critic_output))</span><br><span class="line">self.critic_train = self.critic_optimizer.minimize(self.critic_loss)</span><br></pre></td></tr></table></figure><p><strong>定义三个Agent</strong></p><p>随后，我们分别建立三个Agent，每个Agent对应两个DDPG结构，一个是eval-net，一个是target-net：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">agent1_ddpg = MADDPG(<span class="string">'agent1'</span>)</span><br><span class="line">agent1_ddpg_target = MADDPG(<span class="string">'agent1_target'</span>)</span><br><span class="line"></span><br><span class="line">agent2_ddpg = MADDPG(<span class="string">'agent2'</span>)</span><br><span class="line">agent2_ddpg_target = MADDPG(<span class="string">'agent2_target'</span>)</span><br><span class="line"></span><br><span class="line">agent3_ddpg = MADDPG(<span class="string">'agent3'</span>)</span><br><span class="line">agent3_ddpg_target = MADDPG(<span class="string">'agent3_target'</span>)</span><br></pre></td></tr></table></figure><p><strong>模型训练</strong></p><p>在训练过程中，假设当前的状态是o_n，我们首先通过Actor得到每个Agent的动作，这里我们将动作定义为一个二维的向量，不过根据OpenAi的环境设置，我们需要将动作展开成一个五维的向量，同时绿色的球也需要定义动作，因此一共将四组动作输入到我们的环境中，可以得到奖励及下一个时刻的状态o_n_next以及当前的奖励r_n：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">agent1_action, agent2_action, agent3_action = get_agents_action(o_n, sess, noise_rate=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#三个agent的行动</span></span><br><span class="line">a = [[<span class="number">0</span>, i[<span class="number">0</span>][<span class="number">0</span>], <span class="number">0</span>, i[<span class="number">0</span>][<span class="number">1</span>], <span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> [agent1_action, agent2_action, agent3_action]]</span><br><span class="line"><span class="comment">#绿球的行动</span></span><br><span class="line">a.append([<span class="number">0</span>, np.random.rand() * <span class="number">2</span> - <span class="number">1</span>, <span class="number">0</span>, np.random.rand() * <span class="number">2</span> - <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">o_n_next, r_n, d_n, i_n = env.step(a)</span><br></pre></td></tr></table></figure><p>随后，我们需要将经验存放到经验池中，供Critic反馈和训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">agent1_memory.add(np.vstack([o_n[<span class="number">0</span>], o_n[<span class="number">1</span>], o_n[<span class="number">2</span>]]),</span><br><span class="line">                  np.vstack([agent1_action[<span class="number">0</span>], agent2_action[<span class="number">0</span>], agent3_action[<span class="number">0</span>]]),</span><br><span class="line">                  r_n[<span class="number">0</span>], np.vstack([o_n_next[<span class="number">0</span>], o_n_next[<span class="number">1</span>], o_n_next[<span class="number">2</span>]]), <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">agent2_memory.add(np.vstack([o_n[<span class="number">1</span>], o_n[<span class="number">2</span>], o_n[<span class="number">0</span>]]),</span><br><span class="line">                  np.vstack([agent2_action[<span class="number">0</span>], agent3_action[<span class="number">0</span>], agent1_action[<span class="number">0</span>]]),</span><br><span class="line">                  r_n[<span class="number">1</span>], np.vstack([o_n_next[<span class="number">1</span>], o_n_next[<span class="number">2</span>], o_n_next[<span class="number">0</span>]]), <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">agent3_memory.add(np.vstack([o_n[<span class="number">2</span>], o_n[<span class="number">0</span>], o_n[<span class="number">1</span>]]),</span><br><span class="line">                  np.vstack([agent3_action[<span class="number">0</span>], agent1_action[<span class="number">0</span>], agent2_action[<span class="number">0</span>]]),</span><br><span class="line">                  r_n[<span class="number">2</span>], np.vstack([o_n_next[<span class="number">2</span>], o_n_next[<span class="number">0</span>], o_n_next[<span class="number">1</span>]]), <span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><p>当经验池中存储了一定的经验之后，我们就可以根据前文介绍过的双网络结构和损失函数来训练每个Agent的Actor和Critic：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">train_agent(agent1_ddpg, agent1_ddpg_target, agent1_memory, agent1_actor_target_update,</span><br><span class="line">            agent1_critic_target_update, sess, [agent2_ddpg_target, agent3_ddpg_target])</span><br><span class="line"></span><br><span class="line">train_agent(agent2_ddpg, agent2_ddpg_target, agent2_memory, agent2_actor_target_update,</span><br><span class="line">            agent2_critic_target_update, sess, [agent3_ddpg_target, agent1_ddpg_target])</span><br><span class="line"></span><br><span class="line">train_agent(agent3_ddpg, agent3_ddpg_target, agent3_memory, agent3_actor_target_update,</span><br><span class="line">            agent3_critic_target_update, sess, [agent1_ddpg_target, agent2_ddpg_target]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0B/0F/ChMlWlyAyIiIQH8pABv6qMmlUWEAAIp0AAv7LcAG_rA821.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="强化学习" scheme="https://leesen998.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习实践" scheme="https://leesen998.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>深度强化学习-DDPG算法原理和实现</title>
    <link href="https://leesen998.github.io/2018/06/01/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-DDPG%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0/"/>
    <id>https://leesen998.github.io/2018/06/01/深度强化学习-DDPG算法原理和实现/</id>
    <published>2018-06-01T11:48:29.000Z</published>
    <updated>2019-03-22T04:05:28.362Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297638/samples/java%20files/photo-1546398770-b134faf3de65.jpg" alt="" style="width:100%"></p><a id="more"></a><h1 id="深度强化学习-DDPG算法原理和实现"><a href="#深度强化学习-DDPG算法原理和实现" class="headerlink" title="深度强化学习-DDPG算法原理和实现"></a>深度强化学习-DDPG算法原理和实现</h1><h1 id="1、DDPG原理"><a href="#1、DDPG原理" class="headerlink" title="1、DDPG原理"></a>1、DDPG原理</h1><p><strong>什么是DDPG呢</strong></p><p>什么是DDPG呢？前面我们介绍过了，它是Actor-Critic 和 DQN 算法的结合体。</p><p>DDPG的全称是Deep Deterministic Policy Gradient。</p><p>我们首先来看Deep，正如Q-learning加上一个Deep就变成了DQN一样，这里的Deep即同样使用DQN中的经验池和双网络结构来促进神经网络能够有效学习。</p><p>再来看Deterministic，即我们的Actor不再输出每个动作的概率，而是一个具体的动作，这更有助于我们连续动作空间中进行学习。之前不太理解这个连续动作空间是什么意思，既然policy gradient和dqn都是输出每个动作的概率和q值，那么我们为什么还要用policy gradient呢？这个连续动作空间的例子可以举一个么？既然已经诚心诚意的发问了，那么我就班门弄斧回答一下。假如想要通过强化学习得到一个词的32维词向量，哇，这个词向量的动作空间可是无限大的呀，[1,0….0]是一个动作，[0,1…0]是一个动作，如果加上小数，那更是数不过来啦，这时候我们根本不可能去计算每个动作的概率或者q值，我们只能给定状态即一个单词，直接输出一个合适的词向量。类似于这种情况，DDPG就可以大显神威了。</p><p><strong>DDPG的网络结构</strong><br>盗用莫烦老师的一张图片来形象的表示DDPG的网络结构，同图片里一样，我们称Actor里面的两个网络分别是动作估计网络和动作现实网络，我们称Critic中的两个网络分别是状态现实网络和状态估计网络：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-ce6a9c4cbcea760b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/638/format/webp" alt="img"></p><p>我们采用了类似DQN的双网络结构，而且Actor和Critic都有target-net和eval-net。我们需要强调一点的事，我们只需要训练动作估计网络和状态估计网络的参数，而动作现实网络和状态现实网络的参数是由前面两个网络每隔一定的时间复制过去的。</p><p>我们先来说说Critic这边，Critic这边的学习过程跟DQN类似，我们都知道DQN根据下面的损失函数来进行网络学习，即现实的Q值和估计的Q值的平方损失：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-55f150ba84667f4f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/506/format/webp" alt="img"></p><p>上面式子中Q(S,A)是根据状态估计网络得到的，A是动作估计网络传过来的动作。而前面部分R + gamma * maxQ(S’,A’)是现实的Q值，这里不一样的是，我们计算现实的Q值，不在使用贪心算法，来选择动作A’,而是动作现实网络得到这里的A’。总的来说，Critic的状态估计网络的训练还是基于现实的Q值和估计的Q值的平方损失，估计的Q值根据当前的状态S和动作估计网络输出的动作A输入状态估计网络得到，而现实的Q值根据现实的奖励R，以及将下一时刻的状态S’和动作现实网络得到的动作A’ 输入到状态现实网络 而得到的Q值的折现值加和得到(这里运用的是贝尔曼方程)。</p><p>我们再来说一下Actor这边，论文中，我们基于下面的式子进行动作估计网络的参数：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-34a570dbf6435608.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/698/format/webp" alt="img"></p><p>这个式子看上去很吓人，但是其实理解起来很简单。假如对同一个状态，我们输出了两个不同的动作a1和a2，从状态估计网络得到了两个反馈的Q值，分别是Q1和Q2，假设Q1&gt;Q2,即采取动作1可以得到更多的奖励，那么Policy gradient的思想是什么呢，就是增加a1的概率，降低a2的概率，也就是说，Actor想要尽可能的得到更大的Q值。所以我们的Actor的损失可以简单的理解为得到的反馈Q值越大损失越小，得到的反馈Q值越小损失越大，因此只要对状态估计网络返回的Q值取个负号就好啦。是不是很简单。</p><p><strong>DDPG学习中的小trick</strong></p><p>与传统的DQN不同的是，传统的DQN采用的是一种被称为’hard’模式的target-net网络参数更新，即每隔一定的步数就将eval-net中的网络参数赋值过去，而在DDPG中，采用的是一种’soft’模式的target-net网络参数更新，即每一步都对target-net网络中的参数更新一点点，这种参数更新方式经过试验表明可以大大的提高学习的稳定性。’soft’模式到底是如何更新网络的？我们可以通过代码更好的理解。</p><p>论文中提到的另一个小trick是对采取的动作增加一定的噪声：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-50e520f113459320.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p><strong>DDPG的完整流程</strong></p><p>介绍了这么多，我们也就能顺利理解原文中的DDPG算法的流程：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-e77eec1baba5aeea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><h1 id="2、DDPG算法实现"><a href="#2、DDPG算法实现" class="headerlink" title="2、DDPG算法实现"></a>2、DDPG算法实现</h1><p>好了，原理介绍的差不多了，我们来看一下代码的实现。本文的代码仍然参考的是莫烦老师的代码。</p><p><strong>定义超参数</strong><br>我们首先定义网络中的超参数，比如经验池的大小，两个网络的学习率等等:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">MAX_EPISODES = <span class="number">200</span></span><br><span class="line">MAX_EP_STEPS = <span class="number">200</span></span><br><span class="line">LR_A = <span class="number">0.001</span>    <span class="comment"># learning rate for actor</span></span><br><span class="line">LR_C = <span class="number">0.002</span>    <span class="comment"># learning rate for critic</span></span><br><span class="line">GAMMA = <span class="number">0.9</span>     <span class="comment"># reward discount</span></span><br><span class="line">TAU = <span class="number">0.01</span>      <span class="comment"># soft replacement</span></span><br><span class="line">MEMORY_CAPACITY = <span class="number">10000</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">RENDER = <span class="keyword">False</span></span><br><span class="line">ENV_NAME = <span class="string">'Pendulum-v0'</span></span><br></pre></td></tr></table></figure><p><strong>定义网络输入</strong><br>我们需要定义的placeholder包括当前的状态S，下一时刻的状态S’,以及对应的奖励R，而动作A由Actor得到，因此不需要再定义：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.S = tf.placeholder(tf.float32, [<span class="keyword">None</span>, s_dim], <span class="string">'s'</span>)</span><br><span class="line">self.S_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, s_dim], <span class="string">'s_'</span>)</span><br><span class="line">self.R = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">1</span>], <span class="string">'r'</span>)</span><br></pre></td></tr></table></figure><p><strong>构建两个网络</strong><br>两个网络都是两层全链接的神经网络，Actor输出一个具体的动作，而Critic网络输出一个具体的Q值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_build_a</span><span class="params">(self, s, scope, trainable)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope):</span><br><span class="line">        net = tf.layers.dense(s, <span class="number">30</span>, activation=tf.nn.relu, name=<span class="string">'l1'</span>, trainable=trainable)</span><br><span class="line">        a = tf.layers.dense(net, self.a_dim, activation=tf.nn.tanh, name=<span class="string">'a'</span>, trainable=trainable)</span><br><span class="line">        <span class="keyword">return</span> tf.multiply(a, self.a_bound, name=<span class="string">'scaled_a'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_build_c</span><span class="params">(self, s, a, scope, trainable)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope):</span><br><span class="line">        n_l1 = <span class="number">30</span></span><br><span class="line">        w1_s = tf.get_variable(<span class="string">'w1_s'</span>, [self.s_dim, n_l1], trainable=trainable)</span><br><span class="line">        w1_a = tf.get_variable(<span class="string">'w1_a'</span>, [self.a_dim, n_l1], trainable=trainable)</span><br><span class="line">        b1 = tf.get_variable(<span class="string">'b1'</span>, [<span class="number">1</span>, n_l1], trainable=trainable)</span><br><span class="line">        net = tf.nn.relu(tf.matmul(s, w1_s) + tf.matmul(a, w1_a) + b1)</span><br><span class="line">        <span class="keyword">return</span> tf.layers.dense(net, <span class="number">1</span>, trainable=trainable)  <span class="comment"># Q(s,a)</span></span><br></pre></td></tr></table></figure><p><strong>soft模式参数更新</strong><br>可以看到，我们这里进行的是soft模式的参数更新，每次在原来target-net参数的基础上，改变一丢丢，增加一点点eval-net的参数信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># networks parameters</span></span><br><span class="line">self.ae_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=<span class="string">'Actor/eval'</span>)</span><br><span class="line">self.at_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=<span class="string">'Actor/target'</span>)</span><br><span class="line">self.ce_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=<span class="string">'Critic/eval'</span>)</span><br><span class="line">self.ct_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=<span class="string">'Critic/target'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># target net replacement</span></span><br><span class="line">self.soft_replace = [[tf.assign(ta, (<span class="number">1</span> - TAU) * ta + TAU * ea), tf.assign(tc, (<span class="number">1</span> - TAU) * tc + TAU * ec)]</span><br><span class="line">                     <span class="keyword">for</span> ta, ea, tc, ec <span class="keyword">in</span> zip(self.at_params, self.ae_params, self.ct_params, self.ce_params)]</span><br></pre></td></tr></table></figure><p><strong>定义两个网络的损失</strong><br>关于两个网络的损失，我们之前已经详细介绍过了，这里只是对刚才思路的一个代码实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">q_target = self.R + GAMMA * q_</span><br><span class="line"><span class="comment"># in the feed_dic for the td_error, the self.a should change to actions in memory</span></span><br><span class="line">td_error = tf.losses.mean_squared_error(labels=q_target, predictions=q)</span><br><span class="line">self.ctrain = tf.train.AdamOptimizer(LR_C).minimize(td_error, var_list=self.ce_params)</span><br><span class="line"></span><br><span class="line">a_loss = - tf.reduce_mean(q)    <span class="comment"># maximize the q</span></span><br><span class="line">self.atrain = tf.train.AdamOptimizer(LR_A).minimize(a_loss, var_list=self.ae_params)</span><br></pre></td></tr></table></figure><p><strong>学习</strong><br>我们首先要从经验池中取出一个batch的数据，然后训练我们的Actor和Critic</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">learn</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="comment"># soft target replacement</span></span><br><span class="line">    self.sess.run(self.soft_replace)</span><br><span class="line"></span><br><span class="line">    indices = np.random.choice(MEMORY_CAPACITY, size=BATCH_SIZE)</span><br><span class="line">    bt = self.memory[indices, :]</span><br><span class="line">    bs = bt[:, :self.s_dim]</span><br><span class="line">    ba = bt[:, self.s_dim: self.s_dim + self.a_dim]</span><br><span class="line">    br = bt[:, -self.s_dim - <span class="number">1</span>: -self.s_dim]</span><br><span class="line">    bs_ = bt[:, -self.s_dim:]</span><br><span class="line"></span><br><span class="line">    self.sess.run(self.atrain, &#123;self.S: bs&#125;)</span><br><span class="line">    self.sess.run(self.ctrain, &#123;self.S: bs, self.a: ba, self.R: br, self.S_: bs_&#125;)</span><br></pre></td></tr></table></figure><p><strong>存储经验</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">store_transition</span><span class="params">(self, s, a, r, s_)</span>:</span></span><br><span class="line">    transition = np.hstack((s, a, [r], s_))</span><br><span class="line">    index = self.pointer % MEMORY_CAPACITY  <span class="comment"># replace the old memory with new memory</span></span><br><span class="line">    self.memory[index, :] = transition</span><br><span class="line">    self.pointer += <span class="number">1</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297638/samples/java%20files/photo-1546398770-b134faf3de65.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="强化学习" scheme="https://leesen998.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习实践" scheme="https://leesen998.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>深度强化学习-Actor-Critic算法原理和实现</title>
    <link href="https://leesen998.github.io/2018/05/19/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-Actor-Critic%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0/"/>
    <id>https://leesen998.github.io/2018/05/19/深度强化学习-Actor-Critic算法原理和实现/</id>
    <published>2018-05-19T11:48:29.000Z</published>
    <updated>2019-03-22T04:06:21.900Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1544080633/samples/java%20files/photo-1542127556-39e356556a8a.jpg" alt="" style="width:100%"></p><a id="more"></a><h1 id="深度强化学习-Actor-Critic算法原理和实现"><a href="#深度强化学习-Actor-Critic算法原理和实现" class="headerlink" title="深度强化学习-Actor-Critic算法原理和实现"></a>深度强化学习-Actor-Critic算法原理和实现</h1><h1 id="1、Actor-Critic算法原理"><a href="#1、Actor-Critic算法原理" class="headerlink" title="1、Actor-Critic算法原理"></a>1、Actor-Critic算法原理</h1><p>我们为什么要有Actor-Critic呢，下面的话摘自莫烦老师的文章：</p><blockquote><p>我们有了像 Q-learning这么伟大的算法, 为什么还要瞎折腾出一个 Actor-Critic? 原来 Actor-Critic 的 Actor 的前生是 Policy Gradients, 这能让它毫不费力地在连续动作中选取合适的动作, 而 Q-learning 做这件事会瘫痪. 那为什么不直接用 Policy Gradients 呢? 原来 Actor Critic 中的 Critic 的前生是 Q-learning 或者其他的 以值为基础的学习法 , 能进行单步更新, 而传统的 Policy Gradients 则是回合更新, 这降低了学习效率.</p></blockquote><p>上面的一段话不仅解释了为什么会有Actor-Critic这么一个算法，同时也告诉了我们，这个算法具体是怎么做的。如果大家已经心中有数并且想马上看代码的话，这一段是可以直接跳过的。既然Actor其实是一个Policy Network ,那么他就需要奖惩信息来进行调节不同状态下采取各种动作的概率，在传统的Policy Gradient算法中，这种奖惩信息是通过走完一个完整的episode来计算得到的。这不免导致了学习速率很慢，需要很长时间才可以学到东西。既然Critic是一个以值为基础的学习法，那么他可以进行单步更新，计算每一步的奖惩值。那么二者相结合，Actor来选择动作，Critic来告诉Actor它选择的动作是否合适。在这一过程中，Actor不断迭代，得到每一个状态下选择每一动作的合理概率，Critic也不断迭代，不断完善每个状态下选择每一个动作的奖惩值。</p><p>下图就简单的介绍了Actor-Critic算法的流程：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-dcf91ca7e3be3b10.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>但Actor-Critic并不是一个完善的算法， 后面还会提到进一步的改进:</p><blockquote><p>Actor-Critic 涉及到了两个神经网络, 而且每次都是在连续状态中更新参数, 每次参数更新前后都存在相关性, 导致神经网络只能片面的看待问题, 甚至导致神经网络学不到东西。</p></blockquote><h1 id="2、代码解析"><a href="#2、代码解析" class="headerlink" title="2、代码解析"></a>2、代码解析</h1><h2 id="2-1-Actor"><a href="#2-1-Actor" class="headerlink" title="2.1 Actor"></a>2.1 Actor</h2><p><strong>定义Actor输入</strong><br>在这里，由于我们的Actor可以进行单次训练，所以我们的输入只需要是一个状态，一个动作和一个奖励：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.s = tf.placeholder(tf.float32,[<span class="number">1</span>,n_features],name=<span class="string">'state'</span>)</span><br><span class="line">self.a = tf.placeholder(tf.int32,<span class="keyword">None</span>,name=<span class="string">'act'</span>)</span><br><span class="line">self.td_error = tf.placeholder(tf.float32,<span class="keyword">None</span>,<span class="string">"td_error"</span>)</span><br></pre></td></tr></table></figure><p><strong>Actor的网络定义</strong><br>Actor的神经网络结构和我们的Policy Gradient定义的是一样的，是一个双层的全链接神经网络：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'Actor'</span>):</span><br><span class="line">    l1 = tf.layers.dense(</span><br><span class="line">        inputs = self.s,</span><br><span class="line">        units = <span class="number">20</span>,</span><br><span class="line">        activation = tf.nn.relu,</span><br><span class="line">        kernel_initializer = tf.random_normal_initializer(mean=<span class="number">0</span>,stddev=<span class="number">0.1</span>),</span><br><span class="line">        bias_initializer = tf.constant_initializer(<span class="number">0.1</span>),</span><br><span class="line">        name = <span class="string">'l1'</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    self.acts_prob = tf.layers.dense(</span><br><span class="line">        inputs = l1,</span><br><span class="line">        units = n_actions,</span><br><span class="line">        activation = tf.nn.softmax,</span><br><span class="line">        kernel_initializer = tf.random_normal_initializer(mean=<span class="number">0</span>,stddev=<span class="number">0.1</span>),</span><br><span class="line">        bias_initializer = tf.constant_initializer(<span class="number">0.1</span>),</span><br><span class="line">        name = <span class="string">'acts_prob'</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p><strong>损失函数</strong><br>损失函数还是使用的Policy Gradient中提到过的<strong>loss= -log(prob)*vt</strong>,只不过这里的vt换成了由Critic计算出的时间差分误差td_error</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'exp_v'</span>):</span><br><span class="line">    log_prob = tf.log(self.acts_prob[<span class="number">0</span>,self.a])</span><br><span class="line">    self.exp_v = tf.reduce_mean(log_prob * self.td_error)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'train'</span>):</span><br><span class="line">    self.train_op =  tf.train.AdamOptimizer(lr).minimize(-self.exp_v)</span><br></pre></td></tr></table></figure><p><strong>Actor训练</strong><br>Actor的训练只需要将状态，动作以及时间差分值喂给网络就可以。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">learn</span><span class="params">(self,s,a,td)</span>:</span></span><br><span class="line">    s = s[np.newaxis,:]</span><br><span class="line">    feed_dict = &#123;self.s:s,self.a:a,self.td_error:td&#125;</span><br><span class="line">    _,exp_v = self.sess.run([self.train_op,self.exp_v],feed_dict=feed_dict)</span><br><span class="line">    <span class="keyword">return</span> exp_v</span><br></pre></td></tr></table></figure><p><strong>选择动作</strong></p><p>选择动作和Policy Gradient一样，根据计算出的softmax值来选择动作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_action</span><span class="params">(self,s)</span>:</span></span><br><span class="line">    s = s[np.newaxis,:]</span><br><span class="line">    probs = self.sess.run(self.acts_prob,feed_dict=&#123;self.s:s&#125;)</span><br><span class="line">    <span class="keyword">return</span> np.random.choice(np.arange(probs.shape[<span class="number">1</span>]),p=probs.ravel())</span><br></pre></td></tr></table></figure><h2 id="2-2-Critic"><a href="#2-2-Critic" class="headerlink" title="2.2 Critic"></a>2.2 Critic</h2><p><strong>定义Critic输入</strong></p><p>Critic要反馈给Actor一个时间差分值，来决定Actor选择动作的好坏，如果时间差分值大的话，说明当前Actor选择的这个动作的惊喜度较高，需要更多的出现来使得时间差分值减小。<br>考虑时间差分的计算：<br><strong>TD = r + gamma * f(s’) - f(s)</strong>,这里f(s)代表将s状态输入到Critic神经网络中得到的Q值。<br>所以Critic的输入也分三个，首先是当前状态，当前的奖励，以及下一个时刻的奖励折现值。为什么没有动作A呢？动作A是确定的呀，是Actor选的呀，对不对！还有为什么不是下一时刻的Q值而不是下一个时刻的状态，因为我们已经在计算TD时已经把状态带入到神经网络中得到Q值了。相信你看代码就明白了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.s = tf.placeholder(tf.float32,[<span class="number">1</span>,n_features],name=<span class="string">'state'</span>)</span><br><span class="line">self.v_ = tf.placeholder(tf.float32,[<span class="number">1</span>,<span class="number">1</span>],name=<span class="string">'v_next'</span>)</span><br><span class="line">self.r = tf.placeholder(tf.float32,<span class="keyword">None</span>,name=<span class="string">'r'</span>)</span><br></pre></td></tr></table></figure><p><strong>定义网络结构</strong></p><p>同Actor一样，我们的Critic也是一个双层的神经网络结构。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'Critic'</span>):</span><br><span class="line">    l1 = tf.layers.dense(</span><br><span class="line">        inputs = self.s,</span><br><span class="line">        units = <span class="number">20</span>,</span><br><span class="line">        activation = tf.nn.relu,</span><br><span class="line">        kernel_initializer = tf.random_normal_initializer(<span class="number">0</span>,<span class="number">0.1</span>),</span><br><span class="line">        bias_initializer = tf.constant_initializer(<span class="number">0.1</span>),</span><br><span class="line">        name = <span class="string">'l1'</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    self.v = tf.layers.dense(</span><br><span class="line">        inputs = l1,</span><br><span class="line">        units = <span class="number">1</span>,</span><br><span class="line">        activation = <span class="keyword">None</span>,</span><br><span class="line">        kernel_initializer=tf.random_normal_initializer(<span class="number">0</span>,<span class="number">0.1</span>),</span><br><span class="line">        bias_initializer = tf.constant_initializer(<span class="number">0.1</span>),</span><br><span class="line">        name = <span class="string">'V'</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p><strong>定义损失</strong><br>Critic的损失定义为时间差分值的平方值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'squared_TD_error'</span>):</span><br><span class="line">    self.td_error  = self.r + gamma * self.v_ - self.v</span><br><span class="line">    self.loss = tf.square(self.td_error)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'train'</span>):</span><br><span class="line">    self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)</span><br></pre></td></tr></table></figure><p><strong>训练Critic</strong><br>Critic的任务就是告诉Actor当前选择的动作好不好，所以我们只要训练得到TD并返回给Actor就好：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">learn</span><span class="params">(self,s,r,s_)</span>:</span></span><br><span class="line">    s,s_ = s[np.newaxis,:],s_[np.newaxis,:]</span><br><span class="line"></span><br><span class="line">    v_ = self.sess.run(self.v,feed_dict = &#123;self.s:s_&#125;)</span><br><span class="line"></span><br><span class="line">    td_error,_ = self.sess.run([self.td_error,self.train_op],</span><br><span class="line">                               feed_dict=&#123;self.s:s,self.v_:v_,self.r:r&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> td_error</span><br></pre></td></tr></table></figure><h2 id="2-3-整体模型训练"><a href="#2-3-整体模型训练" class="headerlink" title="2.3 整体模型训练"></a>2.3 整体模型训练</h2><p>有了Critic之后，Actor就可以进行单步训练和更新了，所以训练中的关键的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">      a = actor.choose_action(s)</span><br><span class="line">      s_,r,done,info = env.step(a)</span><br><span class="line">      td_error = critic.learn(s,r,s_)</span><br><span class="line">      actor.learn(s,a,td_error)</span><br><span class="line">      s = s_</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1544080633/samples/java%20files/photo-1542127556-39e356556a8a.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="强化学习" scheme="https://leesen998.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习实践" scheme="https://leesen998.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>深度强化学习-Policy Gradient基本实现</title>
    <link href="https://leesen998.github.io/2018/05/05/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-Policy%20Gradient%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0/"/>
    <id>https://leesen998.github.io/2018/05/05/深度强化学习-Policy Gradient基本实现/</id>
    <published>2018-05-05T11:48:29.000Z</published>
    <updated>2019-03-22T04:04:17.579Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1544080580/samples/java%20files/photo-1541706140-fd57c55e85e6.jpg" alt="" style="width:100%"></p><a id="more"></a><h1 id="深度强化学习-Policy-Gradient基本实现"><a href="#深度强化学习-Policy-Gradient基本实现" class="headerlink" title="深度强化学习-Policy Gradient基本实现"></a>深度强化学习-Policy Gradient基本实现</h1><h1 id="1、什么是-Policy-Gradients"><a href="#1、什么是-Policy-Gradients" class="headerlink" title="1、什么是 Policy Gradients"></a>1、什么是 Policy Gradients</h1><p>其实在引言部分我们已经介绍了策略梯度的基本思想，就是直接根据状态输出动作或者动作的概率。那么怎么输出呢，最简单的就是使用神经网络啦！<br>我们使用神经网络输入当前的状态，网络就可以输出我们在这个状态下采取每个动作的概率，那么网络应该如何训练来实现最终的收敛呢？<br>我们之前在训练神经网络时，使用最多的方法就是反向传播算法，我们需要一个误差函数，通过梯度下降来使我们的损失最小。但对于强化学习来说，我们不知道动作的正确与否，只能通过奖励值来判断这个动作的相对好坏。基于上面的想法，我们有个非常简单的想法：</p><p><strong>如果一个动作得到的reward多，那么我们就使其出现的概率增加，如果一个动作得到的reward少，我们就使其出现的概率减小。</strong></p><p>根据这个思想，我们构造如下的损失函数：<strong>loss= -log(prob)*vt</strong></p><p>我们简单用白话介绍一下上面这个损失函数的合理性，那么至于从数学角度上为什么要使用上面的损失函数，可以参考：<a href="https://link.jianshu.com/?t=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttp%253A%2F%2Fmath.stackexchange.com%2Fquestions%2F892832%2Fwhy-we-consider-log-likelihood-instead-of-likelihood-in-gaussian-distribution" target="_blank" rel="noopener">Why we consider log likelihood instead of Likelihood in Gaussian Distribution</a>。</p><p>上式中log(prob)表示在状态 s 对所选动作 a 的吃惊度, 如果概率越小, 反向的log(prob) 反而越大. 而vt代表的是当前状态s下采取动作a所能得到的奖励，这是当前的奖励和未来奖励的贴现值的求和。也就是说，我们的策略梯度算法必须要完成一个完整的eposide才可以进行参数更新，而不是像值方法那样，每一个(s,a,r,s’)都可以进行参数更新。如果在prob很小的情况下, 得到了一个大的Reward, 也就是大的vt, 那么-log(prob)*vt就更大, 表示更吃惊, (我选了一个不常选的动作, 却发现原来它能得到了一个好的 reward, 那我就得对我这次的参数进行一个大幅修改)。</p><p>这就是 -log(prob)*vt的物理意义啦.Policy Gradient的核心思想是更新参数时有两个考虑：如果这个回合选择某一动作，下一回合选择该动作的概率大一些，然后再看奖惩值，如果奖惩是正的，那么会放大这个动作的概率，如果奖惩是负的，就会减小该动作的概率。</p><p>策略梯度的过程如下图所示：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-c805cf0835fb28b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>我们在介绍代码实战之前，最后在强调Policy Gradient的一些细节：</p><ol><li>算法输出的是<strong>动作的概率</strong>，而不是Q值。</li><li>损失函数的形式为：<strong>loss= -log(prob)*vt</strong></li><li>需要一次<strong>完整的episode</strong>才可以进行参数的更新</li></ol><h1 id="2、Policy-Gradient算法实现"><a href="#2、Policy-Gradient算法实现" class="headerlink" title="2、Policy Gradient算法实现"></a>2、Policy Gradient算法实现</h1><p>我们通过Policy Gradient算法来实现让钟摆倒立的过程。</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-56f5e77ac7b0b4e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>本文的代码思路完全按照policy gradient的过程展开。</p><p><strong>定义参数</strong><br>首先，我们定义了一些模型的参数：</p><p>self.ep_obs,self.ep_as,self.ep_rs分别存储了当前episode的状态，动作和奖励。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">self.n_actions = n_actions</span><br><span class="line">self.n_features = n_features</span><br><span class="line">self.lr = learning_rate</span><br><span class="line">self.gamma = reward_decay</span><br><span class="line"></span><br><span class="line">self.ep_obs,self.ep_as,self.ep_rs = [],[],[]</span><br></pre></td></tr></table></figure><p><strong>定义模型输入</strong><br>模型的输入包括三部分，分别是观察值，动作和奖励值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'inputs'</span>):</span><br><span class="line">    self.tf_obs = tf.placeholder(tf.float32,[<span class="keyword">None</span>,self.n_features],name=<span class="string">'observation'</span>)</span><br><span class="line">    self.tf_acts = tf.placeholder(tf.int32,[<span class="keyword">None</span>,],name=<span class="string">'actions_num'</span>)</span><br><span class="line">    self.tf_vt = tf.placeholder(tf.float32,[<span class="keyword">None</span>,],name=<span class="string">'actions_value'</span>)</span><br></pre></td></tr></table></figure><p><strong>构建模型</strong><br>我们的模型定义了两层的神经网络，网络的输入是每次的观测值，而输出是该状态下采取每个动作的概率，这些概率在最后会经过一个softmax处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">layer = tf.layers.dense(</span><br><span class="line">    inputs = self.tf_obs,</span><br><span class="line">    units = <span class="number">10</span>,</span><br><span class="line">    activation= tf.nn.tanh,</span><br><span class="line">    kernel_initializer=tf.random_normal_initializer(mean=<span class="number">0</span>,stddev=<span class="number">0.3</span>),</span><br><span class="line">    bias_initializer= tf.constant_initializer(<span class="number">0.1</span>),</span><br><span class="line">    name=<span class="string">'fc1'</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">all_act = tf.layers.dense(</span><br><span class="line">    inputs = layer,</span><br><span class="line">    units = self.n_actions,</span><br><span class="line">    activation = <span class="keyword">None</span>,</span><br><span class="line">    kernel_initializer=tf.random_normal_initializer(mean=<span class="number">0</span>,stddev=<span class="number">0.3</span>),</span><br><span class="line">    bias_initializer = tf.constant_initializer(<span class="number">0.1</span>),</span><br><span class="line">    name=<span class="string">'fc2'</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">self.all_act_prob = tf.nn.softmax(all_act,name=<span class="string">'act_prob'</span>)</span><br></pre></td></tr></table></figure><p><strong>模型的损失</strong><br>我们之前介绍过了，模型的损失函数计算公式为：<strong>loss= -log(prob)*vt</strong>，我们可以直接使用tf.nn.sparse_softmax_cross_entropy_with_logits 来计算前面一部分，即-log(prob)，不过为了更清楚的显示我们的计算过程，我们使用了如下的方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'loss'</span>):</span><br><span class="line">    <span class="comment">#neg_log_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.all_act_prob,labels =self.tf_acts)</span></span><br><span class="line"></span><br><span class="line">    neg_log_prob = tf.reduce_sum(-tf.log(self.all_act_prob) * tf.one_hot(indices=self.tf_acts,depth=self.n_actions),axis=<span class="number">1</span>)</span><br><span class="line">    loss = tf.reduce_mean(neg_log_prob * self.tf_vt)</span><br></pre></td></tr></table></figure><p>而我们选择AdamOptimizer优化器进行参数的更新：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'train'</span>):</span><br><span class="line">    self.train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)</span><br></pre></td></tr></table></figure><p><strong>动作选择</strong><br>我们这里动作的选择不再根据贪心的策略来选择了，而是根据输出动作概率的softmax值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_action</span><span class="params">(self,observation)</span>:</span></span><br><span class="line">    prob_weights = self.sess.run(self.all_act_prob,feed_dict=&#123;self.tf_obs:observation[np.newaxis,:]&#125;)</span><br><span class="line">    action = np.random.choice(range(prob_weights.shape[<span class="number">1</span>]),p=prob_weights.ravel())</span><br><span class="line">    <span class="keyword">return</span> action</span><br></pre></td></tr></table></figure><p><strong>存储经验</strong><br>之前说过，policy gradient是在一个完整的episode结束后才开始训练的，因此，在一个episode结束前，我们要存储这个episode所有的<strong>经验</strong>，即状态，动作和奖励。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">store_transition</span><span class="params">(self,s,a,r)</span>:</span></span><br><span class="line">    self.ep_obs.append(s)</span><br><span class="line">    self.ep_as.append(a)</span><br><span class="line">    self.ep_rs.append(r)</span><br></pre></td></tr></table></figure><p><strong>计算奖励的贴现值</strong><br>我们之前存储的奖励是当前状态s采取动作a获得的即时奖励，而当前状态s采取动作a所获得的真实奖励应该是即时奖励加上未来直到episode结束的奖励贴现和。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_discount_and_norm_rewards</span><span class="params">(self)</span>:</span></span><br><span class="line">    discounted_ep_rs = np.zeros_like(self.ep_rs)</span><br><span class="line">    running_add = <span class="number">0</span></span><br><span class="line">    <span class="comment"># reserved 返回的是列表的反序，这样就得到了贴现求和值。</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> reversed(range(<span class="number">0</span>,len(self.ep_rs))):</span><br><span class="line">        running_add = running_add * self.gamma + self.ep_rs[t]</span><br><span class="line">        discounted_ep_rs[t] = running_add</span><br><span class="line"></span><br><span class="line">    discounted_ep_rs -= np.mean(discounted_ep_rs)</span><br><span class="line">    discounted_ep_rs /= np.std(discounted_ep_rs)</span><br><span class="line">    <span class="keyword">return</span> discounted_ep_rs</span><br></pre></td></tr></table></figure><p><strong>模型训练</strong><br>在定义好上面所有的部件之后，我们就可以编写模型训练函数了，这里需要注意的是，我们喂给模型的并不是我们存储的奖励值，而是在经过上一步计算的奖励贴现和。另外，我们需要在每一次训练之后清空我们的经验池。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">learn</span><span class="params">(self)</span>:</span></span><br><span class="line">    discounted_ep_rs_norm = self._discount_and_norm_rewards()</span><br><span class="line"></span><br><span class="line">    self.sess.run(self.train_op,feed_dict=&#123;</span><br><span class="line">        self.tf_obs:np.vstack(self.ep_obs),</span><br><span class="line">        self.tf_acts:np.array(self.ep_as),</span><br><span class="line">        self.tf_vt:discounted_ep_rs_norm,</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    self.ep_obs,self.ep_as,self.ep_rs = [],[],[]</span><br><span class="line">    <span class="keyword">return</span> discounted_ep_rs_norm</span><br></pre></td></tr></table></figure><p>好了，模型相关的代码我们就介绍完了，如何调用这个模型的代码相信大家一看便明白，我们就不再介绍啦。</p>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1544080580/samples/java%20files/photo-1541706140-fd57c55e85e6.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="强化学习" scheme="https://leesen998.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习实践" scheme="https://leesen998.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>SA-ABR Code</title>
    <link href="https://leesen998.github.io/2018/04/26/SA-ABR%20Code/"/>
    <id>https://leesen998.github.io/2018/04/26/SA-ABR Code/</id>
    <published>2018-04-26T11:48:29.000Z</published>
    <updated>2019-03-22T04:03:35.710Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg" alt="" style="width:100%"></p><a id="more"></a><p>这部分详细讲解我们实现的自适应算法的代码实现部分，主要包括系统信息获取部分、网络部分以及网络更新部分。其中系统信息获取部分包括导入训练数据及数据预处理、得到网络输入、更新视频缓存、获取奖励等；网络部分主要是上一节提到的actor-critic网络的搭建；网络更新部分主要是根据强化学习算法部分多网络进行优化更新，这也是我们的重点。<br>我们在实际实现时，采取了CNN、CNN+传感器、RNN+传感器三种方式的网络，三者在大体上差不多，因此在这我们仅介绍前面谈到过的CNN+传感器的网络实现。如果想看完整的代码和采集的无人机飞行中吞吐量与速度、加速度、距离之间的数据信息，请查看allData目录.<br>下面是我们系统部分部分代码的结构：<br><img src="https://i.imgur.com/wMFtPSP.png" alt=""></p><p>其中文件夹train_data里面是采集的数据，readData、py导入训练数据及数据预处理，helperwithspeed、py包含系统网络输入获取、缓存更新、获取奖励等功能、train_with_speed、py主要是网络的搭建以及网络的更新。下面将详细讲解每个部分的具体功能以及实现。</p><h2 id="1、数据部分："><a href="#1、数据部分：" class="headerlink" title="1、数据部分："></a>1、数据部分：</h2><p>包括测量的吞吐量throughput.txt以及对应的速度信息speed.txt、距离信息distance.txt、加速度信息acce.txt.后续数据还在继续扩充。 </p><p>吞吐量中一共95组数据，每一组数据包括50s的吞吐量大小，大小在0到16Mps之间。 </p><p>加速度一共95组，每一组是与吞吐量相对应的50s的加速度大小，通过预处理，我们将加速度分为0和1两个等级，当实际加速度超过18.5m/s^2的时候将加速度置为1，反之则为0. </p><p>距离一共95组，每一组是与吞吐量对应的50m的距离大小，通过预处理，将加速度分为0和1两个等级，当与接收端距离超过50m时将距离置为1，反之则为0 </p><p>速度也是95组，每一组是与吞吐量对应的50s的速度大小，通过预处理，将速度划分为三个等级，速度不超过8m/s的置为0，8-12m/s的置为1，超过12m/s的置为2. </p><h2 id="2、数据导入及预处理"><a href="#2、数据导入及预处理" class="headerlink" title="2、数据导入及预处理"></a>2、数据导入及预处理</h2><p>这部分主要是从txt中导入数据以及进行数据归一化预处理。<br><img src="https://i.imgur.com/uNSJkt1.png" alt=""></p><p>数据的读取比较简单，用np.loadtxt()就可以直接将txt读取为numpy数组。 </p><p>接下来是数据的归一化，在这里我们将吞吐量归一化到0.5-2.5之间。<br><img src="https://i.imgur.com/3FsbaBX.png" alt=""></p><p>最后，我们将数据进行重复，得到N组数据，即train_throughput、train_speed、train_distance、train_acce,他们都是维数为N*50的二维数组，其中，N为我们训练的次数，在实验中我们可以根据需要进行自行调整，在这里，我们暂取N=10000.<br><img src="https://i.imgur.com/wXr0Wci.png" alt=""></p><h2 id="3-网络搭建"><a href="#3-网络搭建" class="headerlink" title="3.网络搭建"></a>3.网络搭建</h2><p>网络的搭建和深度学习中的网络类似，唯一需要注意的是在这里两个有两个独立的网络：actor和critic网络。前面已经谈到过，这两个网络的输入部分相同，都是输入的相应的状态，即一个1x13的numpy数组。具体网络搭建的代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ActorNetwork</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(ActorNetwork, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.rnn = nn.LSTM(</span><br><span class="line">            input_size=<span class="number">2</span>,</span><br><span class="line">            hidden_size=<span class="number">64</span>,</span><br><span class="line">            num_layers=<span class="number">2</span>,</span><br><span class="line">            batch_first=<span class="keyword">True</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">69</span>, <span class="number">30</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">30</span>, <span class="number">10</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">10</span>, <span class="number">4</span>)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span>  <span class="comment"># x shape(1x1x13)</span></span><br><span class="line">        x1 = np.zeros([<span class="number">8</span>], dtype=np.float32)  <span class="comment"># 代表throughput</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">         x1[i] = x[i]</span><br><span class="line"></span><br><span class="line">        x2 = np.array([x[<span class="number">8</span>]], dtype=np.float32)  <span class="comment"># 代表buffersize</span></span><br><span class="line">        x3 = np.array([x[<span class="number">9</span>]], dtype=np.float32)  <span class="comment"># 代表lastAction</span></span><br><span class="line">        x4 = np.array([x[<span class="number">10</span>]], dtype=np.float32)  <span class="comment"># 代表speed</span></span><br><span class="line">        x5 = np.array([x[<span class="number">11</span>]], dtype=np.float32)  <span class="comment"># 代表distance</span></span><br><span class="line">        x6 = np.array([x[<span class="number">12</span>]], dtype=np.float32)  <span class="comment"># 代表acce</span></span><br><span class="line"></span><br><span class="line">        x1 = Variable(torch.from_numpy(x1))</span><br><span class="line">        x2 = Variable(torch.from_numpy(x2))</span><br><span class="line">        x3 = Variable(torch.from_numpy(x3))</span><br><span class="line">        x4 = Variable(torch.from_numpy(x4))</span><br><span class="line">        x5 = Variable(torch.from_numpy(x5))</span><br><span class="line">        x6 = Variable(torch.from_numpy(x6))</span><br><span class="line"></span><br><span class="line">        x1 = x1.view(<span class="number">-1</span>, <span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line">        x2 = x2.view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        x3 = x3.view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        x4 = x4.view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        x5 = x5.view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        x6 = x6.view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">        r_out, (h_n, h_c) = self.rnn(x1, <span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#r_out = r_out.view(-1, num_flat_features(r_out))</span></span><br><span class="line">        datain = torch.cat((r_out[:,<span class="number">-1</span>,:], x2), <span class="number">1</span>)</span><br><span class="line">        datain = torch.cat((datain, x3), <span class="number">1</span>)</span><br><span class="line">        datain = torch.cat((datain, x4), <span class="number">1</span>)</span><br><span class="line">        datain = torch.cat((datain, x5), <span class="number">1</span>)</span><br><span class="line">        datain = torch.cat((datain, x6), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        out = self.relu(self.fc1(datain))</span><br><span class="line">        out = self.relu(self.fc2(out))</span><br><span class="line">        out = self.fc3(out)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(out)</span><br></pre></td></tr></table></figure></p><p>上面是actor网络部分的实现，网络的输入是每时刻的状态，是一个1x13维的numpy数组，输出为1x4维的tesnor，标识的是状态动作概率。需要注意的是，这里输出的是log_softmax处理后的概率，在具体使用时需要进行指数处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ValueNetwork</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,input_channels=<span class="number">1</span>,output_channels=<span class="number">128</span>,output_size=<span class="number">1</span>)</span>:</span></span><br><span class="line">        super(ValueNetwork  ,self ).__init__()</span><br><span class="line">        self.cov1 = nn.Conv1d(input_channels, <span class="number">64</span>, kernel_size=<span class="number">3</span>)</span><br><span class="line">        self.cov2 = nn.Conv1d(<span class="number">64</span>, output_channels, kernel_size=<span class="number">3</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">517</span>, <span class="number">128</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">128</span>, <span class="number">30</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">30</span>, <span class="number">8</span>)</span><br><span class="line">        self.fc4 = nn.Linear(<span class="number">8</span>, output_size)</span><br><span class="line">        self.drop = nn.Dropout(p=<span class="number">0.5</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span><span class="comment">#输入1x1x13</span></span><br><span class="line">        <span class="comment">#in_size=x.size(0)</span></span><br><span class="line">        x1 = np.zeros([<span class="number">8</span>], dtype=np.float32) <span class="comment">#代表throughput</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">            x1[i] = x[i]</span><br><span class="line">        x2 = np.array([x[<span class="number">8</span>]], dtype=np.float32) <span class="comment">#代表buffersize</span></span><br><span class="line">        x3 = np.array([x[<span class="number">9</span>]], dtype=np.float32) <span class="comment">#代表lastAction</span></span><br><span class="line">        x4 = np.array([x[<span class="number">10</span>]],dtype=np.float32) <span class="comment">#代表speed</span></span><br><span class="line">        x5 =np.array([[x[<span class="number">11</span>]]],dtype=np.float32) <span class="comment">#代表distance</span></span><br><span class="line">        x6 =np.array([x[<span class="number">12</span>]],dtype=np.float32) <span class="comment">#代表acce</span></span><br><span class="line"></span><br><span class="line">        x1 = Variable(torch.from_numpy(x1))</span><br><span class="line">        x2 = Variable(torch.from_numpy(x2))</span><br><span class="line">        x3 = Variable(torch.from_numpy(x3))</span><br><span class="line">        x4= Variable(torch.from_numpy(x4))</span><br><span class="line">        x5 = Variable(torch.from_numpy(x5))</span><br><span class="line">        x6 = Variable(torch.from_numpy(x6))</span><br><span class="line"></span><br><span class="line">        x1 = x1.view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        x2 = x2.view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        x3 = x3.view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        x4 = x4.view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        x5 = x5.view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        x6 = x6.view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        x1 = self.cov1(x1)</span><br><span class="line">        x1= self.cov2(x1)</span><br><span class="line">        x1 = x1.view(<span class="number">-1</span>, num_flat_features(x1))</span><br><span class="line">        datain = torch.cat((x1, x2), <span class="number">1</span>)</span><br><span class="line">        datain = torch.cat((datain, x3), <span class="number">1</span>)</span><br><span class="line">        datain = torch.cat((datain, x4), <span class="number">1</span>)</span><br><span class="line">        datain = torch.cat((datain, x5), <span class="number">1</span>)</span><br><span class="line">        datain = torch.cat((datain, x6), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        out = F.relu(self.fc1(datain))</span><br><span class="line">        out = self.drop(F.relu(self.fc2(out)))</span><br><span class="line">        out = F.relu(self.fc3(out))</span><br><span class="line">        out = self.fc4(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>上面是critic网路部分的实现，输入的也是每时刻的1x13维的状态矩阵，输出的是1x1维的tesnor，表示的是每个状态下的状态价值V(s).</p><p>从结构上来说，actor网络和critic网络的输入以及网络结构都是相同的，均是2层1维CNN后在连接三层全连层网络。需要注意并不是将输入直接进行卷积处理，因为我们卷积的只是输入的一部分，因此需要进行数据的拆分和合并处理。在这里，还需要注意的是tensor,variable以及numpy数组的转换。</p><h2 id="4、系统状态获取及更新"><a href="#4、系统状态获取及更新" class="headerlink" title="4、系统状态获取及更新"></a>4、系统状态获取及更新</h2><p>系统状态获取以及更新也是整个系统比较重要的部分，其中主要包括获训练数据，获取送入网络的数据，状态更新以及计算奖励。下面我主要介绍这部分的相关函数。</p><p>1 函数getThroughput比较简单，输入参数是训练的epoch，返回参数是这次训练整个过程中的吞吐量以及对应的速度、加速度以及距离信息。代码如下：</p><pre><code class="python"><span class="function"><span class="keyword">def</span> <span class="title">getThroughputData</span><span class="params">(epoch)</span>:</span>    <span class="keyword">global</span> train_throughput    <span class="keyword">global</span> train_speed    <span class="keyword">global</span> train_distance    <span class="keyword">global</span> train_acce    <span class="keyword">return</span> train_throughput[epoch],train_speed[epoch],train_distance[epoch],train_acce[epoch]</code></pre><p>2 函数Input实现的是根据上面得到的每个epoch的数据，在每个视频块需要播放的时候送往actor-critic网络的表示状态的1x13维的numpy数组。状态是由过去八个视频块的吞吐量、此刻的视频缓存、上一视频块的比特率、此刻的速度、距离以及加速度组成。具体实现的代码如下：</p><pre><code class="python"><span class="function"><span class="keyword">def</span> <span class="title">Input</span><span class="params">(SyntheticData,TestSpeed,TestDistance,TestAcce,BufferSize,BitRate,TrainTime)</span>:</span>    ThroughPut = SyntheticData[TrainTime - <span class="number">1</span>:TrainTime + <span class="number">7</span>]    ThroughPut =np.array(ThroughPut,dtype=np.float32)    speed=np.array(TestSpeed[TrainTime+<span class="number">7</span>:TrainTime+<span class="number">8</span>],dtype=np.float32)    distance = np.array(TestDistance[TrainTime + <span class="number">7</span>: TrainTime + <span class="number">8</span>], dtype=np.float32)    acce = np.array(TestAcce[TrainTime + <span class="number">7</span> :TrainTime + <span class="number">8</span>], dtype=np.float32)    buffer=np.array([BufferSize],dtype=np.float32)    action=np.array([BitRate],dtype=np.float32)    networkIn= np.append(ThroughPut,buffer)    networkIn = np.append(networkIn, action)    networkIn =np.append(networkIn,speed)    networkIn =np.append(networkIn,distance)    networkIn =np.append(networkIn,acce)    <span class="keyword">return</span> networkIn</code></pre><p>3 函数UpdateBuffer实现的是在状态s下，选择特定比特率action之后到达下一个状态，此过程中buffer的更新以及此action导致的卡顿时间rebuffering.需要注意的是我们在这里提到的action都是用{0，1，2，3}来表示{300kbps,750kpbs,1850kbps,2850kbps}的视频比特率的，在具体计算的时候需要通过函数BiterateTransform来进行转换一下，这一函数很简单，我们就不做描述。具体代码如下：</p><pre><code class="python"><span class="function"><span class="keyword">def</span> <span class="title">updateBuffer</span><span class="params">(buffer,action,throughput)</span>:</span>    <span class="keyword">if</span> <span class="number">2</span>*BitrateTransform(action)/throughput &lt; buffer : <span class="comment">#不卡</span>        newbuffer =buffer +<span class="number">2</span>- <span class="number">2</span>*BitrateTransform(action)/throughput        rebuffering = <span class="number">0</span>    <span class="keyword">elif</span> <span class="number">2</span>*BitrateTransform(action)/throughput &gt;buffer  <span class="keyword">and</span>  buffer+<span class="number">2</span> &gt; <span class="number">2</span>*BitrateTransform(action)/throughput: <span class="comment">#不卡</span>        newbuffer = buffer +<span class="number">2</span>- <span class="number">2</span>*BitrateTransform(action)/throughput        rebuffering = <span class="number">0</span>    <span class="keyword">else</span>:        newbuffer = <span class="number">0</span>        rebuffering = (math.ceil((<span class="number">2</span>*BitrateTransform(action)/throughput <span class="number">-2</span>-buffer)/<span class="number">0.5</span>))*<span class="number">0.5</span>    <span class="keyword">return</span> newbuffer, rebuffering</code></pre><p> 4 函数Reward是根据选择视频块的BitRate以及这一BitRate造成的卡顿时间rebuffering和上一视频块的比特率来计算的，计算的是根据下面公式算出的视频的QoE,也就是我们系统中的奖励值。<br><img src="https://i.imgur.com/Ihffn1y.png" alt=""></p><p>具体实现的代码如下，实现思路就是比较视频缓存大小和下载该视频块的时间进行比较来分类讨论进行的。</p><pre><code class="python"><span class="function"><span class="keyword">def</span> <span class="title">updateBuffer</span><span class="params">(buffer,action,throughput)</span>:</span>    <span class="keyword">if</span> <span class="number">2</span>*BitrateTransform(action)/throughput &lt; buffer : <span class="comment">#不卡</span>        newbuffer =buffer +<span class="number">2</span>- <span class="number">2</span>*BitrateTransform(action)/throughput        rebuffering = <span class="number">0</span>    <span class="keyword">elif</span> <span class="number">2</span>*BitrateTransform(action)/throughput &gt;buffer  <span class="keyword">and</span>  buffer+<span class="number">2</span> &gt; <span class="number">2</span>*BitrateTransform(action)/throughput: <span class="comment">#不卡</span>        newbuffer = buffer +<span class="number">2</span>- <span class="number">2</span>*BitrateTransform(action)/throughput        rebuffering = <span class="number">0</span>    <span class="keyword">else</span>:        newbuffer = <span class="number">0</span>        rebuffering = (math.ceil((<span class="number">2</span>*BitrateTransform(action)/throughput <span class="number">-2</span>-buffer)/<span class="number">0.5</span>))*<span class="number">0.5</span>    <span class="keyword">return</span> newbuffer, rebuffering</code></pre><p>4.1 函数discount_reward是根据某次播放一段视频每个状态选择动作后得到的奖励值r、最后一步的奖励值final_r以及折扣因子gama来计算这段视频中每个状态的动作价值函数的，计算的依据是下面动作价值函数的定义：<br><img src="https://i.imgur.com/KRe2bNq.png" alt=""></p><p>具体实现的代码如下：</p><pre><code class="python"><span class="function"><span class="keyword">def</span> <span class="title">discount_reward</span><span class="params">(r,gama,final_r)</span>:</span>    discounted_r =np.zeros_like(r)    running_add =final_r    <span class="keyword">for</span> t <span class="keyword">in</span> reversed(range(<span class="number">0</span>,len(r))):    running_add=running_add*gama+r[t]    discounted_r[t]=running_add    <span class="keyword">return</span> discounted_r</code></pre><h2 id="5-网络优化更新"><a href="#5-网络优化更新" class="headerlink" title="5.网络优化更新"></a>5.网络优化更新</h2><p>前面我们已经做好了所有的准备工作，我们大致实现了如下功能：</p><p>每一次你训练时得到一段50s包含吞吐量以及对应速度、加速度、距离的训练数据。这一组数据对应一段完整的视频播放过程，需要进行42次视频比特率的选择。</p><p>对于每一组训练数据，我们在每个视频块需要选择比特率的时候得到此刻的状态信息，将它合并在一个1x13维的numpy数组中。<br>搭建好actor-critic网络，对于每一个视频块，输入此刻的状态，actor网络可以输出动作概率用来选择概率，value网络输出此状态下的状态价值V(st)。<br>选择比特率后，我们能达到下一状态并进行状态的更新以及获得即时奖励r。<br>计算每一个状态的动作价值函数Q(st,at)<br>接下来我们需要做的是根据这一过程进行网络的优化更新，这也是我们的重中之重。更新过程主要分为两部分，第一部分是根据每个epoch得到的数据进行一次完整的视频播放。具体代码如下：</p><pre><code class="python"><span class="function"><span class="keyword">def</span> <span class="title">roll_out</span><span class="params">(actor_network,value_network,TestThroughput,TestSpeed,TestDistance,TestAcce)</span>:</span><span class="comment">#initial</span>    CurrentBufferSize =<span class="number">0</span>    LastBitRate = <span class="number">0</span>    train_time =<span class="number">1</span>    initial_state=Input(TestThroughput,TestSpeed,TestDistance,TestAcce, CurrentBufferSize, LastBitRate, train_time)    state=initial_state    <span class="comment">#return data</span>    states=[]    actions =[]    rewards =[]    buffers=[]    rebuffer_all=[]    action_all=[]    buffers.append(CurrentBufferSize)    <span class="comment">#is_done =False</span>    final_r =<span class="number">0</span>    <span class="keyword">for</span> j <span class="keyword">in</span> range(total_times<span class="number">-1</span>):        states.append(state)        log_softmax_action =actor_network(state)        softmax_action =torch.exp(log_softmax_action)        action=np.random.choice(<span class="number">4</span>,p=softmax_action.cpu().data.numpy()[<span class="number">0</span>])        <span class="comment">#action=makeChoice(softmax_action.cpu().data.numpy()[0])</span>        print(action)        action_all.append(action)        one_hot_action=[int (k==action) <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">4</span>)]        throughput=TestThroughput[train_time+<span class="number">8</span>]        CurrentBufferSize,rebuffer =updateBuffer(CurrentBufferSize,action,throughput)        rebuffer_all.append(rebuffer)        buffers.append(CurrentBufferSize)        reward=Reward(action,LastBitRate,rebuffer)        LastBitRate = action        train_time =train_time+<span class="number">1</span>        next_state =Input(TestThroughput,TestSpeed,TestDistance,TestAcce, CurrentBufferSize, LastBitRate, train_time)        final_state=next_state        state=next_state        actions.append(one_hot_action)        rewards.append(reward)        <span class="keyword">if</span> (j == total_times - <span class="number">1</span>):            last_softmax_action = actor_network(final_state)            last_action = torch.exp(last_softmax_action)            last_choose_action = np.random.choice(<span class="number">4</span>, p=last_action.cpu().data.numpy()[<span class="number">0</span>])            last_throughput = TestThroughput[train_time + <span class="number">8</span>]            last_buffer, last_rebuffer = updateBuffer(CurrentBufferSize, last_choose_action, last_throughput)            final_r = Reward(last_action, LastBitRate, last_rebuffer)    <span class="keyword">return</span> states,actions,rewards,buffers,final_r,action_all,rebuffer_all</code></pre><p>这一部分的思路是在每个视频快获取到状态信息，然后送入actor网络根据网络输出选择特定的比特率,然后更新到下一个状态并计算出此选择的奖励值，这样循环下去直到这个视频播放完毕。在这个过程中我们只进行选择但不进行网络更新，返回值主要包括以下参数： 这一段视频中的所有状态信息（以矩阵的形式存储在states中）、每个状态下选择的动作的one_hot编码表示（以矩阵的形式存储在actions中，每个元素都是用[1，0，0，0]、[0，1，0，0]、[0，0，1，0]、[0，0，0，1]表示）、每个状态下的动作（以矩阵的形式存储在action_all中，每个元素都是0，1，2，3来表示不同的比特率)、每个状态下做出动作后的奖励（以矩阵形式存储在rewards中）、最后一个状态的奖励（final_r）以及每个状态下的卡段时间（以矩阵形式存储在rebuffer_all中。</p><p>上面得到了一个完整视频播放的所有信息，接下来就可以进行一次更新了。更新分为actor网络的更新和value网络的更新。更新的核心代码如下：</p><pre><code class="python">train_throughput,train_speed,train_distance,train_acce= getThroughputData(step)value_network_optim = torch.optim.Adam(value_network.parameters(), lr=decayed_learning_rate_value)actor_network_optim = torch.optim.Adam(actor_network.parameters(), lr=decayed_learning_rate_actor)states, actions, rewards, buffers, final_r, _,_ = roll_out(actor_network, value_network, train_throughput,train_speed,train_distance,train_acce)data=sum(rewards)total_reward.append(data)new_states=np.zeros([len(states),len(states[<span class="number">0</span>])],dtype=np.float32)<span class="keyword">for</span> i <span class="keyword">in</span> range(len(states)):    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(states[i])):        new_states[i][j]=states[i][j]actions_var=Variable(torch.Tensor(actions).view(<span class="number">-1</span>,<span class="number">4</span>))states_var= Variable(torch.from_numpy(new_states))<span class="comment">#train actor_network</span>actor_network_optim.zero_grad()log_softmax_actions=actor_network(states[<span class="number">0</span>])<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(states)):    log_softmax_actions=torch.cat((log_softmax_actions,actor_network(states[i])),<span class="number">0</span>)vs=value_network(states[<span class="number">0</span>]<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(states)):    vs=torch.cat((vs,value_network(states[i])),<span class="number">0</span>)vs=vs.detach()qs=Variable(torch.Tensor(discount_reward(rewards,<span class="number">0.99</span>,final_r)))advantages= qs-vsactor_network_loss=-torch.mean(torch.sum(log_softmax_actions*actions_var,<span class="number">1</span>)*advantages)total_actorloss.append(actor_network_loss.cpu().data.numpy())actor_network_loss.backward()torch.nn.utils.clip_grad_norm(actor_network.parameters(),<span class="number">0.5</span>)actor_network_optim.step()<span class="comment">#train value_network</span>value_network_optim.zero_grad()target_value =qsvalues=value_network(states[<span class="number">0</span>])<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(states)):    values=torch.cat((values,value_network(states[i])),<span class="number">0</span>)criterion =nn.MSELoss()       target_value  = target_value.view(<span class="number">-1</span>,<span class="number">1</span>)<span class="comment">#print(target_value.size())</span>value_network_loss=criterion(values,target_value)value_network_loss.backward()torch.nn.utils.clip_grad_norm(value_network.parameters(),<span class="number">0.5</span>)value_network_optim.step()total_valueloss.append(value_network_loss.cpu().data.numpy())</code></pre><p>actor网络是根据梯度上升来进行更新的。<br><img src="https://i.imgur.com/fvv5OkX.png" alt=""></p><p>actor网络更新需要log_sofmax动作概率以及优势函数A(st,at)=Q(st,at)-V(st,w).其中log_softmax动作概率由action网络得到，Q(st,at)由实际选择获得的即时奖励与折扣因子计算得到，V（st,w）由critic网络得到。</p><p>critic网络根据梯度下降来进行更新的。<br><img src="https://i.imgur.com/zzYS6lm.png" alt=""></p><p>critic网络更新需要即时奖励rt，下一个状态的价值函数V(st+1)以及这个状态的状态价值V(st).其中rt是根据实际值得到的QoE,V(st+1)和V(st)是根据critic网络得到的。</p><p>上面完成的就是一次完整的视频播放及更新过程。在设置好训练次数进行多次的更新即可达到稳定值。在这个心目中，我们大概训练15000次左右就能达到稳定的reward值。我们在训练过程中主要是根据actor-loss和value-loss来进行网络参数的调整，经过尝试，对网络效果影响最大的参数是actor和value网络的学习率，最终，我们发现两者在0.00003和0.01左右事能达到较好的效果。</p><p>在下一节，我们主要展示训练得到的结果以及将要介绍一下其他自适应比特率算法。</p><p>本节是项目的重点，中间网络的训练我们采取了较为简单的actor-critic网络来训练，后续我们将在网络结构以及考虑用异步actor-critic（A3C）算法来提升训练速度和效果。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="强化学习" scheme="https://leesen998.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习基础" scheme="https://leesen998.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>实战深度强化学习DQN-理论和实践</title>
    <link href="https://leesen998.github.io/2018/04/19/%E5%AE%9E%E6%88%98%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0DQN-%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5/"/>
    <id>https://leesen998.github.io/2018/04/19/实战深度强化学习DQN-理论和实践/</id>
    <published>2018-04-19T11:48:29.000Z</published>
    <updated>2019-03-22T03:58:18.876Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0B/0F/ChMlWlyAyIiIQH8pABv6qMmlUWEAAIp0AAv7LcAG_rA821.jpg" alt="" style="width:100%"></p><a id="more"></a><h1 id="1、Q-learning回顾"><a href="#1、Q-learning回顾" class="headerlink" title="1、Q-learning回顾"></a>1、Q-learning回顾</h1><p>Q-learning 的 算法过程如下图所示：</p><p><img src="https:////upload-images.jianshu.io/upload_images/4155986-d07028ff460d5979.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>在Q-learning中，我们维护一张Q值表，表的维数为：状态数S * 动作数A，表中每个数代表在当前状态S下可以采用动作A可以获得的未来收益的折现和。我们不断的迭代我们的Q值表使其最终收敛，然后根据Q值表我们就可以在每个状态下选取一个最优策略。</p><p>Q值表的更新公式为：</p><p><img src="https:////upload-images.jianshu.io/upload_images/4155986-23e17f9c5b81efce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/992/format/webp" alt="img"></p><p>公式中，Q(S,A) 我们可以称做Q估计值，即我们当前估计的Q值，而：</p><p><img src="https:////upload-images.jianshu.io/upload_images/4155986-4035ec3ed3ef5d87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/486/format/webp" alt="img"></p><p>称为Q-target，即我们使用贝尔曼方程加贪心策略认为实际应该得到的奖励，我们的目标就是使我们的Q值不断的接近Q-target值。</p><h1 id="2、深度Q网络-Deep-Q-Network"><a href="#2、深度Q网络-Deep-Q-Network" class="headerlink" title="2、深度Q网络(Deep - Q - Network)"></a>2、深度Q网络(Deep - Q - Network)</h1><h2 id="2-1-DQN简介"><a href="#2-1-DQN简介" class="headerlink" title="2.1 DQN简介"></a>2.1 DQN简介</h2><p><strong>为什么会出现DQN呢</strong><br> 在普通的Q-learning中，当状态和动作空间是离散且维数不高时可使用Q-Table储存每个状态动作对的Q值，而当状态和动作空间是高维连续时，使用Q-Table不现实。</p><p><strong>两篇DQN奠基之作</strong></p><p>[1]<a href="https://link.jianshu.com?t=https%3A%2F%2Fpdfs.semanticscholar.org%2F667f%2Fb84bfca10bec165f9e2cca3e21f5e4829ca7.pdf" target="_blank" rel="noopener">Playing Atari with Deep Reinforcement Learning</a><br> [2]<a href="https://link.jianshu.com?t=http%3A%2F%2Fwww.nature.com%2Fnature%2Fjournal%2Fv518%2Fn7540%2Fabs%2Fnature14236.html" target="_blank" rel="noopener">Human-level control through deep reinforcement learning</a></p><p><strong>如何将原始的Q-learning转换成深度学习问题</strong><br> 将Q-Table的更新问题变成一个函数拟合问题，相近的状态得到相近的输出动作。如下式，通过更新参数 θ 使Q函数逼近最优Q值 。因此，DQN就是要设计一个神经网络结构，通过函数来拟合Q值，即：</p><p><img src="https:////upload-images.jianshu.io/upload_images/4155986-4a043cff8b6469f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/342/format/webp" alt="img"></p><h2 id="2-2-DL和RL结合带来的问题"><a href="#2-2-DL和RL结合带来的问题" class="headerlink" title="2.2 DL和RL结合带来的问题"></a>2.2 DL和RL结合带来的问题</h2><p>1、DL需要大量带标签的样本进行监督学习；RL只有reward返回值，而且伴随着噪声，延迟（过了几十毫秒才返回），稀疏（很多State的reward是0）等问题；<br> 2、DL的样本独立；RL前后state状态相关；<br> 3、DL目标分布固定；RL的分布一直变化，比如你玩一个游戏，一个关卡和下一个关卡的状态分布是不同的，所以训练好了前一个关卡，下一个关卡又要重新训练；<br> 4、过往的研究表明，使用非线性网络表示值函数时出现不稳定等问题。</p><h2 id="2-3-DQN解决问题方法"><a href="#2-3-DQN解决问题方法" class="headerlink" title="2.3 DQN解决问题方法"></a>2.3 DQN解决问题方法</h2><p>那么DQN是如何解决上述问题的呢？</p><p>1、通过Q-Learning使用reward来构造标签（对应问题1）<br> 2、通过experience replay（经验池）的方法来解决相关性及非静态分布问题（对应问题2、3）<br> 3、使用一个神经网络产生当前Q值，使用另外一个神经网络产生Target Q值（对应问题4）</p><p><strong>构造标签</strong><br> 对于函数优化问题，监督学习的一般方法是先确定Loss Function，然后求梯度，使用随机梯度下降等方法更新参数。DQN则基于Q-Learning来确定Loss Function。我们想要使q-target值和q-eval值相差越小越好。DQN中的损失函数是：</p><p><img src="https:////upload-images.jianshu.io/upload_images/4155986-942f42c0296e9b43.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/316/format/webp" alt="img"></p><p>这里yi是根据上一个迭代周期或者说target-net网络的参数计算出的q-target值，跟当前网络结构中的参数无关，yi的计算如下：</p><p><img src="https:////upload-images.jianshu.io/upload_images/4155986-c72188e8486b477a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/874/format/webp" alt="img"></p><p>这样，整个目标函数就可以通过随机梯度下降方法来进行优化：</p><p><img src="https:////upload-images.jianshu.io/upload_images/4155986-75b8ec056073baae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p><strong>经验回放</strong><br> 经验池的功能主要是解决相关性及非静态分布问题。具体做法是把每个时间步agent与环境交互得到的转移样本 (st,at,rt,st+1) 储存到回放记忆单元，要训练时就随机拿出一些（minibatch）来训练。（其实就是将游戏的过程打成碎片存储，训练时随机抽取就避免了相关性问题）</p><p><strong>双网络结构</strong><br> 在Nature 2015版本的DQN中提出了这个改进，使用另一个网络（这里称为target_net）产生Target Q值。具体地，Q(s,a;θi) 表示当前网络eval_net的输出，用来评估当前状态动作对的值函数；Q(s,a;θ−i) 表示target_net的输出，代入上面求 TargetQ 值的公式中得到目标Q值。根据上面的Loss Function更新eval_net的参数，每经过N轮迭代，将MainNet的参数复制给target_net。</p><p>引入target_net后，再一段时间里目标Q值使保持不变的，一定程度降低了当前Q值和目标Q值的相关性，提高了算法稳定性。</p><h2 id="2-4-DQN算法流程"><a href="#2-4-DQN算法流程" class="headerlink" title="2.4 DQN算法流程"></a>2.4 DQN算法流程</h2><p><strong>NIPS 2013版</strong></p><p><img src="https:////upload-images.jianshu.io/upload_images/4155986-5710fdadc565c0dc?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p><strong>Nature 2015版</strong></p><p><img src="https:////upload-images.jianshu.io/upload_images/4155986-14d930f99a102729?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>可以看到，两版的DQN都使用了经验池，而2015版的DQN增加了target-net，提高了算法稳定性。</p><h1 id="3、DQN实现DEMO"><a href="#3、DQN实现DEMO" class="headerlink" title="3、DQN实现DEMO"></a>3、DQN实现DEMO</h1><p>找了很多DQN的例子，有原版的实现Atari的，也有Flappy Bird的，但是最简单的还是莫烦大神的Demo，github地址是：<a href="https://link.jianshu.com?t=https%3A%2F%2Fgithub.com%2FMorvanZhou%2FReinforcement-learning-with-tensorflow" target="_blank" rel="noopener">https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow</a>。</p><p>在介绍整个Demo前，我们介绍两种DQN的实现方式，一种是将s和a输入到网络，得到q值，另一种是只将s输入到网络，输出为s和每个a结合的q值。这里莫烦大神的代码采取了后一种方式。</p><p>如果你对DQN的原理有比较深刻的认识，那么读莫烦大神的代码也并不是十分困难。这里我们想要实现的效果类似于寻宝。</p><p><img src="https:////upload-images.jianshu.io/upload_images/4155986-fd3c59c61907c4ad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/542/format/webp" alt="img"></p><p>其中，红色的方块代表寻宝人，黑色的方块代表陷阱，黄色的方块代表宝藏，我们的目标就是让寻宝人找到最终的宝藏。</p><p>这里，我们的状态可以用横纵坐标表示，而动作有上下左右四个动作。使用tkinter来做这样一个动画效果。宝藏的奖励是1，陷阱的奖励是-1，而其他时候的奖励都为0。</p><p>接下来，我们重点看一下我们DQN相关的代码。<br> <strong>定义相关输入</strong><br> 这了，我们用s代表当前状态，用a代表当前状态下采取的动作，r代表获得的奖励，s_代表转移后的状态。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">self.s = tf.placeholder(tf.float32,[<span class="keyword">None</span>,self.n_features],name=<span class="string">'s'</span>)</span><br><span class="line">self.s_ = tf.placeholder(tf.float32,[<span class="keyword">None</span>,self.n_features],name=<span class="string">'s_'</span>)</span><br><span class="line">self.r = tf.placeholder(tf.float32,[<span class="keyword">None</span>,],name=<span class="string">'r'</span>)</span><br><span class="line">self.a = tf.placeholder(tf.int32,[<span class="keyword">None</span>,],name=<span class="string">'a'</span>)</span><br></pre></td></tr></table></figure><p><strong>经验池</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">store_transition</span><span class="params">(self,s,a,r,s_)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">'memory_counter'</span>):</span><br><span class="line">        self.memory_counter = <span class="number">0</span></span><br><span class="line">    <span class="comment"># hstack:Stack arrays in sequence horizontally</span></span><br><span class="line">    transition = np.hstack((s,[a,r],s_))</span><br><span class="line">    index = self.memory_counter % self.memory_size</span><br><span class="line">    self.memory[index,:] = transition</span><br><span class="line">    self.memory_counter += <span class="number">1</span></span><br></pre></td></tr></table></figure><p><strong>双网络结构</strong><br> target_net和eval_net的网络结构必须保持一致，这里我们使用的是两层全链接的神经网络，值得注意的一点是对于eval_net来说，网络的输入是当前的状态s，而对target_net网络来说，网络的输入是下一个状态s_，因为target_net的输出要根据贝尔曼公式计算q-target值，即</p><p><img src="https:////upload-images.jianshu.io/upload_images/4155986-4035ec3ed3ef5d87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/486/format/webp" alt="img"></p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">w_initializer, b_initializer = tf.random_normal_initializer(<span class="number">0.</span>, <span class="number">0.3</span>), tf.constant_initializer(<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------ build evaluate_net ------------------</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'eval_net'</span>):</span><br><span class="line">    e1 = tf.layers.dense(self.s,<span class="number">20</span>,tf.nn.relu,kernel_initializer=w_initializer,</span><br><span class="line">                         bias_initializer=b_initializer,name=<span class="string">'e1'</span></span><br><span class="line">                         )</span><br><span class="line"></span><br><span class="line">    self.q_eval = tf.layers.dense(e1,self.n_actions,kernel_initializer=w_initializer,</span><br><span class="line">                                  bias_initializer=b_initializer,name=<span class="string">'q'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------ build target_net ------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'target_net'</span>):</span><br><span class="line">    t1 = tf.layers.dense(self.s_, <span class="number">20</span>, tf.nn.relu, kernel_initializer=w_initializer,</span><br><span class="line">                         bias_initializer=b_initializer, name=<span class="string">'t1'</span>)</span><br><span class="line">    self.q_next = tf.layers.dense(t1, self.n_actions, kernel_initializer=w_initializer,</span><br><span class="line">                                  bias_initializer=b_initializer, name=<span class="string">'t2'</span>)</span><br></pre></td></tr></table></figure><p>每隔一定的步数，我们就要将target_net中的参数复制到eval_net中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=<span class="string">'target_net'</span>)</span><br><span class="line">e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=<span class="string">'eval_net'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'soft_replacement'</span>):</span><br><span class="line">      self.target_replace_op = [tf.assign(t,e) <span class="keyword">for</span> t,e <span class="keyword">in</span> zip(t_params,e_params)]</span><br></pre></td></tr></table></figure><p><strong>计算损失并优化</strong><br> 首先，对于eval_net来说，我们只要得到当前的网络输出即可，但是我们定义的网络输出是四个动作对应的q-eval值，我们要根据实际的a来选择对应的q-eval值，这一部分的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'q_eval'</span>):</span><br><span class="line">    <span class="comment"># tf.stack</span></span><br><span class="line">    <span class="comment">#a = tf.constant([1,2,3])</span></span><br><span class="line">    <span class="comment"># b = tf.constant([4,5,6])</span></span><br><span class="line">    <span class="comment"># c = tf.stack([a,b],axis=1)</span></span><br><span class="line">    <span class="comment"># [[1 4]</span></span><br><span class="line">    <span class="comment">#  [2 5]</span></span><br><span class="line">    <span class="comment"># [3 6]]</span></span><br><span class="line">    a_indices = tf.stack([tf.range(tf.shape(self.a)[<span class="number">0</span>], dtype=tf.int32), self.a], axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 用indices从张量params得到新张量</span></span><br><span class="line">    <span class="comment"># indices = [[0, 0], [1, 1]]</span></span><br><span class="line">    <span class="comment"># params = [['a', 'b'], ['c', 'd']]</span></span><br><span class="line">    <span class="comment"># output = ['a', 'd']</span></span><br><span class="line">    <span class="comment"># 这里self.q_eval是batch * action_number,a_indices是batch * 1，也就是说选择当前估计每个动作的Q值</span></span><br><span class="line">    self.q_eval_wrt_a = tf.gather_nd(params=self.q_eval, indices=a_indices)</span><br></pre></td></tr></table></figure><p>中间有几个函数不太了解的，上面都有详细的注释，如果还不是很理解的话，大家可以百度或者阅读相应函数的源码。</p><p>对于target_net网络来说，我们要根据下面的式子来计算q-target值：</p><p><img src="https:////upload-images.jianshu.io/upload_images/4155986-4035ec3ed3ef5d87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/486/format/webp" alt="img"></p><p>第一部分的R我们是已经得到了的，剩下的就是根据贪心策略选择四个输出中最大的一个即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'q_target'</span>):</span><br><span class="line">    q_target = self.r + self.gamma * tf.reduce_max(self.q_next,axis=<span class="number">1</span>,name=<span class="string">'Qmax_s_'</span>)</span><br><span class="line">    <span class="comment"># 一个节点被 stop之后，这个节点上的梯度，就无法再向前BP了</span></span><br><span class="line">    self.q_target = tf.stop_gradient(q_target)</span><br></pre></td></tr></table></figure><p>接下来，我们就可以定义我们的损失函数并选择优化器进行优化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'loss'</span>):</span><br><span class="line">    self.loss = tf.reduce_mean(tf.squared_difference(self.q_target,self.q_eval_wrt_a,name=<span class="string">'TD_error'</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'train'</span>):</span><br><span class="line">    self._train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)</span><br></pre></td></tr></table></figure><p><strong>网络的训练</strong><br> 每隔一定的步数，我们就要将eval_net中的参数复制到target_net中，同时我们要从经验池中选择batch大小的数据输入到网络中进行训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">learn</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> self.learn_step_counter % self.replace_target_iter == <span class="number">0</span>:</span><br><span class="line">        self.sess.run(self.target_replace_op)</span><br><span class="line">        print(<span class="string">'\ntarget_params_replaced\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.memory_counter &gt; self.memory_size:</span><br><span class="line">        sample_index = np.random.choice(self.memory_size,size=self.batch_size)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        sample_index = np.random.choice(self.memory_counter,size = self.batch_size)</span><br><span class="line"></span><br><span class="line">    batch_memory = self.memory[sample_index,:]</span><br><span class="line"></span><br><span class="line">    _,cost = self.sess.run(</span><br><span class="line">        [self._train_op,self.loss],</span><br><span class="line">        feed_dict=&#123;</span><br><span class="line">            self.s:batch_memory[:,:self.n_features],</span><br><span class="line">            self.a:batch_memory[:,self.n_features],</span><br><span class="line">            self.r:batch_memory[:,self.n_features+<span class="number">1</span>],</span><br><span class="line">            self.s_:batch_memory[:,-self.n_features:]</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>剩下的代码就不介绍啦，跟着进行练习，相信会对DQN的原理有一个更进一步的认识。</p>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0B/0F/ChMlWlyAyIiIQH8pABv6qMmlUWEAAIp0AAv7LcAG_rA821.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="强化学习" scheme="https://leesen998.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习实践" scheme="https://leesen998.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>DQN三大改进(二)-Prioritised replay</title>
    <link href="https://leesen998.github.io/2018/03/19/DQN%E4%B8%89%E5%A4%A7%E6%94%B9%E8%BF%9B(%E4%BA%8C)-Prioritised%20replay/"/>
    <id>https://leesen998.github.io/2018/03/19/DQN三大改进(二)-Prioritised replay/</id>
    <published>2018-03-19T11:48:29.000Z</published>
    <updated>2019-03-22T03:52:02.557Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0B/0F/ChMlWlyAyIiIQH8pABv6qMmlUWEAAIp0AAv7LcAG_rA821.jpg" alt="" style="width:100%"></p><a id="more"></a><h1 id="DQN三大改进-二-Prioritised-replay"><a href="#DQN三大改进-二-Prioritised-replay" class="headerlink" title="DQN三大改进(二)-Prioritised replay"></a>DQN三大改进(二)-Prioritised replay</h1><h1 id="1、背景"><a href="#1、背景" class="headerlink" title="1、背景"></a>1、背景</h1><p>我们简单回顾一下DQN的过程(这里是2015版的DQN)：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-9fef6ee4dcf856a1?imageMogr2/auto-orient/strip%7CimageView2/2/w/700/format/webp" alt="img"></p><p>DQN中有两个关键的技术，叫做经验回放和双网络结构。</p><p>DQN中的损失函数定义为：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-03f9734450028881?imageMogr2/auto-orient/strip%7CimageView2/2/w/316/format/webp" alt="img"></p><p>其中，yi也被我们称为q-target值，而后面的Q(s,a)我们称为q-eval值，我们希望q-target和q-eval值越接近越好。</p><p>q-target如何计算呢？根据下面的公式：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-ec89daa12307440c?imageMogr2/auto-orient/strip%7CimageView2/2/w/405/format/webp" alt="img"></p><p>上面的两个公式分别截取自两篇不同的文章，所以可能有些出入。我们之前说到过，我们有经验池存储的历史经验，经验池中每一条的结构是(s,a,r,s’)，我们的q-target值根据该轮的奖励r以及将s’输入到target-net网络中得到的Q(s’,a’)的最大值决定。</p><p>经验回放的功能主要是解决相关性及非静态分布问题。具体做法是把每个时间步agent与环境交互得到的转移样本 (st,at,rt,st+1) 储存到回放记忆单元，要训练时就随机拿出一些（minibatch）来训练。（其实就是将游戏的过程打成碎片存储，训练时随机抽取就避免了相关性问题）</p><p>但是经验回放也存在一定的问题，在奖励十分少的时候，会出现学习速度非常慢的问题。在新的文章中，提出了一种“Blind Cliffwalk”的环境。来示例说明当奖赏非常rare的时候，探索所遇到的挑战。假设仅有 n 个状态，这个环境就要求足够的随机步骤知道得到第一个非零奖励；确切的讲，随机的选择动作序列就会有 2−n的概率才能得到第一个非零奖赏。此外，最相关的 transitions 却藏在大量的失败的尝试当中。“Blind Cliffwalk”环境如下图所示：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-5ddd082f6ef04c40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/862/format/webp" alt="img"></p><p>为了有效的解决上述的问题，提出了Prioritized replay的做法，我们先看看文中给出的算法流程：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-4ead700b9c3c42af..png?imageMogr2/auto-orient/strip%7CimageView2/2/w/748/format/webp" alt="img"></p><p>这一套算法重点就在我们 batch 抽样的时候并不是随机抽样, 而是按照 Memory 中的样本优先级来抽. 所以这能更有效地找到我们需要学习的样本. 样本的优先级如何确定？我们可以用到 <strong>TD-error</strong>, 也就是 q-target - q-eval 来规定优先学习的程度. 如果 TD-error 越大, 就代表我们的预测精度还有很多上升空间, 那么这个样本就越需要被学习, 也就是优先级 p 越高.</p><p>优先级的计算基于如下公式：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-39978d2a00a4dc33.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/320/format/webp" alt="img"></p><p>式中的pi即我们计算的TD-error。</p><p>有了 TD-error 就有了优先级 p, 那我们如何有效地根据 p 来抽样呢? 如果每次抽样都需要针对 p 对所有样本排序, 这将会是一件非常消耗计算能力的事. 文中提出了一种被称作<strong>SumTree</strong>的方法。</p><p>SumTree 是一种树形结构, 每片树叶存储每个样本的优先级 p, 每个树枝节点只有两个分叉, 节点的值是两个分叉的合, 所以 SumTree 的顶端就是所有 p 的合. 如下图所示。最下面一层树叶存储样本的 p, 叶子上一层最左边的 13 = 3 + 10, 按这个规律相加, 顶层的 root 就是全部 p 的合了.</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-722ed5e61722e494.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>抽样时, 我们会将 p 的总合 除以 batch size, 分成 batch size 那么多区间, (n=sum(p)/batch_size). 如果将所有 node 的 priority 加起来是42的话, 我们如果抽6个样本, 这时的区间拥有的 priority 可能是这样.</p><p>[0-7], [7-14], [14-21], [21-28], [28-35], [35-42]</p><p>然后在每个区间里随机选取一个数. 比如在第区间 [21-28] 里选到了24, 就按照这个 24 从最顶上的42开始向下搜索. 首先看到最顶上 42 下面有两个 child nodes, 拿着手中的24对比左边的 child 29, 如果 左边的 child 比自己手中的值大, 那我们就走左边这条路, 接着再对比 29 下面的左边那个点 13, 这时, 手中的 24 比 13 大, 那我们就走右边的路, 并且将手中的值根据 13 修改一下, 变成 24-13 = 11. 接着拿着 11 和 13 左下角的 12 比, 结果 12 比 11 大, 那我们就选 12 当做这次选到的 priority, 并且也选择 12 对应的数据.</p><h1 id="2、代码实现"><a href="#2、代码实现" class="headerlink" title="2、代码实现"></a>2、代码实现</h1><p><img src="https://upload-images.jianshu.io/upload_images/4155986-c7f26991da0b2f47?imageMogr2/auto-orient/strip%7CimageView2/2/w/542/format/webp" alt="img"></p><p>其中，红色的方块代表寻宝人，黑色的方块代表陷阱，黄色的方块代表宝藏，我们的目标就是让寻宝人找到最终的宝藏。</p><p>这里，我们的状态可以用横纵坐标表示，而动作有上下左右四个动作。使用tkinter来做这样一个动画效果。宝藏的奖励是1，陷阱的奖励是-1，而其他时候的奖励都为0。</p><p>接下来，我们重点看一下我们Prioritised replay Double-DQN相关的代码。</p><p><strong>定义输入</strong></p><p>在通过梯度下降法进行参数更新时，由于需要加入权重项，因此增加了ISWeigths这一个输入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#---------------------input----------------------</span></span><br><span class="line">self.s = tf.placeholder(tf.float32,[<span class="keyword">None</span>,self.n_features],name=<span class="string">'s'</span>)</span><br><span class="line">self.q_target = tf.placeholder(tf.float32,[<span class="keyword">None</span>,self.n_actions],name=<span class="string">'Q_target'</span>)</span><br><span class="line">self.s_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, self.n_features], name=<span class="string">'s_'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> self.prioritized:</span><br><span class="line">    self.ISWeights = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">1</span>],name=<span class="string">'IS_weights'</span>)</span><br></pre></td></tr></table></figure><p><strong>定义双网络结构</strong><br>这里我们的双网络结构都简单的采用简单的全链接神经网络，包含一个隐藏层。这里我们得到的输出是一个向量，表示该状态才取每个动作可以获得的Q值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_layers</span><span class="params">(s, c_names, n_l1, w_initializer, b_initializer, trainable)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'l1'</span>):</span><br><span class="line">        w1 = tf.get_variable(<span class="string">'w1'</span>, [self.n_features, n_l1], initializer=w_initializer, collections=c_names, trainable=trainable)</span><br><span class="line">        b1 = tf.get_variable(<span class="string">'b1'</span>, [<span class="number">1</span>, n_l1], initializer=b_initializer, collections=c_names,  trainable=trainable)</span><br><span class="line">        l1 = tf.nn.relu(tf.matmul(s, w1) + b1)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'l2'</span>):</span><br><span class="line">        w2 = tf.get_variable(<span class="string">'w2'</span>, [n_l1, self.n_actions], initializer=w_initializer, collections=c_names,  trainable=trainable)</span><br><span class="line">        b2 = tf.get_variable(<span class="string">'b2'</span>, [<span class="number">1</span>, self.n_actions], initializer=b_initializer, collections=c_names,  trainable=trainable)</span><br><span class="line">        out = tf.matmul(l1, w2) + b2</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>接下来，我们定义两个网络：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ---------------------eval net -----------------</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'eval_net'</span>):</span><br><span class="line">    c_names, n_l1, w_initializer, b_initializer = \</span><br><span class="line">        [<span class="string">'eval_net_params'</span>, tf.GraphKeys.GLOBAL_VARIABLES], <span class="number">20</span>, \</span><br><span class="line">        tf.random_normal_initializer(<span class="number">0.</span>, <span class="number">0.3</span>), tf.constant_initializer(<span class="number">0.1</span>)  <span class="comment"># config of layers</span></span><br><span class="line"></span><br><span class="line">    self.q_eval = build_layers(self.s, c_names, n_l1, w_initializer, b_initializer, <span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------target net----------------</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'target_net'</span>):</span><br><span class="line">    c_names = [<span class="string">'target_net_params'</span>, tf.GraphKeys.GLOBAL_VARIABLES]</span><br><span class="line">    self.q_next = build_layers(self.s_, c_names, n_l1, w_initializer, b_initializer, <span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><p><strong>定义损失和优化器</strong><br>接下来，我们定义我们的损失，和DQN一样，我们使用的是平方损失，但是此时我们的损失是有权重的！：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># --------------------loss and train -----------</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'loss'</span>):</span><br><span class="line">    <span class="keyword">if</span> self.prioritized:</span><br><span class="line">        self.abs_errors = tf.reduce_sum(tf.abs(self.q_target - self.q_eval), axis=<span class="number">1</span>)    <span class="comment"># for updating Sumtree</span></span><br><span class="line">        self.loss = tf.reduce_mean(self.ISWeights * tf.squared_difference(self.q_target, self.q_eval))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval))</span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'train'</span>):</span><br><span class="line">    self._train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)</span><br></pre></td></tr></table></figure><p><strong>定义SumTree类</strong><br>定义完我们的网络结构之后，我们介绍两个辅助类，一个是用于Sample的SumTree类，另一个是用于记忆存储和读取的Memory类。</p><p>在初始化我们的SumTree类时，我们要定义好树的容量，即经验池的容量，以及用于存储优先级的tree结构和存储数据的data。tree结构我们使用一维数组实现，采取从上往下，从左往右的层次结构进行存储,同时，我们定义一个返回树根节点也就是树中叶子结点总优先级的函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,capacity)</span>:</span></span><br><span class="line">    self.capacity = capacity</span><br><span class="line">    self.data_pointer = <span class="number">0</span></span><br><span class="line">    self.tree = np.zeros(<span class="number">2</span> * capacity - <span class="number">1</span>)</span><br><span class="line">    self.data = np.zeros(capacity,dtype=object)</span><br><span class="line"></span><br><span class="line"><span class="meta">@property</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">total_p</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.tree[<span class="number">0</span>]  <span class="comment"># the root</span></span><br></pre></td></tr></table></figure><p>接下来，我们定义一个用于添加数据的add函数，在添加数据的时候会触发我们的update函数，用于更新树中节点的值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self,p,data)</span>:</span></span><br><span class="line">    tree_idx = self.data_pointer + self.capacity - <span class="number">1</span></span><br><span class="line">    self.data[self.data_pointer] = data</span><br><span class="line">    self.update(tree_idx,p)</span><br><span class="line"></span><br><span class="line">    self.data_pointer += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> self.data_pointer &gt;= self.capacity:  <span class="comment"># replace when exceed the capacity</span></span><br><span class="line">        self.data_pointer = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>刚才提到了，在添加数据的时候，由于某个叶子结点的数值改变了，那么它的一系列父节点的数值也会发生改变，所以我们定义了一个update函数如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self,tree_idx,p)</span>:</span></span><br><span class="line">    change = p - self.tree[tree_idx]</span><br><span class="line">    self.tree[tree_idx] = p</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> tree_idx!=<span class="number">0</span>:</span><br><span class="line">        tree_idx = (tree_idx - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">        self.tree[tree_idx] += change</span><br></pre></td></tr></table></figure><p>最后，我们要定义一个根据数字来采样节点的算法，如何采样我们刚才已经介绍过了，即从头节点开始，每次决定往左还是往右，直到到达叶子结点为止，并返回叶子结点的id，优先级以对应的转移数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_leaf</span><span class="params">(self,v)</span>:</span></span><br><span class="line">    parent_idx = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        cl_idx = <span class="number">2</span> * parent_idx + <span class="number">1</span></span><br><span class="line">        cr_idx = cl_idx + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> cl_idx &gt;= len(self.tree):</span><br><span class="line">            leaf_idx = parent_idx</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> v &lt;= self.tree[cl_idx]:</span><br><span class="line">                parent_idx = cl_idx</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                v -= self.tree[cl_idx]</span><br><span class="line">                parent_idx = cr_idx</span><br><span class="line">    data_idx = leaf_idx - self.capacity + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> leaf_idx,self.tree[leaf_idx],self.data[data_idx]</span><br></pre></td></tr></table></figure><p><strong>定义Memory类</strong><br>在初始化时，我们首先要定义好我们的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, capacity)</span>:</span></span><br><span class="line">    self.tree = SumTree(capacity)</span><br><span class="line">    self.epsilon = <span class="number">0.01</span>  <span class="comment"># small amount to avoid zero priority</span></span><br><span class="line">    self.alpha = <span class="number">0.6</span>  <span class="comment"># [0~1] convert the importance of TD error to priority</span></span><br><span class="line">    self.beta = <span class="number">0.4</span>  <span class="comment"># importance-sampling, from initial value increasing to 1</span></span><br><span class="line">    self.beta_increment_per_sampling = <span class="number">0.001</span></span><br><span class="line">    self.abs_err_upper = <span class="number">1.</span>  <span class="comment"># clipped abs error</span></span><br></pre></td></tr></table></figure><p>接下来，我们定义一个store函数，用于将新的经验数据存储到Sumtree中，我们定义了一个abs_err_upper和epsilon ，表明p的范围在[epsilon,abs_err_upper]之间，对于第一条存储的数据，我们认为它的优先级P是最大的，同时，对于新来的数据，我们也认为它的优先级与当前树中优先级最大的经验相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">store</span><span class="params">(self, transition)</span>:</span></span><br><span class="line">    max_p = np.max(self.tree.tree[-self.tree.capacity:])</span><br><span class="line">    <span class="keyword">if</span> max_p == <span class="number">0</span>:</span><br><span class="line">        max_p = self.abs_err_upper</span><br><span class="line">    self.tree.add(max_p, transition)   <span class="comment"># set the max p for new p</span></span><br></pre></td></tr></table></figure><p>随后，我们定义了一个采样函数,根据batch的大小对经验进行采样，采样的过程如我们上面所讲的，调用的是tree.get_leaf方法。同时在采样的过程中，我们还要计算在进行参数更新时每条数据的权重，代码之中权重的计算是对原文中的公式进行了修改，如下图所示：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-b652693262b54768.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>因此，我们的代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(self,n)</span>:</span></span><br><span class="line">    b_idx,b_memory,ISWeights = np.empty((n,),dtype=np.int32),np.empty((n,self.tree.data[<span class="number">0</span>].size)),np.empty((n,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    pri_seg = self.tree.total_p / n</span><br><span class="line"></span><br><span class="line">    self.beta = np.min([<span class="number">1.</span>, self.beta + self.beta_increment_per_sampling])</span><br><span class="line"></span><br><span class="line">    min_prob = np.min(self.tree.tree[-self.tree.capacity:]) / self.tree.total_p  <span class="comment"># for later calculate ISweight</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        a, b = pri_seg * i, pri_seg * (i + <span class="number">1</span>)</span><br><span class="line">        v = np.random.uniform(a, b)</span><br><span class="line">        idx, p, data = self.tree.get_leaf(v)</span><br><span class="line">        prob = p / self.tree.total_p</span><br><span class="line">        ISWeights[i, <span class="number">0</span>] = np.power(prob/min_prob, -self.beta)</span><br><span class="line">        b_idx[i], b_memory[i, :] = idx, data</span><br><span class="line">    <span class="keyword">return</span> b_idx, b_memory, ISWeights</span><br></pre></td></tr></table></figure><p>最后，我们还定义了一个更新树中权重的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_update</span><span class="params">(self, tree_idx, abs_errors)</span>:</span></span><br><span class="line">    abs_errors += self.epsilon  <span class="comment"># convert to abs and avoid 0</span></span><br><span class="line">    clipped_errors = np.minimum(abs_errors, self.abs_err_upper)</span><br><span class="line">    ps = np.power(clipped_errors, self.alpha)</span><br><span class="line">    <span class="keyword">for</span> ti, p <span class="keyword">in</span> zip(tree_idx, ps):</span><br><span class="line">        self.tree.update(ti, p)</span><br></pre></td></tr></table></figure><p><strong>选择action</strong><br>选择action的代码没有变化，仍然采用e-greedy算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_action</span><span class="params">(self, observation)</span>:</span></span><br><span class="line">    observation = observation[np.newaxis, :]</span><br><span class="line">    <span class="keyword">if</span> np.random.uniform() &lt; self.epsilon:</span><br><span class="line">        actions_value = self.sess.run(self.q_eval, feed_dict=&#123;self.s: observation&#125;)</span><br><span class="line">        action = np.argmax(actions_value)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        action = np.random.randint(<span class="number">0</span>, self.n_actions)</span><br><span class="line">    <span class="keyword">return</span> action</span><br></pre></td></tr></table></figure><p><strong>存储经验</strong><br>由于我们定义了专门的Memory类，因此在存储经验的时候，直接调用该类的store方法即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">store</span><span class="params">(self,s,a,r,s_)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> self.prioritized:</span><br><span class="line">        transition = np.hstack((s, [a, r], s_))</span><br><span class="line">        self.memory.store(transition)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># random replay</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">'memory_counter'</span>):</span><br><span class="line">            self.memory_counter = <span class="number">0</span></span><br><span class="line">        transition = np.hstack((s, [a, r], s_))</span><br><span class="line">        index = self.memory_counter % self.memory_size</span><br><span class="line">        self.memory[index, :] = transition</span><br><span class="line">        self.memory_counter += <span class="number">1</span></span><br></pre></td></tr></table></figure><p><strong>更新target-net</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">t_params = tf.get_collection(<span class="string">'target_net_params'</span>)</span><br><span class="line">e_params = tf.get_collection(<span class="string">'eval_net_params'</span>)</span><br><span class="line"></span><br><span class="line">self.replace_target_op = [tf.assign(t, e) <span class="keyword">for</span> t, e <span class="keyword">in</span> zip(t_params, e_params)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> self.learn_step_counter % self.replace_target_iter == <span class="number">0</span>:</span><br><span class="line">    self.sess.run(self.replace_target_op)</span><br><span class="line">    print(<span class="string">'\ntarget_params_replaced\n'</span>)</span><br></pre></td></tr></table></figure><p><strong>选择batch</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.prioritized:</span><br><span class="line">    tree_idx, batch_memory, ISWeights = self.memory.sample(self.batch_size)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    sample_index = np.random.choice(self.memory_size, size=self.batch_size)</span><br><span class="line">    batch_memory = self.memory[sample_index, :]</span><br></pre></td></tr></table></figure><p><strong>更新网络参数</strong><br>这里我们采用double-dqn的网络参数更新方法，这里有三点更新，首先，我们在训练的时候要同时计算我们的td-error，其次，每次训练之后，要根据td-error对树进行更新，最后，在计算误差的时候要考虑权重项。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">q_next, q_eval = self.sess.run(</span><br><span class="line">    [self.q_next, self.q_eval],</span><br><span class="line">    feed_dict=&#123;self.s_: batch_memory[:, -self.n_features:],</span><br><span class="line">               self.s: batch_memory[:, :self.n_features]&#125;)</span><br><span class="line"></span><br><span class="line">q_target = q_eval.copy()</span><br><span class="line">batch_index = np.arange(self.batch_size, dtype=np.int32)</span><br><span class="line">eval_act_index = batch_memory[:, self.n_features].astype(int)</span><br><span class="line">reward = batch_memory[:, self.n_features + <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">q_target[batch_index, eval_act_index] = reward + self.gamma * np.max(q_next, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> self.prioritized:</span><br><span class="line">    _, abs_errors, self.cost = self.sess.run([self._train_op, self.abs_errors, self.loss],</span><br><span class="line">                                 feed_dict=&#123;self.s: batch_memory[:, :self.n_features],</span><br><span class="line">                                            self.q_target: q_target,</span><br><span class="line">                                            self.ISWeights: ISWeights&#125;)</span><br><span class="line">    self.memory.batch_update(tree_idx, abs_errors)     <span class="comment"># update priority</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    _, self.cost = self.sess.run([self._train_op, self.loss],</span><br><span class="line">                                 feed_dict=&#123;self.s: batch_memory[:, :self.n_features],</span><br><span class="line">                                            self.q_target: q_target&#125;)</span><br><span class="line"></span><br><span class="line">self.cost_his.append(self.cost)</span><br><span class="line"></span><br><span class="line">self.epsilon = self.epsilon + self.epsilon_increment <span class="keyword">if</span> self.epsilon &lt; self.epsilon_max <span class="keyword">else</span> self.epsilon_max</span><br><span class="line">self.learn_step_counter += <span class="number">1</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0B/0F/ChMlWlyAyIiIQH8pABv6qMmlUWEAAIp0AAv7LcAG_rA821.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="强化学习" scheme="https://leesen998.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习实践" scheme="https://leesen998.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>后端架构选型、离线及实时计算</title>
    <link href="https://leesen998.github.io/2018/03/16/%E7%AC%AC%E5%8D%81%E5%85%AB%E7%AB%A0_%E5%90%8E%E7%AB%AF%E6%9E%B6%E6%9E%84%E9%80%89%E5%9E%8B%E3%80%81%E7%A6%BB%E7%BA%BF%E5%8F%8A%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    <id>https://leesen998.github.io/2018/03/16/第十八章_后端架构选型、离线及实时计算/</id>
    <published>2018-03-16T11:48:29.000Z</published>
    <updated>2019-03-22T07:39:43.957Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg" alt="" style="width:100%"></p><a id="more"></a><pre><code>Markdown Revision 1;Date: 2018/11/11Editor: 梁志成Contact: superzhicheng@foxmail.com</code></pre><h2 id="18-1-为什么需要分布式计算？"><a href="#18-1-为什么需要分布式计算？" class="headerlink" title="18.1 为什么需要分布式计算？"></a>18.1 为什么需要分布式计算？</h2><p>&emsp;&emsp;在这个数据爆炸的时代，产生的数据量不断地在攀升，从GB,TB,PB,ZB.挖掘其中数据的价值也是企业在不断地追求的终极目标。但是要想对海量的数据进行挖掘，首先要考虑的就是海量数据的存储问题，比如Tb量级的数据。</p><p>&emsp;&emsp;谈到数据的存储，则不得不说的是磁盘的数据读写速度问题。早在上个世纪90年代初期，普通硬盘的可以存储的容量大概是1G左右，硬盘的读取速度大概为4.4MB/s.读取一张硬盘大概需要5分钟时间，但是如今硬盘的容量都在1TB左右了,相比扩展了近千倍。但是硬盘的读取速度大概是100MB/s。读完一个硬盘所需要的时间大概是2.5个小时。所以如果是基于TB级别的数据进行分析的话，光硬盘读取完数据都要好几天了，更谈不上计算分析了。那么该如何处理大数据的存储，计算分析呢？</p><p>&emsp;&emsp;一个很简单的减少数据读写时间的方法就是同时从多个硬盘上读写数据，比如，如果我们有100个硬盘，每个硬盘存储1%的数据 ，并行读取，那么不到两分钟就可以完成之前需要2.5小时的数据读写任务了。这就是大数据中的分布式存储的模型。当然实现分布式存储还需要解决很多问题，比如硬件故障的问题，使用多台主机进行分布式存储时，若主机故障，会出现数据丢失的问题，所以有了副本机制：系统中保存数据的副本。一旦有系统发生故障，就可以使用另外的副本进行替换（著名的RAID冗余磁盘阵列就是按这个原理实现的）。其次比如一个很大的文件如何进行拆分存储，读取拆分以后的文件如何进行校验都是要考虑的问题。比如我们使用Hadoop中的HDFS也面临这个问题，只是框架给我们实现了这些问题的解决办法，开发中开发者不用考虑这些问题，底层框架已经实现了封装。</p><p>&emsp;&emsp;同样假如有一个10TB的文件，我们要统计其中某个关键字的出现次数，传统的做法是遍历整个文件，然后统计出关键字的出现次数，这样效率会特别特别低。基于分布式存储以后，数据被分布式存储在不同的服务器上，那么我们就可以使用分布式计算框架（比如MapReduce,Spark等）来进行并行计算（或者说是分布式计算），即：每个服务器上分别统计自己存储的数据中关键字出现的次数，最后进行一次汇总，那么假如数据分布在100台服务器上，即同时100台服务器同时进行关键字统计工作，效率一下子可以提高几十倍。</p><h2 id="18-2-目前有哪些深度学习分布式计算框架？"><a href="#18-2-目前有哪些深度学习分布式计算框架？" class="headerlink" title="18.2 目前有哪些深度学习分布式计算框架？"></a>18.2 目前有哪些深度学习分布式计算框架？</h2><h3 id="18-2-1-PaddlePaddle"><a href="#18-2-1-PaddlePaddle" class="headerlink" title="18.2.1 PaddlePaddle"></a>18.2.1 PaddlePaddle</h3><p>&emsp;&emsp;PaddlePaddle【1】是百度开源的一个深度学习平台。PaddlePaddle为深度学习研究人员提供了丰富的API，可以轻松地完成神经网络配置，模型训练等任务。<br>官方文档中简易介绍了如何使用框架在</p><ul><li>线性回归</li><li>识别数字</li><li>图像分类</li><li>词向量</li><li>个性化推荐</li><li>情感分析</li><li>语义角色标注</li><li>机器翻译</li></ul><p>等方面的应用</p><p>&emsp;&emsp;Github地址：<a href="https://github.com/PaddlePaddle/Paddle" target="_blank" rel="noopener">https://github.com/PaddlePaddle/Paddle</a></p><h3 id="18-2-2-Deeplearning4j"><a href="#18-2-2-Deeplearning4j" class="headerlink" title="18.2.2 Deeplearning4j"></a>18.2.2 Deeplearning4j</h3><p>&emsp;&emsp;DeepLearning4J（DL4J）【2】是一套基于Java语言的神经网络工具包，可以构建、定型和部署神经网络。DL4J与Hadoop和Spark集成，支持分布式CPU和GPU。</p><p>&emsp;&emsp;Deeplearning4j包括了分布式、多线程的深度学习框架，以及普通的单线程深度学习框架。定型过程以集群进行，也就是说，Deeplearning4j可以快速处理大量数据。Deeplearning4j在开放堆栈中作为模块组件的功能，使之成为为微服务架构打造的深度学习框架。</p><p>&emsp;&emsp;Deeplearning4j从各类浅层网络出发，设计深层神经网络。这一灵活性使用户可以根据所需，在分布式、生产级、能够在分布式CPU或GPU的基础上与Spark和Hadoop协同工作的框架内，整合受限玻尔兹曼机、其他自动编码器、卷积网络或递归网络。</p><p>&emsp;&emsp;Deeplearning4j在已建立的各个库及其在系统整体中的所处位置</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-2.png" alt="Deeplearning4j"></p><p>&emsp;&emsp;Github地址：<a href="https://github.com/deeplearning4j/deeplearning4j" target="_blank" rel="noopener">https://github.com/deeplearning4j/deeplearning4j</a></p><h3 id="18-2-3-Mahout"><a href="#18-2-3-Mahout" class="headerlink" title="18.2.3 Mahout"></a>18.2.3 Mahout</h3><p>&emsp;&emsp;Mahout【3】是基于Hadoop的机器学习和数据挖掘的一个分布式框架。Mahout用MapReduce实现了部分数据挖掘算法，解决了并行挖掘的问题。</p><p>&emsp;&emsp;Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘等。</p><p>&emsp;&emsp;Mahout算法库：</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-3-1.png" alt="Mahout"></p><p>&emsp;&emsp;Mahout应用场景：</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-3-2.png" alt="Mahout"></p><p>&emsp;&emsp;Github地址：<a href="https://github.com/apache/mahout" target="_blank" rel="noopener">https://github.com/apache/mahout</a></p><h3 id="18-2-4-Spark-MLllib"><a href="#18-2-4-Spark-MLllib" class="headerlink" title="18.2.4 Spark MLllib"></a>18.2.4 Spark MLllib</h3><p>&emsp;&emsp;MLlib(Machine Learnig lib) 【4】是Spark对常用的机器学习算法的实现库，同时包括相关的测试和数据生成器。</p><p>&emsp;&emsp;MLlib是MLBase一部分，其中MLBase分为四部分：MLlib、MLI、ML Optimizer和MLRuntime。</p><ul><li>ML Optimizer会选择它认为最适合的已经在内部实现好了的机器学习算法和相关参数，来处理用户输入的数据，并返回模型或别的帮助分析的结果；</li><li>MLI 是一个进行特征抽取和高级ML编程抽象的算法实现的API或平台；</li><li>MLlib是Spark实现一些常见的机器学习算法和实用程序，包括分类、回归、聚类、协同过滤、降维以及底层优化，该算法可以进行可扩充； MLRuntime 基于Spark计算框架，将Spark的分布式计算应用到机器学习领域。</li></ul><p>&emsp;&emsp;MLlib主要包含三个部分：</p><ul><li>底层基础：包括Spark的运行库、矩阵库和向量库</li><li>算法库：包含广义线性模型、推荐系统、聚类、决策树和评估的算法</li><li>实用程序：包括测试数据的生成、外部数据的读入等功能</li></ul><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-4-1.png" alt="架构图"></p><center>架构图</center><p>&emsp;&emsp;MLlib目前支持4种常见的机器学习问题: 分类、回归、聚类和协同过滤，MLlib在Spark整个生态系统中的位置如图下图所示。</p><h3 id="18-2-5-Ray"><a href="#18-2-5-Ray" class="headerlink" title="18.2.5 Ray"></a>18.2.5 Ray</h3><p>&emsp;&emsp;Ray【5】是加州大学伯克利分校实时智能安全执行实验室(RISELab)的研究人员针对机器学习领域开发的一种新的分布式计算框架，该框架旨在让基于Python的机器学习和深度学习工作负载能够实时执行，并具有类似消息传递接口(MPI)的性能和细粒度。</p><p>&emsp;&emsp;增强学习的场景，按照原理定义，因为没有预先可用的静态标签信息，所以通常需要引入实际的目标系统（为了加快训练，往往是目标系统的模拟环境）来获取反馈信息，用做损失/收益判断，进而完成整个训练过程的闭环反馈。典型的步骤是通过观察特定目标系统的状态，收集反馈信息，判断收益，用这些信息来调整参数，训练模型，并根据新的训练结果产出可用于调整目标系统的行为Action，输出到目标系统，进而影响目标系统状态变化，完成闭环，如此反复迭代，最终目标是追求某种收益的最大化（比如对AlphoGo来说，收益是赢得一盘围棋的比赛）。</p><p>&emsp;&emsp;在这个过程中，一方面，模拟目标系统，收集状态和反馈信息，判断收益，训练参数，生成Action等等行为可能涉及大量的任务和计算（为了选择最佳Action，可能要并发模拟众多可能的行为）。而这些行为本身可能也是千差万别的异构的任务，任务执行的时间也可能长短不一，执行过程有些可能要求同步，也有些可能更适合异步。</p><p>&emsp;&emsp;另一方面，整个任务流程的DAG图也可能是动态变化的，系统往往可能需要根据前一个环节的结果，调整下一个环节的行为参数或者流程。这种调整，可能是目标系统的需要（比如在自动驾驶过程中遇到行人了，那么我们可能需要模拟计算刹车的距离来判断该采取的行动是刹车还是拐弯，而平时可能不需要这个环节），也可能是增强学习特定训练算法的需要（比如根据多个并行训练的模型的当前收益，调整模型超参数，替换模型等等）。</p><p>&emsp;&emsp;此外，由于所涉及到的目标系统可能是具体的，现实物理世界中的系统，所以对时效性也可能是有强要求的。举个例子，比如你想要实现的系统是用来控制机器人行走，或者是用来打视频游戏的。那么整个闭环反馈流程就需要在特定的时间限制内完成（比如毫秒级别）。</p><p>&emsp;&emsp;总结来说，就是增强学习的场景，对分布式计算框架的任务调度延迟，吞吐量和动态修改DAG图的能力都可能有很高的要求。按照官方的设计目标，Ray需要支持异构计算任务，动态计算链路，毫秒级别延迟和每秒调度百万级别任务的能力。</p><p>&emsp;&emsp;Ray的目标问题，主要是在类似增强学习这样的场景中所遇到的工程问题。那么增强学习的场景和普通的机器学习，深度学习的场景又有什么不同呢？简单来说，就是对整个处理链路流程的时效性和灵活性有更高的要求。</p><p>Ray框架优点</p><ul><li>海量任务调度能力</li><li>毫秒级别的延迟</li><li>异构任务的支持</li><li>任务拓扑图动态修改的能力</li></ul><p>&emsp;&emsp;Ray没有采用中心任务调度的方案，而是采用了类似层级（hierarchy）调度的方案，除了一个全局的中心调度服务节点（实际上这个中心调度节点也是可以水平拓展的），任务的调度也可以在具体的执行任务的工作节点上，由本地调度服务来管理和执行。<br>与传统的层级调度方案，至上而下分配调度任务的方式不同的是，Ray采用了至下而上的调度策略。也就是说，任务调度的发起，并不是先提交给全局的中心调度器统筹规划以后再分发给次级调度器的。而是由任务执行节点直接提交给本地的调度器，本地的调度器如果能满足该任务的调度需求就直接完成调度请求，在无法满足的情况下，才会提交给全局调度器，由全局调度器协调转发给有能力满足需求的另外一个节点上的本地调度器去调度执行。</p><p>&emsp;&emsp;架构设计一方面减少了跨节点的RPC开销，另一方面也能规避中心节点的瓶颈问题。当然缺点也不是没有，由于缺乏全局的任务视图，无法进行全局规划，因此任务的拓扑逻辑结构也就未必是最优的了。</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-5-1.png" alt="架构图"></p><center>架构图</center><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-5-2.png" alt="任务调度图"></p><center>任务调度图</center><p>&emsp;&emsp;Ray架构现状：</p><ul><li>API层以上 的部分还比较薄弱，Core模块核心逻辑估需要时间打磨。</li><li>国内目前除了蚂蚁金服和RISELab有针对性的合作以外，关注程度还很低，没有实际的应用实例看到，整体来说还处于比较早期的框架构建阶段。</li></ul><p>&emsp;&emsp;Github地址：<a href="https://github.com/ray-project/ray" target="_blank" rel="noopener">https://github.com/ray-project/ray</a></p><h3 id="18-2-6-Spark-stream"><a href="#18-2-6-Spark-stream" class="headerlink" title="18.2.6 Spark stream"></a>18.2.6 Spark stream</h3><p>&emsp;&emsp;随着大数据的发展，人们对大数据的处理要求也越来越高，原有的批处理框架MapReduce适合离线计算，却无法满足实时性要求较高的业务，如实时推荐、用户行为分析等。 Spark Streaming是建立在Spark上的实时计算框架，通过它提供的丰富的API、基于内存的高速执行引擎，用户可以结合流式、批处理和交互试查询应用。</p><p>&emsp;&emsp;Spark是一个类似于MapReduce的分布式计算框架，其核心是弹性分布式数据集，提供了比MapReduce更丰富的模型，可以在快速在内存中对数据集进行多次迭代，以支持复杂的数据挖掘算法和图形计算算法。Spark Streaming【6】是一种构建在Spark上的实时计算框架，它扩展了Spark处理大规模流式数据的能力。</p><p>&emsp;&emsp;Spark Streaming的优势在于：</p><ul><li>能运行在100+的结点上，并达到秒级延迟。</li><li>使用基于内存的Spark作为执行引擎，具有高效和容错的特性。</li><li>能集成Spark的批处理和交互查询。</li><li>为实现复杂的算法提供和批处理类似的简单接口。</li></ul><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-6-1.png" alt="Spark Streaming架构图"></p><center>Spark Streaming架构图</center><p>&emsp;&emsp;Spark Streaming把实时输入数据流以时间片Δt （如1秒）为单位切分成块。Spark Streaming会把每块数据作为一个RDD，并使用RDD操作处理每一小块数据。每个块都会生成一个Spark Job处理，最终结果也返回多块。</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-6-2.png" alt="Spark Streaming基本原理图"></p><center>Spark Streaming基本原理图</center><p>&emsp;&emsp;正如Spark Streaming最初的目标一样，它通过丰富的API和基于内存的高速计算引擎让用户可以结合流式处理，批处理和交互查询等应用。因此Spark Streaming适合一些需要历史数据和实时数据结合分析的应用场合。当然，对于实时性要求不是特别高的应用也能完全胜任。另外通过RDD的数据重用机制可以得到更高效的容错处理。</p><h3 id="18-2-7-Horovod"><a href="#18-2-7-Horovod" class="headerlink" title="18.2.7 Horovod"></a>18.2.7 Horovod</h3><p>&emsp;&emsp;Horovod【7】 是 Uber 开源的又一个深度学习工具，它的发展吸取了 Facebook「一小时训练 ImageNet 论文」与百度 Ring Allreduce 的优点，可为用户实现分布式训练提供帮助。</p><p>&emsp;&emsp;Horovod 支持通过用于高性能并行计算的低层次接口 – 消息传递接口 (MPI) 进行分布式模型训练。有了 MPI，就可以利用分布式 Kubernetes 集群来训练 TensorFlow 和 PyTorch 模型。</p><p>&emsp;&emsp;分布式 TensorFlow 的参数服务器模型（parameter server paradigm）通常需要对大量样板代码进行认真的实现。但是 Horovod 仅需要几行。下面是一个分布式 TensorFlow 项目使用 Horovod 的示例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">import  tensorflow as tf</span><br><span class="line">import horovod.tensorflow as hvd</span><br><span class="line"># Initialize Horovod</span><br><span class="line">hvd.init()</span><br><span class="line"># Pin GPU to be used to process local rank (one GPU per process)</span><br><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.visible_device_list = str(hvd.local_rank())</span><br><span class="line"># Build model…</span><br><span class="line">loss = …</span><br><span class="line">opt = tf.train.AdagradOptimizer(0.01)</span><br><span class="line"># Add Horovod Distributed Optimizer</span><br><span class="line">opt = hvd.DistributedOptimizer(opt)</span><br><span class="line"># Add hook to broadcast variables from rank 0 to all other processes during</span><br><span class="line"># initialization.</span><br><span class="line">hooks = [hvd.BroadcastGlobalVariablesHook(0)]</span><br><span class="line"># Make training operation</span><br><span class="line">train_op = opt.minimize(loss)</span><br><span class="line"># The MonitoredTrainingSession takes care of session initialization,</span><br><span class="line"># restoring from a checkpoint, saving to a checkpoint, and closing when done</span><br><span class="line"># or an error occurs.</span><br><span class="line">with tf.train.MonitoredTrainingSession(checkpoint_dir=“/tmp/train_logs”,</span><br><span class="line">                                      config=config,</span><br><span class="line">                                      hooks=hooks) as mon_sess:</span><br><span class="line"> while not mon_sess.should_stop():</span><br><span class="line">   # Perform synchronous training.</span><br><span class="line">   mon_sess.run(train_op)</span><br></pre></td></tr></table></figure></p><p>&emsp;&emsp;在该示例中，粗体文字指进行单个 GPU 分布式项目时必须做的改变：</p><ul><li>hvd.init() 初始化 Horovod。</li><li>config.gpu_options.visible_device_list = str(hvd.local_rank()) 向每个 TensorFlow 流程分配一个 GPU。</li><li>opt=hvd.DistributedOptimizer(opt) 使用 Horovod 优化器包裹每一个常规 TensorFlow 优化器，Horovod 优化器使用 ring-allreduce 平均梯度。</li><li>hvd.BroadcastGlobalVariablesHook(0) 将变量从第一个流程向其他流程传播，以实现一致性初始化。如果该项目无法使用 MonitoredTrainingSession，则用户可以运行 hvd.broadcast_global_variables(0)。</li></ul><p>&emsp;&emsp;之后，可以使用 mpirun 命令使该项目的多个拷贝在多个服务器中运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mpirun -np 16 -x LD_LIBRARY_PATH -H </span><br><span class="line">server1:4,server2:4,server3:4,server4:4 python train.py</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;mpirun 命令向四个节点分布 train.py，然后在每个节点的四个 GPU 上运行 train.py。</p><p>&emsp;&emsp;Github地址：<a href="https://github.com/uber/horovod" target="_blank" rel="noopener">https://github.com/uber/horovod</a></p><h3 id="18-2-8-BigDL"><a href="#18-2-8-BigDL" class="headerlink" title="18.2.8 BigDL"></a>18.2.8 BigDL</h3><p>&emsp;&emsp;BigDL【9】是一种基于Apache Spark的分布式深度学习框架。它可以无缝的直接运行在现有的Apache Spark和Hadoop集群之上。BigDL的设计吸取了Torch框架许多方面的知识，为深度学习提供了全面的支持；包括数值计算和高级神经网络；借助现有的Spark集群来运行深度学习计算，并简化存储在Hadoop中的大数据集的数据加载。</p><p>&emsp;&emsp;BigDL优点：</p><ul><li>丰富的深度学习支持。模拟Torch之后，BigDL为深入学习提供全面支持，包括数字计算（通过Tensor）和高级神经网络 ; 此外，用户可以使用BigDL将预先训练好的Caffe或Torch模型加载到Spark程序中。</li><li>极高的性能。为了实现高性能，BigDL在每个Spark任务中使用英特尔MKL和多线程编程。因此，在单节点Xeon（即与主流GPU 相当）上，它比开箱即用开源Caffe，Torch或TensorFlow快了数量级。</li><li>有效地横向扩展。BigDL可以通过利用Apache Spark（快速分布式数据处理框架），以及高效实施同步SGD和全面减少Spark的通信，从而有效地扩展到“大数据规模”上的数据分析</li></ul><p>&emsp;&emsp;BigDL缺点：</p><ul><li>对机器要求高 jdk7上运行性能差 在CentOS 6和7上，要将最大用户进程增加到更大的值（例如514585）; 否则，可能会看到错误，如“无法创建新的本机线程”。 </li><li>训练和验证的数据会加载到内存，挤占内存</li></ul><p>&emsp;&emsp;BigDL满足的应用场景：</p><ul><li>直接在Hadoop/Spark框架下使用深度学习进行大数据分析（即将数据存储在HDFS、HBase、Hive等数据库上）；</li><li>在Spark程序中/工作流中加入深度学习功能；</li><li>利用现有的 Hadoop/Spark 集群来运行深度学习程序，然后将代码与其他的应用场景进行动态共享，例如ETL（Extract、Transform、Load，即通常所说的数据抽取）、数据仓库（data warehouse）、功能引擎、经典机器学习、图表分析等。</li></ul><h3 id="18-2-9-Petastorm"><a href="#18-2-9-Petastorm" class="headerlink" title="18.2.9 Petastorm"></a>18.2.9 Petastorm</h3><p>&emsp;&emsp;Petastorm是一个由 Uber ATG 开发的开源数据访问库。这个库可以直接基于数 TB Parquet 格式的数据集进行单机或分布式训练和深度学习模型评估。Petastorm 支持基于 Python 的机器学习框架，如 Tensorflow、Pytorch 和 PySpark，也可以直接用在 Python 代码中。</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-9-1.png" alt="深度学习集群"></p><center>深度学习集群</center><p>&emsp;&emsp;即使是在现代硬件上训练深度模型也很耗时，而且在很多情况下，很有必要在多台机器上分配训练负载。典型的深度学习集群需要执行以下几个步骤：</p><ul><li>一台或多台机器读取集中式或本地数据集。</li><li>每台机器计算损失函数的值，并根据模型参数计算梯度。在这一步通常会使用 GPU。</li><li>通过组合估计的梯度（通常由多台机器以分布式的方式计算得出）来更新模型系数。</li></ul><p>&emsp;&emsp;通常，一个数据集是通过连接多个数据源的记录而生成的。这个由 Apache Spark 的 Python 接口 PySpark 生成的数据集稍后将被用在机器学习训练中。Petastorm 提供了一个简单的功能，使用 Petastorm 特定的元数据对标准的 Parquet 进行了扩展，从而让它可以与 Petastorm 兼容。<br>有了 Petastorm，消费数据就像在 HDFS 或文件系统中创建和迭代读取对象一样简单。Petastorm 使用 PyArrow 来读取 Parquet 文件。</p><p>&emsp;&emsp;将多个数据源组合到单个表格结构中，从而生成数据集。可以多次使用相同的数据集进行模型训练和评估。<br><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-9-2.png" alt="深度学习集群"></p><center>深度学习集群</center><p>&emsp;&emsp;为分布式训练进行分片<br>在分布式训练环境中，每个进程通常负责训练数据的一个子集。一个进程的数据子集与其他进程的数据子集正交。Petastorm 支持将数据集的读时分片转换为正交的样本集。<br><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-9-3.png" alt="Petastorm 将数据集的非重叠子集提供给参与分布式训练的不同机器"></p><center>Petastorm 将数据集的非重叠子集提供给参与分布式训练的不同机器</center><p>&emsp;&emsp;本地缓存<br>Petastorm 支持在本地存储中缓存数据。当网络连接速度较慢或带宽很昂贵时，这会派上用场。<br><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-9-4.png" alt="本地缓存"></p><p>Github地址：<a href="https://github.com/uber/petastorm" target="_blank" rel="noopener">https://github.com/uber/petastorm</a></p><h3 id="18-2-10-TensorFlowOnSpark"><a href="#18-2-10-TensorFlowOnSpark" class="headerlink" title="18.2.10 TensorFlowOnSpark"></a>18.2.10 TensorFlowOnSpark</h3><p>&emsp;&emsp;TensorFlowOnSpark【10】为 Apache Hadoop 和 Apache Spark 集群带来可扩展的深度学习。 通过结合深入学习框架 TensorFlow 和大数据框架 Apache Spark 、Apache Hadoop 的显着特征，TensorFlowOnSpark 能够在 GPU 和 CPU 服务器集群上实现分布式深度学习。</p><p>&emsp;&emsp;满足的应用场景：<br>为了利用TensorFlow在现有的Spark和Hadoop集群上进行深度学习。而不需要为深度学习设置单独的集群。</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-10-1.png" alt="架构图"></p><center>架构图</center><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-2-10-2.png" alt="运行流程图"></p><center>运行流程图</center><p>&emsp;&emsp;优点：</p><ul><li>轻松迁移所有现有的TensorFlow程序，&lt;10行代码更改; </li><li>支持所有TensorFlow功能：同步/异步训练，模型/数据并行，推理和TensorBoard; </li><li>服务器到服务器的直接通信在可用时实现更快的学习; </li><li>允许数据集在HDFS和由Spark推动的其他来源或由TensorFlow拖动; </li><li>轻松集成您现有的数据处理流水线和机器学习算法（例如，MLlib，CaffeOnSpark）; </li><li>轻松部署在云或内部部署：CPU和GPU，以太网和Infiniband。</li><li>TensorFlowOnSpark是基于google的TensorFlow的实现，而TensorFlow有着一套完善的教程，内容丰富。 </li></ul><p>&emsp;&emsp;劣势：</p><ul><li>开源时间不长，未得到充分的验证。</li></ul><p>&emsp;&emsp;Github 地址:<a href="https://github.com/yahoo/TensorFlowOnSpark" target="_blank" rel="noopener">https://github.com/yahoo/TensorFlowOnSpark</a></p><h2 id="18-3-如何选择合适的分布式计算框架进行模型训练？"><a href="#18-3-如何选择合适的分布式计算框架进行模型训练？" class="headerlink" title="18.3 如何选择合适的分布式计算框架进行模型训练？"></a>18.3 如何选择合适的分布式计算框架进行模型训练？</h2><h2 id="18-4-如何进行实时计算？"><a href="#18-4-如何进行实时计算？" class="headerlink" title="18.4 如何进行实时计算？"></a>18.4 如何进行实时计算？</h2><h3 id="18-4-1-什么是实时流计算？"><a href="#18-4-1-什么是实时流计算？" class="headerlink" title="18.4.1 什么是实时流计算？"></a>18.4.1 什么是实时流计算？</h3><p>&emsp;&emsp;所谓实时流计算，就是近几年由于数据得到广泛应用之后，在数据持久性建模不满足现状的情况下，急需数据流的瞬时建模或者计算处理。这种实时计算的应用实例有金融服务、网络监控、电信数据管理、 Web 应用、生产制造、传感检测，等等。在这种数据流模型中，单独的数据单元可能是相关的元组（Tuple），如网络测量、呼叫记录、网页访问等产生的数据。但是，这些数据以大量、快速、时变（可能是不可预知）的数据流持续到达，由此产生了一些基础性的新的研究问题——实时计算。实时计算的一个重要方向就是实时流计算。</p><h3 id="18-4-2-实时流计算过程"><a href="#18-4-2-实时流计算过程" class="headerlink" title="18.4.2 实时流计算过程"></a>18.4.2 实时流计算过程</h3><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-4-1.png" alt=""></p><p>&emsp;&emsp;我们以热卖产品的统计为例，看下传统的计算手段：</p><ul><li>将用户行为、log等信息清洗后保存在数据库中.</li><li>将订单信息保存在数据库中.</li><li>利用触发器或者协程等方式建立本地索引，或者远程的独立索引.</li><li>join订单信息、订单明细、用户信息、商品信息等等表，聚合统计20分钟内热卖产品，并返回top-10.</li><li>web或app展示.</li></ul><p>&emsp;&emsp;这是一个假想的场景，但假设你具有处理类似场景的经验，应该会体会到这样一些问题和难处：</p><ul><li>水平扩展问题（scale-out）<br>显然，如果是一个具有一定规模的电子商务网站，数据量都是很大的。而交易信息因为涉及事务，所以很难直接舍弃关系型数据库的事务能力，迁移到具有更好的scale-out能力的NoSQL数据库中。</li></ul><p>&emsp;&emsp;那么，一般都会做sharding。历史数据还好说，我们可以按日期来归档，并可以通过批处理式的离线计算，将结果缓存起来。<br>但是，这里的要求是20分钟内，这很难。</p><ul><li>性能问题<br>这个问题，和scale-out是一致的，假设我们做了sharding，因为表分散在各个节点中，所以我们需要多次入库，并在业务层做聚合计算。</li></ul><p>&emsp;&emsp;问题是，20分钟的时间要求，我们需要入库多少次呢？<br>10分钟呢？<br>5分钟呢？<br>实时呢？</p><p>&emsp;&emsp;而且，业务层也同样面临着单点计算能力的局限，需要水平扩展，那么还需要考虑一致性的问题。<br>所以，到这里一切都显得很复杂。</p><ul><li>业务扩展问题</li></ul><p>&emsp;&emsp;假设我们不仅仅要处理热卖商品的统计，还要统计广告点击、或者迅速根据用户的访问行为判断用户特征以调整其所见的信息，更加符合用户的潜在需求等，那么业务层将会更加复杂。<br>也许你有更好的办法，但实际上，我们需要的是一种新的认知：<br>这个世界发生的事，是实时的。<br>所以我们需要一种实时计算的模型，而不是批处理模型。<br>我们需要的这种模型，必须能够处理很大的数据，所以要有很好的scale-out能力，最好是，我们都不需要考虑太多一致性、复制的问题。</p><p>&emsp;&emsp;那么，这种计算模型就是实时计算模型，也可以认为是流式计算模型。<br>现在假设我们有了这样的模型，我们就可以愉快地设计新的业务场景：</p><ul><li>转发最多的微博是什么？</li><li>最热卖的商品有哪些？</li><li>大家都在搜索的热点是什么？</li><li>我们哪个广告，在哪个位置，被点击最多？<br>或者说，我们可以问：<br>&emsp;&emsp;这个世界，在发生什么？</li></ul><p>&emsp;&emsp;最热的微博话题是什么？<br>我们以一个简单的滑动窗口计数的问题，来揭开所谓实时计算的神秘面纱。<br>假设，我们的业务要求是：<br>统计20分钟内最热的10个微博话题。</p><p>&emsp;&emsp;解决这个问题，我们需要考虑：</p><ul><li>数据源</li></ul><p>&emsp;&emsp;这里，假设我们的数据，来自微博长连接推送的话题。</p><ul><li>问题建模</li></ul><p>&emsp;&emsp;我们认为的话题是#号扩起来的话题，最热的话题是此话题出现的次数比其它话题都要多。<br>比如：@foreach_break : 你好,#世界#,我爱你，#微博#。<br>“世界”和“微博”就是话题。</p><ul><li><p>计算引擎采用storm</p></li><li><p>定义时间</p></li></ul><p>&emsp;&emsp;时间的定义是一件很难的事情，取决于所需的精度是多少。<br>根据实际，我们一般采用tick来表示时刻这一概念。<br>在storm的基础设施中，executor启动阶段，采用了定时器来触发“过了一段时间”这个事件。<br>如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">(defn setup-ticks! [worker executor-data]</span><br><span class="line">  (let [storm-conf (:storm-conf executor-data)</span><br><span class="line">        tick-time-secs (storm-conf TOPOLOGY-TICK-TUPLE-FREQ-SECS)</span><br><span class="line">        receive-queue (:receive-queue executor-data)</span><br><span class="line">        context (:worker-context executor-data)]</span><br><span class="line">    (when tick-time-secs</span><br><span class="line">      (if (or (system-id? (:component-id executor-data))</span><br><span class="line">              (and (= false (storm-conf TOPOLOGY-ENABLE-MESSAGE-TIMEOUTS))</span><br><span class="line">                   (= :spout (:type executor-data))))</span><br><span class="line">        (log-message &quot;Timeouts disabled for executor &quot; (:component-id executor-data) &quot;:&quot; (:executor-id executor-data))</span><br><span class="line">        (schedule-recurring</span><br><span class="line">          (:user-timer worker)</span><br><span class="line">          tick-time-secs</span><br><span class="line">          tick-time-secs</span><br><span class="line">          (fn []</span><br><span class="line">            (disruptor/publish</span><br><span class="line">              receive-queue</span><br><span class="line">              [[nil (TupleImpl. context [tick-time-secs] Constants/SYSTEM_TASK_ID Constants/SYSTEM_TICK_STREAM_ID)]]</span><br><span class="line">              )))))))</span><br></pre></td></tr></table></figure></p><p>之前的博文中，已经详细分析了这些基础设施的关系，不理解的童鞋可以翻看前面的文章。<br>每隔一段时间，就会触发这样一个事件，当流的下游的bolt收到一个这样的事件时，就可以选择是增量计数还是将结果聚合并发送到流中。<br>bolt如何判断收到的tuple表示的是“tick”呢？<br>负责管理bolt的executor线程，从其订阅的消息队列消费消息时，会调用到bolt的execute方法，那么，可以在execute中这样判断：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public static boolean isTick(Tuple tuple) &#123;</span><br><span class="line">    return tuple != null</span><br><span class="line">           &amp;&amp; Constants.SYSTEM_COMPONENT_ID  .equals(tuple.getSourceComponent())</span><br><span class="line">           &amp;&amp; Constants.SYSTEM_TICK_STREAM_ID.equals(tuple.getSourceStreamId());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>结合上面的setup-tick!的clojure代码，我们可以知道SYSTEM_TICK_STREAM_ID在定时事件的回调中就以构造函数的参数传递给了tuple，那么SYSTEM_COMPONENT_ID是如何来的呢？<br>可以看到，下面的代码中，SYSTEM_TASK_ID同样传给了tuple：<br>;; 请注意SYSTEM_TASK_ID和SYSTEM_TICK_STREAM_ID<br>(TupleImpl. context [tick-time-secs] Constants/SYSTEM_TASK_ID Constants/SYSTEM_TICK_STREAM_ID)<br>然后利用下面的代码，就可以得到SYSTEM_COMPONENT_ID：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public String getComponentId(int taskId) &#123;</span><br><span class="line">    if(taskId==Constants.SYSTEM_TASK_ID) &#123;</span><br><span class="line">        return Constants.SYSTEM_COMPONENT_ID;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        return _taskToComponent.get(taskId);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>滑动窗口<br>有了上面的基础设施，我们还需要一些手段来完成“工程化”，将设想变为现实。<br>这里，我们看看Michael G. Noll的滑动窗口设计。</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-4-2.png" alt=""></p><p>Topology</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">String spoutId = &quot;wordGenerator&quot;;</span><br><span class="line">String counterId = &quot;counter&quot;;</span><br><span class="line">String intermediateRankerId = &quot;intermediateRanker&quot;;</span><br><span class="line">String totalRankerId = &quot;finalRanker&quot;;</span><br><span class="line">// 这里，假设TestWordSpout就是我们发送话题tuple的源</span><br><span class="line">builder.setSpout(spoutId, new TestWordSpout(), 5);</span><br><span class="line">// RollingCountBolt的时间窗口为9秒钟，每3秒发送一次统计结果到下游</span><br><span class="line">builder.setBolt(counterId, new RollingCountBolt(9, 3), 4).fieldsGrouping(spoutId, new Fields(&quot;word&quot;));</span><br><span class="line">// IntermediateRankingsBolt，将完成部分聚合，统计出top-n的话题</span><br><span class="line">builder.setBolt(intermediateRankerId, new IntermediateRankingsBolt(TOP_N), 4).fieldsGrouping(counterId, new Fields(</span><br><span class="line">    &quot;obj&quot;));</span><br><span class="line">    // TotalRankingsBolt， 将完成完整聚合，统计出top-n的话题</span><br><span class="line">builder.setBolt(totalRankerId, new TotalRankingsBolt(TOP_N)).globalGrouping(intermediateRankerId);</span><br></pre></td></tr></table></figure><p>上面的topology设计如下：</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-4-3.png" alt=""></p><p>将聚合计算与时间结合起来<br>前文，我们叙述了tick事件，回调中会触发bolt的execute方法，那可以这么做：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">RollingCountBolt:</span><br><span class="line">  @Override</span><br><span class="line">  public void execute(Tuple tuple) &#123;</span><br><span class="line">    if (TupleUtils.isTick(tuple)) &#123;</span><br><span class="line">      LOG.debug(&quot;Received tick tuple, triggering emit of current window counts&quot;);</span><br><span class="line">      // tick来了，将时间窗口内的统计结果发送，并让窗口滚动</span><br><span class="line">      emitCurrentWindowCounts();</span><br><span class="line">    &#125;</span><br><span class="line">    else &#123;</span><br><span class="line">      // 常规tuple，对话题计数即可</span><br><span class="line">      countObjAndAck(tuple);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // obj即为话题，增加一个计数 count++</span><br><span class="line">  // 注意，这里的速度基本取决于流的速度，可能每秒百万，也可能每秒几十.</span><br><span class="line">  // 内存不足？ bolt可以scale-out.</span><br><span class="line">  private void countObjAndAck(Tuple tuple) &#123;</span><br><span class="line">    Object obj = tuple.getValue(0);</span><br><span class="line">    counter.incrementCount(obj);</span><br><span class="line">    collector.ack(tuple);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  // 将统计结果发送到下游</span><br><span class="line">  private void emitCurrentWindowCounts() &#123;</span><br><span class="line">    Map&lt;Object, Long&gt; counts = counter.getCountsThenAdvanceWindow();</span><br><span class="line">    int actualWindowLengthInSeconds = lastModifiedTracker.secondsSinceOldestModification();</span><br><span class="line">    lastModifiedTracker.markAsModified();</span><br><span class="line">    if (actualWindowLengthInSeconds != windowLengthInSeconds) &#123;</span><br><span class="line">      LOG.warn(String.format(WINDOW_LENGTH_WARNING_TEMPLATE, actualWindowLengthInSeconds, windowLengthInSeconds));</span><br><span class="line">    &#125;</span><br><span class="line">    emit(counts, actualWindowLengthInSeconds);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>上面的代码可能有点抽象，看下这个图就明白了，tick一到，窗口就滚动：</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-4-4.png" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">IntermediateRankingsBolt &amp; TotalRankingsBolt：</span><br><span class="line">  public final void execute(Tuple tuple, BasicOutputCollector collector) &#123;</span><br><span class="line">    if (TupleUtils.isTick(tuple)) &#123;</span><br><span class="line">      getLogger().debug(&quot;Received tick tuple, triggering emit of current rankings&quot;);</span><br><span class="line">      // 将聚合并排序的结果发送到下游</span><br><span class="line">      emitRankings(collector);</span><br><span class="line">    &#125;</span><br><span class="line">    else &#123;</span><br><span class="line">      // 聚合并排序</span><br><span class="line">      updateRankingsWithTuple(tuple);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;其中，IntermediateRankingsBolt和TotalRankingsBolt的聚合排序方法略有不同：</p><p>IntermediateRankingsBolt的聚合排序方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">void updateRankingsWithTuple(Tuple tuple) &#123;</span><br><span class="line">  // 这一步，将话题、话题出现的次数提取出来</span><br><span class="line">  Rankable rankable = RankableObjectWithFields.from(tuple);</span><br><span class="line">  // 这一步，将话题出现的次数进行聚合，然后重排序所有话题</span><br><span class="line">  super.getRankings().updateWith(rankable);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>TotalRankingsBolt的聚合排序方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">void updateRankingsWithTuple(Tuple tuple) &#123;</span><br><span class="line">// 提出来自IntermediateRankingsBolt的中间结果</span><br><span class="line">  Rankings rankingsToBeMerged = (Rankings) tuple.getValue(0);</span><br><span class="line">// 聚合并排序</span><br><span class="line">  super.getRankings().updateWith(rankingsToBeMerged);</span><br><span class="line">// 去0，节约内存</span><br><span class="line">  super.getRankings().pruneZeroCounts();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而重排序方法比较简单粗暴，因为只求前N个，N不会很大：</p><pre><code>private void rerank() {  Collections.sort(rankedItems);  Collections.reverse(rankedItems);}</code></pre><p>&emsp;&emsp;结语</p><p>&emsp;&emsp;下图可能就是我们想要的结果，我们完成了t0 - t1时刻之间的热点话题统计.<br><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-4-5.png" alt=""></p><h2 id="18-5-如何进行离线计算？"><a href="#18-5-如何进行离线计算？" class="headerlink" title="18.5 如何进行离线计算？"></a>18.5 如何进行离线计算？</h2><h2 id="18-6-如何使用分布式框架提高模型训练速度？"><a href="#18-6-如何使用分布式框架提高模型训练速度？" class="headerlink" title="18.6 如何使用分布式框架提高模型训练速度？"></a>18.6 如何使用分布式框架提高模型训练速度？</h2><h2 id="18-7-深度学习分布式计算框架如何在移动互联网中应用？"><a href="#18-7-深度学习分布式计算框架如何在移动互联网中应用？" class="headerlink" title="18.7 深度学习分布式计算框架如何在移动互联网中应用？"></a>18.7 深度学习分布式计算框架如何在移动互联网中应用？</h2><h2 id="18-8-如何在个性化推荐中应用深度学习分布式框架？"><a href="#18-8-如何在个性化推荐中应用深度学习分布式框架？" class="headerlink" title="18.8 如何在个性化推荐中应用深度学习分布式框架？"></a>18.8 如何在个性化推荐中应用深度学习分布式框架？</h2><h2 id="18-9-如何评价个性化推荐系统的效果？"><a href="#18-9-如何评价个性化推荐系统的效果？" class="headerlink" title="18.9 如何评价个性化推荐系统的效果？"></a>18.9 如何评价个性化推荐系统的效果？</h2><h3 id="18-9-1-准确率与召回率（Precision-amp-Recall）"><a href="#18-9-1-准确率与召回率（Precision-amp-Recall）" class="headerlink" title="18.9.1 准确率与召回率（Precision &amp; Recall）"></a>18.9.1 准确率与召回率（Precision &amp; Recall）</h3><p>&emsp;&emsp;准确率和召回率是广泛用于信息检索和统计学分类领域的两个度量值，用来评价结果的质量。其中精度是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的查准率；召回率是指检索出的相关文档数和文档库中所有的相关文档数的比率，衡量的是检索系统的查全率。</p><p>&emsp;&emsp;一般来说，Precision就是检索出来的条目（比如：文档、网页等）有多少是准确的，Recall就是所有准确的条目有多少被检索出来了。</p><p>&emsp;&emsp;正确率、召回率和 F 值是在鱼龙混杂的环境中，选出目标的重要评价指标。不妨看看这些指标的定义先：</p><pre><code>正确率 = 提取出的正确信息条数 /  提取出的信息条数 召回率 = 提取出的正确信息条数 /  样本中的信息条数    </code></pre><p>&emsp;&emsp;两者取值在0和1之间，数值越接近1，查准率或查全率就越高。   </p><pre><code>F值  = 正确率 * 召回率 * 2 / (正确率 + 召回率) （F 值即为正确率和召回率的调和平均值）</code></pre><p>&emsp;&emsp;不妨举这样一个例子：某池塘有1400条鲤鱼，300只虾，300只鳖。现在以捕鲤鱼为目的。撒一大网，逮着了700条鲤鱼，200只虾，100只鳖。那么，这些指标分别如下：</p><pre><code>正确率 = 700 / (700 + 200 + 100) = 70%召回率 = 700 / 1400 = 50%F值 = 70% * 50% * 2 / (70% + 50%) = 58.3%</code></pre><p>&emsp;&emsp;不妨看看如果把池子里的所有的鲤鱼、虾和鳖都一网打尽，这些指标又有何变化：</p><pre><code>正确率 = 1400 / (1400 + 300 + 300) = 70%召回率 = 1400 / 1400 = 100%F值 = 70% * 100% * 2 / (70% + 100%) = 82.35%        </code></pre><p>&emsp;&emsp;由此可见，正确率是评估捕获的成果中目标成果所占得比例；召回率，顾名思义，就是从关注领域中，召回目标类别的比例；而F值，则是综合这二者指标的评估指标，用于综合反映整体的指标。</p><p>&emsp;&emsp;当然希望检索结果Precision越高越好，同时Recall也越高越好，但事实上这两者在某些情况下有矛盾的。比如极端情况下，我们只搜索出了一个结果，且是准确的，那么Precision就是100%，但是Recall就很低；而如果我们把所有结果都返回，那么比如Recall是100%，但是Precision就会很低。因此在不同的场合中需要自己判断希望Precision比较高或是Recall比较高。如果是做实验研究，可以绘制Precision-Recall曲线来帮助分析。</p><h3 id="18-9-2-综合评价指标（F-Measure）"><a href="#18-9-2-综合评价指标（F-Measure）" class="headerlink" title="18.9.2 综合评价指标（F-Measure）"></a>18.9.2 综合评价指标（F-Measure）</h3><p>&emsp;&emsp;P和R指标有时候会出现的矛盾的情况，这样就需要综合考虑他们，最常见的方法就是F-Measure（又称为F-Score）。</p><p>&emsp;&emsp;F-Measure是Precision和Recall加权调和平均：</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-9-2-1.png" alt="F-Measure"></p><p>&emsp;&emsp;当参数α=1时，就是最常见的F1，也即</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-9-2-2.png" alt="F-Measure"></p><p>&emsp;&emsp;可知F1综合了P和R的结果，当F1较高时则能说明试验方法比较有效。</p><h3 id="18-9-3-E值"><a href="#18-9-3-E值" class="headerlink" title="18.9.3 E值"></a>18.9.3 E值</h3><p>&emsp;&emsp;E值表示查准率P和查全率R的加权平均值，当其中一个为0时，E值为1，其计算公式：</p><p><img src="/2018/03/16/第十八章_后端架构选型、离线及实时计算/img/18-9-3-1.png" alt="E值"></p><p>&emsp;&emsp;b越大，表示查准率的权重越大。</p><h3 id="18-9-4-平均正确率（Average-Precision）"><a href="#18-9-4-平均正确率（Average-Precision）" class="headerlink" title="18.9.4 平均正确率（Average Precision）"></a>18.9.4 平均正确率（Average Precision）</h3><p>&emsp;&emsp;平均正确率表示不同查全率的点上的正确率的平均。</p><h2 id="18-10-参考文献"><a href="#18-10-参考文献" class="headerlink" title="18.10 参考文献"></a>18.10 参考文献</h2><p>【1】<a href="http://www.paddlepaddle.org/documentation/book/zh/0.11.0/05.recommender_system/index.cn.html" target="_blank" rel="noopener">http://www.paddlepaddle.org/documentation/book/zh/0.11.0/05.recommender_system/index.cn.html</a></p><p>【2】<a href="https://deeplearning4j.org/cn/compare-dl4j-torch7-pylearn.html" target="_blank" rel="noopener">https://deeplearning4j.org/cn/compare-dl4j-torch7-pylearn.html</a></p><p>【3】<a href="http://mahout.apache.org/" target="_blank" rel="noopener">http://mahout.apache.org/</a></p><p>【4】<a href="http://spark.apache.org/docs/1.1.0/mllib-guide.html" target="_blank" rel="noopener">http://spark.apache.org/docs/1.1.0/mllib-guide.html</a></p><p>【5】<a href="https://ray.readthedocs.io/en/latest/tutorial.html" target="_blank" rel="noopener">https://ray.readthedocs.io/en/latest/tutorial.html</a></p><p>【6】<a href="http://spark.apache.org/streaming/" target="_blank" rel="noopener">http://spark.apache.org/streaming/</a></p><p>【7】<a href="https://github.com/uber/horovod" target="_blank" rel="noopener">https://github.com/uber/horovod</a></p><p>【8】<a href="https://software.intel.com/en-us/articles/bigdl-distributed-deep-learning-on-apache-spark" target="_blank" rel="noopener">https://software.intel.com/en-us/articles/bigdl-distributed-deep-learning-on-apache-spark</a></p><p>【9】<a href="https://eng.uber.com/petastorm/" target="_blank" rel="noopener">https://eng.uber.com/petastorm/</a></p><p>【10】<a href="https://yahoo.github.io/TensorFlowOnSpark/#" target="_blank" rel="noopener">https://yahoo.github.io/TensorFlowOnSpark/#</a></p><p> ….</p><p> 未完待续！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://leesen998.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习基础" scheme="https://leesen998.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>DQN三大改进(三)-Dueling Network</title>
    <link href="https://leesen998.github.io/2018/03/12/DQN%E4%B8%89%E5%A4%A7%E6%94%B9%E8%BF%9B(%E4%B8%89)-Dueling%20Network/"/>
    <id>https://leesen998.github.io/2018/03/12/DQN三大改进(三)-Dueling Network/</id>
    <published>2018-03-12T11:48:29.000Z</published>
    <updated>2019-03-22T04:04:53.919Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1541640107/samples/test/photo-1538831539254-abe4ffd1a812.jpg" alt="" style="width:100%"></p><a id="more"></a><h1 id="DQN三大改进-三-Dueling-Network"><a href="#DQN三大改进-三-Dueling-Network" class="headerlink" title="DQN三大改进(三)-Dueling Network"></a>DQN三大改进(三)-Dueling Network</h1><h1 id="1、Dueling-Network"><a href="#1、Dueling-Network" class="headerlink" title="1、Dueling Network"></a>1、Dueling Network</h1><p>什么是Dueling Deep Q Network呢？看下面的图片</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-01c76dca38f8cdc6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/830/format/webp" alt="img"></p><p>上面是我们传统的DQN，下面是我们的Dueling DQN。在原始的DQN中，神经网络直接输出的是每种动作的 Q值, 而 Dueling DQN 每个动作的 Q值 是有下面的公式确定的：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-c12853a38dd23922.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/762/format/webp" alt="img"></p><p>它分成了这个 state 的值, 加上每个动作在这个 state 上的 advantage。我们通过下面这张图来解释一下：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-8bcd1af0e78a2e58.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/636/format/webp" alt="img"></p><p>在这款赛车游戏中。左边是 state value, 发红的部分证明了 state value 和前面的路线有关, 右边是 advantage, 发红的部分说明了 advantage 很在乎旁边要靠近的车子, 这时的动作会受更多 advantage 的影响. 发红的地方左右了自己车子的移动原则。</p><p>但是，利用上面的式子计算Q值会出现一个<strong>unidentifiable</strong>问题：给定一个Q，是无法得到唯一的V和A的。比如，V和A分别加上和减去一个值能够得到同样的Q，但反过来显然无法由Q得到唯一的V和A。</p><p><strong>解决方法</strong><br>强制令所选择贪婪动作的优势函数为0：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-c122f3f4abef6806..jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/435/format/webp" alt="img"></p><p>则我们能得到唯一的值函数：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-d88ff1a2c411da81..jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/720/format/webp" alt="img"></p><p><strong>解决方法的改进</strong><br>使用优势函数的平均值代替上述的最优值</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-a52472a4dcb324ad..jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/460/format/webp" alt="img"></p><p>采用这种方法，虽然使得值函数V和优势函数A不再完美的表示值函数和优势函数(在语义上的表示)，但是这种操作提高了稳定性。而且，并没有改变值函数V和优势函数A的本质表示。</p><h1 id="2、代码实现"><a href="#2、代码实现" class="headerlink" title="2、代码实现"></a>2、代码实现</h1><p>这里我们想要实现的效果类似于寻宝。</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-150fa8b561f59ba7?imageMogr2/auto-orient/strip%7CimageView2/2/w/542/format/webp" alt="img"></p><p>其中，红色的方块代表寻宝人，黑色的方块代表陷阱，黄色的方块代表宝藏，我们的目标就是让寻宝人找到最终的宝藏。</p><p>这里，我们的状态可以用横纵坐标表示，而动作有上下左右四个动作。使用tkinter来做这样一个动画效果。宝藏的奖励是1，陷阱的奖励是-1，而其他时候的奖励都为0。</p><p>接下来，我们重点看一下我们Dueling-DQN相关的代码。</p><p><strong>定义输入</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ------------------------input---------------------------</span></span><br><span class="line">self.s = tf.placeholder(tf.float32, [<span class="keyword">None</span>, self.n_features], name=<span class="string">'s'</span>)</span><br><span class="line">self.q_target = tf.placeholder(tf.float32, [<span class="keyword">None</span>, self.n_actions], name=<span class="string">'Q-target'</span>)</span><br><span class="line">self.s_ = tf.placeholder(tf.float32,[<span class="keyword">None</span>,self.n_features],name=<span class="string">'s_'</span>)</span><br></pre></td></tr></table></figure><p><strong>定义网络结构</strong><br>根据Dueling DQN的网络结构，我们首先定义一个隐藏层，针对隐藏层的输出，我们将此输出分别作为两个隐藏层的输入，分别输出state的Value，和每个action的Advantage，最后， 根据Q = V+A得到每个action的Q值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_layers</span><span class="params">(s, c_names, n_l1, w_initializer, b_initializer)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'l1'</span>):</span><br><span class="line">        w1 = tf.get_variable(<span class="string">'w1'</span>, [self.n_features, n_l1], initializer=w_initializer, collections=c_names)</span><br><span class="line">        b1 = tf.get_variable(<span class="string">'b1'</span>, [<span class="number">1</span>, n_l1], initializer=b_initializer, collections=c_names)</span><br><span class="line">        l1 = tf.nn.relu(tf.matmul(s, w1) + b1)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.dueling:</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'Value'</span>):</span><br><span class="line">            w2 = tf.get_variable(<span class="string">'w2'</span>,[n_l1,<span class="number">1</span>],initializer=w_initializer,collections=c_names)</span><br><span class="line">            b2 = tf.get_variable(<span class="string">'b2'</span>,[<span class="number">1</span>,<span class="number">1</span>],initializer=b_initializer,collections=c_names)</span><br><span class="line">            self.V = tf.matmul(l1,w2) + b2</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'Advantage'</span>):</span><br><span class="line">            w2 = tf.get_variable(<span class="string">'w2'</span>,[n_l1,self.n_actions],initializer=w_initializer,collections=c_names)</span><br><span class="line">            b2 = tf.get_variable(<span class="string">'b2'</span>,[<span class="number">1</span>,self.n_actions],initializer=b_initializer,collections=c_names)</span><br><span class="line">            self.A = tf.matmul(l1,w2) + b2</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'Q'</span>):</span><br><span class="line">            out = self.V + self.A - tf.reduce_mean(self.A,axis=<span class="number">1</span>,keep_dims=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'Q'</span>):</span><br><span class="line">            w2 = tf.get_variable(<span class="string">'w2'</span>, [n_l1, self.n_actions], initializer=w_initializer, collections=c_names)</span><br><span class="line">            b2 = tf.get_variable(<span class="string">'b2'</span>, [<span class="number">1</span>, self.n_actions], initializer=b_initializer, collections=c_names)</span><br><span class="line">            out = tf.matmul(l1, w2) + b2</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>接下来，我们定义我们的eval-net和target-net</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -----------------------------eval net ---------------------</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'eval_net'</span>):</span><br><span class="line">    c_names, n_l1, w_initializer, b_initializer = \</span><br><span class="line">        [<span class="string">'eval_net_params'</span>, tf.GraphKeys.GLOBAL_VARIABLES], <span class="number">20</span>, \</span><br><span class="line">        tf.random_normal_initializer(<span class="number">0.</span>, <span class="number">0.3</span>), tf.constant_initializer(<span class="number">0.1</span>)  <span class="comment"># config of layers</span></span><br><span class="line"></span><br><span class="line">    self.q_eval = build_layers(self.s, c_names, n_l1, w_initializer, b_initializer)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------ build target_net ------------------</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'target_net'</span>):</span><br><span class="line">    c_names = [<span class="string">'target_net_params'</span>, tf.GraphKeys.GLOBAL_VARIABLES]</span><br><span class="line">    self.q_next = build_layers(self.s_, c_names, n_l1, w_initializer, b_initializer)</span><br></pre></td></tr></table></figure><p><strong>定义损失和优化器</strong><br>接下来，我们定义我们的损失，和DQN一样，我们使用的是平方损失：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'loss'</span>):</span><br><span class="line">    self.loss = tf.reduce_mean(tf.squared_difference(self.q_target,self.q_eval))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'train'</span>):</span><br><span class="line">    self.train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)</span><br></pre></td></tr></table></figure><p><strong>定义经验池</strong><br>我们使用一个函数定义我们的经验池，经验池每一行的长度为 状态feature * 2 + 2。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">store_transition</span><span class="params">(self,s,a,r,s_)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">'memory_counter'</span>):</span><br><span class="line">        self.memory_counter = <span class="number">0</span></span><br><span class="line">    transition = np.hstack((s, [a, r], s_))</span><br><span class="line">    index = self.memory_counter % self.memory_size</span><br><span class="line">    self.memory[index, :] = transition</span><br><span class="line">    self.memory_counter += <span class="number">1</span></span><br></pre></td></tr></table></figure><p><strong>选择action</strong><br>我们仍然使用的是e-greedy的选择动作策略，即以e的概率选择随机动作，以1-e的概率通过贪心算法选择能得到最多奖励的动作a。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_action</span><span class="params">(self,observation)</span>:</span></span><br><span class="line">    observation = observation[np.newaxis,:]</span><br><span class="line">    actions_value = self.sess.run(self.q_eval,feed_dict=&#123;self.s:observation&#125;)</span><br><span class="line">    action = np.argmax(actions_value)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> np.random.random() &gt; self.epsilon:</span><br><span class="line">        action = np.random.randint(<span class="number">0</span>,self.n_actions)</span><br><span class="line">    <span class="keyword">return</span> action</span><br></pre></td></tr></table></figure><p><strong>选择数据batch</strong><br>我们从经验池中选择我们训练要使用的数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.memory_counter &gt; self.memory_size:</span><br><span class="line">    sample_index = np.random.choice(self.memory_size, size=self.batch_size)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    sample_index = np.random.choice(self.memory_counter, size=self.batch_size)</span><br><span class="line"></span><br><span class="line">batch_memory = self.memory[sample_index,:]</span><br></pre></td></tr></table></figure><p><strong>更新target-net</strong><br>这里，每个一定的步数，我们就更新target-net中的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">t_params = tf.get_collection(<span class="string">'target_net_params'</span>)</span><br><span class="line">e_params = tf.get_collection(<span class="string">'eval_net_params'</span>)</span><br><span class="line"></span><br><span class="line">self.replace_target_op = [tf.assign(t, e) <span class="keyword">for</span> t, e <span class="keyword">in</span> zip(t_params, e_params)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> self.learn_step_counter % self.replace_target_iter == <span class="number">0</span>:</span><br><span class="line">    self.sess.run(self.replace_target_op)</span><br><span class="line">    print(<span class="string">'\ntarget_params_replaced\n'</span>)</span><br></pre></td></tr></table></figure><p><strong>更新网络参数</strong><br>我们使用DQN的做法来更新网络参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">q_next = self.sess.run(self.q_next, feed_dict=&#123;self.s_: batch_memory[:, -self.n_features:]&#125;)  <span class="comment"># next observation</span></span><br><span class="line">q_eval = self.sess.run(self.q_eval, &#123;self.s: batch_memory[:, :self.n_features]&#125;)</span><br><span class="line"></span><br><span class="line">q_target = q_eval.copy()</span><br><span class="line"></span><br><span class="line">batch_index = np.arange(self.batch_size, dtype=np.int32)</span><br><span class="line">eval_act_index = batch_memory[:, self.n_features].astype(int)</span><br><span class="line">reward = batch_memory[:, self.n_features + <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">q_target[batch_index, eval_act_index] = reward + self.gamma * np.max(q_next, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">_, self.cost = self.sess.run([self._train_op, self.loss],</span><br><span class="line">                             feed_dict=&#123;self.s: batch_memory[:, :self.n_features],</span><br><span class="line">                                        self.q_target: q_target&#125;)</span><br><span class="line">self.cost_his.append(self.cost)</span><br><span class="line"></span><br><span class="line">self.epsilon = self.epsilon + self.epsilon_increment <span class="keyword">if</span> self.epsilon &lt; self.epsilon_max <span class="keyword">else</span> self.epsilon_max</span><br><span class="line">self.learn_step_counter += <span class="number">1</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1541640107/samples/test/photo-1538831539254-abe4ffd1a812.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="强化学习" scheme="https://leesen998.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习实践" scheme="https://leesen998.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>DQN改进-Double DQN</title>
    <link href="https://leesen998.github.io/2018/03/05/DQN%E4%B8%89%E5%A4%A7%E6%94%B9%E8%BF%9B(%E4%B8%80)-Double%20DQN/"/>
    <id>https://leesen998.github.io/2018/03/05/DQN三大改进(一)-Double DQN/</id>
    <published>2018-03-05T11:48:29.000Z</published>
    <updated>2019-03-22T03:56:04.177Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0B/0F/ChMlWlyAyIiIQH8pABv6qMmlUWEAAIp0AAv7LcAG_rA821.jpg" alt="" style="width:100%"></p><a id="more"></a><h1 id="DQN三大改进-一-Double-DQN"><a href="#DQN三大改进-一-Double-DQN" class="headerlink" title="DQN三大改进(一)-Double DQN"></a>DQN三大改进(一)-Double DQN</h1><h1 id="1、背景"><a href="#1、背景" class="headerlink" title="1、背景"></a>1、背景</h1><p>我们简单回顾一下DQN的过程(这里是2015版的DQN)：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-9fef6ee4dcf856a1?imageMogr2/auto-orient/strip%7CimageView2/2/w/700/format/webp" alt="img"></p><p>DQN中有两个关键的技术，叫做经验回放和双网络结构。</p><p>DQN中的损失函数定义为：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-03f9734450028881?imageMogr2/auto-orient/strip%7CimageView2/2/w/316/format/webp" alt="img"></p><p>其中，yi也被我们称为q-target值，而后面的Q(s,a)我们称为q-eval值，我们希望q-target和q-eval值越接近越好。</p><p>q-target如何计算呢？根据下面的公式：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-ec89daa12307440c?imageMogr2/auto-orient/strip%7CimageView2/2/w/405/format/webp" alt="img"></p><p>上面的两个公式分别截取自两篇不同的文章，所以可能有些出入。我们之前说到过，我们有经验池存储的历史经验，经验池中每一条的结构是(s,a,r,s’)，我们的q-target值根据该轮的奖励r以及将s’输入到target-net网络中得到的Q(s’,a’)的最大值决定。</p><p>我们进一步展开我们的q-target计算公式：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-928fcf5fad29d787?imageMogr2/auto-orient/strip%7CimageView2/2/w/454/format/webp" alt="img"></p><p>也就是说，我们根据状态s’选择动作a’的过程,以及估计Q(s’,a’)使用的是同一张Q值表，或者说使用的同一个网络参数，这可能导致选择过高的估计值，从而导致过于乐观的值估计。为了避免这种情况的出现，我们可以对选择和衡量进行解耦，从而就有了双Q学习，在Double DQN中，q-target的计算基于如下的公式：</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-fe9db451ace25e85.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>我们根据一张Q表或者网络参数来选择我们的动作a’,再用另一张Q值表活着网络参数来衡量Q(s’,a’)的值。</p><h1 id="2、代码实现"><a href="#2、代码实现" class="headerlink" title="2、代码实现"></a>2、代码实现</h1><p>本文的代码还是根据莫烦大神的代码，它的github地址为：<a href="https://link.jianshu.com/?t=https%3A%2F%2Fgithub.com%2FMorvanZhou%2FReinforcement-learning-with-tensorflow" target="_blank" rel="noopener">https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow</a></p><p>这里我们想要实现的效果类似于寻宝。</p><p><img src="https://upload-images.jianshu.io/upload_images/4155986-ea8032e664be9be0?imageMogr2/auto-orient/strip%7CimageView2/2/w/542/format/webp" alt="img"></p><p>其中，红色的方块代表寻宝人，黑色的方块代表陷阱，黄色的方块代表宝藏，我们的目标就是让寻宝人找到最终的宝藏。</p><p>这里，我们的状态可以用横纵坐标表示，而动作有上下左右四个动作。使用tkinter来做这样一个动画效果。宝藏的奖励是1，陷阱的奖励是-1，而其他时候的奖励都为0。</p><p>接下来，我们重点看一下我们Double-DQN相关的代码。</p><p><strong>定义输入</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ------------------------input---------------------------</span></span><br><span class="line">self.s = tf.placeholder(tf.float32, [<span class="keyword">None</span>, self.n_features], name=<span class="string">'s'</span>)</span><br><span class="line">self.q_target = tf.placeholder(tf.float32, [<span class="keyword">None</span>, self.n_actions], name=<span class="string">'Q-target'</span>)</span><br><span class="line">self.s_ = tf.placeholder(tf.float32,[<span class="keyword">None</span>,self.n_features],name=<span class="string">'s_'</span>)</span><br></pre></td></tr></table></figure><p><strong>定义双网络结构</strong></p><p>这里我们的双网络结构都简单的采用简单的全链接神经网络，包含一个隐藏层。这里我们得到的输出是一个向量，表示该状态才取每个动作可以获得的Q值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_layers</span><span class="params">(s,c_name,n_l1,w_initializer,b_initializer)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'l1'</span>):</span><br><span class="line">        w1 = tf.get_variable(name=<span class="string">'w1'</span>,shape=[self.n_features,n_l1],initializer=w_initializer,collections=c_name)</span><br><span class="line">        b1 = tf.get_variable(name=<span class="string">'b1'</span>,shape=[<span class="number">1</span>,n_l1],initializer=b_initializer,collections=c_name)</span><br><span class="line">        l1 = tf.nn.relu(tf.matmul(s,w1)+b1)</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'l2'</span>):</span><br><span class="line">        w2 = tf.get_variable(name=<span class="string">'w2'</span>,shape=[n_l1,self.n_actions],initializer=w_initializer,collections=c_name)</span><br><span class="line">        b2 = tf.get_variable(name=<span class="string">'b2'</span>,shape=[<span class="number">1</span>,self.n_actions],initializer=b_initializer,collections=c_name)</span><br><span class="line">        out = tf.matmul(l1,w2) + b2</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>接下来，我们定义两个网络：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ------------------ build evaluate_net ------------------</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'eval_net'</span>):</span><br><span class="line">    c_names = [<span class="string">'eval_net_params'</span>,tf.GraphKeys.GLOBAL_VARIABLES]</span><br><span class="line">    n_l1 = <span class="number">20</span></span><br><span class="line">    w_initializer = tf.random_normal_initializer(<span class="number">0</span>,<span class="number">0.3</span>)</span><br><span class="line">    b_initializer =tf.constant_initializer(<span class="number">0.1</span>)</span><br><span class="line">    self.q_eval = build_layers(self.s,c_names,n_l1,w_initializer,b_initializer)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------ build target_net ------------------</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'target_net'</span>):</span><br><span class="line">    c_names = [<span class="string">'target_net_params'</span>, tf.GraphKeys.GLOBAL_VARIABLES]</span><br><span class="line"></span><br><span class="line">    self.q_next = build_layers(self.s_, c_names, n_l1, w_initializer, b_initializer)</span><br></pre></td></tr></table></figure><p><strong>定义损失和优化器</strong><br>接下来，我们定义我们的损失，和DQN一样，我们使用的是平方损失：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'loss'</span>):</span><br><span class="line">    self.loss = tf.reduce_mean(tf.squared_difference(self.q_target,self.q_eval))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'train'</span>):</span><br><span class="line">    self.train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)</span><br></pre></td></tr></table></figure><p><strong>定义我们的经验池</strong><br>我们使用一个函数定义我们的经验池，经验池每一行的长度为 状态feature * 2 + 2。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">store_transition</span><span class="params">(self,s,a,r,s_)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">'memory_counter'</span>):</span><br><span class="line">        self.memory_counter = <span class="number">0</span></span><br><span class="line">    transition = np.hstack((s, [a, r], s_))</span><br><span class="line">    index = self.memory_counter % self.memory_size</span><br><span class="line">    self.memory[index, :] = transition</span><br><span class="line">    self.memory_counter += <span class="number">1</span></span><br></pre></td></tr></table></figure><p><strong>选择action</strong><br>我们仍然使用的是e-greedy的选择动作策略，即以e的概率选择随机动作，以1-e的概率通过贪心算法选择能得到最多奖励的动作a。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_action</span><span class="params">(self,observation)</span>:</span></span><br><span class="line">    observation = observation[np.newaxis,:]</span><br><span class="line">    actions_value = self.sess.run(self.q_eval,feed_dict=&#123;self.s:observation&#125;)</span><br><span class="line">    action = np.argmax(actions_value)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> np.random.random() &gt; self.epsilon:</span><br><span class="line">        action = np.random.randint(<span class="number">0</span>,self.n_actions)</span><br><span class="line">    <span class="keyword">return</span> action</span><br></pre></td></tr></table></figure><p><strong>选择数据batch</strong><br>我们从经验池中选择我们训练要使用的数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.memory_counter &gt; self.memory_size:</span><br><span class="line">    sample_index = np.random.choice(self.memory_size, size=self.batch_size)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    sample_index = np.random.choice(self.memory_counter, size=self.batch_size)</span><br><span class="line"></span><br><span class="line">batch_memory = self.memory[sample_index,:]</span><br></pre></td></tr></table></figure><p><strong>更新target-net</strong><br>这里，每个一定的步数，我们就更新target-net中的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">t_params = tf.get_collection(<span class="string">'target_net_params'</span>)</span><br><span class="line">e_params = tf.get_collection(<span class="string">'eval_net_params'</span>)</span><br><span class="line"></span><br><span class="line">self.replace_target_op = [tf.assign(t, e) <span class="keyword">for</span> t, e <span class="keyword">in</span> zip(t_params, e_params)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> self.learn_step_counter % self.replace_target_iter == <span class="number">0</span>:</span><br><span class="line">    self.sess.run(self.replace_target_op)</span><br><span class="line">    print(<span class="string">'\ntarget_params_replaced\n'</span>)</span><br></pre></td></tr></table></figure><p><strong>更新网络参数</strong><br>根据Double DQN的做法，我们需要用两个网络的来计算我们的q-target值，同时通过最小化损失来更新网络参数。这里的做法是，根据eval-net的值来选择动作，然后根据target-net的值来计算Q值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">q_next,q_eval4next = self.sess.run([self.q_next, self.q_eval],</span><br><span class="line">                                           feed_dict=&#123;self.s_: batch_memory[:, -self.n_features:],</span><br><span class="line">                                                      self.s: batch_memory[:, -self.n_features:]&#125;)</span><br></pre></td></tr></table></figure><p>q_next是根据经验池中下一时刻状态输入到target-net计算得到的q值，而q_eval4next是根据经验池中下一时刻状态s’输入到eval-net计算得到的q值，这个q值主要用来选择动作。</p><p>下面的动作用来得到我们batch中的实际动作和奖励</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">batch_index = np.arange(self.batch_size, dtype=np.int32)</span><br><span class="line">eval_act_index = batch_memory[:, self.n_features].astype(int)</span><br><span class="line">reward = batch_memory[:, self.n_features + <span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>接下来，我们就要来选择动作并计算该动作的q值了,如果是double dqn的话，我们是根据刚刚计算的q_eval4next来选择动作，然后根据q_next来得到q值的。而原始的dqn直接通过最大的q_next来得到q值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.double_q:</span><br><span class="line">    max_act4next = np.argmax(q_eval4next, axis=<span class="number">1</span>)        <span class="comment"># the action that brings the highest value is evaluated by q_eval</span></span><br><span class="line">    selected_q_next = q_next[batch_index, max_act4next]  <span class="comment"># Double DQN, select q_next depending on above actions</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    selected_q_next = np.max(q_next, axis=<span class="number">1</span>)    <span class="comment"># the natural DQN</span></span><br></pre></td></tr></table></figure><p>那么我们的q-target值就可以计算得到了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">q_target = q_eval.copy()</span><br><span class="line">q_target[batch_index, eval_act_index] = reward + self.gamma * selected_q_next</span><br></pre></td></tr></table></figure><p>有了q-target值，我们就可以结合eval-net计算的q-eval值来更新网络参数了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">_, self.cost = self.sess.run([self.train_op, self.loss],</span><br><span class="line">                             feed_dict=&#123;self.s: batch_memory[:, :self.n_features],</span><br><span class="line">                                        self.q_target: q_target&#125;)</span><br><span class="line">self.cost_his.append(self.cost)</span><br><span class="line"></span><br><span class="line">self.epsilon = self.epsilon + self.epsilon_increment <span class="keyword">if</span> self.epsilon &lt; self.epsilon_max <span class="keyword">else</span> self.epsilon_max</span><br><span class="line">self.learn_step_counter += <span class="number">1</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0B/0F/ChMlWlyAyIiIQH8pABv6qMmlUWEAAIp0AAv7LcAG_rA821.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="强化学习" scheme="https://leesen998.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习实践" scheme="https://leesen998.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>模型压缩及移动端部署</title>
    <link href="https://leesen998.github.io/2018/01/15/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/"/>
    <id>https://leesen998.github.io/2018/01/15/第十七章_模型压缩、加速及移动端部署/</id>
    <published>2018-01-15T11:48:29.000Z</published>
    <updated>2019-03-22T07:37:25.735Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg" alt="" style="width:100%"></p><a id="more"></a><pre><code>Markdown Revision 1;Editor: 谈继勇Contact: scutjy2015@163.comupdata:张达峰</code></pre><h2 id="17-1-为什么需要模型压缩和加速？"><a href="#17-1-为什么需要模型压缩和加速？" class="headerlink" title="17.1 为什么需要模型压缩和加速？"></a>17.1 为什么需要模型压缩和加速？</h2><p>（1）随着AI技术的飞速发展，越来越多的公司希望在自己的移动端产品中注入AI能力</p><p>（2）对于在线学习和增量学习等实时应用而言，如何减少含有大量层级及结点的大型神经网络所需要的内存和计算量显得极为重要。<br>（3）智能设备的流行提供了内存、CPU、能耗和宽带等资源，使得深度学习模型部署在智能移动设备上变得可行。<br>（4）高效的深度学习方法可以有效的帮助嵌入式设备、分布式系统完成复杂工作，在移动端部署深度学习有很重要的意义。   </p><h2 id="17-2-目前有哪些深度学习模型压缩方法？"><a href="#17-2-目前有哪些深度学习模型压缩方法？" class="headerlink" title="17.2 目前有哪些深度学习模型压缩方法？"></a>17.2 目前有哪些深度学习模型压缩方法？</h2><p><a href="https://blog.csdn.net/wspba/article/details/75671573" target="_blank" rel="noopener">https://blog.csdn.net/wspba/article/details/75671573</a><br><a href="https://blog.csdn.net/Touch_Dream/article/details/78441332" target="_blank" rel="noopener">https://blog.csdn.net/Touch_Dream/article/details/78441332</a></p><h3 id="17-2-1-前端压缩"><a href="#17-2-1-前端压缩" class="headerlink" title="17.2.1 前端压缩"></a>17.2.1 前端压缩</h3><p>（1）知识蒸馏（简单介绍）<br>一个复杂的模型可以认为是由多个简单模型或者强约束条件训练而来，具有很好的性能，但是参数量很大，计算效率低，而小模型计算效率高，但是其性能较差。知识蒸馏是让复杂模型学习到的知识迁移到小模型当中,使其保持其快速的计算速度前提下，同时拥有复杂模型的性能，达到模型压缩的目的。但与剪枝、量化等方法想比，效果较差。(<a href="https://blog.csdn.net/Lucifer_zzq/article/details/79489248" target="_blank" rel="noopener">https://blog.csdn.net/Lucifer_zzq/article/details/79489248</a>)<br>（2）紧凑的模型结构设计（简单介绍）<br>紧凑的模型结构设计主要是对神经网络卷积的方式进行改进，比如使用两个3x3的卷积替换一个5x5的卷积、使用深度可分离卷积等等方式降低计算参数量。<br>（3）滤波器层面的剪枝（简单介绍）<br>参考链接  <a href="https://blog.csdn.net/JNingWei/article/details/79218745" target="_blank" rel="noopener">https://blog.csdn.net/JNingWei/article/details/79218745</a> 补充优缺点<br>滤波器层面的剪枝属于非结构花剪枝，主要是对较小的权重矩阵整个剔除，然后对整个神经网络进行微调。此方式由于剪枝过于粗放，容易导致精度损失较大，而且部分权重矩阵中会存留一些较小的权重造成冗余，剪枝不彻底。  </p><h3 id="17-2-2-后端压缩"><a href="#17-2-2-后端压缩" class="headerlink" title="17.2.2 后端压缩"></a>17.2.2 后端压缩</h3><p>（1）低秩近似   （简单介绍，参考链接补充优缺点）<br>在卷积神经网络中，卷积运算都是以矩阵相乘的方式进行。对于复杂网络，权重矩阵往往非常大，非常消耗存储和计算资源。低秩近似就是用若干个低秩矩阵组合重构大的权重矩阵，以此降低存储和计算资源消耗。<br>优点：  </p><ul><li><p>可以降低存储和计算消耗；</p></li><li><p>一般可以压缩2-3倍；精度几乎没有损失；  </p></li></ul><p>缺点：  </p><ul><li>模型越复杂，权重矩阵越大，利用低秩近似重构参数矩阵不能保证模型的性能      </li></ul><p>（2）未加限制的剪枝   （简单介绍，参考链接补充优缺点）<br>剪枝操作包括：非结构化剪枝和结构化剪枝。非结构化剪枝是对神经网络中权重较小的权重或者权重矩阵进剔除，然后对整个神经网络进行微调；结构化剪枝是在网络优化目标中加入权重稀疏正则项，使部分权重在训练时趋于0。  </p><p>优点： </p><ul><li><p>保持模型性能不损失的情况下，减少参数量9-11倍；</p></li><li><p>剔除不重要的权重，可以加快计算速度，同时也可以提高模型的泛化能力；</p></li></ul><p>缺点：  </p><ul><li><p>非结构化剪枝会增加内存访问成本；</p></li><li><p>极度依赖专门的运行库和特殊的运行平台，不具有通用性；</p></li><li><p>压缩率过大时，破坏性能；     </p></li></ul><p>（3）参数量化   （简单介绍，参考链接补充优缺点）<br>神经网络的参数类型一般是32位浮点型，使用较小的精度代替32位所表示的精度。或者是将多个权重映射到同一数值，权重共享<br>优点：</p><ul><li>模型性能损失很小，大小减少8-16倍；</li></ul><p>缺点：</p><ul><li><p>压缩率大时，性能显著下降；</p></li><li><p>依赖专门的运行库，通用性较差；    </p></li></ul><p>（4）二值网络  （简单介绍，参考链接补充优缺点）<br>对于32bit浮点型数用1bit二进制数-1或者1表示。<br>优点：</p><ul><li>网络体积小，运算速度快     </li></ul><p>目前深度学习模型压缩方法的研究主要可以分为以下几个方向：<br>（1）更精细模型的设计。目前很多网络基于模块化设计思想，在深度和宽度两个维度上都很大，导致参数冗余。因此有很多关于模型设计的研究，如SqueezeNet、MobileNet等，使用更加细致、高效的模型设计，能够很大程度的减少模型尺寸，并且也具有不错的性能。<br>（2）模型裁剪。结构复杂的网络具有非常好的性能，其参数也存在冗余，因此对于已训练好的模型网络，可以寻找一种有效的评判手段，将不重要的connection或者filter进行裁剪来减少模型的冗余。<br>（3）核的稀疏化。在训练过程中，对权重的更新进行诱导，使其更加稀疏，对于稀疏矩阵，可以使用更加紧致的存储方式，如CSC，但是使用稀疏矩阵操作在硬件平台上运算效率不高，容易受到带宽的影响，因此加速并不明显。<br>（4）量化<br>（5）Low-rank分解<br>（6）迁移学习   </p><h2 id="17-3-目前有哪些深度学习模型优化加速方法？"><a href="#17-3-目前有哪些深度学习模型优化加速方法？" class="headerlink" title="17.3 目前有哪些深度学习模型优化加速方法？"></a>17.3 目前有哪些深度学习模型优化加速方法？</h2><p><a href="https://blog.csdn.net/nature553863/article/details/81083955" target="_blank" rel="noopener">https://blog.csdn.net/nature553863/article/details/81083955</a><br>模型优化加速能够提升网络的计算效率，具体包括：<br>（1）Op-level的快速算法：FFT Conv2d (7x7, 9x9), Winograd Conv2d (3x3, 5x5) 等；<br>（2）Layer-level的快速算法：Sparse-block net [1] 等；<br>（3）优化工具与库：TensorRT (Nvidia), Tensor Comprehension (Facebook) 和 Distiller (Intel) 等；   </p><p>原文：<a href="https://blog.csdn.net/nature553863/article/details/81083955" target="_blank" rel="noopener">https://blog.csdn.net/nature553863/article/details/81083955</a>   </p><h2 id="17-4-影响神经网络速度的4个因素（再稍微详细一点）"><a href="#17-4-影响神经网络速度的4个因素（再稍微详细一点）" class="headerlink" title="17.4 影响神经网络速度的4个因素（再稍微详细一点）"></a>17.4 影响神经网络速度的4个因素（再稍微详细一点）</h2><ol><li>FLOPs(FLOPs就是网络执行了多少multiply-adds操作)；  </li><li>MAC(内存访问成本)；   </li><li>并行度(如果网络并行度高，速度明显提升)；   </li><li>计算平台(GPU，ARM)   </li></ol><h2 id="17-5-改变网络结构设计为什么会实现模型压缩、加速？"><a href="#17-5-改变网络结构设计为什么会实现模型压缩、加速？" class="headerlink" title="17.5 改变网络结构设计为什么会实现模型压缩、加速？"></a>17.5 改变网络结构设计为什么会实现模型压缩、加速？</h2><h3 id="1-Group-convolution"><a href="#1-Group-convolution" class="headerlink" title="1. Group convolution"></a>1. Group convolution</h3><p>Group convolution最早出现在AlexNet中，是为了解决单卡显存不够，将网络部署到多卡上进行训练。Group convolution可以减少单个卷积1/g的参数量。<br>假设输入特征的的维度为H * W * c1；卷积核的维度为h1 * w1 * c1，共c2个；输出特征的维度为 H1 * W1 * c2。<br>传统卷积计算方式如下：<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/1.png" alt="image"><br>传统卷积运算量为：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A = H * W * h1 * w1 * c1 * c2</span><br></pre></td></tr></table></figure><p>Group convolution是将输入特征的维度c1分成g份，每个group对应的channel数为c1/g，特征维度H * W * c1/g；，每个group对应的卷积核的维度也相应发生改变为h1 * w1 * c1/9，共c2/g个；每个group相互独立运算，最后将结果叠加在一起。<br>Group convolution计算方式如下：<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/2.png" alt="image"><br>Group convolution运算量为：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">B = H * W * h1 * w1 * c1/g * c2/g * g</span><br></pre></td></tr></table></figure><p>Group卷积相对于传统卷积的运算量：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\dfrac&#123;B&#125;&#123;A&#125; = \dfrac&#123; H * W * h1 * w1 * c1/g * c2/g * g&#125;&#123;H * W * h1 * w1 * c1 * c2&#125; = \dfrac&#123;1&#125;&#123;g&#125;</span><br></pre></td></tr></table></figure></p><p>由此可知：group卷积相对于传统卷积减少了1/g的参数量。</p><h3 id="2-Depthwise-separable-convolution"><a href="#2-Depthwise-separable-convolution" class="headerlink" title="2. Depthwise separable convolution"></a>2. Depthwise separable convolution</h3><p>Depthwise separable convolution是由depthwise conv和pointwise conv构成。<br>depthwise conv(DW)有效减少参数数量并提升运算速度。但是由于每个feature map只被一个卷积核卷积，因此经过DW输出的feature map不能只包含输入特征图的全部信息，而且特征之间的信息不能进行交流，导致“信息流通不畅”。<br>pointwise conv(PW)实现通道特征信息交流，解决DW卷积导致“信息流通不畅”的问题。<br>假设输入特征的的维度为H * W * c1；卷积核的维度为h1 * w1 * c1，共c2个；输出特征的维度为 H1 * W1 * c2。<br>传统卷积计算方式如下：<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/3.png" alt="image"><br>传统卷积运算量为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A = H * W * h1 * w1 * c1 * c2</span><br></pre></td></tr></table></figure></p><p>DW卷积的计算方式如下：<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/4.png" alt="image"><br>DW卷积运算量为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">B_DW = H * W * h1 * w1 * 1 * c1</span><br></pre></td></tr></table></figure></p><p>PW卷积的计算方式如下：<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/5.png" alt="image"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">B_PW = H_m * W_m * 1 * 1 * c1 * c2</span><br></pre></td></tr></table></figure></p><p>Depthwise separable convolution运算量为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">B = B_DW + B_PW</span><br></pre></td></tr></table></figure></p><p>Depthwise separable convolution相对于传统卷积的运算量：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">\dfrac&#123;B&#125;&#123;A&#125; = \dfrac&#123; H * W * h1 * w1 * 1 * c1 + H_m * W_m * 1 * 1 * c1 * c2&#125;&#123;H * W * h1 * w1 * c1 * c2&#125;  </span><br><span class="line"></span><br><span class="line">= \dfrac&#123;1&#125;&#123;c2&#125; + \dfrac&#123;1&#125;&#123;h1 * w1&#125;</span><br></pre></td></tr></table></figure></p><p>由此可知，随着卷积通道数的增加，Depthwise separable convolution的运算量相对于传统卷积更少。</p><h3 id="3-输入输出的channel相同时，MAC最小"><a href="#3-输入输出的channel相同时，MAC最小" class="headerlink" title="3. 输入输出的channel相同时，MAC最小"></a>3. 输入输出的channel相同时，MAC最小</h3><p><strong>卷积层的输入和输出特征通道数相等时MAC最小，此时模型速度最快。</strong><br>假设feature map的大小为h*w，输入通道c1，输出通道c2。<br>已知：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">FLOPs = B = h * w * c1 * c2</span><br><span class="line"></span><br><span class="line">=&gt; c1 * c2 = \dfrac&#123;B&#125;&#123;h * w&#125;</span><br><span class="line"></span><br><span class="line">MAC = h * w * (c1 + c2) + c1 * c2</span><br><span class="line"></span><br><span class="line">c1 + c2 \geq 2 * \sqrt&#123;c1 * c2&#125;</span><br><span class="line"></span><br><span class="line">=&gt; MAC \geq 2 * h * w \sqrt&#123;\dfrac&#123;B&#125;&#123;h * w&#125;&#125; + \dfrac&#123;B&#125;&#123;h * w&#125;</span><br></pre></td></tr></table></figure></p><p>根据均值不等式得到(c1-c2)^2&gt;=0，等式成立的条件是c1=c2，也就是输入特征通道数和输出特征通道数相等时，在给定FLOPs前提下，MAC达到取值的下界。</p><h3 id="4-减少组卷积的数量"><a href="#4-减少组卷积的数量" class="headerlink" title="4. 减少组卷积的数量"></a>4. 减少组卷积的数量</h3><p><strong>过多的group操作会增大MAC，从而使模型速度变慢</strong><br>由以上公式可知，group卷积想比与传统的卷积可以降低计算量，提高模型的效率；如果在相同的FLOPs时，group卷积为了满足FLOPs会是使用更多channels，可以提高模型的精度。但是随着channel数量的增加，也会增加MAC。<br>FLOPs：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">B = \dfrac&#123;h * w * c1 * c2&#125;&#123;g&#125;</span><br></pre></td></tr></table></figure></p><p>MAC：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAC = h * w * (c1 + c2) + \dfrac&#123;c1 * c2&#125;&#123;g&#125;</span><br></pre></td></tr></table></figure></p><p>由MAC，FLOPs可知：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAC = h * w * c1 + \dfrac&#123;B*g&#125;&#123;c1&#125; + \dfrac&#123;B&#125;&#123;h * w&#125;</span><br></pre></td></tr></table></figure></p><p>当FLOPs固定(B不变)时，g越大，MAC越大。</p><h3 id="5-减少网络碎片化程度-分支数量"><a href="#5-减少网络碎片化程度-分支数量" class="headerlink" title="5. 减少网络碎片化程度(分支数量)"></a>5. 减少网络碎片化程度(分支数量)</h3><p><strong>模型中分支数量越少，模型速度越快</strong><br>此结论主要是由实验结果所得。<br>以下为网络分支数和各分支包含的卷积数目对神经网络速度的影响。<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/6.png" alt="image"><br>实验中使用的基本网络结构，分别将它们重复10次，然后进行实验。实验结果如下：<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/7.png" alt="image"><br>由实验结果可知，随着网络分支数量的增加，神经网络的速度在降低。网络碎片化程度对GPU的影响效果明显，对CPU不明显，但是网络速度同样在降低。</p><h3 id="6-减少元素级操作"><a href="#6-减少元素级操作" class="headerlink" title="6. 减少元素级操作"></a>6. 减少元素级操作</h3><p><strong>元素级操作所带来的时间消耗也不能忽视</strong><br>ReLU ，Tensor 相加，Bias相加的操作，分离卷积（depthwise convolution）都定义为元素级操作。<br>FLOPs大多数是对于卷积计算而言的，因为元素级操作的FLOPs相对要低很多。但是过的元素级操作也会带来时间成本。ShuffleNet作者对ShuffleNet v1和MobileNet v2的几种层操作的时间消耗做了分析，发现元素级操作对于网络速度的影响也很大。<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/8.png" alt="image"></p><h2 id="17-6-常用的轻量级网络有哪些？（再琢磨下语言和排版）"><a href="#17-6-常用的轻量级网络有哪些？（再琢磨下语言和排版）" class="headerlink" title="17.6 常用的轻量级网络有哪些？（再琢磨下语言和排版）"></a>17.6 常用的轻量级网络有哪些？（再琢磨下语言和排版）</h2><ul><li><strong>SqueezeNet</strong></li><li><strong>MobileNet</strong></li><li><strong>ShuffleNet</strong></li><li><strong>Xception</strong></li></ul><h3 id="1-SequeezeNet"><a href="#1-SequeezeNet" class="headerlink" title="1. SequeezeNet"></a>1. SequeezeNet</h3><p>SqueenzeNet出自F. N. Iandola, S.Han等人发表的论文《SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt; 0.5MB model size》，作者在保证精度不损失的同时，将原始AlexNet压缩至原来的510倍。  </p><h4 id="1-1-设计思想"><a href="#1-1-设计思想" class="headerlink" title="1.1 设计思想"></a>1.1 设计思想</h4><p>在网络结构设计方面主要采取以下三种方式：</p><ul><li>用1*1卷积核替换3*3卷积<ul><li>理论上一个1*1卷积核的参数是一个3*3卷积核的1/9，可以将模型尺寸压缩9倍。</li></ul></li><li>减小3*3卷积的输入通道数<ul><li>根据上述公式，减少输入通道数不仅可以减少卷积的运算量，而且输入通道数与输出通道数相同时还可以减少MAC。</li></ul></li><li>延迟降采样<ul><li>分辨率越大的输入能够提供更多特征的信息，有利于网络的训练判断，延迟降采样可以提高网络精度。<h4 id="1-2-网络架构"><a href="#1-2-网络架构" class="headerlink" title="1.2 网络架构"></a>1.2 网络架构</h4>SqueezeNet提出一种多分支结构——fire model，其中是由Squeeze层和expand层构成。Squeeze层是由s1个1*1卷积组成，主要是通过1*1的卷积降低expand层的输入维度；expand层利用e1个1*1和e3个3*3卷积构成多分支结构提取输入特征，以此提高网络的精度(其中e1=e3=4*s1)。<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/9.png" alt="image"><br>SqueezeNet整体网络结构如下图所示：<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/10.png" alt="image"><h4 id="1-3实验结果"><a href="#1-3实验结果" class="headerlink" title="1.3实验结果"></a>1.3实验结果</h4>不同压缩方法在ImageNet上的对比实验结果<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/11.png" alt="image"><br>由实验结果可知，SqueezeNet不仅保证了精度，而且将原始AlexNet从240M压缩至4.8M，压缩50倍，说明此轻量级网络设计是可行。</li></ul></li></ul><h3 id="2-MobileNet"><a href="#2-MobileNet" class="headerlink" title="2. MobileNet"></a>2. MobileNet</h3><p>MobileNet 是Google团队于CVPR-2017的论文《MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications》中针对手机等嵌入式设备提出的一种轻量级的深层神经网络，该网络结构在VGG的基础上使用DW+PW的组合，在保证不损失太大精度的同时，降低模型参数量。</p><h4 id="2-1-设计思想"><a href="#2-1-设计思想" class="headerlink" title="2.1 设计思想"></a>2.1 设计思想</h4><ul><li>采用深度可分离卷积代替传统卷积<ul><li>采用DW卷积在减少参数数量的同时提升运算速度。但是由于每个feature map只被一个卷积核卷积，因此经过DW输出的feature map不能只包含输入特征图的全部信息，而且特征之间的信息不能进行交流，导致“信息流通不畅”。</li><li>采用PW卷积实现通道特征信息交流，解决DW卷积导致“信息流通不畅”的问题。</li></ul></li><li>使用stride=2的卷积替换pooling<ul><li>直接在卷积时利用stride=2完成了下采样，从而节省了需要再去用pooling再去进行一次下采样的时间，可以提升运算速度。同时，因为pooling之前需要一个stride=1的 conv，而与stride=2 conv的计算量想比要高近4倍(<strong>个人理解</strong>)。<h4 id="2-2-网络架构"><a href="#2-2-网络架构" class="headerlink" title="2.2 网络架构"></a>2.2 网络架构</h4></li></ul></li><li><p>DW conv和PW conv<br>MobileNet的网络架构主要是由DW conv和PW conv组成，相比于传统卷积可以降低<code>$\dfrac{1}{N} + \dfrac{1}{Dk}$</code>倍的计算量。<br>标准卷积与DW conv和PW conv如图所示:<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/12.png" alt="image"><br>深度可分离卷积与传统卷积运算量对比：<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/13.png" alt="image"><br>网络结构：<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/14.png" alt="image"></p></li><li><p>MobileNets的架构<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/15.png" alt="image"></p></li></ul><h4 id="2-3-实验结果"><a href="#2-3-实验结果" class="headerlink" title="2.3 实验结果"></a>2.3 实验结果</h4><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/16.png" alt="image"><br>由上表可知，使用相同的结构，深度可分离卷积虽然准确率降低1%，但是参数量减少了6/7。</p><h3 id="3-MobileNet-v2"><a href="#3-MobileNet-v2" class="headerlink" title="3. MobileNet-v2"></a>3. MobileNet-v2</h3><p>MobileNet-V2是2018年1月公开在arXiv上论文《Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation》，是对MobileNet-V1的改进，同样是一个轻量化卷积神经网络。</p><h4 id="3-1-设计思想"><a href="#3-1-设计思想" class="headerlink" title="3.1 设计思想"></a>3.1 设计思想</h4><ul><li>采用Inverted residuals<ul><li>为了保证网络可以提取更多的特征，在residual block中第一个1*1 Conv和3*3 DW Conv之前进行通道扩充</li></ul></li><li>Linear bottlenecks<ul><li>为了避免Relu对特征的破坏，在residual block的Eltwise sum之前的那个 1*1 Conv 不再采用Relu</li></ul></li><li>stride=2的conv不使用shot-cot，stride=1的conv使用shot-cut</li></ul><h4 id="3-2-网络架构"><a href="#3-2-网络架构" class="headerlink" title="3.2 网络架构"></a>3.2 网络架构</h4><ul><li>Inverted residuals<br>ResNet中Residuals block先经过1*1的Conv layer，把feature map的通道数降下来，再经过3*3 Conv layer，最后经过一个1*1 的Conv layer，将feature map 通道数再“扩张”回去。即采用先压缩，后扩张的方式。而 inverted residuals采用先扩张，后压缩的方式。<br>MobileNet采用DW conv提取特征，由于DW conv本身提取的特征数就少，再经过传统residuals block进行“压缩”，此时提取的特征数会更少，因此inverted residuals对其进行“扩张”，保证网络可以提取更多的特征。<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/17.png" alt="image"></li><li>Linear bottlenecks<br>ReLu激活函数会破坏特征。ReLu对于负的输入，输出全为0，而本来DW conv特征通道已经被“压缩”，再经过ReLu的话，又会损失一部分特征。采用Linear，目的是防止Relu破坏特征。<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/18.png" alt="image"></li><li>shortcut<br>stride=2的conv不使用shot-cot，stride=1的conv使用shot-cut<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/19.png" alt="image"></li><li>网络架构<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/20.png" alt="image"></li></ul><h3 id="4-Xception"><a href="#4-Xception" class="headerlink" title="4. Xception"></a>4. Xception</h3><p>Xception是Google提出的，arXiv 的V1 于2016年10月公开《Xception: Deep Learning with Depthwise Separable Convolutions 》，Xception是对Inception v3的另一种改进，主要是采用depthwise separable convolution来替换原来Inception v3中的卷积操作。</p><h4 id="4-1设计思想"><a href="#4-1设计思想" class="headerlink" title="4.1设计思想"></a>4.1设计思想</h4><ul><li>采用depthwise separable convolution来替换原来Inception v3中的卷积操作<br>  与原版的Depth-wise convolution有两个不同之处：<ul><li>第一个：原版Depth-wise convolution，先逐通道卷积，再1<em>1卷积; 而Xception是反过来，先1\</em>1卷积，再逐通道卷积；</li><li>第二个：原版Depth-wise convolution的两个卷积之间是不带激活函数的，而Xception在经过1*1卷积之后会带上一个Relu的非线性激活函数；</li></ul></li></ul><h4 id="4-2网络架构"><a href="#4-2网络架构" class="headerlink" title="4.2网络架构"></a>4.2网络架构</h4><p>feature map在空间和通道上具有一定的相关性，通过Inception模块和非线性激活函数实现通道之间的解耦。增多3*3的卷积的分支的数量，使它与1*1的卷积的输出通道数相等，此时每个3*3的卷积只作用与一个通道的特征图上，作者称之为“极致的Inception（Extream Inception）”模块，这就是Xception的基本模块。<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/21.png" alt="image"></p><h3 id="5-ShuffleNet-v1"><a href="#5-ShuffleNet-v1" class="headerlink" title="5. ShuffleNet-v1"></a>5. ShuffleNet-v1</h3><p>ShuffleNet 是Face++团队提出的，晚于MobileNet两个月在arXiv上公开《ShuffleNet： An Extremely Efficient Convolutional Neural Network for Mobile Devices 》用于移动端前向部署的网络架构。ShuffleNet基于MobileNet的group思想，将卷积操作限制到特定的输入通道。而与之不同的是，ShuffleNet将输入的group进行打散，从而保证每个卷积核的感受野能够分散到不同group的输入中，增加了模型的学习能力。</p><h4 id="5-1-设计思想"><a href="#5-1-设计思想" class="headerlink" title="5.1 设计思想"></a>5.1 设计思想</h4><ul><li>采用group conv减少大量参数<ul><li>roup conv与DW conv存在相同的“信息流通不畅”问题 </li></ul></li><li>采用channel shuffle解决上述问题<ul><li>MobileNet中采用PW conv解决上述问题，SheffleNet中采用channel shuffle</li></ul></li><li>采用concat替换add操作<ul><li>avg pooling和DW conv(s=2)会减小feature map的分辨率，采用concat增加通道数从而弥补分辨率减小而带来信息的损失</li></ul></li></ul><h4 id="5-2-网络架构"><a href="#5-2-网络架构" class="headerlink" title="5.2 网络架构"></a>5.2 网络架构</h4><p>MobileNet中1*1卷积的操作占据了约95%的计算量，所以作者将1*1也更改为group卷积，使得相比MobileNet的计算量大大减少。<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/22.png" alt="image"><br>group卷积与DW存在同样使“通道信息交流不畅”的问题，MobileNet中采用PW conv解决上述问题，SheffleNet中采用channel shuffle。<br>ShuffleNet的shuffle操作如图所示<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/24.png" alt="image"><br>avg pooling和DW conv(s=2)会减小feature map的分辨率，采用concat增加通道数从而弥补分辨率减小而带来信息的损失；实验表明：多多使用通道(提升通道的使用率)，有助于提高小模型的准确率。<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/23.png" alt="image"><br>网络结构：<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/25.png" alt="image"></p><h3 id="6-ShuffleNet-v2"><a href="#6-ShuffleNet-v2" class="headerlink" title="6. ShuffleNet-v2"></a>6. ShuffleNet-v2</h3><p>huffleNet-v2 是Face++团队提出的《ShuffleNet V2: Practical Guidelines for Ecient CNN Architecture Design》，旨在设计一个轻量级但是保证精度、速度的深度网络。</p><h4 id="6-1-设计思想"><a href="#6-1-设计思想" class="headerlink" title="6.1 设计思想"></a>6.1 设计思想</h4><ul><li>文中提出影响神经网络速度的4个因素：<ul><li>a. FLOPs(FLOPs就是网络执行了多少multiply-adds操作)</li><li>b. MAC(内存访问成本)</li><li>c. 并行度(如果网络并行度高，速度明显提升)</li><li>d. 计算平台(GPU，ARM)</li></ul></li><li>ShuffleNet-v2 提出了4点网络结构设计策略：<ul><li>G1.输入输出的channel相同时，MAC最小</li><li>G2.过度的组卷积会增加MAC</li><li>G3.网络碎片化会降低并行度</li><li>G4.元素级运算不可忽视  </li></ul></li></ul><h4 id="6-2-网络结构"><a href="#6-2-网络结构" class="headerlink" title="6.2 网络结构"></a>6.2 网络结构</h4><p>depthwise convolution 和 瓶颈结构增加了 MAC，用了太多的 group，跨层连接中的 element-wise Add 操作也是可以优化的点。所以在 shuffleNet V2 中增加了几种新特性。<br>所谓的 channel split 其实就是将通道数一分为2，化成两分支来代替原先的分组卷积结构（G2），并且每个分支中的卷积层都是保持输入输出通道数相同（G1），其中一个分支不采取任何操作减少基本单元数（G3），最后使用了 concat 代替原来的 elementy-wise add，并且后面不加 ReLU 直接（G4），再加入channle shuffle 来增加通道之间的信息交流。 对于下采样层，在这一层中对通道数进行翻倍。 在网络结构的最后，即平均值池化层前加入一层 1x1 的卷积层来进一步的混合特征。<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/26.png" alt="image"><br>网络结构<br><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/27.png" alt="image"></p><h4 id="6-4-ShuffleNet-v2具有高精度的原因"><a href="#6-4-ShuffleNet-v2具有高精度的原因" class="headerlink" title="6.4  ShuffleNet-v2具有高精度的原因"></a>6.4  ShuffleNet-v2具有高精度的原因</h4><ul><li>由于高效，可以增加更多的channel，增加网络容量</li><li>采用split使得一部分特征直接与下面的block相连，特征复用(DenseNet)</li></ul><h2 id="17-7-现有移动端开源框架及其特点"><a href="#17-7-现有移动端开源框架及其特点" class="headerlink" title="17.7 现有移动端开源框架及其特点"></a>17.7 现有移动端开源框架及其特点</h2><h3 id="17-7-1-NCNN"><a href="#17-7-1-NCNN" class="headerlink" title="17.7.1 NCNN"></a>17.7.1 NCNN</h3><p>１、开源时间：2017年7月　　　</p><p>２、开源用户：腾讯优图　　　　</p><p>３、GitHub地址：<a href="https://github.com/Tencent/ncnn" target="_blank" rel="noopener">https://github.com/Tencent/ncnn</a> 　　</p><p>4、特点：</p><ul><li>1）NCNN考虑了手机端的硬件和系统差异以及调用方式，架构设计以手机端运行为主要原则。</li><li>2）无第三方依赖，跨平台，手机端 CPU 的速度快于目前所有已知的开源框架（以开源时间为参照对象）。</li><li>3）基于 ncnn，开发者能够将深度学习算法轻松移植到手机端高效执行，开发出人工智能 APP。   </li></ul><p>5、功能：    </p><ul><li>1、NCNN支持卷积神经网络、多分支多输入的复杂网络结构，如vgg、googlenet、resnet、squeezenet 等。</li><li>2、NCNN无需依赖任何第三方库。    </li><li>3、NCNN全部使用C/C++实现，以及跨平台的cmake编译系统，可轻松移植到其他系统和设备上。    </li><li>4、汇编级优化，计算速度极快。使用ARM NEON指令集实现卷积层，全连接层，池化层等大部分 CNN 关键层。 </li><li>5、精细的数据结构设计，没有采用需消耗大量内存的通常框架——im2col + 矩阵乘法，使得内存占用极低。   </li><li>6、支持多核并行计算，优化CPU调度。   </li><li>7、整体库体积小于500K，可精简到小于300K。   </li><li>8、可扩展的模型设计，支持8bit 量化和半精度浮点存储。   </li><li>9、支持直接内存引用加载网络模型。   </li><li>10、可注册自定义层实现并扩展。   </li></ul><p>6、NCNN在Android端部署示例</p><ul><li>1）选择合适的Android Studio版本并安装。</li><li>2）根据需求选择NDK版本并安装。</li><li>3）在Android Studio上配置NDK的环境变量。</li><li>4）根据自己需要编译NCNN sdk</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir build-android cd build-android cmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake \ -DANDROID_ABI=&quot;armeabi-v7a&quot; -DANDROID_ARM_NEON=ON \ -DANDROID_PLATFORM=android-14 .. make make install</span><br></pre></td></tr></table></figure><p>​    安装完成之后，install下有include和lib两个文件夹。</p><p>​    备注：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ANDROID_ABI 是架构名字，&quot;armeabi-v7a&quot; 支持绝大部分手机硬件 </span><br><span class="line">ANDROID_ARM_NEON 是否使用 NEON 指令集，设为 ON 支持绝大部分手机硬件 </span><br><span class="line">ANDROID_PLATFORM 指定最低系统版本，&quot;android-14&quot; 就是 android-4.0</span><br></pre></td></tr></table></figure><ul><li>5）进行NDK开发。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1）assets文件夹下放置你的bin和param文件。</span><br><span class="line">2）jni文件夹下放置你的cpp和mk文件。</span><br><span class="line">3）修改你的app gradle文件。</span><br><span class="line">4）配置Android.mk和Application.mk文件。</span><br><span class="line">5）进行java接口的编写。</span><br><span class="line">6）读取拷贝bin和param文件（有些则是pb文件，根据实际情况）。</span><br><span class="line">7）进行模型的初始化和执行预测等操作。</span><br><span class="line">8）build。</span><br><span class="line">9）cd到src/main/jni目录下，执行ndk-build，生成.so文件。</span><br><span class="line">10）接着就可写自己的操作处理需求。</span><br></pre></td></tr></table></figure><h3 id="17-7-2-QNNPACK"><a href="#17-7-2-QNNPACK" class="headerlink" title="17.7.2 QNNPACK"></a>17.7.2 QNNPACK</h3><p>全称：Quantized Neural Network PACKage（量化神经网络包）　　　</p><p>１、开源时间：2018年10月　　　</p><p>２、开源用户：Facebook　　　　</p><p>３、GitHub地址：<a href="https://github.com/pytorch/QNNPACK" target="_blank" rel="noopener">https://github.com/pytorch/QNNPACK</a>　　　　</p><p>４、特点：　　　</p><p>​    １）低密度卷积优化函数库；　　　</p><p>　    ２）可在手机上实时运行Mask R-CNN 和 DensePose;</p><p>​    ３） 能在性能受限的移动设备中用 100ms 以内的时间实施图像分类；　　　</p><p>5、QNNPACK 如何提高效率？</p><p>1)<strong>QNNPACK 使用与安卓神经网络 API 兼容的线性量化方案</strong></p><p>QNNPACK 的输入矩阵来自低精度、移动专用的计算机视觉模型。其它库在计算A和B矩阵相乘时，重新打包 A 和 B 矩阵以更好地利用缓存层次结构，希望在大量计算中分摊打包开销，QNNPACK 删除所有计算非必需的内存转换，针对 A和B矩阵相乘适用于一级缓存的情况进行了优化。</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/QNNPACK1.jpeg" alt=""></p><p>​    在量化矩阵-矩阵乘法中，8  位整数的乘积通常会被累加至 32 位的中间结果中，随后重新量化以产生 8 位的输出。常规的实现会对大矩阵尺寸进行优化——有时 K 太大无法将 A  和 B 的面板转入缓存中。为了有效利用缓存层次结构，传统的 GEMM 实现将 A 和 B 的面板沿 K  维分割成固定大小的子面板，从而每个面板都适应 L1 缓存，随后为每个子面板调用微内核。这一缓存优化需要 PDOT 为内核输出 32  位中间结果，最终将它们相加并重新量化为 8 位整数。</p><p>​    由于  ONNPACK 对于面板 A 和 B 总是适应 L1 缓存的移动神经网络进行了优化，因此它在调用微内核时处理整个 A 和 B  的面板。而由于无需在微内核之外积累 32 位的中间结果，QNNPACK 会将 32 位的中间结果整合进微内核中并写出 8  位值，这节省了内存带宽和缓存占用。</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/QNNPACK2.jpeg" alt=""></p><p>使整个 A、B  面板适配缓存帮助实现了 QNNPACK 中的另一个优化：取消了矩阵 A 的重新打包。矩阵 B 包含静态权重，可以一次性转换成任何内存布局，但矩阵  A 包含卷积输入，每次推理运行都会改变。因此，重新打包矩阵 A 在每次运行时都会产生开销。尽管存在开销，传统的 GEMM  实现还是出于以下两个原因对矩阵 A 进行重新打包：缓存关联性及微内核效率受限。如果不重新打包，微内核将不得不读取被潜在的大跨距隔开的几行  A。如果这个跨距恰好是 2 的许多次幂的倍数，面板中不同行 A  的元素可能会落入同一缓存集中。如果冲突的行数超过了缓存关联性，它们就会相互驱逐，性能也会大幅下降。幸运的是，当面板适配一级缓存时，这种情况不会发生，就像  QNNPACK 优化的模型一样。</p><p>打包对微内核效率的影响与当前所有移动处理器支持的  SIMD  向量指令的使用密切相关。这些指令加载、存储或者计算小型的固定大小元素向量，而不是单个标量（scalar）。在矩阵相乘中，充分利用向量指令达到高性能很重要。在传统的  GEMM 实现中，微内核把 MR 元素重新打包到向量暂存器里的 MR 线路中。在 QNNPACK 实现中，MR  元素在存储中不是连续的，微内核需要把它们加载到不同的向量暂存器中。越来越大的暂存器压力迫使 QNNPACK 使用较小的 MRxNR  拼贴，但实际上这种差异很小，而且可以通过消除打包开销来补偿。例如，在 32 位 ARM 架构上，QNNPACK 使用 4×8 微内核，其中  57% 的向量指令是乘-加；另一方面，gemmlowp 库使用效率稍高的 4×12 微内核，其中 60% 的向量指令是乘-加。</p><p>微内核加载 A  的多个行，乘以 B 的满列，结果相加，然后完成再量化并记下量化和。A 和 B 的元素被量化为 8 位整数，但乘积结果相加到 32 位。大部分  ARM 和 ARM64 处理器没有直接完成这一运算的指令，所以它必须分解为多个支持运算。QNNPACK  提供微内核的两个版本，其不同之处在于用于乘以 8 位值并将它们累加到 32 位的指令序列。</p><p>2)<strong>从矩阵相乘到卷积</strong></p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/QNNPACK3.jpeg" alt=""></p><p>简单的 1×1  卷积可直接映射到矩阵相乘，但对于具备较大卷积核、padding 或子采样（步幅）的卷积而言则并非如此。但是，这些较复杂的卷积能够通过记忆变换  im2col 映射到矩阵相乘。对于每个输出像素，im2col 复制输入图像的图像块并将其计算为 2D 矩阵。由于每个输出像素都受 KHxKWxC  输入像素值的影响（KH 和 KW 分别指卷积核的高度和宽度，C 指输入图像中的通道数），因此该矩阵的大小是输入图像的 KHxKW  倍，im2col 给内存占用和性能都带来了一定的开销。和 Caffe 一样，大部分深度学习框架转而使用基于 im2col  的实现，利用现有的高度优化矩阵相乘库来执行卷积操作。</p><p>Facebook  研究者在 QNNPACK 中实现了一种更高效的算法。他们没有变换卷积输入使其适应矩阵相乘的实现，而是调整 PDOT 微内核的实现，在运行中执行  im2col 变换。这样就无需将输入张量的实际输入复制到 im2col 缓存，而是使用输入像素行的指针设置 indirection  buffer，输入像素与每个输出像素的计算有关。研究者还修改了矩阵相乘微内核，以便从 indirection buffer  加载虚构矩阵（imaginary matrix）A 的行指针，indirection buffer 通常比 im2col buffer  小得多。此外，如果两次推断运行的输入张量存储位置不变，则 indirection buffer  还可使用输入张量行的指针进行初始化，然后在多次推断运行中重新使用。研究者观察到具备 indirection buffer 的微内核不仅消除了  im2col 变换的开销，其性能也比矩阵相乘微内核略好（可能由于输入行在计算不同输出像素时被重用）。</p><p>3)<strong>深度卷积</strong></p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/QNNPACK4.jpeg" alt=""></p><p>分组卷积（grouped   convolution）将输入和输出通道分割成多组，然后对每个组进行分别处理。在有限条件下，当组数等于通道数时，该卷积就是深度卷积，常用于当前的神经网络架构中。深度卷积对每个通道分别执行空间滤波，展示了与正常卷积非常不同的计算模式。因此，通常要向深度卷积提供单独实现，QNNPACK  包括一个高度优化版本 3×3 深度卷积。</p><p>深度卷积的传统实现是每次都在卷积核元素上迭代，然后将一个卷积核行和一个输入行的结果累加到输出行。对于一个  3×3 的深度卷积，此类实现将把每个输出行更新 9 次。在 QNNPACK 中，研究者计算所有 3×3 卷积核行和 3×3  输入行的结果，一次性累加到输出行，然后再处理下个输出行。</p><p>QNNPACK  实现高性能的关键因素在于完美利用通用暂存器（GPR）来展开卷积核元素上的循环，同时避免在 hot loop 中重新加载地址寄存器。32-bit  ARM 架构将实现限制在 14 个 GPR。在 3×3 深度卷积中，需要读取 9 个输入行和 9 个卷积核行。这意味着如果想完全展开循环必须存储  18 个地址。然而，实践中推断时卷积核不会发生变化。因此 Facebook 研究者使用之前在 CxKHxKW 中的滤波器，将它们封装进  [C/8]xKWxKHx8，这样就可以仅使用具备地址增量（address increment）的一个 GPR 访问所有滤波器。（研究者使用数字 8  的原因在于，在一个命令中加载 8 个元素然后减去零，在 128-bit NEON 暂存器中生成 8 个 16-bit 值。）然后使用 9  个输入行指针，指针将滤波器重新装进 10 个 GPR，完全展开滤波器元素上的循环。64-bit ARM 架构相比 32-bit 架构，GPR  的数量翻了一倍。QNNPACK 利用额外的 ARM64 GPR，一次性存储 3×5 输入行的指针，并计算 3 个输出行。</p><p>7、性能优势：</p><p>​    测试结果显示出 QNNPACK 在端到端基准上的性能优势。在量化当前最优 MobileNetV2 架构上，基于QNNPACK 的 Caffe2 算子的速度大约是 TensorFlow Lite 速度的 2 倍，在多种手机上都是如此。除了 QNNPACK 之外，Facebook 还开源了 Caffe2 quantized MobileNet v2 模型，其 top-1 准确率比相应的 TensorFlow 模型高出 1.3%。    </p><p><strong>MobileNetV1</strong></p><p>MobileNetV1  架构在使用深度卷积（depthwise convolution）使模型更适合移动设备方面具备开创性。MobileNetV1 包括几乎整个  1×1 卷积和 3×3 卷积。Facebook 研究者将量化 MobileNetV1 模型从 TensorFlow Lite 转换而来，并在  TensorFlow Lite 和 QNNPACK 的 32-bit ARM 设备上对 MobileNetV1 进行基准测试。二者运行时均使用 4  线程，研究者观察到 QNNPACK 的运行速度几何平均值是 TensorFlow Lite 的 1.8 倍。</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/mv1.jpg" alt=""></p><p><strong>MobileNetV2</strong></p><p>作为移动视觉任务的当前最优架构之一，MobileNetV2  引入了瓶颈构造块和瓶颈之间的捷径连接。研究者在 MobileNetV2 分类模型的量化版上对比基于 QNNPACK 的 Caffe2 算子和  TensorFlow Lite 实现。使用的量化 Caffe2 MobileNetV2 模型已开源，量化 TensorFlow Lite  模型来自官方库：<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md。下表展示了二者在常用测试集上的" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md。下表展示了二者在常用测试集上的</a>  top1 准确率：</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/mv2.jpg" alt=""></p><p>​    Facebook 研究者利用这些模型建立了 Facebook AI 性能评估平台（<a href="https://github.com/facebook/FAI-PEP）的基准，该基准基于" target="_blank" rel="noopener">https://github.com/facebook/FAI-PEP）的基准，该基准基于</a> 32-bit ARM 环境的大量手机设备。对于 TensorFlow Lite 线程设置，研究者尝试了一到四个线程，并报告了最快速的结果。结果显示 TensorFlow Lite 使用四线程的性能最优，因此后续研究中使用四线程来对比 TensorFlow Lite 和 QNNPACK。下表展示了结果，以及在典型智能手机和高端机上，基于 QNNPACK 的算子速度比 TensorFlow Lite 快得多。</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/mv3.jpg" alt=""></p><p>Facebook开源高性能内核库QNNPACK<br><a href="https://baijiahao.baidu.com/s?id=1615725346726413945&amp;wfr=spider&amp;for=pc" target="_blank" rel="noopener">https://baijiahao.baidu.com/s?id=1615725346726413945&amp;wfr=spider&amp;for=pc</a><br><a href="http://www.sohu.com/a/272158070_610300" target="_blank" rel="noopener">http://www.sohu.com/a/272158070_610300</a></p><p>支持移动端深度学习的几种开源框架<br><a href="https://blog.csdn.net/zchang81/article/details/74280019" target="_blank" rel="noopener">https://blog.csdn.net/zchang81/article/details/74280019</a></p><h3 id="17-7-3-Prestissimo"><a href="#17-7-3-Prestissimo" class="headerlink" title="17.7.3 Prestissimo"></a>17.7.3 Prestissimo</h3><p>１、开源时间：2017年11月　　　</p><p>２、开源用户：九言科技　　　　</p><p>３、GitHub地址：<a href="https://github.com/in66-dev/In-Prestissimo" target="_blank" rel="noopener">https://github.com/in66-dev/In-Prestissimo</a>　　</p><p>４、功能特点：　</p><p><strong>基础功能</strong></p><ul><li>支持卷积神经网络，支持多输入和多分支结构</li><li>精炼简洁的API设计，使用方便</li><li>提供调试接口，支持打印各个层的数据以及耗时</li><li>不依赖任何第三方计算框架，整体库体积 500K 左右（32位 约400k，64位 约600k）</li><li>纯 C++ 实现，跨平台，支持 android 和 ios</li><li>模型为纯二进制文件，不暴露开发者设计的网络结构</li></ul><p><strong>极快的速度</strong></p><ul><li>大到框架设计，小到汇编书写上全方位的优化，iphone7 上跑 SqueezeNet 仅需 26ms（单线程）</li><li>支持浮点(float)和整型(int)两种运算模式，float模式精度与caffe相同，int模式运算速度快，大部分网络用int的精度便已经足够</li><li>以巧妙的内存布局提升cpu的cache命中率，在中低端机型上性能依然强劲</li><li>针对 float-arm32, float-arm64, int-arm32, int-arm64 四个分支均做了细致的优化，保证arm32位和arm64位版本都有非常好的性能</li></ul><p><strong>SqueezeNet-v1.1 测试结果</strong></p><p><strong>Note</strong>: 手机测试性能存在一定的抖动，连续多次运算取平均时间</p><p><strong>Note</strong>: 像华为mate8, mate9，Google nexus 6 虽然是64位的CPU，但测试用的是 32位的库，因此cpu架构依然写 arm-v7a</p><table><thead><tr><th style="text-align:center">CPU架构</th><th style="text-align:center">机型</th><th style="text-align:center">CPU</th><th style="text-align:center">ncnn（4线程）</th><th style="text-align:center">mdl</th><th style="text-align:center">Prestissimo_float(单线程)</th><th style="text-align:center">Prestissimo_int(单线程)</th></tr></thead><tbody><tr><td style="text-align:center">arm-v7a</td><td style="text-align:center">小米2</td><td style="text-align:center">高通APQ8064 1.5GHz</td><td style="text-align:center">185 ms</td><td style="text-align:center">370 ms</td><td style="text-align:center">184 ms</td><td style="text-align:center">115 ms</td></tr><tr><td style="text-align:center">arm-v7a</td><td style="text-align:center">小米2s</td><td style="text-align:center">四核 骁龙APQ8064 Pro 1.7GHz</td><td style="text-align:center">166 ms</td><td style="text-align:center">-</td><td style="text-align:center">136 ms</td><td style="text-align:center">96 ms</td></tr><tr><td style="text-align:center">arm-v7a</td><td style="text-align:center">红米Note 4x</td><td style="text-align:center">骁龙625 四核2.0GHz</td><td style="text-align:center">124 ms</td><td style="text-align:center">306 ms</td><td style="text-align:center">202 ms</td><td style="text-align:center">110 ms</td></tr><tr><td style="text-align:center">arm-v7a</td><td style="text-align:center">Google Nexus 6</td><td style="text-align:center">骁龙805 四核 2.7GHz</td><td style="text-align:center">84 ms</td><td style="text-align:center">245 ms</td><td style="text-align:center">103 ms</td><td style="text-align:center">63 ms</td></tr><tr><td style="text-align:center">arm-v7a</td><td style="text-align:center">Vivo x6d</td><td style="text-align:center">联发科 MT6752 1.7GHz</td><td style="text-align:center">245 ms</td><td style="text-align:center">502 ms</td><td style="text-align:center">370 ms</td><td style="text-align:center">186 ms</td></tr><tr><td style="text-align:center">arm-v7a</td><td style="text-align:center">华为 Mate 8</td><td style="text-align:center">海思麒麟950 4大4小 2.3GHz 1.8GHz</td><td style="text-align:center">75 ms</td><td style="text-align:center">180 ms</td><td style="text-align:center">95 ms</td><td style="text-align:center">57 ms</td></tr><tr><td style="text-align:center">arm-v7a</td><td style="text-align:center">华为 Mate 9</td><td style="text-align:center">海思麒麟960 4大4小 2.4GHz 1.8GHz</td><td style="text-align:center">61 ms</td><td style="text-align:center">170 ms</td><td style="text-align:center">94 ms</td><td style="text-align:center">48 ms</td></tr><tr><td style="text-align:center">arm-v8</td><td style="text-align:center">iphone7</td><td style="text-align:center">Apple A10 Fusion 2.34GHz</td><td style="text-align:center">-</td><td style="text-align:center">-</td><td style="text-align:center">27 ms</td><td style="text-align:center">26 ms</td></tr></tbody></table><p><strong>未开放特性</strong></p><ul><li>多核并行加速（多核机器可以再提升30%-100% 的速度）</li><li>depthwise卷积运算（支持mobilenet）</li><li>模型压缩功能，压缩后的模型体积可缩小到20%以下</li><li>GPU 运算模式（Android 基于opengl es 3.1，ios 基于metal）</li></ul><p><strong>同类框架对比</strong></p><table><thead><tr><th style="text-align:center">框架</th><th style="text-align:center">caffe</th><th style="text-align:center">tensorflow</th><th style="text-align:center">mdl-android</th><th style="text-align:center">mdl-ios</th><th style="text-align:center">ncnn</th><th style="text-align:center">CoreML</th><th style="text-align:center">Prestissimo</th></tr></thead><tbody><tr><td style="text-align:center">计算硬件</td><td style="text-align:center">cpu</td><td style="text-align:center">cpu</td><td style="text-align:center">cpu</td><td style="text-align:center">gpu</td><td style="text-align:center">cpu</td><td style="text-align:center">gpu</td><td style="text-align:center">cpu （gpu版本未开放）</td></tr><tr><td style="text-align:center">计算速度</td><td style="text-align:center">慢</td><td style="text-align:center">慢</td><td style="text-align:center">慢</td><td style="text-align:center">很快</td><td style="text-align:center">很快</td><td style="text-align:center">极快</td><td style="text-align:center">极快</td></tr><tr><td style="text-align:center">库大小</td><td style="text-align:center">大</td><td style="text-align:center">较大</td><td style="text-align:center">中等</td><td style="text-align:center">小</td><td style="text-align:center">小</td><td style="text-align:center">小</td><td style="text-align:center">小</td></tr><tr><td style="text-align:center">兼容性</td><td style="text-align:center">好</td><td style="text-align:center">好</td><td style="text-align:center">好</td><td style="text-align:center">限ios8以上</td><td style="text-align:center">很好</td><td style="text-align:center">仅支持 ios11</td><td style="text-align:center">很好</td></tr><tr><td style="text-align:center">模型支持度</td><td style="text-align:center">很好</td><td style="text-align:center">好</td><td style="text-align:center">-</td><td style="text-align:center">差（仅限指定模型）</td><td style="text-align:center">较好</td><td style="text-align:center">-</td><td style="text-align:center">中等（当前版本不支持mobilenet）</td></tr></tbody></table><p><strong>使用方法-模型转换</strong></p><p>绝影支持的是私有的模型文件格式，需要把 caffe 训练出来的模型转换为 .prestissimo 格式，模型转换工具为 caffe2Prestissimo.out。caffe2Prestissimo.out 依赖 protobuf 3.30。将 XXX.prototxt 和 YYY.caffemodel 转化为 Prestissimo 模型 ZZZ.prestissimo：（得到）./caffe2Prestissimo.out XXX.prototxt YYY.caffemodel ZZZ.prestissimo</p><h3 id="17-7-4-MDL（mobile-deep-learning）"><a href="#17-7-4-MDL（mobile-deep-learning）" class="headerlink" title="17.7.4 MDL（mobile-deep-learning）"></a>17.7.4 MDL（mobile-deep-learning）</h3><p>１、开源时间：2017年9月（已暂停更新）　　　</p><p>２、开源用户：百度　　　　</p><p>３、GitHub地址：<a href="https://github.com/allonli/mobile-deep-learning" target="_blank" rel="noopener">https://github.com/allonli/mobile-deep-learning</a></p><p>４、功能特点：</p><ul><li>一键部署，脚本参数就可以切换ios或者android</li><li>支持iOS  gpu运行MobileNet、squeezenet模型</li><li>已经测试过可以稳定运行MobileNet、GoogLeNet v1、squeezenet、ResNet-50模型</li><li>体积极小，无任何第三方依赖。纯手工打造。</li><li>提供量化函数，对32位float转8位uint直接支持，模型体积量化后4M上下</li><li>与ARM相关算法团队线上线下多次沟通，针对ARM平台会持续优化</li><li>NEON使用涵盖了卷积、归一化、池化所有方面的操作</li><li>汇编优化，针对寄存器汇编操作具体优化</li><li>loop unrolling 循环展开，为提升性能减少不必要的CPU消耗，全部展开判断操作</li><li>将大量繁重的计算任务前置到overhead过程</li></ul><p>5、框架结构</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/MDL1.png" alt=""></p><p>MDL 框架主要包括：<strong>模型转换模块（MDL Converter）、模型加载模块（Loader）、网络管理模块（Net）、矩阵运算模块（Gemmers）及供 Android 端调用的 JNI 接口层（JNI Interfaces）。</strong></p><p>​    其中，模型转换模块主要负责将Caffe 模型转为 MDL 模型，同时支持将 32bit 浮点型参数量化为 8bit 参数，从而极大地压缩模型体积；模型加载模块主要完成模型的反量化及加载校验、网络注册等过程，网络管理模块主要负责网络中各层 Layer 的初始化及管理工作；MDL 提供了供 Android 端调用的 JNI 接口层，开发者可以通过调用 JNI 接口轻松完成加载及预测过程。</p><p>6、MDL 的性能及兼容性</p><ul><li>体积 armv7 300k+</li><li>速度 iOS GPU mobilenet 可以达到 40ms、squeezenet 可以达到 30ms</li></ul><p>​        MDL  从立项到开源，已经迭代了一年多。移动端比较关注的多个指标都表现良好，如体积、功耗、速度。百度内部产品线在应用前也进行过多次对比，和已开源的相关项目对比，MDL  能够在保证速度和能耗的同时支持多种深度学习模型，如 mobilenet、googlenet v1、squeezenet 等，且具有 iOS  GPU 版本，squeezenet 一次运行最快可以达到 3-40ms。</p><p><strong>同类框架对比</strong></p><p>​     框架Caffe2TensorFlowncnnMDL(CPU)MDL(GPU)硬件CPUCPUCPUCPUGPU速度慢慢快快极快体积大大小小小兼容Android&amp;iOSAndroid&amp;iOSAndroid&amp;iOSAndroid&amp;iOSiOS</p><p>​     与支持 CNN 的移动端框架对比，MDL 速度快、性能稳定、兼容性好、demo 完备。</p><p><strong>兼容性</strong></p><p>​     MDL 在 iOS 和 Android 平台均可以稳定运行，其中 iOS10 及以上平台有基于 GPU 运算的 API，性能表现非常出色，在 Android 平台则是纯 CPU 运行。高中低端机型运行状态和手机百度及其他 App 上的覆盖都有绝对优势。</p><p>​     MDL 同时也支持 Caffe 模型直接转换为 MDL 模型。</p><h3 id="17-7-5-Paddle-Mobile"><a href="#17-7-5-Paddle-Mobile" class="headerlink" title="17.7.5 Paddle-Mobile"></a>17.7.5 Paddle-Mobile</h3><p>１、开源时间：持续更新，已到3.0版本　　　</p><p>２、开源用户：百度　　　　</p><p>３、GitHub地址：<a href="https://github.com/PaddlePaddle/paddle-mobile" target="_blank" rel="noopener">https://github.com/PaddlePaddle/paddle-mobile</a>　</p><p>４、功能特点：</p><p><strong>功能特点</strong></p><ul><li><p>高性能支持ARM CPU </p></li><li><p>支持Mali GPU</p></li><li><p>支持Andreno GPU</p></li><li><p>支持苹果设备的GPU Metal实现</p></li><li><p>支持ZU5、ZU9等FPGA开发板</p></li><li><p>支持树莓派等arm-linux开发板</p></li></ul><h3 id="17-7-6-MACE（-Mobile-AI-Compute-Engine）"><a href="#17-7-6-MACE（-Mobile-AI-Compute-Engine）" class="headerlink" title="17.7.6 MACE（ Mobile AI Compute Engine）"></a>17.7.6 MACE（ Mobile AI Compute Engine）</h3><p>１、开源时间：2018年4月(持续更新，v0.9.0 (2018-07-20))　　　</p><p>２、开源用户：小米　　　　</p><p>３、GitHub地址：<a href="https://github.com/XiaoMi/mace" target="_blank" rel="noopener">https://github.com/XiaoMi/mace</a>    </p><p>４、简介：Mobile AI Compute Engine (MACE) 是一个专为移动端异构计算设备优化的深度学习前向预测框架。<br>MACE覆盖了常见的移动端计算设备（CPU，GPU和DSP），并且提供了完整的工具链和文档，用户借助MACE能够很方便地在移动端部署深度学习模型。MACE已经在小米内部广泛使用并且被充分验证具有业界领先的性能和稳定性。</p><p>5、MACE的基本框架：</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/mace-arch.png" alt=""></p><p><strong>MACE Model</strong></p><p>MACE定义了自有的模型格式（类似于Caffe2），通过MACE提供的工具可以将Caffe和TensorFlow的模型 转为MACE模型。</p><p><strong>MACE Interpreter</strong></p><p>MACE Interpreter主要负责解析运行神经网络图（DAG）并管理网络中的Tensors。</p><p><strong>Runtime</strong></p><p>CPU/GPU/DSP Runtime对应于各个计算设备的算子实现。</p><p>6、MACE使用的基本流程</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/mace-work-flow-zh.png" alt=""></p><p><strong>1. 配置模型部署文件(.yml)</strong></p><p>模型部署文件详细描述了需要部署的模型以及生成库的信息，MACE根据该文件最终生成对应的库文件。</p><p><strong>2.编译MACE库</strong></p><p>编译MACE的静态库或者动态库。</p><p><strong>3.转换模型</strong></p><p>将TensorFlow 或者 Caffe的模型转为MACE的模型。</p><p><strong>4.1. 部署</strong></p><p>根据不同使用目的集成Build阶段生成的库文件，然后调用MACE相应的接口执行模型。</p><p><strong>4.2. 命令行运行</strong></p><p>MACE提供了命令行工具，可以在命令行运行模型，可以用来测试模型运行时间，内存占用和正确性。</p><p><strong>4.3. Benchmark</strong></p><p>MACE提供了命令行benchmark工具，可以细粒度的查看模型中所涉及的所有算子的运行时间。</p><p>7、MACE在哪些角度进行了优化?</p><p><strong>MACE</strong> 专为移动端异构计算平台优化的神经网络计算框架。主要从以下的角度做了专门的优化：</p><ul><li>性能<ul><li>代码经过NEON指令，OpenCL以及Hexagon HVX专门优化，并且采用<br><a href="https://arxiv.org/abs/1509.09308" target="_blank" rel="noopener">Winograd算法</a>来进行卷积操作的加速。<br>此外，还对启动速度进行了专门的优化。</li></ul></li><li><p>功耗</p><ul><li>支持芯片的功耗管理，例如ARM的big.LITTLE调度，以及高通Adreno GPU功耗选项。</li></ul></li><li>系统响应<ul><li>支持自动拆解长时间的OpenCL计算任务，来保证UI渲染任务能够做到较好的抢占调度，<br>从而保证系统UI的相应和用户体验。</li></ul></li><li>内存占用<ul><li>通过运用内存依赖分析技术，以及内存复用，减少内存的占用。另外，保持尽量少的外部<br>依赖，保证代码尺寸精简。</li></ul></li><li><p>模型加密与保护</p><ul><li>模型保护是重要设计目标之一。支持将模型转换成C++代码，以及关键常量字符混淆，增加逆向的难度。</li></ul></li><li>硬件支持范围<ul><li>支持高通，联发科，以及松果等系列芯片的CPU，GPU与DSP(目前仅支持Hexagon)计算加速。</li><li>同时支持在具有POSIX接口的系统的CPU上运行。</li></ul></li></ul><p>8、性能对比：</p><p>MACE 支持 TensorFlow 和 Caffe 模型，提供转换工具，可以将训练好的模型转换成专有的模型数据文件，同时还可以选择将模型转换成C++代码，支持生成动态库或者静态库，提高模型保密性。</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/maca_com.jpg" alt=""></p><h3 id="17-7-7-FeatherCNN"><a href="#17-7-7-FeatherCNN" class="headerlink" title="17.7.7 FeatherCNN"></a>17.7.7 FeatherCNN</h3><p>１、开源时间：持续更新，已到3.0版本　　　</p><p>２、开源用户：腾讯AI　　　　</p><p>３、GitHub地址：<a href="https://github.com/Tencent/FeatherCNN" target="_blank" rel="noopener">https://github.com/Tencent/FeatherCNN</a></p><p>４、功能特点：</p><p><strong>FeatherCNN 是由腾讯 AI 平台部研发的基于 ARM 架构的高效 CNN 推理库，该项目支持 Caffe 模型，且具有高性能、易部署、轻量级三大特性。</strong></p><p><strong>该项目具体特性如下：</strong></p><ul><li><p>高性能：无论是在移动设备（iOS / Android），嵌入式设备（Linux）还是基于 ARM 的服务器（Linux）上，FeatherCNN 均能发挥最先进的推理计算性能；</p></li><li><p>易部署：FeatherCNN 的所有内容都包含在一个代码库中，以消除第三方依赖关系。因此，它便于在移动平台上部署。FeatherCNN 自身的模型格式与 Caffe 模型完全兼容。</p></li><li><p>轻量级：编译后的 FeatherCNN 库的体积仅为数百 KB。</p></li></ul><h3 id="17-7-8-TensorFlow-Lite"><a href="#17-7-8-TensorFlow-Lite" class="headerlink" title="17.7.8 TensorFlow Lite"></a>17.7.8 TensorFlow Lite</h3><p>１、开源时间：2017年11月　　　</p><p>２、开源用户：谷歌　　　</p><p>３、GitHub地址：<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite</a></p><p>４、简介：</p><p>Google 表示 Lite 版本 TensorFlow 是 TensorFlow Mobile 的一个延伸版本。此前，通过TensorFlow Mobile API，TensorFlow已经支持手机上的模型嵌入式部署。TensorFlow Lite应该被视为TensorFlow Mobile的升级版。</p><p>TensorFlow Lite可以与Android 8.1中发布的神经网络API完美配合，即便在没有硬件加速时也能调用CPU处理，确保模型在不同设备上的运行。 而Android端版本演进的控制权是掌握在谷歌手中的，从长期看，TensorFlow Lite会得到Android系统层面上的支持。</p><p>5、架构：</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/tflite_artc.JPEG" alt=""></p><p>其组件包括：</p><ul><li>TensorFlow 模型（TensorFlow Model）：保存在磁盘中的训练模型。</li><li>TensorFlow Lite 转化器（TensorFlow Lite Converter）：将模型转换成 TensorFlow Lite 文件格式的项目。</li><li>TensorFlow Lite 模型文件（TensorFlow Lite Model File）：基于 FlatBuffers，适配最大速度和最小规模的模型。</li></ul><p>6、移动端开发步骤：</p><p>Android Studio 3.0, SDK Version API26, NDK Version 14</p><p>步骤：</p><ol><li><p>将此项目导入到Android Studio：<br><a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/java/demo" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/java/demo</a></p></li><li><p>下载移动端的模型（model）和标签数据（lables）：<br><a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_224_android_quant_2017_11_08.zip" target="_blank" rel="noopener">https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_224_android_quant_2017_11_08.zip</a></p></li><li><p>下载完成解压mobilenet_v1_224_android_quant_2017_11_08.zip文件得到一个xxx.tflite和labes.txt文件，分别是模型和标签文件，并且把这两个文件复制到assets文件夹下。</p></li><li><p>构建app，run……</p></li></ol><p>17.7.9 TensorFlow Lite和TensorFlow Mobile的区别？</p><ul><li>TensorFlow Lite是TensorFlow Mobile的进化版。</li><li>在大多数情况下，TensorFlow Lite拥有跟小的二进制大小，更少的依赖以及更好的性能。</li><li>相比TensorFlow Mobile是对完整TensorFlow的裁减，TensorFlow Lite基本就是重新实现了。从内部实现来说，在TensorFlow内核最基本的OP，Context等数据结构，都是新的。从外在表现来说，模型文件从PB格式改成了FlatBuffers格式，TensorFlow的size有大幅度优化，降至300K，然后提供一个converter将普通TensorFlow模型转化成TensorFlow Lite需要的格式。因此，无论从哪方面看，TensorFlow Lite都是一个新的实现方案。</li></ul><h3 id="17-7-9-PocketFlow"><a href="#17-7-9-PocketFlow" class="headerlink" title="17.7.9 PocketFlow"></a>17.7.9 PocketFlow</h3><p>１、开源时间：2018年9月　　　</p><p>２、开源用户：腾讯　　　</p><p>３、GitHub地址：<a href="https://github.com/Tencent/PocketFlow" target="_blank" rel="noopener">https://github.com/Tencent/PocketFlow</a></p><p>４、简介：</p><p>全球首个自动模型压缩框架</p><p>一款面向移动端AI开发者的自动模型压缩框架，集成了当前主流的模型压缩与训练算法，结合自研超参数优化组件实现了全程自动化托管式的模型压缩与加速。开发者无需了解具体算法细节，即可快速地将AI技术部署到移动端产品上，实现了自动托管式模型压缩与加速，实现用户数据的本地高效处理。</p><p>5、框架介绍</p><p>PocketFlow 框架主要由两部分组件构成，分别是模型压缩/加速算法组件和超参数优化组件，具体结构如下图所示。</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/framework_design.png" alt=""></p><p>​    开发者将未压缩的原始模型作为 PocketFlow 框架的输入，同时指定期望的性能指标，例如模型的压缩和/或加速倍数；在每一轮迭代过程中，超参数优化组件选取一组超参数取值组合，之后模型压缩/加速算法组件基于该超参数取值组合，对原始模型进行压缩，得到一个压缩后的候选模型；基于对候选模型进行性能评估的结果，超参数优化组件调整自身的模型参数，并选取一组新的超参数取值组合，以开始下一轮迭代过程；当迭代终止时，PocketFlow 选取最优的超参数取值组合以及对应的候选模型，作为最终输出，返回给开发者用作移动端的模型部署。</p><p>6、PocketFlow如何实现模型压缩与加速？</p><p>​    具体地，PocketFlow 通过下列各个算法组件的有效结合，实现了精度损失更小、自动化程度更高的深度学习模型的压缩与加速：</p><ul><li><p>a) 通道剪枝（channel pruning）组件：在CNN网络中，通过对特征图中的通道维度进行剪枝，可以同时降低模型大小和计算复杂度，并且压缩后的模型可以直接基于现有的深度学习框架进行部署。在CIFAR-10图像分类任务中，通过对  ResNet-56 模型进行通道剪枝，可以实现2.5倍加速下分类精度损失0.4%，3.3倍加速下精度损失0.7%。</p></li><li><p>b) 权重稀疏化（weight sparsification）组件：通过对网络权重引入稀疏性约束，可以大幅度降低网络权重中的非零元素个数；压缩后模型的网络权重可以以稀疏矩阵的形式进行存储和传输，从而实现模型压缩。对于  MobileNet 图像分类模型，在删去50%网络权重后，在 ImageNet 数据集上的 Top-1 分类精度损失仅为0.6%。</p></li><li><p>c) 权重量化（weight quantization）组件：通过对网络权重引入量化约束，可以降低用于表示每个网络权重所需的比特数；团队同时提供了对于均匀和非均匀两大类量化算法的支持，可以充分利用  ARM 和 FPGA 等设备的硬件优化，以提升移动端的计算效率，并为未来的神经网络芯片设计提供软件支持。以用于 ImageNet  图像分类任务的 ResNet-18 模型为例，在8比特定点量化下可以实现精度无损的4倍压缩。</p></li><li><p>d)网络蒸馏（network distillation）组件：对于上述各种模型压缩组件，通过将未压缩的原始模型的输出作为额外的监督信息，指导压缩后模型的训练，在压缩/加速倍数不变的前提下均可以获得0.5%-2.0%不等的精度提升。</p></li><li><p>e) 多GPU训练（multi-GPU training）组件：深度学习模型训练过程对计算资源要求较高，单个GPU难以在短时间内完成模型训练，因此团队提供了对于多机多卡分布式训练的全面支持，以加快使用者的开发流程。无论是基于  ImageNet 数据的Resnet-50图像分类模型还是基于 WMT14 数据的 Transformer  机器翻译模型，均可以在一个小时内训练完毕。[1] </p></li><li><p>f) 超参数优化（hyper-parameter optimization）组件：多数开发者对模型压缩算法往往不甚了解，但超参数取值对最终结果往往有着巨大的影响，因此团队引入了超参数优化组件，采用了包括强化学习等算法以及  AI Lab 自研的 AutoML  自动超参数优化框架来根据具体性能需求，确定最优超参数取值组合。例如，对于通道剪枝算法，超参数优化组件可以自动地根据原始模型中各层的冗余程度，对各层采用不同的剪枝比例，在保证满足模型整体压缩倍数的前提下，实现压缩后模型识别精度的最大化。</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/packflow1.jpg" alt=""></p></li></ul><p>7、PocketFlow 性能</p><p>​    通过引入超参数优化组件，不仅避免了高门槛、繁琐的人工调参工作，同时也使得  PocketFlow 在各个压缩算法上全面超过了人工调参的效果。以图像分类任务为例，在 CIFAR-10 和 ImageNet  等数据集上，PocketFlow 对 ResNet 和 MobileNet 等多种 CNN 网络结构进行有效的模型压缩与加速。</p><p>​    在  CIFAR-10 数据集上，PocketFlow 以 ResNet-56  作为基准模型进行通道剪枝，并加入了超参数优化和网络蒸馏等训练策略，实现了 2.5 倍加速下分类精度损失 0.4%，3.3 倍加速下精度损失  0.7%，且显著优于未压缩的 ResNet-44 模型； 在 ImageNet 数据集上，PocketFlow 可以对原本已经十分精简的  MobileNet 模型继续进行权重稀疏化，以更小的模型尺寸取得相似的分类精度；与 Inception-V1、ResNet-18  等模型相比，模型大小仅为后者的约 20~40%，但分类精度基本一致（甚至更高）。</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/packflow2.jpg" alt=""></p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/packflow3.jpg" alt=""></p><p>相比于费时费力的人工调参，PocketFlow 框架中的 AutoML 自动超参数优化组件仅需 10<br>余次迭代就能达到与人工调参类似的性能，在经过 100 次迭代后搜索得到的超参数组合可以降低约 0.6%<br>的精度损失；通过使用超参数优化组件自动地确定网络中各层权重的量化比特数，PocketFlow 在对用于 ImageNet 图像分类任务的<br>ResNet-18 模型进行压缩时，取得了一致性的性能提升；当平均量化比特数为 4 比特时，超参数优化组件的引入可以将分类精度从 63.6%<br>提升至 68.1%（原始模型的分类精度为 70.3%）。</p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/packflow4.jpg" alt=""></p><p><img src="/2018/01/15/第十七章_模型压缩、加速及移动端部署/img/ch17/packflow5.jpg" alt=""></p><p><strong>参考文献</strong></p><p>[1]  Zhuangwei Zhuang, Mingkui Tan, Bohan Zhuang, Jing Liu, Jiezhang Cao,  Qingyao Wu, Junzhou Huang, Jinhui Zhu,「Discrimination-aware Channel  Pruning for Deep Neural Networks”, In Proc. of the 32nd Annual  Conference on Neural Information Processing Systems, NIPS ‘18, Montreal,  Canada, December 2018.</p><p>[2] Jiaxiang  Wu, Weidong Huang, Junzhou Huang, Tong Zhang,「Error Compensated  Quantized SGD and its Applications to Large-scale Distributed  Optimization」, In Proc. of the 35th International Conference on Machine  Learning, ICML’18, Stockholm, Sweden, July 2018.</p><h3 id="17-7-10-其他几款支持移动端深度学习的开源框架"><a href="#17-7-10-其他几款支持移动端深度学习的开源框架" class="headerlink" title="17.7.10 其他几款支持移动端深度学习的开源框架"></a>17.7.10 其他几款支持移动端深度学习的开源框架</h3><p><a href="https://blog.csdn.net/zchang81/article/details/74280019" target="_blank" rel="noopener">https://blog.csdn.net/zchang81/article/details/74280019</a></p><h3 id="17-7-11-MDL、NCNN和-TFLite比较"><a href="#17-7-11-MDL、NCNN和-TFLite比较" class="headerlink" title="17.7.11 MDL、NCNN和 TFLite比较"></a>17.7.11 MDL、NCNN和 TFLite比较</h3><p>百度-MDL框架、腾讯-NCNN框架和谷歌TFLite框架比较。</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">MDL</th><th style="text-align:center">NCNN</th><th style="text-align:center">TFLite</th></tr></thead><tbody><tr><td style="text-align:center">代码质量</td><td style="text-align:center">中</td><td style="text-align:center">高</td><td style="text-align:center">很高</td></tr><tr><td style="text-align:center">跨平台</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">支持caffe模型</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">×</td></tr><tr><td style="text-align:center">支持TensorFlow模型</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">CPU NEON指令优化</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">GPU加速</td><td style="text-align:center">√</td><td style="text-align:center">×</td><td style="text-align:center">×</td></tr></tbody></table><p>相同点：</p><ul><li>只含推理（inference）功能，使用的模型文件需要通过离线的方式训练得到。</li><li>最终生成的库尺寸较小，均小于500kB。</li><li>为了提升执行速度，都使用了ARM NEON指令进行加速。</li><li>跨平台，iOS和Android系统都支持。</li></ul><p>不同点：</p><ul><li>MDL和NCNN均是只支持Caffe框架生成的模型文件，而TfLite则毫无意外的只支持自家大哥TensorFlow框架生成的模型文件。</li><li>MDL支持利用iOS系统的Matal框架进行GPU加速，能够显著提升在iPhone上的运行速度，达到准实时的效果。而NCNN和TFLite还没有这个功能。</li></ul><h2 id="17-8-移动端开源框架部署"><a href="#17-8-移动端开源框架部署" class="headerlink" title="17.8 移动端开源框架部署"></a>17.8 移动端开源框架部署</h2><h3 id="17-8-1-以NCNN为例"><a href="#17-8-1-以NCNN为例" class="headerlink" title="17.8.1 以NCNN为例"></a>17.8.1 以NCNN为例</h3><p>部署步骤   </p><h3 id="17-8-2-以QNNPACK为例"><a href="#17-8-2-以QNNPACK为例" class="headerlink" title="17.8.2 以QNNPACK为例"></a>17.8.2 以QNNPACK为例</h3><p>部署步骤     </p><h3 id="17-8-4-在Android手机上使用MACE实现图像分类"><a href="#17-8-4-在Android手机上使用MACE实现图像分类" class="headerlink" title="17.8.4 在Android手机上使用MACE实现图像分类"></a>17.8.4 在Android手机上使用MACE实现图像分类</h3><h3 id="17-8-3-在Android手机上使用PaddleMobile实现图像分类"><a href="#17-8-3-在Android手机上使用PaddleMobile实现图像分类" class="headerlink" title="17.8.3 在Android手机上使用PaddleMobile实现图像分类"></a>17.8.3 在Android手机上使用PaddleMobile实现图像分类</h3><p><strong>编译paddle-mobile库</strong></p><p>1）编译Android能够使用的CPP库：编译Android的paddle-mobile库，可选择使用Docker编译和Ubuntu交叉编译，这里介绍使用Ubuntu交叉编译paddle-mobile库。</p><p><em>注</em>：在Android项目，Java代码调用CPP代码，CPP的函数需要遵循一定的命名规范，比如Java_包名_类名_对应的Java的方法名。</p><p>​    目前官方提供了5个可以给Java调用的函数，该代码在：paddle-mobile/src/jni/paddle_mobile_jni.cpp，如果想要让这些函数能够在自己的包名下的类调用，就要修改CPP的函数名称修改如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">JNIEXPORT jboolean JNICALL <span class="title">Java_com_baidu_paddle_PML_load</span><span class="params">(JNIEnv *env, </span></span></span><br><span class="line"><span class="function"><span class="params">jclass thiz,</span></span></span><br><span class="line"><span class="function"><span class="params">jstring modelPath)</span> </span>&#123; </span><br><span class="line">ANDROIDLOGI(<span class="string">"load invoked"</span>); </span><br><span class="line">bool optimize = <span class="keyword">true</span>; </span><br><span class="line"><span class="keyword">return</span> getPaddleMobileInstance()-&gt;Load(jstring2cppstring(env, modelPath), optimize); &#125;</span><br></pre></td></tr></table></figure><p>​    笔者项目的包名为<code>com.example.paddlemobile1</code>，在这个包下有一个<code>ImageRecognition.java</code>的程序来对应这个CPP程序，那么修改<code>load</code>函数如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">JNIEXPORT jboolean JNICALL <span class="title">Java_com_example_paddlemobile1_ImageRecognition_load</span><span class="params">(JNIEnv *env,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                          jclass thiz,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                          jstring modelPath)</span> </span>&#123;</span><br><span class="line">  ANDROIDLOGI(<span class="string">"load invoked"</span>);</span><br><span class="line">  bool optimize = <span class="keyword">true</span>;</span><br><span class="line">  <span class="keyword">return</span> getPaddleMobileInstance()-&gt;Load(jstring2cppstring(env, modelPath),</span><br><span class="line">                                         optimize);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>使用Ubuntu交叉编译paddle-mobile库</strong></p><p>1、下载和解压NDK。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://dl.google.com/android/repository/android-ndk-r17b-linux-x86_64.zip</span><br><span class="line">unzip android-ndk-r17b-linux-x86_64.zip</span><br></pre></td></tr></table></figure><p>2、设置NDK环境变量，目录是NDK的解压目录。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export NDK_ROOT=&quot;/home/test/paddlepaddle/android-ndk-r17b&quot;</span><br></pre></td></tr></table></figure><p>设置好之后，可以使用以下的命令查看配置情况。</p><pre><code>root@test:/home/test/paddlepaddle# echo $NDK_ROOT/home/test/paddlepaddle/android-ndk-r17b</code></pre><p>3、安装cmake，需要安装较高版本的，笔者的cmake版本是3.11.2。</p><p>下载cmake源码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://cmake.org/files/v3.11/cmake-3.11.2.tar.gz</span><br></pre></td></tr></table></figure><p>解压cmake源码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf cmake-3.11.2.tar.gz</span><br></pre></td></tr></table></figure><p>进入到cmake源码根目录，并执行bootstrap。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd cmake-3.11.2</span><br><span class="line">./bootstrap</span><br></pre></td></tr></table></figure><p>最后执行以下两条命令开始安装cmake。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>安装完成之后，可以使用cmake –version是否安装成功.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@test:/home/test/paddlepaddle# cmake --version</span><br><span class="line">cmake version 3.11.2</span><br><span class="line"></span><br><span class="line">CMake suite maintained and supported by Kitware (kitware.com/cmake).</span><br></pre></td></tr></table></figure><p>4、克隆paddle-mobile源码。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/PaddlePaddle/paddle-mobile.git</span><br></pre></td></tr></table></figure><p>5、进入到paddle-mobile的tools目录下，执行编译。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd paddle-mobile/tools/</span><br><span class="line">sh build.sh android</span><br></pre></td></tr></table></figure><p>（可选）如果想编译针对某一个网络编译更小的库时，可以在命令后面加上相应的参数，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh build.sh android googlenet</span><br></pre></td></tr></table></figure><p>6、最后会在paddle-mobile/build/release/arm-v7a/build目录下生产paddle-mobile库。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@test:/home/test/paddlepaddle/paddle-mobile/build/release/arm-v7a/build# ls</span><br><span class="line">libpaddle-mobile.so</span><br></pre></td></tr></table></figure><p>libpaddle-mobile.so就是我们在开发Android项目的时候使用到的paddle-mobile库。</p><p><strong>创建Android项目</strong></p><p>1、首先使用Android Studio创建一个普通的Android项目，包名为<code>com.example.paddlemobile1</code></p><p>2、在main目录下创建l两个assets/paddle_models文件夹，这个文件夹存放PaddleFluid训练好的预测模型。PaddleMobile支持量化模型，使用模型量化可以把模型缩小至原来的四分之一，如果使用量化模型，那加载模型的接口也有修改一下，使用以下的接口加载模型：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">boolean</span> <span class="title">loadQualified</span><span class="params">(String modelDir)</span></span>;</span><br></pre></td></tr></table></figure><p>3、在<code>main</code>目录下创建一个<code>jniLibs</code>文件夹，这个文件夹是存放CPP编译库的，在本项目中就存放上一部分编译的<code>libpaddle-mobile.so</code></p><p>4、在Android项目的配置文件夹中加上权限声明，因为我们要使用到读取相册和使用相机，所以加上以下的权限声明：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;uses-permission android:name=<span class="string">"android.permission.CAMERA"</span> /&gt;</span><br><span class="line">&lt;uses-permission android:name=<span class="string">"android.permission.WRITE_EXTERNAL_STORAGE"</span> /&gt;</span><br><span class="line">&lt;uses-permission android:name=<span class="string">"android.permission.READ_EXTERNAL_STORAGE"</span> /&gt;</span><br></pre></td></tr></table></figure><p>5、修改<code>activity_main.xml</code>界面，修改成如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"utf-8"</span>?&gt;</span><br><span class="line">&lt;RelativeLayout xmlns:android=<span class="string">"http://schemas.android.com/apk/res/android"</span></span><br><span class="line">    xmlns:app=<span class="string">"http://schemas.android.com/apk/res-auto"</span></span><br><span class="line">    xmlns:tools=<span class="string">"http://schemas.android.com/tools"</span></span><br><span class="line">    android:layout_width=<span class="string">"match_parent"</span></span><br><span class="line">    android:layout_height=<span class="string">"match_parent"</span></span><br><span class="line">    tools:context=<span class="string">".MainActivity"</span>&gt;</span><br><span class="line">&lt;LinearLayout</span><br><span class="line">    android:id=<span class="string">"@+id/btn_ll"</span></span><br><span class="line">    android:layout_alignParentBottom=<span class="string">"true"</span></span><br><span class="line">    android:layout_width=<span class="string">"match_parent"</span></span><br><span class="line">    android:layout_height=<span class="string">"wrap_content"</span></span><br><span class="line">    android:orientation=<span class="string">"horizontal"</span>&gt;</span><br><span class="line"></span><br><span class="line">    &lt;Button</span><br><span class="line">        android:id=<span class="string">"@+id/use_photo"</span></span><br><span class="line">        android:layout_weight=<span class="string">"1"</span></span><br><span class="line">        android:layout_width=<span class="string">"0dp"</span></span><br><span class="line">        android:layout_height=<span class="string">"wrap_content"</span></span><br><span class="line">        android:text=<span class="string">"相册"</span> /&gt;</span><br><span class="line"></span><br><span class="line">    &lt;Button</span><br><span class="line">        android:id=<span class="string">"@+id/start_camera"</span></span><br><span class="line">        android:layout_weight=<span class="string">"1"</span></span><br><span class="line">        android:layout_width=<span class="string">"0dp"</span></span><br><span class="line">        android:layout_height=<span class="string">"wrap_content"</span></span><br><span class="line">        android:text=<span class="string">"拍照"</span> /&gt;</span><br><span class="line">&lt;/LinearLayout&gt;</span><br><span class="line"></span><br><span class="line">&lt;TextView</span><br><span class="line">    android:layout_above=<span class="string">"@id/btn_ll"</span></span><br><span class="line">    android:id=<span class="string">"@+id/result_text"</span></span><br><span class="line">    android:textSize=<span class="string">"16sp"</span></span><br><span class="line">    android:layout_width=<span class="string">"match_parent"</span></span><br><span class="line">    android:hint=<span class="string">"预测结果会在这里显示"</span></span><br><span class="line">    android:layout_height=<span class="string">"100dp"</span> /&gt;</span><br><span class="line"></span><br><span class="line">&lt;ImageView</span><br><span class="line">    android:layout_alignParentTop=<span class="string">"true"</span></span><br><span class="line">    android:layout_above=<span class="string">"@id/result_text"</span></span><br><span class="line">    android:id=<span class="string">"@+id/show_image"</span></span><br><span class="line">    android:layout_width=<span class="string">"match_parent"</span></span><br><span class="line">    android:layout_height=<span class="string">"match_parent"</span> /&gt;</span><br><span class="line">&lt;/RelativeLayout&gt;</span><br></pre></td></tr></table></figure><p>6、创建一个<code>ImageRecognition.java</code>的Java程序，这个程序的作用就是调用<code>paddle-mobile/src/jni/paddle_mobile_jni.cpp</code>的函数，对应的是里面的函数。目前支持一下几个接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.paddlemobile1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ImageRecognition</span> </span>&#123;</span><br><span class="line">    <span class="comment">// set thread num</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">setThread</span><span class="params">(<span class="keyword">int</span> threadCount)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Load seperated parameters</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">boolean</span> <span class="title">load</span><span class="params">(String modelDir)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// load qualified model</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">boolean</span> <span class="title">loadQualified</span><span class="params">(String modelDir)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Load combined parameters</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">boolean</span> <span class="title">loadCombined</span><span class="params">(String modelPath, String paramPath)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// load qualified model</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">boolean</span> <span class="title">loadCombinedQualified</span><span class="params">(String modelPath, String paramPath)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// object detection</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">float</span>[] predictImage(<span class="keyword">float</span>[] buf, <span class="keyword">int</span>[]ddims);</span><br><span class="line"></span><br><span class="line"><span class="comment">// predict yuv image</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">float</span>[] predictYuv(<span class="keyword">byte</span>[] buf, <span class="keyword">int</span> imgWidth, <span class="keyword">int</span> imgHeight, <span class="keyword">int</span>[] ddims, <span class="keyword">float</span>[]meanValues);</span><br><span class="line"></span><br><span class="line"><span class="comment">// clear model</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>7、然后编写一个<code>PhotoUtil.java</code>的工具类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.paddlemobile1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> android.app.Activity;</span><br><span class="line"><span class="keyword">import</span> android.content.Context;</span><br><span class="line"><span class="keyword">import</span> android.content.Intent;</span><br><span class="line"><span class="keyword">import</span> android.database.Cursor;</span><br><span class="line"><span class="keyword">import</span> android.graphics.Bitmap;</span><br><span class="line"><span class="keyword">import</span> android.graphics.BitmapFactory;</span><br><span class="line"><span class="keyword">import</span> android.net.Uri;</span><br><span class="line"><span class="keyword">import</span> android.os.Build;</span><br><span class="line"><span class="keyword">import</span> android.provider.MediaStore;</span><br><span class="line"><span class="keyword">import</span> android.support.v4.content.FileProvider;</span><br><span class="line"><span class="keyword">import</span> android.util.Log;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PhotoUtil</span> </span>&#123;</span><br><span class="line"><span class="comment">// start camera</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Uri <span class="title">start_camera</span><span class="params">(Activity activity, <span class="keyword">int</span> requestCode)</span> </span>&#123;</span><br><span class="line">    Uri imageUri;</span><br><span class="line">    <span class="comment">// save image in cache path</span></span><br><span class="line">    File outputImage = <span class="keyword">new</span> File(activity.getExternalCacheDir(), <span class="string">"out_image.jpg"</span>);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (outputImage.exists()) &#123;</span><br><span class="line">            outputImage.delete();</span><br><span class="line">        &#125;</span><br><span class="line">        outputImage.createNewFile();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (Build.VERSION.SDK_INT &gt;= <span class="number">24</span>) &#123;</span><br><span class="line">        <span class="comment">// compatible with Android 7.0 or over</span></span><br><span class="line">        imageUri = FileProvider.getUriForFile(activity,</span><br><span class="line">                <span class="string">"com.example.paddlemobile1"</span>, outputImage);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        imageUri = Uri.fromFile(outputImage);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// set system camera Action</span></span><br><span class="line">    Intent intent = <span class="keyword">new</span> Intent(MediaStore.ACTION_IMAGE_CAPTURE);</span><br><span class="line">    <span class="comment">// set save photo path</span></span><br><span class="line">    intent.putExtra(MediaStore.EXTRA_OUTPUT, imageUri);</span><br><span class="line">    <span class="comment">// set photo quality, min is 0, max is 1</span></span><br><span class="line">    intent.putExtra(MediaStore.EXTRA_VIDEO_QUALITY, <span class="number">0</span>);</span><br><span class="line">    activity.startActivityForResult(intent, requestCode);</span><br><span class="line">    <span class="keyword">return</span> imageUri;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// get picture in photo</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">use_photo</span><span class="params">(Activity activity, <span class="keyword">int</span> requestCode)</span></span>&#123;</span><br><span class="line">    Intent intent = <span class="keyword">new</span> Intent(Intent.ACTION_PICK);</span><br><span class="line">    intent.setType(<span class="string">"image/*"</span>);</span><br><span class="line">    activity.startActivityForResult(intent, requestCode);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// get photo from Uri</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">get_path_from_URI</span><span class="params">(Context context, Uri uri)</span> </span>&#123;</span><br><span class="line">    String result;</span><br><span class="line">    Cursor cursor = context.getContentResolver().query(uri, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">    <span class="keyword">if</span> (cursor == <span class="keyword">null</span>) &#123;</span><br><span class="line">        result = uri.getPath();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        cursor.moveToFirst();</span><br><span class="line">        <span class="keyword">int</span> idx = cursor.getColumnIndex(MediaStore.Images.ImageColumns.DATA);</span><br><span class="line">        result = cursor.getString(idx);</span><br><span class="line">        cursor.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Compress the image to the size of the training image，and change RGB</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">float</span>[] getScaledMatrix(Bitmap bitmap, <span class="keyword">int</span> desWidth,</span><br><span class="line">                               <span class="keyword">int</span> desHeight) &#123;</span><br><span class="line">    <span class="keyword">float</span>[] dataBuf = <span class="keyword">new</span> <span class="keyword">float</span>[<span class="number">3</span> * desWidth * desHeight];</span><br><span class="line">    <span class="keyword">int</span> rIndex;</span><br><span class="line">    <span class="keyword">int</span> gIndex;</span><br><span class="line">    <span class="keyword">int</span> bIndex;</span><br><span class="line">    <span class="keyword">int</span>[] pixels = <span class="keyword">new</span> <span class="keyword">int</span>[desWidth * desHeight];</span><br><span class="line">    Bitmap bm = Bitmap.createScaledBitmap(bitmap, desWidth, desHeight, <span class="keyword">false</span>);</span><br><span class="line">    bm.getPixels(pixels, <span class="number">0</span>, desWidth, <span class="number">0</span>, <span class="number">0</span>, desWidth, desHeight);</span><br><span class="line">    <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> k = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; pixels.length; i++) &#123;</span><br><span class="line">        <span class="keyword">int</span> clr = pixels[i];</span><br><span class="line">        j = i / desHeight;</span><br><span class="line">        k = i % desWidth;</span><br><span class="line">        rIndex = j * desWidth + k;</span><br><span class="line">        gIndex = rIndex + desHeight * desWidth;</span><br><span class="line">        bIndex = gIndex + desHeight * desWidth;</span><br><span class="line">        dataBuf[rIndex] = (<span class="keyword">float</span>) ((clr &amp; <span class="number">0x00ff0000</span>) &gt;&gt; <span class="number">16</span>) - <span class="number">148</span>;</span><br><span class="line">        dataBuf[gIndex] = (<span class="keyword">float</span>) ((clr &amp; <span class="number">0x0000ff00</span>) &gt;&gt; <span class="number">8</span>) - <span class="number">148</span>;</span><br><span class="line">        dataBuf[bIndex] = (<span class="keyword">float</span>) ((clr &amp; <span class="number">0x000000ff</span>)) - <span class="number">148</span>;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (bm.isRecycled()) &#123;</span><br><span class="line">        bm.recycle();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dataBuf;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// compress picture</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Bitmap <span class="title">getScaleBitmap</span><span class="params">(String filePath)</span> </span>&#123;</span><br><span class="line">    BitmapFactory.Options opt = <span class="keyword">new</span> BitmapFactory.Options();</span><br><span class="line">    opt.inJustDecodeBounds = <span class="keyword">true</span>;</span><br><span class="line">    BitmapFactory.decodeFile(filePath, opt);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> bmpWidth = opt.outWidth;</span><br><span class="line">    <span class="keyword">int</span> bmpHeight = opt.outHeight;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> maxSize = <span class="number">500</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// compress picture with inSampleSize</span></span><br><span class="line">    opt.inSampleSize = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (bmpWidth / opt.inSampleSize &lt; maxSize || bmpHeight / opt.inSampleSize &lt; maxSize) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        opt.inSampleSize *= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    opt.inJustDecodeBounds = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">return</span> BitmapFactory.decodeFile(filePath, opt);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>start_camera()方法是启动相机并返回图片的URI。</li><li>use_photo()方法是打开相册，获取到的图片URI在回到函数中获取。</li><li>get_path_from_URI()方法是把图片的URI转换成绝对路径。</li><li>getScaledMatrix()方法是把图片压缩成跟训练时的大小，并转换成预测需要用的数据格式浮点数组。</li><li>getScaleBitmap()方法是对图片进行等比例压缩，减少内存的支出。</li></ul><p>8、最后修改<code>MainActivity.java</code>，修改如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.paddlemobile1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> android.Manifest;</span><br><span class="line"><span class="keyword">import</span> android.annotation.SuppressLint;</span><br><span class="line"><span class="keyword">import</span> android.app.Activity;</span><br><span class="line"><span class="keyword">import</span> android.content.Context;</span><br><span class="line"><span class="keyword">import</span> android.content.Intent;</span><br><span class="line"><span class="keyword">import</span> android.content.pm.PackageManager;</span><br><span class="line"><span class="keyword">import</span> android.graphics.Bitmap;</span><br><span class="line"><span class="keyword">import</span> android.net.Uri;</span><br><span class="line"><span class="keyword">import</span> android.os.Bundle;</span><br><span class="line"><span class="keyword">import</span> android.os.Environment;</span><br><span class="line"><span class="keyword">import</span> android.support.annotation.NonNull;</span><br><span class="line"><span class="keyword">import</span> android.support.annotation.Nullable;</span><br><span class="line"><span class="keyword">import</span> android.support.v4.app.ActivityCompat;</span><br><span class="line"><span class="keyword">import</span> android.support.v4.content.ContextCompat;</span><br><span class="line"><span class="keyword">import</span> android.support.v7.app.AppCompatActivity;</span><br><span class="line"><span class="keyword">import</span> android.util.Log;</span><br><span class="line"><span class="keyword">import</span> android.view.View;</span><br><span class="line"><span class="keyword">import</span> android.widget.Button;</span><br><span class="line"><span class="keyword">import</span> android.widget.ImageView;</span><br><span class="line"><span class="keyword">import</span> android.widget.TextView;</span><br><span class="line"><span class="keyword">import</span> android.widget.Toast;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.bumptech.glide.Glide;</span><br><span class="line"><span class="keyword">import</span> com.bumptech.glide.load.engine.DiskCacheStrategy;</span><br><span class="line"><span class="keyword">import</span> com.bumptech.glide.request.RequestOptions;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MainActivity</span> <span class="keyword">extends</span> <span class="title">AppCompatActivity</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String TAG = MainActivity.class.getName();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> USE_PHOTO = <span class="number">1001</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> START_CAMERA = <span class="number">1002</span>;</span><br><span class="line">    <span class="keyword">private</span> Uri image_uri;</span><br><span class="line">    <span class="keyword">private</span> ImageView show_image;</span><br><span class="line">    <span class="keyword">private</span> TextView result_text;</span><br><span class="line">    <span class="keyword">private</span> String assets_path = <span class="string">"paddle_models"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> load_result = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span>[] ddims = &#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>&#125;;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String[] PADDLE_MODEL = &#123;</span><br><span class="line">        <span class="string">"lenet"</span>,</span><br><span class="line">        <span class="string">"alexnet"</span>,</span><br><span class="line">        <span class="string">"vgg16"</span>,</span><br><span class="line">        <span class="string">"resnet"</span>,</span><br><span class="line">        <span class="string">"googlenet"</span>,</span><br><span class="line">        <span class="string">"mobilenet_v1"</span>,</span><br><span class="line">        <span class="string">"mobilenet_v2"</span>,</span><br><span class="line">        <span class="string">"inception_v1"</span>,</span><br><span class="line">        <span class="string">"inception_v2"</span>,</span><br><span class="line">        <span class="string">"squeezenet"</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// load paddle-mobile api</span></span><br><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        System.loadLibrary(<span class="string">"paddle-mobile"</span>);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (SecurityException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (UnsatisfiedLinkError e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (NullPointerException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onCreate</span><span class="params">(Bundle savedInstanceState)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onCreate(savedInstanceState);</span><br><span class="line">    setContentView(R.layout.activity_main);</span><br><span class="line"></span><br><span class="line">    init();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// initialize view</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    request_permissions();</span><br><span class="line">    show_image = (ImageView) findViewById(R.id.show_image);</span><br><span class="line">    result_text = (TextView) findViewById(R.id.result_text);</span><br><span class="line">    Button use_photo = (Button) findViewById(R.id.use_photo);</span><br><span class="line">    Button start_photo = (Button) findViewById(R.id.start_camera);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// use photo click</span></span><br><span class="line">    use_photo.setOnClickListener(<span class="keyword">new</span> View.OnClickListener() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View view)</span> </span>&#123;</span><br><span class="line">            PhotoUtil.use_photo(MainActivity.<span class="keyword">this</span>, USE_PHOTO);</span><br><span class="line">            <span class="comment">//                load_model();</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">// start camera click</span></span><br><span class="line">    start_photo.setOnClickListener(<span class="keyword">new</span> View.OnClickListener() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View view)</span> </span>&#123;</span><br><span class="line">            image_uri = PhotoUtil.start_camera(MainActivity.<span class="keyword">this</span>, START_CAMERA);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// copy file from assets to sdcard</span></span><br><span class="line">    String sdcard_path = Environment.getExternalStorageDirectory()</span><br><span class="line">            + File.separator + assets_path;</span><br><span class="line">    copy_file_from_asset(<span class="keyword">this</span>, assets_path, sdcard_path);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// load model</span></span><br><span class="line">    load_model();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// load infer model</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">load_model</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    String model_path = Environment.getExternalStorageDirectory()</span><br><span class="line">            + File.separator + assets_path + File.separator + PADDLE_MODEL[<span class="number">4</span>];</span><br><span class="line">    Log.d(TAG, model_path);</span><br><span class="line">    load_result = ImageRecognition.load(model_path);</span><br><span class="line">    <span class="keyword">if</span> (load_result) &#123;</span><br><span class="line">        Log.d(TAG, <span class="string">"model load success"</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        Log.d(TAG, <span class="string">"model load fail"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// clear infer model</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">clear_model</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ImageRecognition.clear();</span><br><span class="line">    Log.d(TAG, <span class="string">"model is clear"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// copy file from asset to sdcard</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">copy_file_from_asset</span><span class="params">(Context context, String oldPath, String newPath)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        String[] fileNames = context.getAssets().list(oldPath);</span><br><span class="line">        <span class="keyword">if</span> (fileNames.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// directory</span></span><br><span class="line">            File file = <span class="keyword">new</span> File(newPath);</span><br><span class="line">            <span class="keyword">if</span> (!file.exists()) &#123;</span><br><span class="line">                file.mkdirs();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// copy recursivelyC</span></span><br><span class="line">            <span class="keyword">for</span> (String fileName : fileNames) &#123;</span><br><span class="line">                copy_file_from_asset(context, oldPath + <span class="string">"/"</span> + fileName, newPath + <span class="string">"/"</span> + fileName);</span><br><span class="line">            &#125;</span><br><span class="line">            Log.d(TAG, <span class="string">"copy files finish"</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// file</span></span><br><span class="line">            File file = <span class="keyword">new</span> File(newPath);</span><br><span class="line">            <span class="comment">// if file exists will never copy</span></span><br><span class="line">            <span class="keyword">if</span> (file.exists()) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// copy file to new path</span></span><br><span class="line">            InputStream is = context.getAssets().open(oldPath);</span><br><span class="line">            FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(file);</span><br><span class="line">            <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">            <span class="keyword">int</span> byteCount;</span><br><span class="line">            <span class="keyword">while</span> ((byteCount = is.read(buffer)) != -<span class="number">1</span>) &#123;</span><br><span class="line">                fos.write(buffer, <span class="number">0</span>, byteCount);</span><br><span class="line">            &#125;</span><br><span class="line">            fos.flush();</span><br><span class="line">            is.close();</span><br><span class="line">            fos.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onActivityResult</span><span class="params">(<span class="keyword">int</span> requestCode, <span class="keyword">int</span> resultCode, @Nullable Intent data)</span> </span>&#123;</span><br><span class="line">    String image_path;</span><br><span class="line">    RequestOptions options = <span class="keyword">new</span> RequestOptions().skipMemoryCache(<span class="keyword">true</span>).diskCacheStrategy(DiskCacheStrategy.NONE);</span><br><span class="line">    <span class="keyword">if</span> (resultCode == Activity.RESULT_OK) &#123;</span><br><span class="line">        <span class="keyword">switch</span> (requestCode) &#123;</span><br><span class="line">            <span class="keyword">case</span> USE_PHOTO:</span><br><span class="line">                <span class="keyword">if</span> (data == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    Log.w(TAG, <span class="string">"user photo data is null"</span>);</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                image_uri = data.getData();</span><br><span class="line">                Glide.with(MainActivity.<span class="keyword">this</span>).load(image_uri).apply(options).into(show_image);</span><br><span class="line">                <span class="comment">// get image path from uri</span></span><br><span class="line">                image_path = PhotoUtil.get_path_from_URI(MainActivity.<span class="keyword">this</span>, image_uri);</span><br><span class="line">                <span class="comment">// show result</span></span><br><span class="line">                result_text.setText(image_path);</span><br><span class="line">                <span class="comment">// predict image</span></span><br><span class="line">                predict_image(PhotoUtil.get_path_from_URI(MainActivity.<span class="keyword">this</span>, image_uri));</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> START_CAMERA:</span><br><span class="line">                <span class="comment">// show photo</span></span><br><span class="line">                Glide.with(MainActivity.<span class="keyword">this</span>).load(image_uri).apply(options).into(show_image);</span><br><span class="line">                <span class="comment">// get image path from uri</span></span><br><span class="line">                image_path = PhotoUtil.get_path_from_URI(MainActivity.<span class="keyword">this</span>, image_uri);</span><br><span class="line">                <span class="comment">// show result</span></span><br><span class="line">                result_text.setText(image_path);</span><br><span class="line">                <span class="comment">// predict image</span></span><br><span class="line">                predict_image(PhotoUtil.get_path_from_URI(MainActivity.<span class="keyword">this</span>, image_uri));</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SuppressLint</span>(<span class="string">"SetTextI18n"</span>)</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">predict_image</span><span class="params">(String image_path)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// picture to float array</span></span><br><span class="line">    Bitmap bmp = PhotoUtil.getScaleBitmap(image_path);</span><br><span class="line">    <span class="keyword">float</span>[] inputData = PhotoUtil.getScaledMatrix(bmp, ddims[<span class="number">2</span>], ddims[<span class="number">3</span>]);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line">        <span class="comment">// get predict result</span></span><br><span class="line">        <span class="keyword">float</span>[] result = ImageRecognition.predictImage(inputData, ddims);</span><br><span class="line">        Log.d(TAG, <span class="string">"origin predict result:"</span> + Arrays.toString(result));</span><br><span class="line">        <span class="keyword">long</span> end = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">long</span> time = end - start;</span><br><span class="line">        Log.d(<span class="string">"result length"</span>, String.valueOf(result.length));</span><br><span class="line">        <span class="comment">// show predict result and time</span></span><br><span class="line">        <span class="keyword">int</span> r = get_max_result(result);</span><br><span class="line">        String show_text = <span class="string">"result："</span> + r + <span class="string">"\nprobability："</span> + result[r] + <span class="string">"\ntime："</span> + time + <span class="string">"ms"</span>;</span><br><span class="line">        result_text.setText(show_text);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">get_max_result</span><span class="params">(<span class="keyword">float</span>[] result)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">float</span> probability = result[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">int</span> r = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; result.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (probability &lt; result[i]) &#123;</span><br><span class="line">            probability = result[i];</span><br><span class="line">            r = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// request permissions</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">request_permissions</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    List&lt;String&gt; permissionList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    <span class="keyword">if</span> (ContextCompat.checkSelfPermission(<span class="keyword">this</span>, Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) &#123;</span><br><span class="line">        permissionList.add(Manifest.permission.CAMERA);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ContextCompat.checkSelfPermission(<span class="keyword">this</span>, Manifest.permission.WRITE_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED) &#123;</span><br><span class="line">        permissionList.add(Manifest.permission.WRITE_EXTERNAL_STORAGE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ContextCompat.checkSelfPermission(<span class="keyword">this</span>, Manifest.permission.READ_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED) &#123;</span><br><span class="line">        permissionList.add(Manifest.permission.READ_EXTERNAL_STORAGE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if list is not empty will request permissions</span></span><br><span class="line">    <span class="keyword">if</span> (!permissionList.isEmpty()) &#123;</span><br><span class="line">        ActivityCompat.requestPermissions(<span class="keyword">this</span>, permissionList.toArray(<span class="keyword">new</span> String[permissionList.size()]), <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onRequestPermissionsResult</span><span class="params">(<span class="keyword">int</span> requestCode, @NonNull String[] permissions, @NonNull <span class="keyword">int</span>[] grantResults)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onRequestPermissionsResult(requestCode, permissions, grantResults);</span><br><span class="line">    <span class="keyword">switch</span> (requestCode) &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">if</span> (grantResults.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; grantResults.length; i++) &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">int</span> grantResult = grantResults[i];</span><br><span class="line">                    <span class="keyword">if</span> (grantResult == PackageManager.PERMISSION_DENIED) &#123;</span><br><span class="line">                        String s = permissions[i];</span><br><span class="line">                        Toast.makeText(<span class="keyword">this</span>, s + <span class="string">" permission was denied"</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onDestroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// clear model before destroy app</span></span><br><span class="line">    clear_model();</span><br><span class="line">    <span class="keyword">super</span>.onDestroy();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>load_model()方法是加载预测模型的。</li><li>clear_model()方法是清空预测模型的。</li><li>copy_file_from_asset()方法是把预测模型复制到内存卡上。</li><li>predict_image()方法是预测图片的。</li><li>get_max_result()方法是获取概率最大的预测结果。</li><li>request_permissions()方法是动态请求权限的。</li></ul><p>因为使用到图像加载框架Glide，所以要在<code>build.gradle</code>加入以下的引用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">implementation &apos;com.github.bumptech.glide:glide:4.3.1&apos;</span><br></pre></td></tr></table></figure><p>8、最后运行项目，选择图片预测就会得到结果。</p><h2 id="17-9-移动端开源框架部署疑难"><a href="#17-9-移动端开源框架部署疑难" class="headerlink" title="17.9 移动端开源框架部署疑难"></a>17.9 移动端开源框架部署疑难</h2><p>增加常见的几个问题</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://leesen998.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习基础" scheme="https://leesen998.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>深度学习 NLP</title>
    <link href="https://leesen998.github.io/2017/12/29/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0_NLP/"/>
    <id>https://leesen998.github.io/2017/12/29/第十六章_NLP/</id>
    <published>2017-12-29T11:48:29.000Z</published>
    <updated>2019-03-22T07:36:53.784Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg" alt="" style="width:100%"></p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Markdown Revision 1;</span><br><span class="line">Editor: 盛泳潘-电子科技大学;何建宏-学生</span><br><span class="line">Contact: shengyp2011@163.com;Bonopengate@gmail.com</span><br></pre></td></tr></table></figure><h2 id="16-0-NLP-发展史简述"><a href="#16-0-NLP-发展史简述" class="headerlink" title="16.0 NLP 发展史简述"></a>16.0 NLP 发展史简述</h2><p>50多年来 NLP 的历史发展可以分为三个浪潮，前两波以理性主义和经验主义的形式出现，为当前的深度学习浪潮铺平了道路。NLP的深层学习革命的主要支柱是: （1）语言嵌入实体的分布式表征，（2）由于嵌入而产生的语义泛化， （3）自然语言的大跨度深序列建模，（4）能够从低到高表示语言层次的分层网络，以及（5）解决许多联合 NLP 问题的端对端深度学习方法。</p><h3 id="第一个浪潮：理性主义"><a href="#第一个浪潮：理性主义" class="headerlink" title="第一个浪潮：理性主义"></a>第一个浪潮：理性主义</h3><p>在第一个浪潮中，NLP的实验持续了很长一段时间，可以追溯到20世纪50年代。1950年，阿兰·图灵提出了图灵测试，以评估计算机表现出与人类无法区分的智能行为的能力。这项测试是基于人类和计算机之间的自然语言对话，旨在生成类似人类的反应。1954年，George-IBM 实验产出了能够将60多个俄语句子翻译成英语的rrst机器翻译系统。</p><p>这些方法是基于这样一种信念，即人类思维中的语言知识是由泛型继承提前进行的，而这种信念，在大约1960年至1980年代后期，占据了NLP的大部分研究中的主导地位。这些方法被称为理性主义方法（Church 2007）。理性主义方法在 NLP 中的主导地位主要是由于诺姆·乔姆斯基（Noam Chomsky）关于先天语言结构的论点被广泛接受以及他对 N-grams 方法的批评（Chomsky 1957）。理性主义者一般假设语言的关键部分在出生时就被硬连接到大脑中，作为人类遗传遗传的一部分，因此他们试图设计手工制作的规则，将知识和推理机制纳入智能 NLP 系统。直到20世纪80年代，最著名的成功的NLP系统，如为模拟 Rogerian psychotherapist 的 ELIZA 系统和为了规则化真实世界信息为规则本体的 MARGIE 系统，都是基于复杂的手写规则。</p><p>这一时期恰逢以专家知识工程为特点的早期智能的早期发展，即领域专家根据其所掌握的（非常狭窄的）应用领域的知识设计计算机程序（Nilsson 1982; Winston 1993）。专家们使用符号逻辑规则设计了这些程序，这些规则基于对这些知识的仔细表征和工程。这些以知识为基础的智能系统往往通过检测”Head”或最重要的参数，并就每种特殊情况采取特定的解决办法，而这在解决狭义问题方面往往是有效的。这些“Head”参数由人类专家预先确定，使“tail”参数和案例不受影响。由于缺乏学习能力，他们有必要将解决方案推广到新的情况和领域。这一时期的典型方法是专家系统所提供的证据，这是一个模拟人类专家决策能力的计算机系统。这种系统旨在通过知识推理来解决复杂的问题（Nilsson 1982）。第一个专家系统建立于1970年代，然后在1980年代推广。使用的主要”算法”是以”if-then-else”为形式的推断规则（Jackson 1998）。这些智能系统的主要优点是其在进行逻辑推理方面（有限）能力的透明度和可解释性。像NLP系统，如 ELIZA 和 MARGIE ，一般专家系统在早期使用手工制作的专家知识，这往往是有效的狭隘的问题，虽然推理无法处理不确定性，是普遍存在的实际应用。</p><p>同样，语音识别研究和系统设计，这又是另一个长期存在的 NLP 和反智能挑战，在这个理性主义时代，主要基于专家知识工程的范式，如elegantly analyzed in（Church and Mercer 1993）。在1970年代和1980年代初，专家系统的语音识别方法相当流行（Reddy 1976; Zue 1985）。然而，研究人员敏锐地认识到，缺乏从数据中学习和处理推理不确定性的能力，导致了接下来描述的第二波语音识别、NLP和对于文本的人工智能浪潮也走向失败。</p><h3 id="第二波浪潮：经验主义"><a href="#第二波浪潮：经验主义" class="headerlink" title="第二波浪潮：经验主义"></a>第二波浪潮：经验主义</h3><p>第二波 NLP 浪潮的特点是利用语料库数据以及基于（浅层）机器学习、统计学等来利用这些数据（Manning and Schtze 1999）。由于许多自然语言的结构和理论都被贬低或抛弃，而倾向于数据驱动的方法，这个时代发展的主要方法被称为经验或务实的方法（ChurchandMercer 1993;Church 2014）。NLP 的一个主要会议甚至被命名为“自然语言处理的经验方法（Empirical Methods in Natural Language Processing）（EMNLP）”，最直接地反映了NLP研究人员在那个时代对经验方法的强烈积极情绪。</p><p>与理性主义方法相反，经验方法认为人类的思维只是从关联、模式识别和泛化的常规操作开始。丰富的感官输入需要使大脑学习自然语言的详细结构。经验主义盛行于1920年至1960年间，自1990年以来一直在兴起。NLP的早期经验方法主要是开发生成模型，如隐马尔可夫模型 （HMM） （Baum and Petrie 1966）， IBM 翻译模型 （Brown et al. 1993）， 和 head-driven parsing 模型（Collins 1997），以发现大型语料库的规律性。自1990年代后期以来，在各种NLP任务中，歧视性模式已成为事实上的做法。NLP的典型判别模型和方法包括最大熵模型（ratnaparkhi 1997）、支持向量机（Vapnik 1998）、条件随机（Lafferty et al. 2001）、最大相互信息和最小区分器错误（He et al. 2008）还有感知器（Collins 2002）。</p><p>在这种经验主义时代中、NLP 与同样的智能方法如语音识别和计算机视觉是平行的。这是在明确的证据表明，学习和感知能力对复杂的智能系统至关重要，但在前一波流行的专家系统中却不存在。例如，当 DARPA 开始对自动驾驶提出重大挑战时，大多数车辆随后依赖于基于知识的智能智能。正如语音识别和NLP 一样，自主驾驶和计算机视觉研究人员意识到基于知识的范式的局限性，因为机器学习需要进行不确定性处理和泛化能力。</p><p>在第二波浪潮中，NLP的经验主义和语音识别是基于数据密集型机器学习的，我们现在称之为“shallow”，因为在下一节中描述的第三波浪潮中，数据的多层或“deep”表征通常缺乏抽象结构。在机器学习中，在第一次浪潮中，研究人员不需要考虑构造精确规则，为知识为基础的 NLP 和语音系统。相反，他们把重点放在统计模型（Bishop 2006; Murphy 2012）或作为一个基本引擎的简单的神经网络（Bishop 1995）。然后，他们使用足够的训练数据进行自动学习或“tune（调整）”系统的参数，使它们能够处理不确定性，并尝试从一个条件泛化到另一个条件，从一个领域泛化到另一个领域。机器学习的关键算法和方法包括EM （期望最大化）、贝叶斯网络、支持向量机、决策树以及神经网络的反向传播算法。</p><p>一般来说，基于机器学习的NLP、语音和其他智能系统的性能比早期的基于知识的智能系统要好得多。成功的例子包括语音识别 （Jelinek 1998）， 脸部识别 （Viola and Jones 2004）， 实体识别 （Fei-Fei and Perona 2005）， 手写字体识别 （Plamondon and Srihari 2000）， 以及机器翻译 （Och 2003）。</p><p>在语音识别方面，从20世纪80年代初到2010年前后近30年，利用基于 HMM 与高斯混合模型相结合的统计生成模型，以及其推广的各种版本（Baker et al. 2009a，b; Deng and O’Shaughnessy 2003; Rabiner and Juang 1993）的统计生成模式。泛化 HMM 的许多版本都是基于统计和神经网络的隐动态模型（Deng 1998; Bridle et al. 1998; Deng and Yu 2007）。前者采用 EM 和 switching extended Kalman ﬁlter 算法学习模型参数（Ma and Deng 2004; Lee et al. 2004），后者采用反向传播（Picone et al. 1999），两者都广泛地利用多个潜在层表示法进行语音分析的生成过程。将这种“深度”生成过程转化为端到端过程的对应方案，导致了深度学习的工业化成功（Deng et al. 2010， 2013; Hinton et al. 2012） ，从而形成了第三波浪潮的驱动力。</p><h3 id="第三波浪潮：深度学习"><a href="#第三波浪潮：深度学习" class="headerlink" title="第三波浪潮：深度学习"></a>第三波浪潮：深度学习</h3><p>在第二波浪潮中开发的 NLP 系统，包括语音识别、语言理解和机器翻译，表现得比在第一波浪潮时更好，鲁棒性更高，但它们远远没有达到人的水平，而这留下了很多需求。除了少数例外，NLP的（浅层）机器学习模型通常没有足够的容量来吸收大量的训练数据。此外，学习算法、方法和基础设施也都不够强大。所有这一切都在几年前发生了变化，而这导致了第三波 NLP 浪潮，这股浪潮是由深层机器学习或深度学习的新范式推动的（Bengio 2009; Deng and Yu 2014; LeCun et al. 2015; Goodfellow et al. 2016）。</p><p>深度学习起源于人工神经网络，它可以被看作是受生物神经系统启发的细胞类型的级联模型。随着反向传播算法的出现（Rumelhart et al. 1986），90年代对深度神经网络的训练引起了广泛关注。在没有大量训练数据和没有适当的设计和学习范式的情况下，在神经网络训练过程中，学习信号随着层次数（或更严格的信用分配深度）在层层传播时呈指数形式消失，使得调整深层神经网络特别是递归的版本的连接权重变得异常艰难。Hinton 等人（2006）克服了这个问题，使用无人监督的预训练模型来进行学习有用的特征探测器。然后，通过监督学习进一步训练网络，对标记数据进行分类。因此，可以学习使用低维表征的方式来学习高维的表征的分布。这项开创性的工作标志着神经网络的复兴。此后提出和发展了各种网络结构，包括 Deep Belief 网络（Hinton et al.2006）、堆积自编码器（Vincent et al.2010）、深层玻尔兹曼机（Hinton and Salakhutdinov 2012）、深度卷积神经网络（Krizhevsky et al. 2012），深层堆积网络 （Deng et al. 2012），和深层 Q-networks （Mnih et al. 2015）。深度学习自2010年以来已成功地应用于实际智能领域的实际任务，包括语音识别（Yu et al. 2010; Hinton et al. 2012），图像识别（Krizhevsky et al. 2012; He et al. 2016），以及 NLP 绝大多数领域。 </p><p>其中由于微软公司在工业化上的成功，以及愈来愈高的准确率等迹象，这些2010-2011年语音识别的惊人成功预示着 NLP 的第三波浪潮和人工智能的到来。随着深度学习在语音识别方面取得成功，计算机视觉（Krizhevsky et al. 2012）和机器翻译（Bahdanau et al. 2015）被类似的深度学习范式所取代。特别是，虽然 Bengio 等人在2001的工作，在2011年就开发了强大的神经词嵌入技术（Bengio et al. 2001），但由于大数据的可用性和更快的计算，它直到10多年后才被证明在一个大规模和实际有用的规模上才能够实际有用（Mikolov et al. 2013）。此外，许多其他现实世界的NLP应用，如图像字幕（Karpathy and Fei-Fei 2015; Fang et al. 2015; Gan et al. 2017），视觉问题回答（Fei-Fei and Perona 2016），语音理解系统（Mesnil et al. 2013），网络搜索（Huang et al. 2013b）和推荐系统由于深度学习而取得成功，此外还有许多非NLP任务，包括药物发现和药理学、客户关系管理、推荐系统、手势识别、医学信息、广告投放、医学图像分析、机器人、自动驾驶车辆、纸板和电子游戏（例如 Atari， Go， Poker， and the latest， DOTA2）等。详情请参阅维基上的深度学习领域。</p><p>在更多基于文本的应用领域中，机器翻译可能受到深度学习的影响最大。从 NLP 第二波浪潮中发展起来的浅层——统计机器翻译开始看起的话，目前在实际应用中最好的机器翻译系统是基于深神经网络的。例如，谷歌在2016年9月宣布了其转向神经机器翻译的阶段，两个月后微软也发布了类似的声明。Facebook已经进行了大约一年的机器神经网络翻译的转换工作，到2017年8月它已经完全将这个系统部署成功。</p><p>在口语理解和对话系统领域，深度学习也正在产生巨大影响。目前流行的技术以多种方式维护和扩展了第二波时代浪潮中发展起来的统计方法。与经验（浅层）机器学习方法一样，深度学习也是基于数据密集型方法，以降低手工制作规则的成本，对噪声环境下的语音识别错误和语言理解错误具有很强的鲁棒性，并利用决策过程和强化学习的力量来设计对话策略，例如（Gasic et al. 2017; Dhingra et al. 2017）。与早期的方法相比，深度神经网络模型和表征方法更强大，它们使端到端学习成为可能。然而，深度学习也没有解决可解释性和领域泛化问题。</p><p>将深度学习应用于 NLP 问题方面的最近的两个重要技术突破是序列到序列学习（Sutskevar et al. 2014）和注意力机制建模（Bahdanau et al. 2015），以及最近的 BERT模型（Jacob el al.2018） 。序列到序列学习引入了一个强大的学习范式，即使用递归神经网络以端到端的方式进行编码和解码。注意力机制建模最初是为了克服编码一个长序列的难度而开发的，后来的持续发展又扩展了它的能力，提供了两个任意序列的高度可塑对齐能力，而其两个可以同时学习神经网络参数。而 BERT 则是实现了双向建模获取以得到更好的语言表征能力。序列到序列学习和注意力机制的关键概念在基于统计学习和词局部表征的最佳系统上提高了基于分布式单词嵌入的神经机器翻译的性能，而 BERT 更重要的意义是双向获取同一文段的高维意义。在这一成功之后，这些概念也被成功地应用到许多其他与NLP相关的任务中，如图像字幕（Karpathy and Fei-Fei 2015; Devlin et al. 2015）、语音识别（Chorowski et al. 2015）、一次性学习、句法分析、唇读、文本理解、摘要以及问答系统等。撇开他们巨大的经验成功不谈，基于神经网络的深度学习模型往往比早期浪潮中的传统机器学习模型更简单、更容易设计。在许多应用中，在端到端的任务中，模型的所有部分都同时进行深度学习，从特征抽取到预测。导致神经网络模型相对简单的另一个因素是，相同的模型构建成的块（即不同类型的层）通常在许多不同的应用中使用。为多种任务使用相同的构建块，这种方法使得模型更容易迁移到其它任务和数据上。此外，谷歌等公司还开发了软件工具包，以便更快、更有效地实现这些模型。由于以上这些原因，神经网络在数据量大而且基于云的方式上，是更常用的。</p><p>尽管深度学习在重塑语音、图像和视频的处理方面被证明是有效的，而且具有它的革命性，但在将深度学习与基于文本的 NLP 相结合方面的有效性并不那么明确，尽管它在一些实用的 NLP 任务中取得了经验上的成功。在语音、图像和视频处理中，深度学习通过直接从原始数据学习规律来解决语义差距问题。然而，在 NLP 中，人们提出了更强的理论和结构化模型，即语音、语法和语义，来提取理解和生成自然语言的基本机制，这些机制与神经网络不那么容易兼容。与语音、图像和视频信号相比，从文本数据中学习的神经表征可以对自然语言提供同样直接的见解，但是这个也不够直接。因此，将神经网络，特别是那些具有复杂层次结构的神经网络应用于 NLP，已成为 NLP 和深度学习社区中最活跃的领域，近年来取得了非常显著的进展（Deng 2016; Manning and Socher 2017;Jacob el al.2018）。</p><h2 id="16-1-如何理解序列到序列模型？"><a href="#16-1-如何理解序列到序列模型？" class="headerlink" title="16.1 如何理解序列到序列模型？"></a>16.1 如何理解序列到序列模型？</h2><h2 id="16-2-序列到序列模型有什么限制吗？"><a href="#16-2-序列到序列模型有什么限制吗？" class="headerlink" title="16.2 序列到序列模型有什么限制吗？"></a>16.2 序列到序列模型有什么限制吗？</h2><h2 id="16-3-如果不采用序列到序列模型，可以考虑用其它模型方法吗？"><a href="#16-3-如果不采用序列到序列模型，可以考虑用其它模型方法吗？" class="headerlink" title="16.3 如果不采用序列到序列模型，可以考虑用其它模型方法吗？"></a>16.3 如果不采用序列到序列模型，可以考虑用其它模型方法吗？</h2><h2 id="16-4-如何理解词向量？"><a href="#16-4-如何理解词向量？" class="headerlink" title="16.4 如何理解词向量？"></a>16.4 如何理解词向量？</h2><h2 id="16-5-词向量哪家好？"><a href="#16-5-词向量哪家好？" class="headerlink" title="16.5 词向量哪家好？"></a>16.5 词向量哪家好？</h2><h2 id="16-6-解释一下注意力机制的原理？"><a href="#16-6-解释一下注意力机制的原理？" class="headerlink" title="16.6 解释一下注意力机制的原理？"></a>16.6 解释一下注意力机制的原理？</h2><h2 id="16-7-注意力机制是不是适用于所有场景呢？它的鲁棒性如何？"><a href="#16-7-注意力机制是不是适用于所有场景呢？它的鲁棒性如何？" class="headerlink" title="16.7 注意力机制是不是适用于所有场景呢？它的鲁棒性如何？"></a>16.7 注意力机制是不是适用于所有场景呢？它的鲁棒性如何？</h2><h2 id="16-8-怎么将原有的模型加上注意力机制呢？"><a href="#16-8-怎么将原有的模型加上注意力机制呢？" class="headerlink" title="16.8 怎么将原有的模型加上注意力机制呢？"></a>16.8 怎么将原有的模型加上注意力机制呢？</h2><h2 id="16-9-通俗地解释一下词法分析是什么？有什么应用场景？"><a href="#16-9-通俗地解释一下词法分析是什么？有什么应用场景？" class="headerlink" title="16.9 通俗地解释一下词法分析是什么？有什么应用场景？"></a>16.9 通俗地解释一下词法分析是什么？有什么应用场景？</h2><h2 id="16-10-深度学习中的词法分析有哪些常见模型呢？"><a href="#16-10-深度学习中的词法分析有哪些常见模型呢？" class="headerlink" title="16.10 深度学习中的词法分析有哪些常见模型呢？"></a>16.10 深度学习中的词法分析有哪些常见模型呢？</h2><h2 id="16-11-通俗地解释一下知识图谱是什么？有什么应用场景？"><a href="#16-11-通俗地解释一下知识图谱是什么？有什么应用场景？" class="headerlink" title="16.11 通俗地解释一下知识图谱是什么？有什么应用场景？"></a>16.11 通俗地解释一下知识图谱是什么？有什么应用场景？</h2><h2 id="16-12-深度学习中的知识图谱有哪些常见模型呢？"><a href="#16-12-深度学习中的知识图谱有哪些常见模型呢？" class="headerlink" title="16.12 深度学习中的知识图谱有哪些常见模型呢？"></a>16.12 深度学习中的知识图谱有哪些常见模型呢？</h2><h2 id="16-13-深度学习中的机器翻译有哪些常见模型呢？"><a href="#16-13-深度学习中的机器翻译有哪些常见模型呢？" class="headerlink" title="16.13 深度学习中的机器翻译有哪些常见模型呢？"></a>16.13 深度学习中的机器翻译有哪些常见模型呢？</h2><h2 id="16-14-机器翻译的通俗实现以及部署过程是怎样的呢？"><a href="#16-14-机器翻译的通俗实现以及部署过程是怎样的呢？" class="headerlink" title="16.14 机器翻译的通俗实现以及部署过程是怎样的呢？"></a>16.14 机器翻译的通俗实现以及部署过程是怎样的呢？</h2><h2 id="16-15-通俗地解释一下文本情感分析是什么？常见的应用场景是？"><a href="#16-15-通俗地解释一下文本情感分析是什么？常见的应用场景是？" class="headerlink" title="16.15 通俗地解释一下文本情感分析是什么？常见的应用场景是？"></a>16.15 通俗地解释一下文本情感分析是什么？常见的应用场景是？</h2><h2 id="16-16-最常用的情感分析模型是什么呢？如何快速部署呢？"><a href="#16-16-最常用的情感分析模型是什么呢？如何快速部署呢？" class="headerlink" title="16.16 最常用的情感分析模型是什么呢？如何快速部署呢？"></a>16.16 最常用的情感分析模型是什么呢？如何快速部署呢？</h2><h2 id="16-17-通俗地解释一下问答系统？它涵盖哪些领域？常见的应用场景是？"><a href="#16-17-通俗地解释一下问答系统？它涵盖哪些领域？常见的应用场景是？" class="headerlink" title="16.17 通俗地解释一下问答系统？它涵盖哪些领域？常见的应用场景是？"></a>16.17 通俗地解释一下问答系统？它涵盖哪些领域？常见的应用场景是？</h2><h2 id="16-18-常见的问答系统模型是什么？如何快速部署呢？"><a href="#16-18-常见的问答系统模型是什么？如何快速部署呢？" class="headerlink" title="16.18 常见的问答系统模型是什么？如何快速部署呢？"></a>16.18 常见的问答系统模型是什么？如何快速部署呢？</h2><h2 id="16-19-图像文字生成是什么？它的技术原理是什么？"><a href="#16-19-图像文字生成是什么？它的技术原理是什么？" class="headerlink" title="16.19 图像文字生成是什么？它的技术原理是什么？"></a>16.19 图像文字生成是什么？它的技术原理是什么？</h2><h2 id="16-20-常见的图像文字生成模型是什么？"><a href="#16-20-常见的图像文字生成模型是什么？" class="headerlink" title="16.20 常见的图像文字生成模型是什么？"></a>16.20 常见的图像文字生成模型是什么？</h2><h2 id="16-21-NLP-的无监督学习发展动态是怎样的？有哪些领域在尝试无监督学习？"><a href="#16-21-NLP-的无监督学习发展动态是怎样的？有哪些领域在尝试无监督学习？" class="headerlink" title="16.21 NLP 的无监督学习发展动态是怎样的？有哪些领域在尝试无监督学习？"></a>16.21 NLP 的无监督学习发展动态是怎样的？有哪些领域在尝试无监督学习？</h2><h2 id="16-22-NLP-和强化学习的结合方式是怎样的？有哪些方向在尝试强化学习？"><a href="#16-22-NLP-和强化学习的结合方式是怎样的？有哪些方向在尝试强化学习？" class="headerlink" title="16.22 NLP 和强化学习的结合方式是怎样的？有哪些方向在尝试强化学习？"></a>16.22 NLP 和强化学习的结合方式是怎样的？有哪些方向在尝试强化学习？</h2><h2 id="16-23-NLP-和元学习？元学习如何能够和-NLP-结合起来？"><a href="#16-23-NLP-和元学习？元学习如何能够和-NLP-结合起来？" class="headerlink" title="16.23 NLP 和元学习？元学习如何能够和 NLP 结合起来？"></a>16.23 NLP 和元学习？元学习如何能够和 NLP 结合起来？</h2><h2 id="16-24-能说一下各自领域最常用且常见的基准模型有哪些吗？"><a href="#16-24-能说一下各自领域最常用且常见的基准模型有哪些吗？" class="headerlink" title="16.24 能说一下各自领域最常用且常见的基准模型有哪些吗？"></a>16.24 能说一下各自领域最常用且常见的基准模型有哪些吗？</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://leesen998.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习基础" scheme="https://leesen998.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>异构计算， GPU和框架选型指南</title>
    <link href="https://leesen998.github.io/2017/12/20/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0_%E5%BC%82%E6%9E%84%E8%BF%90%E7%AE%97%E3%80%81GPU%E5%8F%8A%E6%A1%86%E6%9E%B6%E9%80%89%E5%9E%8B/"/>
    <id>https://leesen998.github.io/2017/12/20/第十五章_异构运算、GPU及框架选型/</id>
    <published>2017-12-20T11:48:29.000Z</published>
    <updated>2019-03-22T07:36:35.532Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg" alt="" style="width:100%"></p><a id="more"></a><p>深度学习训练和推理的过程中，会涉及到大量的向量(vector)，矩阵(matrix)和张量(tensor)操作，通常需要大量的浮点计算，包括高精度（在训练的时候）和低精度（在推理和部署的时候）。GPU， 作为一种通用可编程的加速器，最初设计是用来进行图形处理和渲染功能，但是从2007年开始，英伟达(NVIDIA)公司提出了第一个可编程通用计算平台（GPGPU），同时提出了CUDA框架，从此开启了GPU用于通用计算的新纪元。此后，不计其数的科研人员和开发者，对各种不同类型的算法用CUDA进行（部分）改写，从而达到几倍到数百倍的加速效果。尤其是在机器学习，特别是深度学习的浪潮来临后，GPU加速已经是各类工具实现的基本底层构架之一。本章里，会简单介绍GPU的基本架构，性能指标，框架选择等等和深度学习相关的内容。</p><h2 id="15-1-什么是异构计算？"><a href="#15-1-什么是异构计算？" class="headerlink" title="15.1 什么是异构计算？"></a>15.1 什么是异构计算？</h2><p>异构计算是基于一个更加朴素的概念，”异构现象“，也就是不同计算平台之间，由于硬件结构（包括计算核心和内存），指令集和底层软件实现等方面的不同而有着不同的特性。异构计算就是使用结合了两个或者多个不同的计算平台，并进行协同运算。比如，比较常见的，在深度学习和机器学习中已经比较成熟的架构：CPU和GPU的异构计算;此外还有比较新的Google推出的协处理器（TPU），根据目的而定制的ASIC，可编程的FPGA等也都是现在在异构计算中使用比较多的协处理器。而，本章中会着重介绍和深度学习共同繁荣的图形加算器，也就是常说的GPU。</p><h2 id="15-2-什么是GPGPU？"><a href="#15-2-什么是GPGPU？" class="headerlink" title="15.2 什么是GPGPU？"></a>15.2 什么是GPGPU？</h2><p>GPU,就如名字所包含的内容，原本开发的目的是为了进行计算机图形渲染，而减少对于CPU的负载。由于图像的原始特性，也就是像素间的独立性，所以GPU在设计的时候就遵从了“单指令流多数据流（SIMD）”架构，使得同一个指令（比如图像的某种变换），可以同时在多一个像素点上进行计算，从而得到比较大的吞吐量，才能使得计算机可以实时渲染比较复杂的2D/3D场景。在最初的应用场景里，GPU并不是作为一种通用计算平台出现的，直到2007年左右，一家伟大的公司—NVIDIA将GPU带到通用计算的世界里，使得其可以在相对比较友好的编程环境（CUDA/OpenCL）里加速通用程序成了可能。从此之后，GPU通用计算(General Purpose Computing on GPU)，也就是GPGPU就成了学界和工业界都频繁使用的技术，在深度学习爆发的年代里，GPGPU成了推动这股浪潮非常重要的力量。</p><h2 id="15-3-GPU架构简介"><a href="#15-3-GPU架构简介" class="headerlink" title="15.3 GPU架构简介"></a>15.3 GPU架构简介</h2><p>GPU，图形显示芯片作为不同于CPU的设计逻辑和应用场景，有着非常不同的架构，理解 GPU 和 CPU 之间区别的一种简单方式是比较它们如何处理任务。CPU 由专为顺序串行处理而优化的几个核心组成，而 GPU 则拥有一个由数以千计的更小、更高效的核心（专为同时处理多重任务而设计）组成的大规模并行计算架构。本部分将简单介绍GPU究竟是如何架构，其中的计算核心有哪些特性。</p><h3 id="15-3-1-如何通俗理解GPU的架构？"><a href="#15-3-1-如何通俗理解GPU的架构？" class="headerlink" title="15.3.1 如何通俗理解GPU的架构？"></a>15.3.1 如何通俗理解GPU的架构？</h3><p>首先，下图简单地展示了几个GPU不同于CPU的特性：</p><ul><li>计算核心： 图中的CPU,i7-5960X，Intel的第五代Broadwell架构，其中包括了8个CPU核心(支持16线程)，也就是理论上可以有16个不同的运算同时进行。除了8个核心计算单元，大部分的芯片面积是被3级缓存，内存和控制电路占据了。同样的，来自NVIDIA的GTX980GPU，在差不多的芯片面积上，大部分是计算单元，16个SM，也就是流处理单元，每个流处理单元中包含着128个CUDA计算核心，所以总共来说，有2048个GPU运算单元，相应地这颗GPU理论上可以在一个时钟周期内可以进行2048次单精度运算。</li></ul><p><img src="/2017/12/20/第十五章_异构运算、GPU及框架选型/img/ch15/cpu_gpu.png" alt="CPU和GPU的简单架构对比图"></p><ul><li>计算核心频率：时钟频率，代表每一秒中内能进行同步脉冲次数，也是从一个侧面反映一个计算元件的工作速度。下图中对比了个别早期产品，比如Intel的X5650和几款NVIDIA的GPU。可以看出核心频率而言，CPU要远高于GPU。对于CPU而言，在不考虑能源消耗和制程工艺限制的情况下，追求更高的主频。但在GPU的设计中，采用了多核心设计，即使是提高一些频率，其实对于总体性能影像不会特别大。当然，其中还有能耗方面的考虑，避免发热过高，也进行了权衡。还有一个可能的原因是，在一个流处理器中的每个核心（CUDA核心）的运行共享非常有限的缓存和寄存器，由于共享内存也是有性能极限的，所以即使每个GPU核心频率提高，如果被缓存等拖累也是无法展现出高性能的。</li></ul><p><img src="/2017/12/20/第十五章_异构运算、GPU及框架选型/img/ch15/cpu_specs.png" alt="CPU简单信息"></p><p><img src="/2017/12/20/第十五章_异构运算、GPU及框架选型/img/ch15/gpu_specs.png" alt="GPU的简单信息对比"></p><ul><li>内存架构：GPU的多层内存架构包括全局内存（也就是通常意义上大部分比较关注的内存，在若干到16GB之间，截至到当前最新），2级缓存，和芯片上的存储（包括寄存器，和1级缓存共用的共享内存，只读/纹理缓存和常量缓存）。通常来说，最高速的共享内存/缓存和寄存器都是非常有限的，比如在Tesla的K20中，只有48K的缓存可以作为共享内存或者1级缓存使用，所以在很多用GPU加速算法实现的过程中，有效地利用这些高速缓存是使得性能提升的非常重要的方面。</li></ul><p><img src="/2017/12/20/第十五章_异构运算、GPU及框架选型/img/ch15/gpu_memory_arch.png" alt="GPU的简单信息对比"></p><p><img src="/2017/12/20/第十五章_异构运算、GPU及框架选型/img/ch15/gpu_memory.png" alt="GPU的内存架构容量信息"></p><h3 id="15-3-2-CUDA-核心是什么？"><a href="#15-3-2-CUDA-核心是什么？" class="headerlink" title="15.3.2 CUDA 核心是什么？"></a>15.3.2 CUDA 核心是什么？</h3><p>上面提到在一个GPU芯片里，会很几千个CUDA核心，被分布在多个流处理单元（SM）中，比如上面提到早期的GTX980中的16个SM中各包含了128个CUDA核心。如下图所示，作为GPU架构中的最小单元，其实它的设计和CPU有着非常类似的结构，其中包括了一个浮点运算单元和整型运算单元，和控制单元。同一个流处理器中，所有的CUDA核心将同步执行同一个指令，但是作用于不同的数据点上。</p><p><img src="/2017/12/20/第十五章_异构运算、GPU及框架选型/img/ch15/cudacore.jpg" alt="CUDA简单介绍"></p><p>一般来说，更加多的CUDA核心意味着有更多的并行执行单元，所以也就可以片面地认为是有更加高的性能。但是，其实这个也是取决于很多方面，最重要的是算法在并行实现的时候有没有高效地调度和内存的使用优化。在现在我们使用的大部分GPU加速的深度学习框架里，包括Tensorflow，PyTorch等都是依赖于底层的GPU的矩阵加速代码的实现。为此Nvidia公司也是制定和实现了统一的接口，比如cuDNN，方便上层框架更好的利用GPU的性能。</p><h3 id="15-3-3-为什么要使用GPU？"><a href="#15-3-3-为什么要使用GPU？" class="headerlink" title="15.3.3 为什么要使用GPU？"></a>15.3.3 为什么要使用GPU？</h3><p>对于并行计算来说，可以非常粗略地分为：</p><ul><li>并行指令： 也就是多个指令可以同时分配到不同的计算核心上同时进行，而他们的操作是不同的，并且他们之间相互独立，不需要额外的同步和信息共享。</li><li>并行数据流： 如果数据本身存在的天然的独立性，比如图像中的每一个像素，那么在对这个图像做处理的过程中，同一个指令可以同时作用于每一个像素。在这种情况下，这个对于完整图像的操作可以并行化。理论上，如果内存不是问题，并且计算单元的数量大于整个图像中总像素点的话，这个操作可以在一个时钟周期内完成。</li></ul><p>GPU整体的架构而言，某种意义上是同时支持以上两种并行模式。在同一个流处理器中，采用了“单一指令并行数据流的模式”，而在多个流处理器中，同一时间可以派发不同的指令。从这一点出发，GPU芯片算是一个非常灵活的架构。一个芯片中，流处理器的个数和其中包含的CUDA核心的数量也是一种面向应用设计时候找到的一个平衡点。</p><p>基于深度学习中大部分的操作的天然并行性（大量的矩阵操作），GPU在当下还是一种非常适合的计算平台。一个非常典型的例子就是常见的矩阵相乘（如下图），要计算Z = X×Y，通过并行计算，X和Y中的行向量和列向量的逐元素相乘就可以同时进行，只要得到结果后再进行累加，而且累加的过程中也是可以进行并行化，使得效率有非常大的提高。Nvidia也是制定和开发了一套底层类库，CUBlas方便开发者。我们熟悉的几大框架(e.g. Tensorflow, PyTorch等)也是遵循和使用了这些并行类库，所以才使得训练和部署性能有了非常多的提高。</p><p><img src="/2017/12/20/第十五章_异构运算、GPU及框架选型/img/ch15/mat_mul_gpu.png" alt="CUDA 矩阵乘法示例"></p><h3 id="15-3-4-深度学习中的GPU应用"><a href="#15-3-4-深度学习中的GPU应用" class="headerlink" title="15.3.4 深度学习中的GPU应用"></a>15.3.4 深度学习中的GPU应用</h3><p>深度学习在最近几年内出现的井喷现象背后也是GPU的存在和发展作为坚实的推动力量。</p><p>哪些场景使用GPU<br>在涉及大型矩阵运算的时候使用GPU可以显著加速处理速度，由于GPU架构的独特设计，针对矩阵运算可以实现高速并行计算，极大提高计算速度。<br>一般在高性能计算，机器学习，深度学习，图像渲染等等场景中会比较多的使用矩阵运算，使用GPU可以显著加快处理速度。<br>在一般的深度学习训练中，通常来说使用GPU比使用CPU都有10倍以上的速度提升，所以几乎所有深度学习的研究者几乎都是在使用GPU进行训练。</p><p>ImageNet的例子</p><h3 id="15-3-5-新图灵架构里的tensor-core对深度学习有什么作用？"><a href="#15-3-5-新图灵架构里的tensor-core对深度学习有什么作用？" class="headerlink" title="15.3.5 新图灵架构里的tensor core对深度学习有什么作用？"></a>15.3.5 新图灵架构里的tensor core对深度学习有什么作用？</h3><p>我们知道在深度学习中,矩阵-矩阵乘法运算（BLAS GEMM）是神经网络训练和推理的核心，并且矩阵乘法运算占据了所有计算量的大部分，而Tensor core就是为了解决这个问题而推出的，它的出现极大的提高了计算效率，大大加速了深度学习的计算速度，对深度学习的发展具有极大意义。</p><p>Tensor Core是Volta架构最重磅特性，是专门针对Deep Learning应用而设计的专用ASIC单元，实际上是一种矩阵乘累加的计算单元。（矩阵乘累加计算在Deep Learning网络层算法中，比如卷积层、全连接层等是最重要、最耗时的一部分。）Tensor Core可以在一个时钟周期内实现两个4×4矩阵乘法以及与另一个4×4矩阵加法。整个计算的个数，就是在一个时钟周期内可以实现64次乘和64次加。</p><p>所以Tensor Core就是为了矩阵乘法的加速而设计的，使用具有Tensor Core的GPU来进行深度学习的训练会极大的提高训练速度。</p><h2 id="15-4-CUDA-框架"><a href="#15-4-CUDA-框架" class="headerlink" title="15.4 CUDA 框架"></a>15.4 CUDA 框架</h2><h3 id="15-4-1-做CUDA编程难不难？"><a href="#15-4-1-做CUDA编程难不难？" class="headerlink" title="15.4.1 做CUDA编程难不难？"></a>15.4.1 做CUDA编程难不难？</h3><h3 id="15-4-2-cuDNN"><a href="#15-4-2-cuDNN" class="headerlink" title="15.4.2 cuDNN"></a>15.4.2 cuDNN</h3><h2 id="15-5-GPU硬件环境配置推荐"><a href="#15-5-GPU硬件环境配置推荐" class="headerlink" title="15.5 GPU硬件环境配置推荐"></a>15.5 GPU硬件环境配置推荐</h2><h3 id="15-5-1-GPU主要性能指标"><a href="#15-5-1-GPU主要性能指标" class="headerlink" title="15.5.1 GPU主要性能指标"></a>15.5.1 GPU主要性能指标</h3><p>GPU的性能主要由以下三个参数构成：</p><ol><li>计算能力。通常我们关心的是32位浮点计算能力。16位浮点训练也开始流行，如果只做预测的话也可以用8位整数。</li><li>显存大小。当模型越大，或者训练时的批量越大时，所需要的GPU显存就越多。</li><li>显存带宽。只有当显存带宽足够时才能充分发挥计算能力。</li></ol><p>对于大部分用户来说，只要考虑计算能力就可以了。GPU显存尽量不小于4GB。但如果GPU要同时显示图形界面，那么推荐的显存大小至少为6GB。显存带宽通常相对固定，选择空间较小。</p><p>下图描绘了GTX 900和1000系列里各个型号的32位浮点计算能力和价格的对比。其中价格为Wikipedia的建议价格。</p><p><img src="/2017/12/20/第十五章_异构运算、GPU及框架选型/img/ch15/gtx.png" alt="浮点计算能力和价格的对比。"></p><p>我们可以从图中读出两点信息：</p><ol><li>在同一个系列里面，价格和性能大体上成正比。但后发布的型号性价比更高，例如980 Ti和1080 Ti。</li><li>GTX 1000系列比900系列在性价比上高出2倍左右。</li></ol><p>如果大家继续比较GTX较早的系列，也可以发现类似的规律。据此，我们推荐大家在能力范围内尽可能买较新的GPU。</p><h3 id="15-5-2-购买建议"><a href="#15-5-2-购买建议" class="headerlink" title="15.5.2 购买建议"></a>15.5.2 购买建议</h3><h5 id="首先给出一些总体的建议"><a href="#首先给出一些总体的建议" class="headerlink" title="首先给出一些总体的建议"></a>首先给出一些总体的建议</h5><p>最好的GPU整体（小幅度）：Titan Xp<br>综合性价比高，但略贵：GTX 1080 Ti，GTX 1070，GTX 1080<br>性价比还不错且便宜：GTX 1060（6GB）</p><p>当使用数据集&gt; 250GB：GTX Titan X（Maxwell） ，NVIDIA Titan X Pascal或NVIDIA Titan Xp</p><p>没有足够的钱：GTX 1060（6GB）</p><p>几乎没有钱，入门级：GTX 1050 Ti（4GB）</p><p>做Kaggle比赛：GTX 1060（6GB）适用于任何“正常”比赛，或GTX 1080 Ti用于“深度学习竞赛”</p><p>计算机视觉研究员：NVIDIA Titan Xp；不要买现在新出的Titan X（Pascal或Maxwell）</p><p>一名研究员人员：GTX 1080 Ti。在某些情况下，如自然语言处理，一个GTX 1070或GTX 1080已经足够了-检查你现在模型的内存需求</p><p>搭建一个GPU集群：这个有点复杂，另做探讨。</p><p>刚开始进行深度学习研究：从GTX 1060（6GB）开始。根据你下一步兴趣（入门，Kaggle比赛，研究，应用深度学习）等等，在进行选择。目前，GTX 1060更合适。</p><p>想尝试下深度学习，但没有过多要求：GTX 1050 Ti（4或2GB）</p><p>目前独立GPU主要有AMD和NVIDIA两家厂商。其中NVIDIA在深度学习布局较早，对深度学习框架支持更好。因此，目前大家主要会选择NVIDIA的GPU。</p><p>NVIDIA有面向个人用户（例如GTX系列）和企业用户（例如Tesla系列）的两类GPU。这两类GPU的计算能力相当。然而，面向企业用户的GPU通常使用被动散热并增加了内存校验，从而更适合数据中心，并通常要比面向个人用户的GPU贵上10倍。</p><p>如果你是拥有100台机器以上的大公司用户，通常可以考虑针对企业用户的NVIDIA Tesla系列。如果你是拥有10到100台机器的实验室和中小公司用户，预算充足的情况下可以考虑NVIDIA DGX系列，否则可以考虑购买如Supermicro之类的性价比比较高的服务器，然后再购买安装GTX系列的GPU。</p><p>NVIDIA一般每一两年发布一次新版本的GPU，例如2016年发布的是GTX 1000系列。每个系列中会有数个不同的型号，分别对应不同的性能。</p><h2 id="15-6-软件环境搭建"><a href="#15-6-软件环境搭建" class="headerlink" title="15.6 软件环境搭建"></a>15.6 软件环境搭建</h2><p>深度学习其实就是指基于一套完整的软件系统来构建算法，训练模型。如何搭建一套完整的软件系统，比如操作系统的选择？安装环境中遇到的问题等等，本节做一个简单的总结。</p><h3 id="15-6-1-操作系统选择？"><a href="#15-6-1-操作系统选择？" class="headerlink" title="15.6.1 操作系统选择？"></a>15.6.1 操作系统选择？</h3><p>针对硬件厂商来说，比如NVIDIA，对各个操作系统的支持都是比较好的 ，比如Windows系列,Linux系列，但是由于Linux系统对专业技术人员比较友好，所以目前几乎所有的深度学习系统构建都是基于Linux的，比较常用的系统如Ubuntu系列，CentOS系列等等。<br>在构建系统的时候，如何选择合适的操作系是一个刚刚入门深度学习的工作者面临的问题，在这里给出几点建议：<br>（1）刚刚入门，熟悉Windows系统，但是对Linux和深度学习都不太熟，这个时候可以基于windows系列系统来做入门学习<br>（2）简单了解Linux的使用，不太懂深度学习相关知识，可以直接基于Linux系统来搭建框架，跑一些开源的项目，慢慢深入研究学习<br>（3）熟悉Linux，不熟悉深度学习理论，毫无疑问，强烈推荐使用Linux系统，安装软件简单，工作效率高<br>总之一句话，如果不熟悉Linux，就先慢慢熟悉，最终还是要回归到Linux系统来构建深度学习系统</p><h3 id="15-6-2-常用基础软件安装？"><a href="#15-6-2-常用基础软件安装？" class="headerlink" title="15.6.2 常用基础软件安装？"></a>15.6.2 常用基础软件安装？</h3><p>目前有众多深度学习框架可供大家使用，但是所有框架基本都有一个共同的特点，目前几乎都是基于Nvidia的GPU来训练模型，要想更好的使用NVIDIA的GPU，cuda和cudnn就是必备的软件安装。  </p><ol><li><p><strong>安装cuda</strong><br>上文中有关于cuda的介绍，这里只是简单介绍基于Linux系统安装cuda的具体步骤，可以根据自己的需要安装cuda8.0或者cuda9.0，这两种版本的安装步骤基本一致，这里以最常用的ubuntu 16.04 lts版本为例：  </p><ol><li><p>官网下载，地址<br>cuda8.0<a href="https://developer.nvidia.com/cuda-80-ga2-download-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-80-ga2-download-archive</a><br>cuda9.0<a href="https://developer.nvidia.com/cuda-90-download-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-90-download-archive</a><br>进入网址之后选择对应的系统版本即可，如下图所示：<br><img src="/2017/12/20/第十五章_异构运算、GPU及框架选型/img/ch15/cuda8.0.png" alt="cuda8.0"></p><p><img src="/2017/12/20/第十五章_异构运算、GPU及框架选型/img/ch15/cuda9.0.png" alt="cuda9.0">  </p></li><li><p>命令行中进入到cuda所在的位置，授予运行权限：<br>cuda8.0: sudo chmod +x cuda_8.0.61_375.26_linux.run<br>cuda9.0:sudo chmod +x cuda_9.0.176_384.81_linux.run</p></li><li><p>执行命令安装cuda：<br>cuda8.0:sudo sh cuda_8.0.61_375.26_linux.run<br>cuda9.0:sudo sh cuda_9.0.176_384.81_linux.run<br>之后命令之后下面就是安装步骤，cuda8.0和cuda9.0几乎一致：  </p><ul><li><p>首先出现cuda软件的版权说明，可以直接按q键跳过阅读  </p></li><li><p>Do you accept the previously read EULA?<br>​accept/decline/quit: <strong>accept</strong></p></li><li><p>Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 384.81?<br>​(y)es/(n)o/(q)uit:<strong>no</strong></p></li><li><p>Install the CUDA 9.0 Toolkit?<br>​(y)es/(n)o/(q)uit:<strong>yes</strong></p></li><li><p>Enter Toolkit Location<br>​ [ default is /usr/local/cuda-9.0 ]:直接按enter键即可</p></li><li><p>Do you want to install a symbolic link at /usr/local/cuda?<br>​(y)es/(n)o/(q)uit:<strong>yes</strong></p></li><li><p>Install the CUDA 9.0 Samples?<br>​ (y)es/(n)o/(q)uit:<strong>yes</strong></p></li></ul><p>以上步骤基本就是cuda的安装步骤。</p></li></ol></li><li><p><strong>安装cudnn</strong><br>cudnn是Nvidia的专门针对深度学习的加速库。。。</p></li></ol><h3 id="15-6-3-本机安装还是使用docker？"><a href="#15-6-3-本机安装还是使用docker？" class="headerlink" title="15.6.3 本机安装还是使用docker？"></a>15.6.3 本机安装还是使用docker？</h3><h3 id="15-6-4-GPU驱动问题"><a href="#15-6-4-GPU驱动问题" class="headerlink" title="15.6.4 GPU驱动问题"></a>15.6.4 GPU驱动问题</h3><h2 id="15-7-框架选择"><a href="#15-7-框架选择" class="headerlink" title="15.7 框架选择"></a>15.7 框架选择</h2><h3 id="15-7-1-主流框架比较"><a href="#15-7-1-主流框架比较" class="headerlink" title="15.7.1 主流框架比较"></a>15.7.1 主流框架比较</h3><p>（一个大表格比较）</p><h3 id="15-7-2-框架详细信息"><a href="#15-7-2-框架详细信息" class="headerlink" title="15.7.2 框架详细信息"></a>15.7.2 框架详细信息</h3><ul><li>Tensorflow<br>Tensorflow是Google于2015年开源的基于数据流编程的深度学习框架，得益于Google强大的技术实力和品牌背书，目前Tensorflow发展迅猛，其用户量远远超过其它框架用户。<br>优点：  <ol><li>由谷歌开发、维护，因此可以保障支持、开发的持续性</li><li>巨大、活跃的社区</li><li>网络训练的低级、高级接口</li><li>「TensorBoard」是一款强大的可视化套件，旨在跟踪网络拓扑和性能，使调试更加简单</li><li>TensorFlow 不仅支持深度学习，还有支持强化学习和其他算法的工具<br>缺点：  </li><li>计算图是纯 Python 的，因此速度较慢</li><li>图构造是静态的，意味着图必须先被「编译」再运行</li></ol></li></ul><ul><li>PyTorch<br>pytorch是Facebook于2017年才推出的深度学习框架，相对于其它框架，算是比较晚的了，但是这个同时也是优势，在设计的时候就会避免很多之前框架的问题，所以一经推出，就收到大家极大的欢迎<br>优点：  <ol><li>接口简洁且规范，文档齐全，和python无缝结合，</li><li>社区非常活跃，开源实现较多</li><li>提供动态计算图（意味着图是在运行时生成的），允许你处理可变长度的输入和输出，例如，在使用 RNN 时非常有用</li><li>易于编写自己的图层类型，易于在 GPU 上运行</li><li>「TensorBoard」缺少一些关键功能时，「Losswise」可以作为 Pytorch 的替代品</li></ol></li></ul><p>缺点:  </p><ol><li>模型部署相对其它框架稍有劣势，不过后续的pytorch1.0版本应该会有很大改善，和caffe2合并后，caffe2的优秀的模型部署能力可以弥补这个不足</li><li></li><li></li></ol><p>相关资源链接：  </p><ol><li>官网教程：<a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener">https://pytorch.org/tutorials/</a></li><li>基于pytorch的开源项目汇总：<a href="https://github.com/bharathgs/Awesome-pytorch-list" target="_blank" rel="noopener">https://github.com/bharathgs/Awesome-pytorch-list</a><br>3.</li></ol><ul><li>Keras<br>Keras 是一个更高级、对用户最友好的 API，具有可配置的后端，由 Google Brain 团队成员 Francis Chollet 编写和维护<br>优点：  <ol><li>提供高级 API 来构建深度学习模型，使其易于阅读和使用 </li><li>编写规范的文档</li><li>大型、活跃的社区</li><li>位于其他深度学习库（如 Theano 和 TensorFlow，可配置）之上</li><li>使用面向对象的设计，因此所有内容都被视为对象（如网络层、参数、优化器等）。所有模型参数都可以作为对象属性进行访问<br>缺点：  </li><li>由于用途非常普遍，所以在性能方面比较欠缺</li><li>与 TensorFlow 后端配合使用时会出现性能问题（因为并未针对其进行优化），但与 Theano 后端配合使用时效果良好</li><li>不像 TensorFlow 或 PyTorch 那样灵活</li></ol></li></ul><ul><li><p>Sonnet</p></li><li><p>Caffe<br>caffe是第一个主流产品级深度学习库，于 2014 年由 UC Berkeley 发布开源<br>优点：  </p><ol><li>简单网络结构无需编写代码，可快速实现</li><li>漂亮的 Matlab 和 Python 接口</li><li>完全由c++编程实现，部署方便</li></ol></li></ul><p>缺点：  </p><ol><li>不灵活。在 Caffe 中，每个节点被当做一个层，因此如果你想要一种新的层类型，你需要定义完整的前向、后向和梯度更新过程。这些层是网络的构建模块，你需要在无穷无尽的列表中进行选择。（相反，在 TensorFlow 中，每个节点被当做一个张量运算例如矩阵相加、相乘或卷积。你可以轻易地定义一个层作为这些运算的组合。因此 TensorFlow 的构建模块更小巧，允许更灵活的模块化。）</li><li>需要大量的非必要冗长代码。如果你希望同时支持 CPU 和 GPU，你需要为每一个实现额外的函数。你还需要使用普通的文本编辑器来定义你的模型。真令人头疼！几乎每个人都希望程序化地定义模型，因为这有利于不同组件之间的模块化。有趣的是，Caffe 的主要架构师现在在 TensorFlow 团队工作</li><li>专一性。仅定位在计算机视觉（但做得很不错）  </li><li>不是以 Python 编写！如果你希望引入新的变动，你需要在 C++和 CUDA 上编程（对于更小的变动，你可以使用它的 Python 和 Matlab 接口）</li><li>糟糕的文档</li><li>安装比较困难！有大量的依赖包</li></ol><ul><li>Caffe2</li></ul><ul><li>MxNet<br>MxNet是dmlc社区推出的深度学习框架，MXNet由学术界发起，包括数个顶尖大学的多个学科的研究人员的贡献，在2017年被亚马逊指定为官方框架。<br>mxnet的最知名的优点就是其对多GPU的支持和扩展性强，其优秀的性能使之在工业界占有一席之地，在amazon支持之后，其文档和开发进度明显好很多。除了高可扩展性，MXNet 还提供混合编程模型（命令式和声明式），同时兼容多种编程语言（包括 Python、C ++、R、Scala、Julia、Matlab 和 JavaScript）的代码，目前主要在推python高层接口gluon</li></ul><p>优点：  </p><ol><li>多GPU支持好，扩展性强，支持多种编程语言接口，主要是由华人团队开发，中文社区活跃，中文文档资源和课程丰富</li><li>针对两大热门领域推出gluoncv和gluonNLP模块，复现经典论文，达到State-of-the-art，接口设计简单，文档齐全，拿来就可以用<br>缺点:  </li><li>现在mxnet官方社区主要在推gluon接口，接口稍有混乱，坑较多，入手门槛稍高</li><li>偏小众，经典网络和项目的开源实现相对于tensorflow和pytorch还是比较少，很多还是需要自己手动实现<br>相关资源链接：  </li><li>官方教程：<a href="http://mxnet.incubator.apache.org" target="_blank" rel="noopener">http://mxnet.incubator.apache.org</a> 提供有快速入门教程和详细文档说明</li><li>中文教程：<a href="http://zh.gluon.ai/" target="_blank" rel="noopener">http://zh.gluon.ai/</a> 官方的中文教程，此课程有对应的中文版视频，主要由李沐大神讲课</li><li>中文论坛：<a href="https://discuss.gluon.ai/" target="_blank" rel="noopener">https://discuss.gluon.ai/</a> 官方发中文论坛，mxnet的主要作者都在这里，论坛比较活跃，可及时得到作者的回答</li><li>基于mxnet的开源项目实现：<a href="https://github.com/chinakook/Awesome-MXNet这里主要列举了mxnet在各个领域的项目的开源实现" target="_blank" rel="noopener">https://github.com/chinakook/Awesome-MXNet这里主要列举了mxnet在各个领域的项目的开源实现</a></li></ol><ul><li><p>CNTK</p></li><li><p>PaddlePaddle</p></li><li><p>其他国内自主开发开源框架</p></li></ul><h3 id="15-7-3-哪些框架对于部署环境友好？"><a href="#15-7-3-哪些框架对于部署环境友好？" class="headerlink" title="15.7.3 哪些框架对于部署环境友好？"></a>15.7.3 哪些框架对于部署环境友好？</h3><ul><li><p>Tensorflow Serving</p></li><li><p>ONNX 标准</p></li><li><p>TensorRT</p></li><li><p>ONNPACK</p></li><li><p>Clipper</p></li></ul><h3 id="15-7-4-移动平台的框架如何选择？"><a href="#15-7-4-移动平台的框架如何选择？" class="headerlink" title="15.7.4 移动平台的框架如何选择？"></a>15.7.4 移动平台的框架如何选择？</h3><ul><li><p>Tensorflow Lite</p></li><li><p>Caffe2</p></li></ul><h2 id="15-8-其他"><a href="#15-8-其他" class="headerlink" title="15.8 其他"></a>15.8 其他</h2><h3 id="15-8-1-多GPU环境的配置"><a href="#15-8-1-多GPU环境的配置" class="headerlink" title="15.8.1 多GPU环境的配置"></a>15.8.1 多GPU环境的配置</h3><ul><li><p>Tensorflow</p></li><li><p>PyTorch</p></li></ul><h3 id="15-8-2-是不是可以分布式训练？"><a href="#15-8-2-是不是可以分布式训练？" class="headerlink" title="15.8.2 是不是可以分布式训练？"></a>15.8.2 是不是可以分布式训练？</h3><h3 id="15-8-3-可以在SPARK环境里训练或者部署模型吗？"><a href="#15-8-3-可以在SPARK环境里训练或者部署模型吗？" class="headerlink" title="15.8.3 可以在SPARK环境里训练或者部署模型吗？"></a>15.8.3 可以在SPARK环境里训练或者部署模型吗？</h3><h3 id="15-8-4-怎么进一步优化性能？"><a href="#15-8-4-怎么进一步优化性能？" class="headerlink" title="15.8.4 怎么进一步优化性能？"></a>15.8.4 怎么进一步优化性能？</h3><ul><li><p>TVM</p></li><li><p>nGraph</p></li></ul><h3 id="15-8-5-TPU和GPU的区别？"><a href="#15-8-5-TPU和GPU的区别？" class="headerlink" title="15.8.5 TPU和GPU的区别？"></a>15.8.5 TPU和GPU的区别？</h3><h3 id="15-8-6-未来量子计算对于深度学习等AI技术的影响？"><a href="#15-8-6-未来量子计算对于深度学习等AI技术的影响？" class="headerlink" title="15.8.6 未来量子计算对于深度学习等AI技术的影响？"></a>15.8.6 未来量子计算对于深度学习等AI技术的影响？</h3><hr><h2 id="15-1-GPU购买指南"><a href="#15-1-GPU购买指南" class="headerlink" title="15.1 GPU购买指南"></a>15.1 GPU购买指南</h2><p>深度学习训练通常需要大量的计算资源。GPU目前是深度学习最常使用的计算加速硬件。相对于CPU来说，GPU更便宜且计算更加密集。一方面，相同计算能力的GPU的价格一般是CPU价格的十分之一。另一方面，一台服务器通常可以搭载8块或者16块GPU。因此，GPU数量可以看作是衡量一台服务器的深度学习计算能力的一个标准。</p><h3 id="15-1-1-如何选择GPU"><a href="#15-1-1-如何选择GPU" class="headerlink" title="15.1.1 如何选择GPU"></a>15.1.1 如何选择GPU</h3><h3 id="15-1-2-GPU的主要性能指标"><a href="#15-1-2-GPU的主要性能指标" class="headerlink" title="15.1.2 GPU的主要性能指标"></a>15.1.2 GPU的主要性能指标</h3><p>在选择GPU时，首先要考虑的第一个GPU性能问题是什么呢：是否为cuda核心？时钟速度多大？内存大小多少？<br>这些都不是，对于深度学习性能而言，最重要的特征是内存带宽（memory bandwidth）。<br>简而言之：GPU针对内存带宽进行了优化，但同时牺牲了内存访问时间（延迟）。CPU的设计恰恰相反：如果涉及少量内存（例如几个数字相乘（3 <em> 6 </em> 9）），CPU可以快速计算，但是对于大量内存（如矩阵乘法（A <em> B </em> C）则很慢。由于内存带宽的限制，当涉及大量内存的问题时，GPU快速计算的优势往往会受到限制。当然，GPU和CPU之间还有更复杂的区别，关于为何GPU如此适用于处理深度学习问题，另做探讨。</p><p>所以如果你想购买一个快速的GPU，首先要关注的是GPU的带宽（bandwidth）。</p><h3 id="15-1-3-整机配置"><a href="#15-1-3-整机配置" class="headerlink" title="15.1.3 整机配置"></a>15.1.3 整机配置</h3><p>通常，我们主要用GPU做深度学习训练。因此，不需要购买高端的CPU。至于整机配置，尽量参考网上推荐的中高档的配置就好。不过，考虑到GPU的功耗、散热和体积，我们在整机配置上也需要考虑以下三个额外因素。</p><ol><li>机箱体积。GPU尺寸较大，通常考虑较大且自带风扇的机箱。</li><li>电源。购买GPU时需要查一下GPU的功耗，例如50W到300W不等。购买电源要确保功率足够，且不会过载机房的供电。</li><li>主板的PCIe卡槽。推荐使用PCIe 3.0 16x来保证充足的GPU到主内存的带宽。如果搭载多块GPU，要仔细阅读主板说明，以确保多块GPU一起使用时仍然是16x带宽。注意，有些主板搭载4块GPU时会降到8x甚至4x带宽。</li></ol><h3 id="15-1-4-小结"><a href="#15-1-4-小结" class="headerlink" title="15.1.4 小结"></a>15.1.4 小结</h3><ul><li>在预算范围之内，尽可能买较新的GPU。</li><li>整机配置需要考虑到GPU的功耗、散热和体积。</li></ul><h2 id="15-2-框架选型"><a href="#15-2-框架选型" class="headerlink" title="15.2 框架选型"></a>15.2 框架选型</h2><p>目前常用的框架有tensorflow,keras,pytorch,mxnet等等，各个框架的优缺点在此简单介绍：</p><h3 id="15-2-1-常用框架简介"><a href="#15-2-1-常用框架简介" class="headerlink" title="15.2.1 常用框架简介"></a>15.2.1 常用框架简介</h3><p>1，tensorflow：<br>tensorflow由于有google的强大背书，加上其优秀的分布式设计，丰富的教程资源和论坛，工业部署方便，基本很多人都是从tensorflow入门的<br>优点：google的强大背书，分布式训练，教程资源丰富，常见问题基本都可以在互联网中找到解决办法，工业部署方便<br>缺点: 接口混乱，官方文档不够简洁，清晰，</p><p>2，keras:<br>keras是一种高层编程接口，其可以选择不同的后端，比如tensorflow，therao等等<br>优点：接口简洁，上手快，文档好，资源多<br>缺点: 封装的太好了导致不理解其技术细节</p><p>3,pytorch:</p><p>4,caffe2:<br>caffe2是在caffe之后的第二代版本，同属于Facebook。。。<br>优点：支持模型的全平台部署，。。。。<br>缺点:使用人数相对较少，资源较少，和pytorch合并后应该会更受欢迎</p><p>5,mxnet<br>mxnet是dmlc社区推出的深度学习框架，在2017年被亚马逊指定为官方框架<br>优点：支持多种语言，代码设计优秀，省显存，华人团队开发，中文社区活跃，官方复现经典论文推出gluoncv和gluonNLP模块，非常方便，拿来就可以用。<br>缺点:现在mxnet官方社区主要在推gluon接口，接口稍有混乱，坑较多，入手门槛稍高</p><p>6，caffe：<br>目前很多做深度学习比较早的大厂基本都是在用caffe，因为在2013-2015年基本就是caffe的天下，并且caffe的代码设计很优秀，基本所有代码都被翻了很多遍了，被各种分析，大厂基本都是魔改caffe，基于caffe来进行二次开发，所在目前在很多大厂还是在使用caffe<br>优点：资源丰富，代码容易理解，部署方便<br>缺点：入门门槛高，文档较少</p><p>###15.2.1 框架选型总结<br>1，新手入门，首推pytorch，上手快，资源丰富,官方文档写的非常好(<a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener">https://pytorch.org/tutorials/</a>)<br>2，目前工业部署，tensorflow是首选,资源丰富，并且在分布式训练这一块基本一家独大<br>3，mxnet的gluon接口有比较丰富的中文资源（教程：zh.gluon.ai，论坛：discuss.gluon.ai）,gluoncv模块（<a href="https://gluon-cv.mxnet.io）,gluonNLP模块（https://gluon-nlp.mxnet.io）" target="_blank" rel="noopener">https://gluon-cv.mxnet.io）,gluonNLP模块（https://gluon-nlp.mxnet.io）</a></p><p>##15.3 模型部署<br>我们一般都是通过python或者其他语言来编码训练模型，然后基于后端来进行部署<br>一般的框架都有自身的部署框架，比如tensorflow，pytorch，caffe2，mxnet等等<br>有一些框架是专门做推理部署使用的，比如<br>（1）tensorRT</p><p> (2)TVM</p><p> (3)ONNX</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://leesen998.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习基础" scheme="https://leesen998.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式</title>
    <link href="https://leesen998.github.io/2017/12/05/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%EF%BC%88MLE%EF%BC%89%E3%80%81%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E4%BC%B0%E8%AE%A1%EF%BC%88MAP%EF%BC%89%EF%BC%8C%E4%BB%A5%E5%8F%8A%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F/"/>
    <id>https://leesen998.github.io/2017/12/05/最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式/</id>
    <published>2017-12-05T11:48:29.000Z</published>
    <updated>2019-03-22T07:38:52.576Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1544254144/samples/java%20files/photo-1542312455-e31bb150371c.jpg" alt="" style="width:100%"></p><p>最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式</p><a id="more"></a><h2 id="第一部分"><a href="#第一部分" class="headerlink" title="第一部分"></a>第一部分</h2><h3 id="Likelihood-amp-Maximum-likelihood"><a href="#Likelihood-amp-Maximum-likelihood" class="headerlink" title="Likelihood &amp; Maximum likelihood"></a>Likelihood &amp; Maximum likelihood</h3><p>似然与概率<br>在统计学中，似然函数（likelihood function，通常简写为likelihood，似然）是一个非常重要的内容，在非正式场合似然和概率（Probability）几乎是一对同义词，但是在统计学中似然和概率却是两个不同的概念。概率是在特定环境下某件事情发生的可能性，也就是结果没有产生之前依据环境所对应的参数来预测某件事情发生的可能性，比如抛硬币，抛之前我们不知道最后是哪一面朝上，但是根据硬币的性质我们可以推测任何一面朝上的可能性均为50%，这个概率只有在抛硬币之前才是有意义的，抛完硬币后的结果便是确定的；而似然刚好相反，是在确定的结果下去推测产生这个结果的可能环境（参数），还是抛硬币的例子，假设我们随机抛掷一枚硬币1,000次，结果500次人头朝上，500次数字朝上（实际情况一般不会这么理想，这里只是举个例子），我们很容易判断这是一枚标准的硬币，两面朝上的概率均为50%，这个过程就是我们运用出现的结果来判断这个事情本身的性质（参数），也就是似然。</p><p>结果和参数相互对应的时候，似然和概率在数值上是相等的，如果用 θ 表示环境对应的参数，x 表示结果，那么概率可以表示为：P(x|θ)</p><p>p(x|θ) 是条件概率的表示方法，θ 是前置条件，理解为在 θ 的前提下，事件 x 发生的概率，相对应的似然可以表示为：L(θ|x)</p><p>可以理解为已知结果为 x ，参数为 θ (似然函数里 θ 是变量，这里说的参数和变量是相对与概率而言的)对应的概率，即：L(θ|x)=P(x|θ)<br>需要说明的是两者在数值上相等，但是意义并不相同，L 是关于 θ 的函数，而 P 则是关于 x 的函数，两者从不同的角度描述一件事情。</p><h2 id="第二部分"><a href="#第二部分" class="headerlink" title="第二部分"></a>第二部分</h2><p>最大似然估计（Maximum likelihood estimation, 简称MLE）和最大后验概率估计（Maximum a posteriori estimation, 简称MAP）是很常用的两种参数估计方法，如果不理解这两种方法的思路，很容易弄混它们。下文将详细说明MLE和MAP的思路与区别。</p><p>但别急，我们先从概率和统计的区别讲起。</p><h3 id="概率和统计是一个东西吗？"><a href="#概率和统计是一个东西吗？" class="headerlink" title="概率和统计是一个东西吗？"></a>概率和统计是一个东西吗？</h3><p>概率（probabilty）和统计（statistics）看似两个相近的概念，其实研究的问题刚好相反。</p><p>概率研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性（例如均值，方差，协方差等等）。 举个例子，我想研究怎么养猪（模型是猪），我选好了想养的品种、喂养方式、猪棚的设计等等（选择参数），我想知道我养出来的猪大概能有多肥，肉质怎么样（预测结果）。</p><p>统计研究的问题则相反。统计是，有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉（这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等），然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等（推测模型参数）。</p><p>一句话总结：概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。</p><p>显然，本文解释的MLE和MAP都是统计领域的问题。它们都是用来推测参数的方法。为什么会存在着两种不同方法呢？ 这需要理解贝叶斯思想。我们来看看贝叶斯公式。</p><h3 id="贝叶斯公式到底在说什么？"><a href="#贝叶斯公式到底在说什么？" class="headerlink" title="贝叶斯公式到底在说什么？"></a>贝叶斯公式到底在说什么？</h3><p>学习机器学习和模式识别的人一定都听过贝叶斯公式(Bayes’ Theorem)：</p><p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1551412124/samples/java%20files/kjghk.jpg" alt=""></p><p>【式1】贝叶斯公式看起来很简单，无非是倒了倒条件概率和联合概率的公式。</p><p>把B展开，可以写成：</p><p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1551412124/samples/java%20files/hjk.jpg" alt=""><br>【式2】（∼A∼A表示”非A”）</p><p>这个式子就很有意思了。</p><p>想想这个情况。一辆汽车（或者电瓶车）的警报响了，你通常是什么反应？有小偷？撞车了？ 不。。 你通常什么反应都没有。因为汽车警报响一响实在是太正常了！每天都要发生好多次。本来，汽车警报设置的功能是，出现了异常情况，需要人关注。然而，由于虚警实在是太多，人们渐渐不相信警报的功能了。</p><p>贝叶斯公式就是在描述，你有多大把握能相信一件证据？（how much you can trust the evidence）</p><p>我们假设响警报的目的就是想说汽车被砸了。把A计作“汽车被砸了”，B计作“警报响了”，带进贝叶斯公式里看。我们想求等式左边发生A|B的概率，这是在说警报响了，汽车也确实被砸了。汽车被砸引起（trigger）警报响，即B|A。但是，也有可能是汽车被小孩子皮球踢了一下、被行人碰了一下等其他原因（统统计作∼A），其他原因引起汽车警报响了，即B|∼A。那么，现在突然听见警报响了，这时汽车已经被砸了的概率是多少呢（这即是说，警报响这个证据有了，多大把握能相信它确实是在报警说汽车被砸了）？想一想，应当这样来计算。用警报响起、汽车也被砸了这事件的数量，除以响警报事件的数量（这即【式1】）。进一步展开，即警报响起、汽车也被砸了的事件的数量，除以警报响起、汽车被砸了的事件数量加上警报响起、汽车没被砸的事件数量（这即【式2】）。</p><p>可能有点绕，请稍稍想一想。</p><p>再思考【式2】。想让P(A|B)=1，即警报响了，汽车一定被砸了，该怎么做呢？让P(B|∼A)P(∼A)=0即可。很容易想清楚，假若让P(∼A)=0，即杜绝了汽车被球踢、被行人碰到等等其他所有情况，那自然，警报响了，只剩下一种可能——汽车被砸了。这即是提高了响警报这个证据的说服力。</p><p>从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。 老板骂你，不一定是你把什么工作搞砸了，可能只是他今天出门前和太太吵了一架。</p><p>再思考【式2】。观察【式2】右边的分子，P(B|A)为汽车被砸后响警报的概率。姑且仍为这是1吧。但是，若P(A)很小，即汽车被砸的概率本身就很小，则P(B|A)P(A)仍然很小，即【式2】右边分子仍然很小，P(A|B) 还是大不起来。 这里，​P(A)即是常说的先验概率，如果A的先验概率很小，就算P(B|A)较大，可能A的后验概率P(A|B)还是不会大（假设P(B|∼A)P(∼A)不变的情况下）。</p><p>从这个角度思考贝叶斯公式：一个本来就难以发生的事情，就算出现某个证据和他强烈相关，也要谨慎。证据很可能来自别的虽然不是很相关，但发生概率较高的事情。 发现刚才写的代码编译报错，可是我今天状态特别好，这语言我也很熟悉，犯错的概率很低。因此觉得是编译器出错了。 ————别，还是先再检查下自己的代码吧。</p><p>好了好了，说了这么多，下面言归正传，说一说MLE。</p><p>——————不行，还得先说似然函数（likelihood function）</p><h3 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a>似然函数</h3><p>似然（likelihood）这个词其实和概率（probability）是差不多的意思，Colins字典这么解释：The likelihood of something happening is how likely it is to happen. 你把likelihood换成probability，这解释也读得通。但是在统计里面，似然函数和概率函数却是两个不同的概念（其实也很相近就是了）。</p><p>对于这个函数：</p><p>**P(x|θ)<br>输入有两个：x表示某一个具体的数据；θ表示模型的参数。</p><p>如果θ是已知确定的，xx是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少。</p><p>如果x是已知确定的，θ是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现x这个样本点的概率是多少。**</p><p>这有点像“一菜两吃”的意思。其实这样的形式我们以前也不是没遇到过。例如，f(x,y)=x^y, 即x的y次方。如果xx是已知确定的(例如x=2)，这就是f(y)=2^y, 这是指数函数。 如果yy是已知确定的(例如y=2)，这就是f(x)=x^2，这是二次函数。同一个数学形式，从不同的变量角度观察，可以有不同的名字。</p><p>这么说应该清楚了吧？ 如果还没讲清楚，别急，下文会有具体例子。</p><p>现在真要先讲讲MLE了。。</p><h3 id="最大似然估计（MLE）"><a href="#最大似然估计（MLE）" class="headerlink" title="最大似然估计（MLE）"></a>最大似然估计（MLE）</h3><p>假设有一个造币厂生产某种硬币，现在我们拿到了一枚这种硬币，想试试这硬币是不是均匀的。即想知道抛这枚硬币，正反面出现的概率（记为θ）各是多少？</p><p>这是一个统计问题，回想一下，解决统计问题需要什么？ 数据！</p><p>于是我们拿这枚硬币抛了10次，得到的数据（x0）是：反正正正正反正正正反。我们想求的正面概率θθ是模型参数，而抛硬币模型我们可以假设是 二项分布。</p><p>那么，出现实验结果x0（即反正正正正反正正正反）的似然函数是多少呢？</p><p>f(x0,θ)=(1−θ)×θ×θ×θ×θ×(1−θ)×θ×θ×θ×(1−θ)=θ^7(1−θ)^3=f(θ)<br>注意，这是个只关于θ的函数。而最大似然估计，顾名思义，就是要最大化这个函数。我们可以画出f(θ)的图像：</p><p><img src="https://img-blog.csdn.net/20170531003926799?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTUwODY0MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br>可以看出，在θ=0.7时，似然函数取得最大值。</p><p>这样，我们已经完成了对θ的最大似然估计。即，抛10次硬币，发现7次硬币正面向上，最大似然估计认为正面向上的概率是0.7。（ummm..这非常直观合理，对吧？）</p><p>且慢，一些人可能会说，硬币一般都是均匀的啊！ 就算你做实验发现结果是“反正正正正反正正正反”，我也不信θ=0.7。</p><p>这里就包含了贝叶斯学派的思想了——要考虑先验概率。 为此，引入了最大后验概率估计。</p><h3 id="最大后验概率估计"><a href="#最大后验概率估计" class="headerlink" title="最大后验概率估计"></a>最大后验概率估计</h3><p>最大似然估计是求参数θθ, 使似然函数P(x0|θ)最大。最大后验概率估计则是想求θθ使P(x0|θ)P(θ)最大。求得的θ不单单让似然函数大，θ自己出现的先验概率也得大。 （这有点像正则化里加惩罚项的思想，不过正则化里是利用加法，而MAP里是利用乘法）</p><p>MAP其实是在最大化P(θ|x0)=P(x0|θ)P(θ)P(x0)，不过因为x0是确定的（即投出的“反正正正正反正正正反”），P(x0)是一个已知值，所以去掉了分母P(x0)（假设“投10次硬币”是一次实验，实验做了1000次，“反正正正正反正正正反”出现了n次，则P(x0)=n/1000。总之，这是一个可以由数据集得到的值）。最大化P(θ|x0)的意义也很明确，x0已经出现了，要求θ取什么值使P(θ|x0)最大。顺带一提，P(θ|x0)即后验概率，这就是“最大后验概率估计”名字的由来。</p><p>对于投硬币的例子来看，我们认为（”先验地知道“）θ取0.5的概率很大，取其他值的概率小一些。我们用一个高斯分布来具体描述我们掌握的这个先验知识，例如假设P(θ)为均值0.5，方差0.1的高斯函数，如下图：<br><img src="https://img-blog.csdn.net/20170531004009269?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTUwODY0MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br>则P(x0|θ)P(θ)的函数图像为：<br><img src="https://img-blog.csdn.net/20170531003829147?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTUwODY0MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p><p>注意，此时函数取最大值时，θ取值已向左偏移，不再是0.7。实际上，在θ=0.558时函数取得了最大值。即，用最大后验概率估计，得到θ=0.558<br>最后，那要怎样才能说服一个贝叶斯派相信θ=0.7呢？你得多做点实验。。</p><p>如果做了1000次实验，其中700次都是正面向上，这时似然函数为:<br><img src="https://img-blog.csdn.net/20170530235524800?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTUwODY0MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br>如果仍然假设P(θ)为均值0.5，方差0.1的高斯函数，P(x0|θ)P(θ)的函数图像为：<br><img src="https://img-blog.csdn.net/20170531003953909?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTUwODY0MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br>在θ=0.696处，P(x0|θ)P(θ)取得最大值。</p><p>这样，就算一个考虑了先验概率的贝叶斯派，也不得不承认得把θ估计在0.7附近了。</p><p>PS. <strong>要是遇上了顽固的贝叶斯派，认为P(θ=0.5)=1 ，那就没得玩了。。 无论怎么做实验，使用MAP估计出来都是θ=0.5。这也说明，一个合理的先验概率假设是很重要的。（通常，先验概率能从数据中直接分析得到）</strong></p><p>最大似然估计和最大后验概率估计的区别<br>相信读完上文，MLE和MAP的区别应该是很清楚的了。MAP就是多个作为因子的先验概率P(θ)。或者，也可以反过来，认为MLE是把先验概率P(θ)认为等于1，即认为θ是均匀分布。</p>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1544254144/samples/java%20files/photo-1542312455-e31bb150371c.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;p&gt;最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://leesen998.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习基础" scheme="https://leesen998.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>深度学习 超参数调整</title>
    <link href="https://leesen998.github.io/2017/11/24/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0_%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E6%95%B4/"/>
    <id>https://leesen998.github.io/2017/11/24/第十四章_超参数调整/</id>
    <published>2017-11-24T11:48:29.000Z</published>
    <updated>2019-03-22T07:40:02.285Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg" alt="" style="width:100%"></p><a id="more"></a><blockquote><p>Markdown Revision 1;<br>Editor: 乔成磊-同济大学，王超锋<br>Contact: <a href="mailto:qchl0318@163.com" target="_blank" rel="noopener">qchl0318@163.com</a>，<a href="mailto:syusuke0516@163.com" target="_blank" rel="noopener">syusuke0516@163.com</a><br>Updater: <a href="https://github.com/sjsdfg" target="_blank" rel="noopener">sjsdfg</a>，王超锋</p></blockquote><h2 id="14-1-写在前面"><a href="#14-1-写在前面" class="headerlink" title="14.1 写在前面"></a>14.1 写在前面</h2><p>　　关于训练深度学习模型最难的事情之一是你要处理的参数的数量。无论是从网络本身的层宽（宽度）、层数（深度）、连接方式，还是损失函数的超参数设计和调试，亦或者是学习率、批样本数量、优化器参数等等。这些大量的参数都会有网络模型最终的有效容限直接或者间接的影响。面对如此众多的参数，如果我们要一一对其优化调整，所需的无论是时间、资源都是不切实际。结果证实一些超参数比其它的更为重要，因此认识各个超参数的作用和其可能会造成的影响是深度学习训练中必不可少的一项重要技能。</p><p>​    目前，超参数调整一般分为手动调整和自动优化超参数两种。本章节不会过多阐述所有超参数的详细原理，如果需要了解这部分，您可以翻阅前面的基础章节或者查阅相关文献资料。当然，下面会讲到的一些超参数优化的建议是根据笔者们的实践以及部分文献资料得到认知建议，并不是非常严格且一定有效的，很多研究者可能会很不同意某些的观点或有着不同的直觉，这都是可保留讨论的，因为这很依赖于数据本身情况。</p><h2 id="14-2-超参数概述"><a href="#14-2-超参数概述" class="headerlink" title="14.2 超参数概述"></a>14.2 超参数概述</h2><h3 id="14-2-1-什么是超参数，参数和超参数的区别"><a href="#14-2-1-什么是超参数，参数和超参数的区别" class="headerlink" title="14.2.1 什么是超参数，参数和超参数的区别"></a>14.2.1 什么是超参数，参数和超参数的区别</h3><p>​    区分两者最大的一点就是是否通过数据来进行调整，模型参数通常是有数据来驱动调整，超参数则不需要数据来驱动，而是在训练前或者训练中人为的进行调整的参数。例如卷积核的具体核参数就是指模型参数，这是有数据驱动的。而学习率则是人为来进行调整的超参数。这里需要注意的是，通常情况下卷积核数量、卷积核尺寸这些也是超参数，注意与卷积核的核参数区分。</p><h3 id="14-2-2-神经网络中包含哪些超参数"><a href="#14-2-2-神经网络中包含哪些超参数" class="headerlink" title="14.2.2 神经网络中包含哪些超参数"></a>14.2.2 神经网络中包含哪些超参数</h3><p>　　 通常可以将超参数分为三类：网络参数、优化参数、正则化参数。</p><p>​    网络参数：可指网络层与层之间的交互方式（相加、相乘或者串接等）、卷积核数量和卷积核尺寸、网络层数（也称深度）和激活函数等。</p><p>​    优化参数：一般指学习率（learning rate）、批样本数量（batch size）、不同优化器的参数以及部分损失函数的可调参数。</p><p>​    正则化：权重衰减系数，丢弃法比率（dropout）</p><h3 id="14-2-3-模型优化寻找最优解和正则项之间的关系"><a href="#14-2-3-模型优化寻找最优解和正则项之间的关系" class="headerlink" title="14.2.3 模型优化寻找最优解和正则项之间的关系"></a>14.2.3 模型优化寻找最优解和正则项之间的关系</h3><p>​    网络模型优化调整的目的是为了寻找到全局最优解（或者相比更好的局部最优解），而正则项又希望模型尽量拟合到最优。两者通常情况下，存在一定的对立，但两者的目标是一致的，即最小化期望风险。模型优化希望最小化经验风险，而容易陷入过拟合，正则项用来约束模型复杂度。所以如何平衡两者之间的关系，得到最优或者较优的解就是超参数调整优化的目的。</p><h3 id="14-2-4-超参数的重要性顺序"><a href="#14-2-4-超参数的重要性顺序" class="headerlink" title="14.2.4 超参数的重要性顺序"></a>14.2.4 超参数的重要性顺序</h3><ul><li><p>首先， <strong>学习率，损失函数上的可调参数</strong>。在网络参数、优化参数、正则化参数中最重要的超参数可能就是学习率了。学习率直接控制着训练中网络梯度更新的量级，直接影响着模型的<strong>有效容限能力</strong>；损失函数上的可调参数，这些参数通常情况下需要结合实际的损失函数来调整，大部分情况下这些参数也能很直接的影响到模型的的有效容限能力。这些损失一般可分成三类，第一类辅助损失结合常见的损失函数，起到辅助优化特征表达的作用。例如度量学习中的Center loss，通常结合交叉熵损失伴随一个权重完成一些特定的任务。这种情况下一般建议辅助损失值不高于或者不低于交叉熵损失值的两个数量级；第二类，多任务模型的多个损失函数，每个损失函数之间或独立或相关，用于各自任务，这种情况取决于任务之间本身的相关性，目前笔者并没有一个普适的经验由于提供参考；第三类，独立损失函数，这类损失通常会在特定的任务有显著性的效果。例如RetinaNet中的focal loss，其中的参数γ，α，对最终的效果会产生较大的影响。这类损失通常论文中会给出特定的建议值。</p></li><li><p>其次，<strong>批样本数量，动量优化器（Gradient Descent with Momentum）的动量参数<em>β</em></strong>。批样本决定了数量梯度下降的方向。过小的批数量，极端情况下，例如batch size为1，即每个样本都去修正一次梯度方向，样本之间的差异越大越难以收敛。若网络中存在批归一化（batchnorm），batch size过小则更难以收敛，甚至垮掉。这是因为数据样本越少，统计量越不具有代表性，噪声也相应的增加。而过大的batch size，会使得梯度方向基本稳定，容易陷入局部最优解，降低精度。一般参考范围会取在[1:1024]之间，当然这个不是绝对的，需要结合具体场景和样本情况；动量衰减参数<em>β</em>是计算梯度的指数加权平均数，并利用该值来更新参数，设置为 0.9 是一个常见且效果不错的选择；</p></li></ul><ul><li>最后，<strong>Adam优化器的超参数、权重衰减系数、丢弃法比率（dropout）和网络参数</strong>。在这里说明下，这些参数重要性放在最后<strong>并不等价于这些参数不重要</strong>。而是表示这些参数在大部分实践中<strong>不建议过多尝试</strong>，例如Adam优化器中的<em>β1，β2，ϵ</em>，常设为 0.9、0.999、10−8就会有不错的表现。权重衰减系数通常会有个建议值，例如0.0005 ，使用建议值即可，不必过多尝试。dropout通常会在全连接层之间使用防止过拟合，建议比率控制在[0.2,0.5]之间。使用dropout时需要特别注意两点：一、在RNN中，如果直接放在memory cell中,循环会放大噪声，扰乱学习。一般会建议放在输入和输出层；二、不建议dropout后直接跟上batchnorm，dropout很可能影响batchnorm计算统计量，导致方差偏移，这种情况下会使得推理阶段出现模型完全垮掉的极端情况；网络参数通常也属于超参数的范围内，通常情况下增加网络层数能增加模型的容限能力，但模型真正有效的容限能力还和样本数量和质量、层之间的关系等有关，所以一般情况下会选择先固定网络层数，调优到一定阶段或者有大量的硬件资源支持可以在网络深度上进行进一步调整。</li></ul><h3 id="14-2-5-部分超参数如何影响模型性能"><a href="#14-2-5-部分超参数如何影响模型性能" class="headerlink" title="14.2.5 部分超参数如何影响模型性能"></a>14.2.5 部分超参数如何影响模型性能</h3><table><thead><tr><th style="text-align:center">超参数</th><th style="text-align:center">如何影响模型容量</th><th style="text-align:center">原因</th><th style="text-align:center">注意事项</th></tr></thead><tbody><tr><td style="text-align:center">学习率</td><td style="text-align:center">调至最优，提升有效容量</td><td style="text-align:center">过高或者过低的学习率，都会由于优化失败而导致降低模型有效容限</td><td style="text-align:center">学习率最优点，在训练的不同时间点都可能变化，所以需要一套有效的学习率衰减策略</td></tr><tr><td style="text-align:center">损失函数部分超参数</td><td style="text-align:center">调至最优，提升有效容量</td><td style="text-align:center">损失函数超参数大部分情况都会可能影响优化，不合适的超参数会使即便是对目标优化非常合适的损失函数同样难以优化模型，降低模型有效容限。</td><td style="text-align:center">对于部分损失函数超参数其变化会对结果十分敏感，而有些则并不会太影响。在调整时，建议参考论文的推荐值，并在该推荐值数量级上进行最大最小值调试该参数对结果的影响。</td></tr><tr><td style="text-align:center">批样本数量</td><td style="text-align:center">过大过小，容易降低有效容量</td><td style="text-align:center">大部分情况下，选择适合自身硬件容量的批样本数量，并不会对模型容限造成。</td><td style="text-align:center">在一些特殊的目标函数的设计中，如何选择样本是很可能影响到模型的有效容限的，例如度量学习（metric learning）中的N-pair loss。这类损失因为需要样本的多样性，可能会依赖于批样本数量。</td></tr><tr><td style="text-align:center">丢弃法</td><td style="text-align:center">比率降低会提升模型的容量</td><td style="text-align:center">较少的丢弃参数意味着模型参数量的提升，参数间适应性提升，模型容量提升，但不一定能提升模型有效容限</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">权重衰减系数</td><td style="text-align:center">调至最优，提升有效容量</td><td style="text-align:center">权重衰减可以有效的起到限制参数变化的幅度，起到一定的正则作用</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">优化器动量</td><td style="text-align:center">调至最优，可能提升有效容量</td><td style="text-align:center">动量参数通常用来加快训练，同时更容易跳出极值点，避免陷入局部最优解。</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">模型深度</td><td style="text-align:center">同条件下，深度增加，模型容量提升</td><td style="text-align:center">同条件，下增加深度意味着模型具有更多的参数，更强的拟合能力。</td><td style="text-align:center">同条件下，深度越深意味着参数越多，需要的时间和硬件资源也越高。</td></tr><tr><td style="text-align:center">卷积核尺寸</td><td style="text-align:center">尺寸增加，模型容量提升</td><td style="text-align:center">增加卷积核尺寸意味着参数量的增加，同条件下，模型参数也相应的增加。</td></tr></tbody></table><h3 id="14-2-6-部分超参数合适的范围"><a href="#14-2-6-部分超参数合适的范围" class="headerlink" title="14.2.6 部分超参数合适的范围"></a>14.2.6 部分超参数合适的范围</h3><table><thead><tr><th style="text-align:center">超参数</th><th style="text-align:center">建议范围</th><th style="text-align:center">注意事项</th></tr></thead><tbody><tr><td style="text-align:center">初始学习率</td><td style="text-align:center">SGD: [1e-2, 1e-1]<br>momentum: [1e-3, 1e-2]<br>Adagrad: [1e-3, 1e-2]<br>Adadelta: [1e-2, 1e-1]<br>RMSprop: [1e-3, 1e-2]<br>Adam: [1e-3, 1e-2]<br>Adamax: [1e-3, 1e-2]<br>Nadam: [1e-3, 1e-2]</td><td style="text-align:center">这些范围通常是指从头开始训练的情况。若是微调，初始学习率可在降低一到两个数量级。</td></tr><tr><td style="text-align:center">损失函数部分超参数</td><td style="text-align:center">多个损失函数之间，损失值之间尽量相近，不建议超过或者低于两个数量级</td><td style="text-align:center">这是指多个损失组合的情况，不一定完全正确。单个损失超参数需结合实际情况。</td></tr><tr><td style="text-align:center">批样本数量</td><td style="text-align:center">[1:1024]</td><td style="text-align:center">当批样本数量过大(大于6000)或者等于1时，需要注意学习策略或者BN的替代品。</td></tr><tr><td style="text-align:center">丢弃法比率</td><td style="text-align:center">[0, 0.5]</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">权重衰减系数</td><td style="text-align:center">[0, 1e-4]</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">卷积核尺寸</td><td style="text-align:center">[7x7],[5x5],[3x3],[1x1], [7x1,1x7]</td></tr></tbody></table><h2 id="14-3-网络训练中的超参调整策略"><a href="#14-3-网络训练中的超参调整策略" class="headerlink" title="14.3 网络训练中的超参调整策略"></a>14.3 网络训练中的超参调整策略</h2><h3 id="14-3-1-如何调试模型？"><a href="#14-3-1-如何调试模型？" class="headerlink" title="14.3.1 如何调试模型？"></a>14.3.1 如何调试模型？</h3><p>在讨论如何调试模型之前，我们先来纠正一个误区。通常理解如何调试模型的时候，我们想到一系列优秀的神经网络模型以及调试技巧。但这里需要指出的是数据才是模型的根本，如果有一批质量优秀的数据，或者说你能将数据质量处理的很好的时候，往往比挑选或者设计模型的收益来的更大。那在这之后才是模型的设计和挑选以及训练技巧上的事情。</p><p>1、探索和清洗数据。探索数据集是设计算法之前最为重要的一步，以图像分类为例，我们需要重点知道给定的数据集样本类别和各类别样本数量是否平衡，图像之间是否存在跨域问题（例如网上爬取的图像通常质量各异，存在噪声）。若是类别数远远超过类别样本数（比如类别10000，每个类别却只有10张图像），那通常的方法可能效果并不显著，这时候few-shot learning或者对数据集做进一步增强可能是你比较不错的选择。再如目标检测，待检测目标在数据集中的尺度范围是对检测器的性能有很大影响的部分。因此重点是检测大目标还是小目标、目标是否密集完全取决于数据集本身。所以，探索和进一步清洗数据集一直都是深度学习中最重要的一步。这是很多新手通常会忽略的一点。</p><p>2、探索模型结果。探索模型的结果，通常是需要对模型在验证集上的性能进行进一步的分析，这是如何进一步提升模型性能很重要的步骤。将模型在训练集和验证集都进行结果的验证和可视化，可直观的分析出模型是否存在较大偏差以及结果的正确性。以图像分类为例，若类别间样本数量很不平衡时，我们需要重点关注少样本类别在验证集的结果是否和训练集的出入较大，对出错类别可进一步进行模型数值分析以及可视化结果分析，进一步确认模型的行为。</p><p>3、监控训练和验证误差。首先很多情况下，我们忽略代码的规范性和算法撰写正确性验证，这点上容易产生致命的影响。在训练和验证都存在问题时，首先请确认自己的代码是否正确。其次，根据训练和验证误差进一步追踪模型的拟合状态。若训练数据集很小，此时监控误差则显得格外重要。确定了模型的拟合状态对进一步调整学习率的策略的选择或者其他有效超参数的选择则会更得心应手。</p><p>4、反向传播数值的计算，这种情况通常适合自己设计一个新操作的情况。目前大部分流行框架都已包含自动求导部分，但并不一定是完全符合你的要求的。验证求导是否正确的方式是比较自动求导的结果和有限差分计算结果是否一致。所谓有限差分即导数的定义，使用一个极小的值近似导数。</p><p><img src="/2017/11/24/第十四章_超参数调整/img/ch14/%E5%AF%BC%E6%95%B0.png" alt=""></p><h3 id="14-3-2-为什么要做学习率调整"><a href="#14-3-2-为什么要做学习率调整" class="headerlink" title="14.3.2 为什么要做学习率调整?"></a>14.3.2 为什么要做学习率调整?</h3><p>​    学习率可以说是模型训练最为重要的超参数。通常情况下，一个或者一组优秀的学习率既能加速模型的训练，又能得到一个较优甚至最优的精度。过大或者过小的学习率会直接影响到模型的收敛。我们知道，当模型训练到一定程度的时候，损失将不再减少，这时候模型的一阶梯度接近零，对应Hessian 矩阵通常是两种情况，一、正定，即所有特征值均为正，此时通常可以得到一个局部极小值，若这个局部极小值接近全局最小则模型已经能得到不错的性能了，但若差距很大，则模型性能还有待于提升，通常情况下后者在训练初最常见。二，特征值有正有负，此时模型很可能陷入了鞍点，若陷入鞍点，模型性能表现就很差。以上两种情况在训练初期以及中期，此时若仍然以固定的学习率，会使模型陷入左右来回的震荡或者鞍点，无法继续优化。所以，学习率衰减或者增大能帮助模型有效的减少震荡或者逃离鞍点。</p><h3 id="14-3-3-学习率调整策略有哪些？"><a href="#14-3-3-学习率调整策略有哪些？" class="headerlink" title="14.3.3 学习率调整策略有哪些？"></a>14.3.3 学习率调整策略有哪些？</h3><p>通常情况下，大部分学习率调整策略都是衰减学习率，当然也有部分增大学习率的策略。这里结合TensorFlow的内置方法来举例。</p><p>1、<strong>exponential_decay</strong>和<strong>natural_exp_decay</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">exponential_decay(learning_rate, global_step, decay_steps, decay_rate,</span><br><span class="line">                   staircase=<span class="keyword">False</span>, name=<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line">natural_exp_decay(learning_rate, global_step, decay_steps, decay_rate,</span><br><span class="line">                   staircase=<span class="keyword">False</span>, name=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure><p>指数衰减是最常用的衰减方式，这种方式简单直接，在训练初期衰减较大利于收敛，在后期衰减较小利于精调。以上两种均为指数衰减，区别在于后者使用以自然指数下降。</p><p><img src="/2017/11/24/第十四章_超参数调整/img\ch14\指数衰减.jpeg" alt="./"></p><p>2、<strong>piecewise_constant</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">piecewise_constant(x, boundaries, values, name=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure><p>分段设置学习率法，跟指数型类似，区别在于每个阶段的衰减并不是按指数调整。可在不同阶段设置手动不同的学习率。这种学习率重点在有利于精调。</p><p>3、<strong>polynomial_decay</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">polynomial_decay(learning_rate, global_step, decay_steps,</span><br><span class="line">                  end_learning_rate=<span class="number">0.0001</span>, power=<span class="number">1.0</span>,</span><br><span class="line">                  cycle=<span class="keyword">False</span>, name=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure><p>多项式衰减，计算如下：</p><p>global_step = min(global_step,decay_steps)</p><p>decayed_learning_rate = (learning_rate-end_learning_rate)*(1-global_step/decay_steps)^ (power)+end_learning_rate</p><p>有别去上述两种，多项式衰减则是在每一步迭代上都会调整学习率。主要看Power参数，若Power为1，则是下图中的红色直线；若power小于1，则是开1/power次方，为蓝色线；绿色线为指数，power大于1。</p><p><img src="/2017/11/24/第十四章_超参数调整/img\ch14\多项式衰减.jpeg" alt=""></p><p>此外，需要注意的是参数cycle，cycle对应的是一种周期循环调整的方式，主要的目的在后期防止在一个局部极小值震荡，若跳出该区域或许能得到更有的结果。这里说明cycle的方式不止可以在多项式中应用，可配合类似的周期函数进行衰减，如下图。</p><p><img src="/2017/11/24/第十四章_超参数调整/img\ch14\cycle衰减.jpeg" alt=""></p><p>4、<strong>inverse_time_decay</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inverse_time_decay(learning_rate, global_step, decay_steps, decay_rate,</span><br><span class="line">                   staircase=<span class="keyword">False</span>, name=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure><p>逆时衰减，这种方式和指数型类似。如图，<img src="/2017/11/24/第十四章_超参数调整/img\ch14\逆时衰减.jpeg" alt=""></p><p>5、<strong>cosine_decay</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cosine_decay(learning_rate, global_step, decay_steps, alpha=<span class="number">0.0</span>,</span><br><span class="line">                 name=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure><p>余弦衰减，即按余弦函数的方式衰减学习率，如图</p><p><img src="/2017/11/24/第十四章_超参数调整/img\ch14\余弦衰减.jpeg" alt=""></p><p>6、<strong>cosine_decay_restarts</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cosine_decay_restarts(learning_rate, global_step, first_decay_steps,</span><br><span class="line">                           t_mul=<span class="number">2.0</span>, m_mul=<span class="number">1.0</span>, alpha=<span class="number">0.0</span>, name=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure><p>余弦重启衰减，即余弦版本的cycle策略，作用与多项式衰减中的cycle相同。区别在于余弦重启衰减会重新回到初始学习率，拉长周期，而多项式版本则会逐周期衰减。</p><p><img src="/2017/11/24/第十四章_超参数调整/img\ch14\余弦cycle衰减.jpeg" alt=""></p><p>7、<strong>linear_cosine_decay</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">linear_cosine_decay(learning_rate, global_step, decay_steps,</span><br><span class="line">                        num_periods=<span class="number">0.5</span>, alpha=<span class="number">0.0</span>, beta=<span class="number">0.001</span>,</span><br><span class="line">                        name=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure><p>线性余弦衰减，主要应用于增强学习领域。</p><p><img src="/2017/11/24/第十四章_超参数调整/img\ch14\线性余弦衰减.jpeg" alt=""></p><p>8、<strong>noisy_linear_cosine_decay</strong></p><p>噪声线性余弦衰减，即在线性余弦衰减中加入随机噪声，增大寻优的随机性。</p><p><img src="/2017/11/24/第十四章_超参数调整/img\ch14\噪声线性余弦衰减.jpeg" alt=""></p><h3 id="14-3-4-极端批样本数量下，如何训练网络？"><a href="#14-3-4-极端批样本数量下，如何训练网络？" class="headerlink" title="14.3.4 极端批样本数量下，如何训练网络？"></a>14.3.4 极端批样本数量下，如何训练网络？</h3><h3 id="14-3-5-为什么卷积核设计尺寸都是奇数"><a href="#14-3-5-为什么卷积核设计尺寸都是奇数" class="headerlink" title="14.3.5 为什么卷积核设计尺寸都是奇数"></a>14.3.5 为什么卷积核设计尺寸都是奇数</h3><p>主要原因有两点：</p><ul><li>保证像素点中心位置，避免位置信息偏移</li><li>填充边缘时能保证两边都能填充，原矩阵依然对称</li></ul><h3 id="14-3-6-权重共享的形式有哪些，为什么要权重共享"><a href="#14-3-6-权重共享的形式有哪些，为什么要权重共享" class="headerlink" title="14.3.6 权重共享的形式有哪些，为什么要权重共享"></a>14.3.6 权重共享的形式有哪些，为什么要权重共享</h3><p>权重共享的形式：</p><ul><li>深度学习中，权重共享最具代表性的就是卷积网络的卷积操作。卷积相比于全连接神经网络参数大大减少；</li><li>多任务网络中，通常为了降低每个任务的计算量，会共享一个骨干网络。</li><li>一些相同尺度下的结构化递归网络</li></ul><p>权重共享的好处：</p><p>​    权重共享一定程度上能增强参数之间的联系，获得更好的共性特征。同时很大程度上降低了网络的参数，节省计算量和计算所需内存（当然，结构化递归并不节省计算量）。此外权重共享能起到很好正则的作用。正则化的目的是为了降低模型复杂度，防止过拟合，而权重共享则正好降低了模型的参数和复杂度。</p><p>​    因此一个设计优秀的权重共享方式，在降低计算量的同时，通常会较独享网络有更好的效果。</p><h2 id="14-4-合理使用预训练网络"><a href="#14-4-合理使用预训练网络" class="headerlink" title="14.4 合理使用预训练网络"></a>14.4 合理使用预训练网络</h2><h3 id="14-4-1-什么是微调（fine-tune）"><a href="#14-4-1-什么是微调（fine-tune）" class="headerlink" title="14.4.1 什么是微调（fine-tune）"></a>14.4.1 什么是微调（fine-tune）</h3><p>​    微调（fine-tune），顾名思义指稍微调整参数即可得到优秀的性能，是迁移学习的一种实现方式。微调和从头训练（train from scratch）的本质区别在于模型参数的初始化，train from scratch通常指对网络各类参数进行随机初始化（当然随机初始化也存在一定技巧），随机初始化模型通常不具有任何预测能力，通常需要大量的数据或者特定域的数据进行从零开始的训练，这样需要训练到优秀的模型通常是稍困难的。而微调的网络，网络各类参数已经在其他数据集（例如ImageNet数据集）完成较好调整的，具备了较优秀的表达能力。因此，我们只需要以较小的学习速率在自己所需的数据集领域进行学习即可得到较为优秀的模型。微调通常情况下，无须再重新设计网络结构，预训练模型提供了优秀的结构，只需稍微修改部分层即可。在小数据集上，通常微调的效果比从头训练要好很多，原因在于数据量较小的前提下，训练更多参数容易导致过度拟合。</p><h3 id="14-4-2-微调有哪些不同方法？"><a href="#14-4-2-微调有哪些不同方法？" class="headerlink" title="14.4.2 微调有哪些不同方法？"></a>14.4.2 微调有哪些不同方法？</h3><p>​    以图像分类为例，通常情况下由于不同数据集需要的类别数不同，我们需要修改网络的输出顶层。这种情况下有两种微调方式：</p><ul><li><p>不冻结网络模型的任何层，对最后的改动层使用较大的学习率，对未改动层以较小的学习率进行训练全模型训练，进行多轮训练即可。即一步完成训练。</p></li><li><p>冻结除了顶部改动层以外的所有层参数，即不对冻结部分的层进行参数训练更新，进行若干轮的微调训练后，放开顶部层以下的若干层或者全部放开所有层的参数，再次进行若干轮训练即可。即分多步训练。</p><p>以上两种都属于微调。目前由于存在大量优秀的预训练模型，如何确定哪个模型适合自己的任务并能得到最佳性能需要花大量的时间探索。此时，上述的前者是种不错训练方式，你无须进行过多分步的操作。而当探索到一个比较适合的模型时，你不妨可以再次重新尝试下以第二种方式进行训练，或许能得到相比于前者稍高些的性能，因为小数据集上调整过多的参数过拟合的机率也会增大，当然这并不是绝对的。</p></li></ul><h3 id="14-4-3-微调先冻结底层，训练顶层的原因？"><a href="#14-4-3-微调先冻结底层，训练顶层的原因？" class="headerlink" title="14.4.3 微调先冻结底层，训练顶层的原因？"></a>14.4.3 微调先冻结底层，训练顶层的原因？</h3><p>​    14.12中第二种冻结多步训练的方式。首先冻结除了顶部改动层以外的所有层参数，对顶层进行训练，这个过程可以理解为顶层的域适应训练，主要用来训练适应模型的现有特征空间，防止顶层糟糕的初始化，对已经具备一定表达能力的层的干扰和破坏，影响最终的性能。之后，在很多深度学习框架教程中会使用放开顶层往下一半的层数，继续进行微调。这样的好处在于越底层的特征通常是越通用的特征，越往上其整体的高层次语义越完备，这通过感受野很容易理解。所以，若预训练模型的数据和微调训练的数据语义差异越大（例如ImageNet的预模型用于医学图像的训练），那越往顶层的特征语义差异就越大，因此通常也需要进行相应的调整。</p><h3 id="14-4-4-不同的数据集特性下如何微调？"><a href="#14-4-4-不同的数据集特性下如何微调？" class="headerlink" title="14.4.4 不同的数据集特性下如何微调？"></a>14.4.4 不同的数据集特性下如何微调？</h3><ul><li>数据集数据量少，数据和原数据集类似。这是通常做法只需修改最后的输出层，训练即可，训练过多参数容易过拟合。</li><li>数据集数据量少，数据和原数据集差异较大。由于数据差异较大，可以在完成输出顶层的微调后，微调顶层往下一半的层数，进行微调。</li><li>数据集数据量大，数据与原数据集差异较大。这种情况下，通常已经不需要用预训练模型进行微调，通常直接重新训练即可。</li><li>数据集数据量大，数据与原数据类似。这时预训练模型的参数是个很好的初始化，可利用预训练模型放开所有层以较小的学习率微调即可。</li></ul><h3 id="14-4-4-目标检测中使用预训练模型的优劣？"><a href="#14-4-4-目标检测中使用预训练模型的优劣？" class="headerlink" title="14.4.4 目标检测中使用预训练模型的优劣？"></a>14.4.4 目标检测中使用预训练模型的优劣？</h3><p>​    目标检测中无论是一阶段的YOLO、SSD或者RetinaNet 还是二阶段的Faster R-CNN、R-FCN 和 FPN都是基于ImageNet上预训练好的分类模型。</p><p>​    优势在于：</p><p>​    1、正如大部分微调的情况一样，使用预训练网络已拥有优秀的语义特征，能有效的加快训练速度；</p><p>​    2、其次，对于大部分二阶段的模型来说，并未实现严格意义上的完全端对端的训练，所以使用预训练模型能直接提取到语义特征，能使两个阶段的网络更容易实现模型的优化。</p><p>​    劣势在于，分类模型和检测模型之间仍然存在一定任务上的差异：</p><p>​    1、检测模型能在多尺度上获取更高的收益；</p><p>​    2、分类模型大部分训练于单目标数据，对同时进行多目标的捕捉能力稍弱；</p><p>​    3、分类模型并不关注目标的位置，在一定程度上让模型损失部分空间信息，这对检测模型通常是不利的。</p><h3 id="14-4-5-目标检测中如何从零开始训练？"><a href="#14-4-5-目标检测中如何从零开始训练？" class="headerlink" title="14.4.5 目标检测中如何从零开始训练？"></a>14.4.5 目标检测中如何从零开始训练？</h3><p>​    参考14.15提到的使用预训练模型训练检测模型的优劣势，有两个方案在实际实现中可能会更有效。</p><p>​    方案一、通常二阶段检测模型并未实现真正完全端对端的训练，因此二阶段模型会更难以训练。所以一阶段检测模型相较起来更适合从零训练，参考DSOD，使用DenseNet使用更多层次的特征将更适应训练。</p><p>​    方案二、二阶段模型从零训练很难，而分类模型对于多目标、尺度并不敏感。因此仍然需要预训练模型的参数，这时借鉴DetNet训练一个专属于目标检测的模型网络，而参考分类模型的劣势，该专属网络应对多目标、尺度和位置拥有更强的适应性。</p><h2 id="14-5-如何改善-GAN-的性能"><a href="#14-5-如何改善-GAN-的性能" class="headerlink" title="14.5 如何改善 GAN 的性能"></a>14.5 如何改善 GAN 的性能</h2><p>优化GAN性能通常需要在如下几个方面进行</p><ul><li>设计或选择更适合目的代价函数。</li><li>添加额外的惩罚。</li><li>避免判别器过度自信和生成器过度拟合。</li><li>更好的优化模型的方法。</li><li>添加标签明确优化目标。</li></ul><p>GAN常用训练技巧</p><ul><li><p>输入规范化到（-1，1）之间，最后一层的激活函数使用tanh（BEGAN除外）</p></li><li><p>使用wassertein GAN的损失函数，</p></li><li><p>如果有标签数据的话，尽量使用标签，也有人提出使用反转标签效果很好，另外使用标签平滑，单边标签平滑或者双边标签平滑</p></li><li><p>使用mini-batch norm， 如果不用batch norm 可以使用instance norm 或者weight norm</p></li><li><p>避免使用RELU和pooling层，减少稀疏梯度的可能性，可以使用leakrelu激活函数</p></li><li><p>优化器尽量选择ADAM，学习率不要设置太大，初始1e-4可以参考，另外可以随着训练进行不断缩小学习率，</p></li><li><p>给D的网络层增加高斯噪声，相当于是一种正则</p><h2 id="14-6-AutoML"><a href="#14-6-AutoML" class="headerlink" title="14.6 AutoML"></a>14.6 AutoML</h2></li></ul><h3 id="14-6-1-什么是AutoML？"><a href="#14-6-1-什么是AutoML？" class="headerlink" title="14.6.1 什么是AutoML？"></a>14.6.1 什么是AutoML？</h3><p>​    目前一个优秀的机器学习和深度学习模型，离不开这几个方面：</p><p>​    一、优秀的数据预处理；</p><p>​    二、合适的模型结构和功能；</p><p>​    三、优秀的训练策略和超参数；</p><p>​    四、合适的后处理操作；</p><p>​    五、严格的结果分析。</p><p>​    这几方面都对最终的结果有着举足轻重的影响，这也是目前的数据工程师和学者们的主要工作。但由于这每一方面都十分繁琐，尤其是在构建模型和训练模型上。而大部分情况下，这些工作有无须过深专业知识就能使用起来。所以AutoML主要的作用就是来帮助实现高效的模型构建和超参数调整。例如深度学习网络的架构搜索、超参数的重要性分析等等。当然AutoML并不简单的进行暴力或者随机的搜索，其仍然需要机器学习方面的知识，例如贝叶斯优化、强化学习、元学习以及迁移学习等等。目前也有些不错的AutoML工具包，例如Alex Honchar的Hyperopt、微软的NNI、Autokeras等。</p><h3 id="14-6-2-自动化超参数搜索方法有哪些？"><a href="#14-6-2-自动化超参数搜索方法有哪些？" class="headerlink" title="14.6.2 自动化超参数搜索方法有哪些？"></a>14.6.2 自动化超参数搜索方法有哪些？</h3><p>​    目前自动化搜索主要包含网格搜索，随机搜索，基于模型的超参优化</p><p>​    网格搜索：</p><p>​        通常当超参数量较少的时候，可以使用网格搜索法。即列出每个超参数的大致候选集合。利用这些集合        进行逐项组合优化。在条件允许的情况下，重复进行网格搜索会当优秀，当然每次重复需要根据上一步得到的最优参数组合，进行进一步的细粒度的调整。网格搜索最大的问题就在于计算时间会随着超参数的数量指数级的增长。</p><p>​    随机搜索：</p><p>​        随机搜索，是一种用来替代网格搜索的搜索方式。随机搜索有别于网格搜索的一点在于，我们不需要设定一个离散的超参数集合，而是对每个超参数定义一个分布函数来生成随机超参数。随机搜索相比于网格搜索在一些不敏感超参上拥有明显优势。例如网格搜索对于批样本数量（batch size），在[16,32,64]这些范围内进行逐项调试，这样的调试显然收益更低下。当然随机搜索也可以进行细粒度范围内的重复的搜索优化。</p><p><img src="/2017/11/24/第十四章_超参数调整/img\ch14\14.14.png" alt=""></p><p>​    基于模型的超参优化：</p><p>​        有别于上述两种的搜索策略，基于模型的超参调优问题转化为了优化问题。直觉上会考虑是否进行一个可导建模，然后利用梯度下降进行优化。但不幸的是我们的超参数通常情况下是离散的，而且其计算代价依旧很高。</p><p>​        基于模型的搜索算法，最常见的就是贝叶斯超参优化。有别于的网格搜索和随机搜索独立于前几次搜索结果的搜索，贝叶斯则是利用历史的搜索结果进行优化搜索。其主要有四部分组成，1.目标函数，大部分情况下就是模型验证集上的损失。2、搜索空间，即各类待搜索的超参数。3、优化策略，建立的概率模型和选择超参数的方式。4、历史的搜索结果。首先对搜索空间进行一个先验性的假设猜想，即假设一种选择超参的方式，然后不断的优化更新概率模型，最终的目标是找到验证集上误差最小的一组超参数。</p><h3 id="14-6-3-什么是神经网络架构搜索（NAS）"><a href="#14-6-3-什么是神经网络架构搜索（NAS）" class="headerlink" title="14.6.3 什么是神经网络架构搜索（NAS）"></a>14.6.3 什么是神经网络架构搜索（NAS）</h3><p>2015至2017年间，是CNN网络设计最兴盛的阶段，大多都是由学者人工设计的网络结构。这个过程通常会很繁琐。其主要原因在于对不同模块组件的组成通常是个黑盒优化的问题，此外，在不同结构超参数以及训练超参数的选择优化上非凸优化问题，或者是个混合优化问题，既有离散空间又有连续空间。NAS（Neural Architecture Search）的出现就是为了解决如何通过机器策略和自动化的方式设计出优秀高效的网络。而这种策略通常不是统一的标准，不同的网络结合实际的需求通常会有不同的设计，比如移动端的模型会在效率和精度之间做平衡。目前的网络架构搜索通常会分为三个方面，搜索空间，搜索策略以及评价预估。链接 | <a href="https://www.paperweekly.site/papers/2249" target="_blank" rel="noopener">https://www.paperweekly.site/papers/2249</a></p><ul><li><p>搜索空间，定义了优化问题的变量，网络结构和超参数的变量定义有所不同，不同的变量规模对于算法的难度来说也不尽相同。早期很多工作都是用以遗传算法为代表的进化算法对神经网络的超参数和权重进行优化，因为当时的神经网络只有几层，每层十几个神经元，也不存在复杂的网络架构，参数很有限，可直接进行优化。而深度学习模型一方面有着复杂的网络结构，另一方面权重参数通常都以百万到亿来计，进化算法根本无法优化。但换个思路，假如我们找到了一组网络架构参数和对应的超参数，深度学习模型的性能其实是由这组参数来控制和决定的，所以只需要对复杂模型的架构参数和对应的超参数进行优化即可。</p></li><li><p>搜索策略， 搜索策略定义了使用怎样的算法可以快速、准确找到最优的网络结构参数配置。常见的搜索方法包括：随机搜索、贝叶斯优化、进化算法、强化学习、基于梯度的算法。其中，2017 年谷歌大脑的那篇强化学习搜索方法将这一研究带成了研究热点，后来 Uber、Sentient、OpenAI、Deepmind 等公司和研究机构用进化算法对这一问题进行了研究，这个 task 算是进化算法一大热点应用。</p></li><li><p>评价预估，类似于工程优化中的代理模型（surrogate model），因为深度学习模型的效果非常依赖于训练数据的规模，大规模数据上的模型训练会非常耗时，对优化结果的评价将会非常耗时，所以需要一些手段去做近似的评估。 </p><p>一种思路是用一些低保真的训练集来训练模型，低保真在实际应用可以有多种表达，比如训练更少的次数，用原始训练数据的一部分，低分辨率的图片，每一层用更少的滤波器等。用这种低保真的训练集来测试优化算法会大大降低计算时间，但也存在一定的 bias，不过选择最优的架构并不需要绝对数值，只需要有相对值就可以进行排序选优了； </p><p>另一种主流思路是借鉴于工程优化中的代理模型，在很多工程优化问题中，每一次优化得到的结果需要经过实验或者高保真仿真（有限元分析）进行评价，实验和仿真的时间非常久，不可能无限制地进行评价尝试，学者们提出了一种叫做代理模型的回归模型，用观测到的点进行插值预测，这类方法中最重要的是在大搜索空间中如何选择尽量少的点预测出最优结果的位置；</p><p>第三种主流思路是参数级别的迁移，用之前已经训练好的模型权重参数对target问题进行赋值，从一个高起点的初值开始寻优将会大大地提高效率。在这类问题中，积累了大量的历史寻优数据，对新问题的寻优将会起到很大的帮助，用迁移学习进行求解，是一个很不错的思路；另一种比较有意思的思路叫做单次（One-Shot）架构搜索，这种方法将所有架构视作一个 one-shot 模型（超图）的子图，子图之间通过超图的边来共享权重。</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://leesen998.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习基础" scheme="https://leesen998.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>深度学习之优化算法</title>
    <link href="https://leesen998.github.io/2017/11/02/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0_%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"/>
    <id>https://leesen998.github.io/2017/11/02/第十三章_优化算法/</id>
    <published>2017-11-02T11:48:29.000Z</published>
    <updated>2019-03-22T07:35:12.001Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg" alt="" style="width:100%"></p><a id="more"></a><h2 id="13-1-CPU-和-GPU-的区别"><a href="#13-1-CPU-和-GPU-的区别" class="headerlink" title="13.1 CPU 和 GPU 的区别?"></a>13.1 CPU 和 GPU 的区别?</h2><p>&emsp;&emsp;<br><strong>概念：</strong><br>&emsp;&emsp;<br>CPU 全称是 central processing unit，CPU 是一块超大规模的集成电路，是一台计算机的运 算和控制核心，它的主要功能是解释计算机指令和处理计算机软件中的数据。  </p><p>&emsp;&emsp;<br>GPU 全称是 graphics processing unit，GPU 是将计算机系统，所需要的显示信息进行转换 的驱动，并向显示器提供扫描信号，控制显示器的正确显示，是连接显示器和个人电脑主板的 重要元件，是人机对话的重要设备之一。</p><p>&emsp;&emsp;<br><strong>缓存：</strong><br>&emsp;&emsp;<br>CPU 有大量的缓存结构，目前主流的 CPU 芯片上都有四级缓存，这些缓存结构消耗了大 量的晶体管，在运行的时候需要大量的电力。反观 GPU 的缓存就很简单，目前主流的 GPU 芯 片最多有两层缓存。CPU 消耗在晶体管上的空间和能耗，GPU 都可以用来做成 ALU 单元，也 因此 GPU 比 CPU 的效率要高一些。</p><p>&emsp;&emsp;<br><strong>响应方式：</strong><br>&emsp;&emsp;<br>对 CPU 来说，要求的是实时响应，对单任务的速度要求很高，所以就要用很多层缓存的 办法来保证单任务的速度。对 GPU 来说大家不关心第一个像素什么时候计算完成，而是都关 心最后一个像素什么时候计算出来，所以 GPU 就把所有的任务都排好，然后再批处理，这样 对缓存的要求就很低了。举个不恰当的例子，在点击 10 次鼠标的时候，CPU 要每一次点击都 要及时响应，而 GPU 会等第 10 次点击后，再一次性批处理响应。</p><p>&emsp;&emsp;<br><strong>浮点运算：</strong><br>&emsp;&emsp;<br>CPU 除了负责浮点整形运算外，还有很多其他的指令集的负载，比如像多媒体解码，硬 件解码等，所以 CPU 是个多才多艺的东西，而 GPU 基本上就是只做浮点运算的，也正是因为 只做浮点运算，所以设计结构简单，也就可以做的更快。另外显卡的 GPU 和单纯为了跑浮点 高性能运算的 GPU 还是不太一样，显卡的 GPU 还要考虑配合图形输出显示等方面，而有些专 用 GPU 设备，就是一个 PCI 卡上面有一个性能很强的浮点运算 GPU，没有显示输出的，这样 的 GPU 就是为了加快某些程序的浮点计算能力。CPU 注重的是单线程的性能，也就是延迟， 对于 CPU 来说，要保证指令流不中断，所以 CPU 需要消耗更多的晶体管和能耗用在控制部分， 于是CPU分配在浮点计算的功耗就会变少。GPU注重的是吞吐量，单指令能驱动更多的计算， 所以相比较而言 GPU 消耗在控制部分的能耗就比较少，因此也就可以把电省下来的资源给浮 点计算使用。</p><p>&emsp;&emsp;<br><strong>应用方向：</strong><br>&emsp;&emsp;<br>像操作系统这一类应用，需要快速响应实时信息，需要针对延迟优化，所以晶体管数量和能耗都需要用在分支预测，乱序执行上，低延迟缓存等控制部分，而这都是 CPU 的所擅长的。 对于像矩阵一类的运算，具有极高的可预测性和大量相似运算的，这种高延迟，高吞吐的架构 运算，就非常适合 GPU。</p><p>&emsp;&emsp;<br><strong>浅显解释：</strong><br>&emsp;&emsp;<br>一块 CPU 相当于一个数学教授，一块 GPU 相当于 100 个小学生。<br>&emsp;&emsp;<br>第一回合，四则运算，一百个题。教授拿到卷子一道道计算。100 个小学生各拿一道题。 教授刚开始计算到第二题的时候，小学生就集体交卷了。<br>&emsp;&emsp;<br>第二回合，高等函数，一百个题。当教授搞定后。一百个小学生可能还不知道该做些什么。<br>&emsp;&emsp;<br>这两个回合就是 CPU 和 GPU 的区别了。</p><h2 id="13-2-如何解决训练样本少的问题"><a href="#13-2-如何解决训练样本少的问题" class="headerlink" title="13.2 如何解决训练样本少的问题"></a>13.2 如何解决训练样本少的问题</h2><p>&emsp;&emsp;<br>要训练一个好的 CNN 模型，通常需要很多训练数据，尤其是模型结构比较复杂的时候， 比如 ImageNet 数据集上训练的模型。虽然深度学习在 ImageNet 上取得了巨大成功，但是一个 现实的问题是，很多应用的训练集是较小的，如何在这种情况下应用深度学习呢?有三种方法 可供读者参考。  </p><p>&emsp;&emsp;<br>（1）可以将 ImageNet 上训练得到的模型做为起点，利用目标训练集和反向传播对其进 行继续训练，将模型适应到特定的应用。ImageNet 起到预训练的作用。<br>&emsp;&emsp;<br>（2）如果目标训练集不够大，也可以将低层的网络参数固定，沿用 ImageNet 上的训练集 结果，只对上层进行更新。这是因为底层的网络参数是最难更新的，而从 ImageNet 学习得到 的底层滤波器往往描述了各种不同的局部边缘和纹理信息，而这些滤波器对一般的图像有较好 的普适性。<br>&emsp;&emsp;<br>（3）直接采用 ImageNet 上训练得到的模型，把最高的隐含层的输出作为特征表达，代 替常用的手工设计的特征。</p><h2 id="13-3-什么样的样本集不适合用深度学习"><a href="#13-3-什么样的样本集不适合用深度学习" class="headerlink" title="13.3 什么样的样本集不适合用深度学习?"></a>13.3 什么样的样本集不适合用深度学习?</h2><p>&emsp;&emsp;<br>（1）数据集太小，数据样本不足时，深度学习相对其它机器学习算法，没有明显优势。<br>&emsp;&emsp;<br>（2）数据集没有局部相关特性，目前深度学习表现比较好的领域主要是图像/语音 /自然语言处理等领域，这些领域的一个共性是局部相关性。图像中像素组成物体，语音 信号中音位组合成单词，文本数据中单词组合成句子，这些特征元素的组合一旦被打乱， 表示的含义同时也被改变。对于没有这样的局部相关性的数据集，不适于使用深度学习算 法进行处理。举个例子:预测一个人的健康状况，相关的参数会有年龄、职业、收入、家 庭状况等各种元素，将这些元素打乱，并不会影响相关的结果。</p><h2 id="13-4-有没有可能找到比已知算法更好的算法"><a href="#13-4-有没有可能找到比已知算法更好的算法" class="headerlink" title="13.4 有没有可能找到比已知算法更好的算法?"></a>13.4 有没有可能找到比已知算法更好的算法?</h2><p>&emsp;&emsp;<br>没有免费的午餐定理:<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_4_1.png" alt="没有免费的午餐定理"></p><center>图 13.4 没有免费的午餐（黑点：训练样本；白点：测试样本）</center><p>&emsp;&emsp;<br>对于训练样本（黑点），不同的算法 A/B 在不同的测试样本（白点）中有不同的表现，这表示:对于一个学习算法A，若它在某些问题上比学习算法B更好，则必然存在一些问题， 在那里B比A好。<br>&emsp;&emsp;<br>也就是说:对于所有问题，无论学习算法 A 多聪明，学习算法 B 多笨拙，它们的期望性 能相同。<br>&emsp;&emsp;<br>但是:没有免费午餐定力假设所有问题出现几率相同，实际应用中，不同的场景，会有不 同的问题分布，所以，在优化算法时，针对具体问题进行分析，是算法优化的核心所在。</p><h2 id="13-5-何为共线性-跟过拟合有啥关联"><a href="#13-5-何为共线性-跟过拟合有啥关联" class="headerlink" title="13.5 何为共线性, 跟过拟合有啥关联?"></a>13.5 何为共线性, 跟过拟合有啥关联?</h2><p>&emsp;&emsp;<br>共线性:多变量线性回归中，变量之间由于存在高度相关关系而使回归估计不准确。<br>&emsp;&emsp;<br>产生问题:共线性会造成冗余，导致过拟合。<br>&emsp;&emsp;<br>解决方法:排除变量的相关性、加入权重正则。</p><h2 id="13-6-广义线性模型是怎被应用在深度学习中"><a href="#13-6-广义线性模型是怎被应用在深度学习中" class="headerlink" title="13.6 广义线性模型是怎被应用在深度学习中?"></a>13.6 广义线性模型是怎被应用在深度学习中?</h2><p>&emsp;&emsp;<br>深度学习从统计学角度，可以看做递归的广义线性模型。<br>&emsp;&emsp;<br>广义线性模型相对于经典的线性模型$(y=wx+b)$，核心在于引入了连接函数 $g(\cdot)$，形式变为: $y=g-1(wx+b)$。<br>&emsp;&emsp;<br>深度学习时递归的广义线性模型，神经元的激活函数，即为广义线性模型的链接函数。逻 辑回归(广义线性模型的一种)的 Logistic 函数即为神经元激活函数中的 Sigmoid 函数，很多 类似的方法在统计学和神经网络中的名称不一样，容易引起困惑。</p><h2 id="13-7-造成梯度消失的原因"><a href="#13-7-造成梯度消失的原因" class="headerlink" title="13.7 造成梯度消失的原因?"></a>13.7 造成梯度消失的原因?</h2><p>&emsp;&emsp;<br>神经网络的训练中，通过改变神经元的权重，使网络的输出值尽可能逼近标签以降低误差 值，训练普遍使用 BP 算法，核心思想是，计算出输出与标签间的损失函数值，然后计算其相 对于每个神经元的梯度，进行权值的迭代。<br>&emsp;&emsp;<br>梯度消失会造成权值更新缓慢，模型训练难度增加。造成梯度消失的一个原因是，许多激 活函数将输出值挤压在很小的区间内，在激活函数两端较大范围的定义域内梯度为 $0$。造成学 习停止。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_7_1.png" alt="sigmoid 函数与其导数"></p><center>图 13.7 sigmoid 函数的梯度消失</center><h2 id="13-8-权值初始化方法有哪些？"><a href="#13-8-权值初始化方法有哪些？" class="headerlink" title="13.8 权值初始化方法有哪些？"></a>13.8 权值初始化方法有哪些？</h2><p>&emsp;&emsp;<br>权值初始化的方法主要有:常量初始化(constant)、高斯分布初始化(gaussian)、 positive_unitball 初始化、均匀分布初始化(uniform)、xavier 初始化、msra 初始化、双线性初 始化(bilinear)。  </p><p>&emsp;&emsp;<br><strong>1. 常量初始化(constant)</strong><br>&emsp;&emsp;<br>把权值或者偏置初始化为一个常数，具体是什么常数，可以自己定义。  </p><p>&emsp;&emsp;<br><strong>2. 高斯分布初始化(gaussian)</strong><br>&emsp;&emsp;<br>需要给定高斯函数的均值与标准差。  </p><p>&emsp;&emsp;<br><strong>3. positive_unitball 初始化</strong><br>&emsp;&emsp;<br>让每一个神经元的输入的权值和为 $1$，例如:一个神经元有 $100$ 个输入，让这 $100$ 个输入<br>的权值和为 $1$. 首先给这 $100$ 个权值赋值为在$(0,1)$之间的均匀分布，然后，每一个权值再 除以它们的和就可以啦。这么做，可以有助于防止权值初始化过大，从而防止激活函数(sigmoid 函数)进入饱和区。所以，它应该比较适合 simgmoid 形的激活函数。  </p><p>&emsp;&emsp;<br><strong>4. 均匀分布初始化(uniform)</strong><br>&emsp;&emsp;<br>将权值与偏置进行均匀分布的初始化，用 min 与 max 控制它们的的上下限，默认为$(0,1)$。  </p><p>&emsp;&emsp;<br><strong>5. xavier 初始化</strong><br>&emsp;&emsp;<br>对于权值的分布:均值为 $0$，方差为($1$ / 输入的个数)的均匀分布。如果我们更注重前<br>向传播的话，我们可以选择 fan_in，即正向传播的输入个数;如果更注重后向传播的话，我们选择 fan_out, 因为在反向传播的时候，fan_out 就是神经元的输入个数;如果两者都考虑的话， 就选 average = (fan_in + fan_out) /$2$。对于 ReLU 激活函数来说，XavierFiller 初始化也是很适合。关于该初始化方法，具体可以参考文章1、文章2，该方法假定激活函数是线性的。  </p><p>&emsp;&emsp;<br><strong>6. msra 初始化</strong><br>&emsp;&emsp;<br>对于权值的分布:基于均值为 $0$，方差为( $2$/输入的个数)的高斯分布;它特别适合 ReLU 激活函数，该方法主要是基于 Relu 函数提出的，推导过程类似于 xavier。  </p><p>&emsp;&emsp;<br><strong>7. 双线性初始化（bilinear）</strong><br>&emsp;&emsp;<br>常用在反卷积神经网络里的权值初始化。</p><h2 id="13-9-启发式优化算法中，如何避免陷入局部最优解"><a href="#13-9-启发式优化算法中，如何避免陷入局部最优解" class="headerlink" title="13.9 启发式优化算法中，如何避免陷入局部最优解?"></a>13.9 启发式优化算法中，如何避免陷入局部最优解?</h2><p>&emsp;&emsp;<br>启发式算法中，局部最优值的陷入无法避免。启发式，本质上是一种贪心策略，这也在客 观上决定了不符合贪心规则的更好(或者最优)解会错过。<br>&emsp;&emsp;<br>简单来说，避免陷入局部最优就是两个字:随机。<br>&emsp;&emsp;<br>具体实现手段上，可以根据所采用的启发式框架来灵活地加入随机性。比如遗传里面，可 以在交叉变异时，可以在控制人口策略中，也可以在选择父本母本样本时;禁忌里面，可以在 禁忌表的长度上体现，也可以在解禁策略中使用，等等。这些都要结合具体问题特定的算例集， 需要反复尝试摸索才行。参数的敏感性是一个问题，建议不要超过 $3$ 个参数，参数越不敏感越好。不同算例集用不同种子运行多次($100$ 次左右才有统计意义)，统计平均性能即可。需注 意全局的随机重启通常来说不是一个好办法，因为等于主动放弃之前搜索结果，万不得已不要 用，或者就是不用。</p><p>&emsp;&emsp;<br><strong>三个原则应该把握:越随机越好;越不随机越好;二者平衡最好。</strong></p><p>&emsp;&emsp;<br><strong>1. 越随机越好</strong><br>&emsp;&emsp;<br>没有随机性，一定会陷入局部最优。为了获得更大的找到最优解的期望，算法中一定要有<br>足够的随机性。具体体现为鲁棒性较好，搜索时多样性较好。算法的每一步选择都可以考虑加入随机性，但要控制好概率。比如，某个贪心策略下，是以概率 $1 $做某一动作，可以考虑将其 改为以概率 $0.999$ 做之前的操作，以剩余概率做其他操作。具体参数设置需调试。</p><p>&emsp;&emsp;<br><strong>2. 越不随机越好</strong><br>&emsp;&emsp;<br>随机性往往是对问题内在规律的一种妥协。即没有找到其内在规律，又不知道如何是好， 为了获得更好的多样性，逼不得已加入随机。因此，对给定问题的深入研究才是根本:分辨出 哪些时候，某个动作就是客观上能严格保证最优的——这点至关重要，直接决定了算法性能。 最好的算法一定是和问题结构紧密相连的，范范地套用某个启发式的框架不会有出色的性能。 当然，如果不是追求性能至上，而是考虑到开发效率实现成本这些额外因素，则另当别论。</p><p>&emsp;&emsp;<br><strong>3. 二者平衡最好</strong><br>&emsp;&emsp;<br>通常情况下，做好第一点，可以略微改善算法性能;做好第二点，有希望给算法带来质的提高。而二者调和后的平衡则会带来质的飞跃。</p><p>&emsp;&emsp;<br>贪心是“自强不息”的精进，不放过任何改进算法的机会;多样性的随机是“厚德载物”的一分包 容，给那些目前看似不那么好的解一些机会。调和好二者，不偏颇任何一方才能使算法有出色 的性能。要把握这种平衡，非一朝一夕之功，只能在反复试验反思中去细细品味。<br>&emsp;&emsp;<br>要结合具体问题而言，范范空谈无太大用。</p><h2 id="13-10-凸优化中如何改进-GD-方法以防止陷入局部最优解"><a href="#13-10-凸优化中如何改进-GD-方法以防止陷入局部最优解" class="headerlink" title="13.10 凸优化中如何改进 GD 方法以防止陷入局部最优解?"></a>13.10 凸优化中如何改进 GD 方法以防止陷入局部最优解?</h2><p>&emsp;&emsp;<br>在对函数进行凸优化时，如果使用导数的方法(如:梯度下降法/GD，牛顿法等)来寻找最优解，有可能陷入到局部最优解而非全局最优解。<br>&emsp;&emsp;<br>为了防止得到局部最优，可以对梯度下降法进行一些改进，防止陷入局部最优。<br>&emsp;&emsp;<br>但是请注意，这些方法只能保证以最大的可能找到全局最优，无法保证 $100\%$得到全局最优。</p><p>&emsp;&emsp;<br><strong>（1）incremental GD/stochastic GD</strong><br>&emsp;&emsp;<br>在 GD 中，是需要遍历所有的点之后才计算 $w$ 的变化的;但是，在 stochastic GD 中，每输入一个点，就根据该点计算下一步的 $w$，这样，不仅可以从 batch training 变成 online training 方法，而且每次是按照单点的最优方向而不是整体的最优方向前进，从而相当于在朝目标前进的路上多拐了好多弯，有可能逃出局部最优。</p><p>&emsp;&emsp;<br><strong>（2）momentum 方法</strong><br>&emsp;&emsp;<br>momentum 相当与记忆住上一次的更新。在每次的更新中，都要加一个 $k$ 倍的上一次更新 量。这样，也不再是按照标准路线前进，每次的步骤都容易受到上一次的影响，从而可能会逃 出局部最优。另外，也会加大步长，从而加快收敛。</p><h2 id="13-11-常见的损失函数"><a href="#13-11-常见的损失函数" class="headerlink" title="13.11 常见的损失函数?"></a>13.11 常见的损失函数?</h2><p>&emsp;&emsp;<br>机器学习通过对算法中的目标函数进行不断求解优化，得到最终想要的结果。分类和回归 问题中，通常使用损失函数或代价函数作为目标函数。<br>&emsp;&emsp;<br>损失函数用来评价预测值和真实值不一样的程度。通常损失函数越好，模型的性能也越好。<br>&emsp;&emsp;<br>损失函数可分为经验风险损失函数和结构风险损失函数。经验风险损失函数指预测结果和 实际结果的差别，结构风险损失函数是在经验风险损失函数上加上正则项。  </p><p>&emsp;&emsp;<br>下面介绍常用的损失函数:</p><p>&emsp;&emsp;<br><strong>1）$0-1$ 损失函数</strong><br>&emsp;&emsp;<br>如果预测值和目标值相等，值为 $0$，如果不相等，值为 $1$：<br>$$<br>L(Y,f(x))=<br>\left{<br>\begin{array}{}<br>1\;\;\;,\;\;Y\ne f(x), \<br>0\;\;\;,\;\;Y=f(x).<br>\end{array}<br>\right.<br>$$</p><p>&emsp;&emsp;<br>一般的在实际使用中，相等的条件过于严格，可适当放宽条件：<br>$$<br>L(Y,f(x))=<br>\left{<br>\begin{array}{}<br>1\;\;\;,\;\;|Y - f(x)| \ge T, \<br>0\;\;\;,\;\;|Y-f(x)| &lt; T.<br>\end{array}<br>\right.<br>$$</p><p>&emsp;&emsp;<br><strong>2）绝对值损失函数</strong><br>&emsp;&emsp;<br>和 $0-1$ 损失函数相似，绝对值损失函数表示为：<br>$$<br>L(Y,f(x))=|Y-f(x)|.<br>$$</p><p>&emsp;&emsp;<br><strong>3）平方损失函数</strong><br>$$<br>L(Y|f(x))=\sum_{N}(Y-f(x))^2.<br>$$</p><p>&emsp;&emsp;<br>这点可从最小二乘法和欧几里得距离角度理解。最小二乘法的原理是，最优拟合曲线应该 使所有点到回归直线的距离和最小。</p><p>&emsp;&emsp;<br><strong>4）$log$ 对数损失函数</strong><br>$$<br>L(Y,P(Y|X))=-logP(Y|X).<br>$$</p><p>&emsp;&emsp;<br>常见的逻辑回归使用的就是对数损失函数，有很多人认为逻辑回归的损失函数式平方损失， 其实不然。逻辑回归它假设样本服从伯努利分布，进而求得满足该分布的似然函数，接着取对 数求极值等。逻辑回归推导出的经验风险函数是最小化负的似然函数，从损失函数的角度看， 就是 $log$ 损失函数。</p><p>&emsp;&emsp;<br><strong>5）指数损失函数</strong><br>&emsp;&emsp;<br>指数损失函数的标准形式为：<br>$$<br>L(Y|f(x))=exp[-yf(x)].<br>$$</p><p>&emsp;&emsp;<br>例如 AdaBoost 就是以指数损失函数为损失函数。</p><p>&emsp;&emsp;<br><strong>6）Hinge 损失函数</strong><br>&emsp;&emsp;<br>Hinge 损失函数的标准形式如下：<br>$$<br>L(y)=max(0, 1-ty).<br>$$</p><p>&emsp;&emsp;<br>其中 $y$ 是预测值，范围为$(-1,1)$, $t$ 为目标值，其为$-1$ 或 $1$。<br>&emsp;&emsp;<br>在线性支持向量机中，最优化问题可等价于：<br>$$<br>\underset{w,b}{min}\sum_{i=1}^{N}(1-y_i(wx_i+b))+\lambda \lVert w^2 \rVert<br>$$</p><p>&emsp;&emsp;<br>$$<br>\frac{1}{m}\sum_{i=1}^{N}l(wx_i+by_i))+\lVert w^2 \rVert<br>$$</p><p>&emsp;&emsp;<br>其中$l(wx_i+by_i))$是Hinge损失函数，$\lVert w^2 \rVert$可看做为正则化项。</p><h2 id="13-14-如何进行特征选择-feature-selection"><a href="#13-14-如何进行特征选择-feature-selection" class="headerlink" title="13.14 如何进行特征选择(feature selection)?"></a>13.14 如何进行特征选择(feature selection)?</h2><h3 id="13-14-1-如何考虑特征选择"><a href="#13-14-1-如何考虑特征选择" class="headerlink" title="13.14.1 如何考虑特征选择"></a>13.14.1 如何考虑特征选择</h3><p>&emsp;&emsp;<br>当数据预处理完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。通常来说，从两个方面考虑来选择特征:</p><p>&emsp;&emsp;<br>（1）特征是否发散:如果一个特征不发散，例如方差接近于 $0$，也就是说样本在这个特 征上基本上没有差异，这个特征对于样本的区分并没有什么用。<br>&emsp;&emsp;<br>（2）特征与目标的相关性:这点比较显见，与目标相关性高的特征，应当优选选择。除移除低方差法外，本文介绍的其他方法均从相关性考虑。</p><h3 id="13-14-2-特征选择方法分类"><a href="#13-14-2-特征选择方法分类" class="headerlink" title="13.14.2 特征选择方法分类"></a>13.14.2 特征选择方法分类</h3><p>&emsp;&emsp;<br>根据特征选择的形式又可以将特征选择方法分为 $3$ 种:</p><p>&emsp;&emsp;<br>（1）Filter:过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择<br>阈值的个数，选择特征。<br>&emsp;&emsp;<br>（2）Wrapper:包装法，根据目标函数(通常是预测效果评分)，每次选择若干特征，或<br>者排除若干特征。<br>&emsp;&emsp;<br>（3）Embedded:嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于 Filter 方法，但是是通过训练来确定特征的优劣。</p><h3 id="13-14-3-特征选择目的"><a href="#13-14-3-特征选择目的" class="headerlink" title="13.14.3 特征选择目的"></a>13.14.3 特征选择目的</h3><p>&emsp;&emsp;<br>（1）减少特征数量、降维，使模型泛化能力更强，减少过拟合;<br>&emsp;&emsp;<br>（2）增强对特征和特征值之间的理解。拿到数据集，一个特征选择方法，往往很难同时完成这两个目的。通常情况下，选择一种自己最熟悉或者最方便的特征选择方法(往往目的是降维，而忽略了对特征和数据理解的目的)。 本文将结合 Scikit-learn 提供的例子介绍几种常用的特征选择方法，它们各自的优缺点和问题。</p><h2 id="13-15-梯度消失-梯度爆炸原因，以及解决方法"><a href="#13-15-梯度消失-梯度爆炸原因，以及解决方法" class="headerlink" title="13.15 梯度消失/梯度爆炸原因，以及解决方法"></a>13.15 梯度消失/梯度爆炸原因，以及解决方法</h2><h3 id="13-15-1-为什么要使用梯度更新规则"><a href="#13-15-1-为什么要使用梯度更新规则" class="headerlink" title="13.15.1 为什么要使用梯度更新规则?"></a>13.15.1 为什么要使用梯度更新规则?</h3><p>&emsp;&emsp;<br>在介绍梯度消失以及爆炸之前，先简单说一说梯度消失的根源—–深度神经网络和反向传 播。目前深度学习方法中，深度神经网络的发展造就了我们可以构建更深层的网络完成更复杂 的任务，深层网络比如深度卷积网络，LSTM 等等，而且最终结果表明，在处理复杂任务上， 深度网络比浅层的网络具有更好的效果。但是，目前优化神经网络的方法都是基于反向传播的 思想，即根据损失函数计算的误差通过梯度反向传播的方式，指导深度网络权值的更新优化。 这样做是有一定原因的，首先，深层网络由许多非线性层堆叠而来，每一层非线性层都可以视 为是一个非线性函数 $f(x)$（$f(x)$非线性来自于非线性激活函数），因此整个深度网络可以视为是一个复合的非线性多元函数：<br>$$F(x)=f_n(\cdots f_3(f_2(f_1(x)<em>\theta_1+b)</em>\theta_2+b)\cdots)$$</p><p>&emsp;&emsp;<br>我们最终的目的是希望这个多元函数可以很好的完成输入到输出之间的映射，假设不同的输入，输出的最优解是$g(x)$ ，那么，优化深度网络就是为了寻找到合适的权值，满足 $Loss=L(g(x),F(x))$取得极小值点，比如最简单的损失函数：<br>$$<br>Loss = \lVert g(x)-f(x) \rVert^2_2.<br>$$</p><p>&emsp;&emsp;<br>假设损失函数的数据空间是下图这样的，我们最优的权值就是为了寻找下图中的最小值点， 对于这种数学寻找最小值问题，采用梯度下降的方法再适合不过了。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_15_1.png" alt=""></p><center>图 13.15.1 </center><h3 id="13-15-2-梯度消失、爆炸原因"><a href="#13-15-2-梯度消失、爆炸原因" class="headerlink" title="13.15.2 梯度消失、爆炸原因?"></a>13.15.2 梯度消失、爆炸原因?</h3><p>&emsp;&emsp;<br>梯度消失与梯度爆炸其实是一种情况，看接下来的文章就知道了。两种情况下梯度消失经 常出现，一是在深层网络中，二是采用了不合适的损失函数，比如 sigmoid。梯度爆炸一般出 现在深层网络和权值初始化值太大的情况下，下面分别从这两个角度分析梯度消失和爆炸的原因。</p><p>&emsp;&emsp;<br>（1）深层网络角度<br>&emsp;&emsp;<br>对激活函数进行求导，如果此部分大于 $1$，那么层数增多的时候，最终的求出的梯度更新 将以指数形式增加，即发生<strong>梯度爆炸</strong>，如果此部分小于 $1$，那么随着层数增多，求出的梯度更 新信息将会以指数形式衰减，即发生了<strong>梯度消失</strong>。<br>&emsp;&emsp;<br>从深层网络角度来讲，不同的层学习的速度差异很大，表现为网络中靠近输出的层学习的 情况很好，靠近输入的层学习的很慢，有时甚至训练了很久，前几层的权值和刚开始随机初始 化的值差不多。因此，梯度消失、爆炸，其根本原因在于反向传播训练法则，属于先天不足， 另外多说一句，Hinton 提出 capsule 的原因就是为了彻底抛弃反向传播，如果真能大范围普及， 那真是一个革命。  </p><p>&emsp;&emsp;<br>（2）激活函数角度<br>&emsp;&emsp;<br>计算权值更新信息的时候需要计算前层偏导信息，因此如果激活函数选择不合适，比如使用 sigmoid，梯度消失就会很明显了，原因看下图，左图是sigmoid的损失函数图，右边是其倒数的图像，如果使用 sigmoid 作为损失函数，其梯度是不可能超过 $0.25$ 的，这样经过链式求导之后，很容易发生梯度消失。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_15_2.png" alt=""></p><center>图 13.15.2 sigmod函数与其导数</center><h3 id="13-15-3-梯度消失、爆炸的解决方案"><a href="#13-15-3-梯度消失、爆炸的解决方案" class="headerlink" title="13.15.3 梯度消失、爆炸的解决方案"></a>13.15.3 梯度消失、爆炸的解决方案</h3><p>&emsp;&emsp;<br><strong>方案1-预训练加微调</strong><br>&emsp;&emsp;<br>此方法来自Hinton在2006年发表的一篇论文，Hinton为了解决梯度的问题，提出采取无监督逐层训练方法，其基本思想是每次训练一层隐节点，训练时将上一层隐节点的输出作为输入，而本层隐节点的输出作为下一层隐节点的输入，此过程就是逐层“预训练”（pre-training）；在预训练完成后，再对整个网络进行“微调”（fine-tunning）。Hinton在训练深度信念网络（Deep Belief Networks中，使用了这个方法，在各层预训练完成后，再利用BP算法对整个网络进行训练。此思想相当于是先寻找局部最优，然后整合起来寻找全局最优，此方法有一定的好处，但是目前应用的不是很多了。</p><p>&emsp;&emsp;<br><strong>方案2-梯度剪切、正则</strong><br>&emsp;&emsp;<br>梯度剪切这个方案主要是针对梯度爆炸提出的，其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。<br>&emsp;&emsp;<br>另外一种解决梯度爆炸的手段是采用权重正则化（weithts regularization）比较常见的是l1l1正则，和l2l2正则，在各个深度框架中都有相应的API可以使用正则化。</p><p>&emsp;&emsp;<br><strong>方案3-relu、leakrelu、elu等激活函数</strong><br>&emsp;&emsp;<br><strong>Relu</strong><br>&emsp;&emsp;<br>思想也很简单，如果激活函数的导数为1，那么就不存在梯度消失爆炸的问题了，每层的网络都可以得到相同的更新速度，relu就这样应运而生。<br>&emsp;&emsp;<br>relu函数的导数在正数部分是恒等于1的，因此在深层网络中使用relu激活函数就不会导致梯度消失和爆炸的问题。<br>relu的主要贡献在于：<br>&emsp;&emsp;<br>（1）解决了梯度消失、爆炸的问题<br>&emsp;&emsp;<br>（2）计算方便，计算速度快<br>&emsp;&emsp;<br>（3）加速了网络的训练  </p><p>&emsp;&emsp;<br>同时也存在一些缺点：<br>&emsp;&emsp;<br>（1）由于负数部分恒为0，会导致一些神经元无法激活（可通过设置小学习率部分解决）；<br>&emsp;&emsp;<br>（2）输出不是以0为中心的。  </p><p>&emsp;&emsp;<br><strong>leakrelu</strong><br>&emsp;&emsp;<br>leakrelu就是为了解决relu的0区间带来的影响，其数学表达为：leakrelu$=max(k*x,0)$其中$k$是leak系数，一般选择$0.01$或者$0.02$，或者通过学习而来。</p><p>&emsp;&emsp;<br><strong>方案4-batchnorm</strong><br>&emsp;&emsp;<br>Batchnorm是深度学习发展以来提出的最重要的成果之一了，目前已经被广泛的应用到了各大网络中，具有加速网络收敛速度，提升训练稳定性的效果，Batchnorm本质上是解决反向传播过程中的梯度问题。Batchnorm全名是Batch Normalization，简称BN，即批规范化，通过规范化操作将输出信号$x$规范化到均值为$0$，方差为$1$保证网络的稳定性。  </p><p>&emsp;&emsp;<br><strong>方案5-残差结构</strong><br>&emsp;&emsp;<br>事实上，就是残差网络的出现导致了Imagenet比赛的终结，自从残差提出后，几乎所有的深度网络都离不开残差的身影，相比较之前的几层，几十层的深度网络，在残差网络面前都不值一提，残差可以很轻松的构建几百层，一千多层的网络而不用担心梯度消失过快的问题，原因就在于残差的捷径（shortcut）部分。</p><p>&emsp;&emsp;<br><strong>方案6-LSTM</strong><br>&emsp;&emsp;<br>LSTM全称是长短期记忆网络（long-short term memory networks），是不那么容易发生梯度消失的，主要原因在于LSTM内部复杂的“门”(gates)。</p><h2 id="13-16-深度学习为什么不用二阶优化"><a href="#13-16-深度学习为什么不用二阶优化" class="headerlink" title="13.16 深度学习为什么不用二阶优化"></a>13.16 深度学习为什么不用二阶优化</h2><ol><li>二阶优化方法可以用到深度学习网络中，比如DistBelief，《Large-scale L-BFGS using MapReduce》.采用了数据并行的方法解决了海量数据下L-BFGS算法的可用性问题。</li><li>二阶优化方法目前还不适用于深度学习训练中，主要存在问题是：<br>（1）最重要的问题是二阶方法的计算量大，训练较慢。<br>（2）求导不易，实现比SGD这类一阶方法复杂。<br>（3）另外其优点在深度学习中无法展现出来，主要是二阶方法能够更快地求得更高精度的解，这在浅层模型是有益的，但是在神经网络这类深层模型中对参数的精度要求不高，相反 相对而言不高的精度对模型还有益处，能够提高模型的泛化能力。<br>（4）稳定性。题主要明白的一点事，越简单的东西往往越robust，对于优化算法也是这样。梯度下降等一阶算法只要步长不选太大基本都不会出问题，但二阶方法遍地是坑，数值稳定性啊等等。</li></ol><h2 id="13-17-怎样优化你的深度学习系统？"><a href="#13-17-怎样优化你的深度学习系统？" class="headerlink" title="13.17 怎样优化你的深度学习系统？"></a>13.17 怎样优化你的深度学习系统？</h2><p>&emsp;&emsp;<br>你可能有很多想法去改善你的系统，比如，你可能想我们去收集更多的训练数据吧。或者你会说，可能你的训练集的多样性还不够，你应该收集更多不同姿势的猫咪图片，或者更多样化的反例集。或者你想再用梯度下降训练算法，训练久一点。或者你想尝试用一个完全不同的优化算法，比如Adam优化算法。或者尝试使用规模更大或者更小的神经网络。或者你想试试dropout或者正则化。或者你想修改网络的架构，比如修改激活函数，改变隐藏单元的数目之类的方法。</p><p>&emsp;&emsp;<br>当你尝试优化一个深度学习系统时，你通常可以有很多想法可以去试，问题在于，如果你做出了错误的选择，你完全有可能白费6个月的时间，往错误的方向前进，在6个月之后才意识到这方法根本不管用。比如，我见过一些团队花了6个月时间收集更多数据，却在6个月之后发现，这些数据几乎没有改善他们系统的性能。所以，假设你的项目没有6个月的时间可以浪费，如果有快速有效的方法能够判断哪些想法是靠谱的，或者甚至提出新的想法，判断哪些是值得一试的想法，哪些是可以放心舍弃的。</p><p>&emsp;&emsp;<br>我希望在这门课程中，可以教给你们一些策略，一些分析机器学习问题的方法，可以指引你们朝着最有希望的方向前进。这门课中，我会和你们分享我在搭建和部署大量深度学习产品时学到的经验和教训，我想这些内容是这门课程独有的。比如说，很多大学深度学习课程很少提到这些策略。事实上，机器学习策略在深度学习的时代也在变化，因为现在对于深度学习算法来说能够做到的事情，比上一代机器学习算法大不一样。我希望这些策略能帮助你们提高效率，让你们的深度学习系统更快投入实用。</p><h2 id="13-18-为什么要设置单一数字评估指标？"><a href="#13-18-为什么要设置单一数字评估指标？" class="headerlink" title="13.18 为什么要设置单一数字评估指标？"></a>13.18 为什么要设置单一数字评估指标？</h2><p>&emsp;&emsp;<br>无论你是调整超参数，或者是尝试不同的学习算法，或者在搭建机器学习系统时尝试不同手段，你会发现，如果你有一个单实数评估指标，你的进展会快得多，它可以快速告诉你，新尝试的手段比之前的手段好还是差。所以当团队开始进行机器学习项目时，我经常推荐他们为问题设置一个单实数评估指标。</p><p>&emsp;&emsp;<br>我发现很多机器学习团队就是这样，有一个定义明确的开发集用来测量查准率和查全率，再加上这样一个单一数值评估指标，有时我叫单实数评估指标，能让你快速判断分类器或者分类器更好。所以有这样一个开发集，加上单实数评估指标，你的迭代速度肯定会很快，它可以加速改进您的机器学习算法的迭代过程。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_18_1.png" alt=""></p><center>图 13.8.1 </center><h2 id="13-19-满足和优化指标（Satisficing-and-optimizing-metrics）"><a href="#13-19-满足和优化指标（Satisficing-and-optimizing-metrics）" class="headerlink" title="13.19 满足和优化指标（Satisficing and optimizing metrics）"></a>13.19 满足和优化指标（Satisficing and optimizing metrics）</h2><p>&emsp;&emsp;<br>要把你顾及到的所有事情组合成单实数评估指标有时并不容易，在那些情况里，我发现有时候设立满足和优化指标是很重要的，让我告诉你是什么意思吧。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_19_1.png" alt=""></p><center>图 13.9.1 </center><p>&emsp;&emsp;<br>假设你已经决定你很看重猫分类器的分类准确度，这可以是分数或者用其他衡量准确度的指标。但除了准确度之外，我们还需要考虑运行时间，就是需要多长时间来分类一张图。分类器需要$80$毫秒，需要$95$毫秒，C需要$1500$毫秒，就是说需要$1.5$秒来分类图像。  </p><p>&emsp;&emsp;<br>你可以这么做，将准确度和运行时间组合成一个整体评估指标。所以成本，比如说，总体成本是，这种组合方式可能太刻意，只用这样的公式来组合准确度和运行时间，两个数值的线性加权求和。   </p><p>&emsp;&emsp;<br>你还可以做其他事情，就是你可能选择一个分类器，能够最大限度提高准确度，但必须满足运行时间要求，就是对图像进行分类所需的时间必须小于等于$100$毫秒。所以在这种情况下，我们就说准确度是一个优化指标，因为你想要准确度最大化，你想做的尽可能准确，但是运行时间就是我们所说的满足指标，意思是它必须足够好，它只需要小于$100$毫秒，达到之后，你不在乎这指标有多好，或者至少你不会那么在乎。所以这是一个相当合理的权衡方式，或者说 将准确度和运行时间结合起来的方式。实际情况可能是，只要运行时间少于 100 毫秒，你的用 户就不会在乎运行时间是 100 毫秒还是 50 毫秒，甚至更快。  </p><p>&emsp;&emsp;<br>通过定义优化和满足指标，就可以给你提供一个明确的方式，去选择“最好的”分类器。在 这种情况下分类器 B 最好，因为在所有的运行时间都小于 100 毫秒的分类器中，它的准确度最好。  </p><p>&emsp;&emsp;<br>总结一下，如果你需要顾及多个指标，比如说，有一个优化指标，你想尽可能优化的，然 后还有一个或多个满足指标，需要满足的，需要达到一定的门槛。现在你就有一个全自动的方 法，在观察多个成本大小时，选出”最好的”那个。现在这些评估指标必须是在训练集或开发集 或测试集上计算或求出来的。所以你还需要做一件事，就是设立训练集、开发集，还有测试集。 在下一个视频里，我想和大家分享一些如何设置训练、开发和测试集的指导方针，我们下一个 视频继续。</p><h2 id="13-20-怎样划分训练-开发-测试集"><a href="#13-20-怎样划分训练-开发-测试集" class="headerlink" title="13.20 怎样划分训练/开发/测试集"></a>13.20 怎样划分训练/开发/测试集</h2><p>&emsp;&emsp;<br>设立训练集，开发集和测试集的方式大大影响了你或者你的团队在建立机器学习应用方面取得进展的速度。同样的团队，即使是大公司里的团队，在设立这些数据集的方式，真的会让团队的进展变慢而不是加快，我们看看应该如何设立这些数据集，让你的团队效率最大化。  </p><p>&emsp;&emsp;<br>我建议你们不要这样，而是让你的开发集和测试集来自同一分布。我的意思是这样，你们要记住，我想就是设立你的开发集加上一个单实数评估指标，这就是像是定下目标，然后告诉你的团队，那就是你要瞄准的靶心，因为你一旦建立了这样的开发集和指标，团队就可以快速迭代，尝试不同的想法，跑实验，可以很快地使用开发集和指标去评估不同分类器，然后尝试选出最好的那个。所以，机器学习团队一般都很擅长使用不同方法去逼近目标，然后不断迭代，不断逼近靶心。所以，针对开发集上的指标优化。  </p><p>&emsp;&emsp;<br>所以我建议你们在设立开发集和测试集时，要选择这样的开发集和测试集，能够反映你未来会得到的数据，认为很重要的数据，必须得到好结果的数据，特别是，这里的开发集和测试集可能来自同一个分布。所以不管你未来会得到什么样的数据，一旦你的算法效果不错，要尝试收集类似的数据，而且，不管那些数据是什么，都要随机分配到开发集和测试集上。因为这样，你才能将瞄准想要的目标，让你的团队高效迭代来逼近同一个目标，希望最好是同一个目标。  </p><p>&emsp;&emsp;<br>我们还没提到如何设立训练集，我们会在之后的视频里谈谈如何设立训练集，但这个视频的重点在于，设立开发集以及评估指标，真的就定义了你要瞄准的目标。我们希望通过在同一分布中设立开发集和测试集，你就可以瞄准你所希望的机器学习团队瞄准的目标。而设立训练集的方式则会影响你逼近那个目标有多快，但我们可以在另一个讲座里提到。我知道有一些机器学习团队，他们如果能遵循这个方针，就可以省下几个月的工作，所以我希望这些方针也能帮到你们。  </p><p>&emsp;&emsp;<br>接下来，实际上你的开发集和测试集的规模，如何选择它们的大小，在深度学习时代也在变化，我们会在下一个视频里提到这些内容。</p><h2 id="13-21-如何划分开发-测试集大小"><a href="#13-21-如何划分开发-测试集大小" class="headerlink" title="13.21 如何划分开发/测试集大小"></a>13.21 如何划分开发/测试集大小</h2><p>&emsp;&emsp;<br>你可能听说过一条经验法则，在机器学习中，把你取得的全部数据用$70/30$比例分成训练集和测试集。或者如果你必须设立训练集、开发集和测试集，你会这么分$60\%$训练集，$20\%$开发集，$20\%$测试集。在机器学习的早期，这样分是相当合理的，特别是以前的数据集大小要小得多。所以如果你总共有100个样本，这样$70/30$或者$60/20/20$分的经验法则是相当合理的。如果你有几千个样本或者有一万个样本，这些做法也还是合理的。  </p><p>&emsp;&emsp;<br>但在现代机器学习中，我们更习惯操作规模大得多的数据集，比如说你有$1$百万个训练样本，这样分可能更合理，$98\%$作为训练集，$1\%$开发集，$1\%$测试集，我们用和缩写来表示开发集和测试集。因为如果你有$1$百万个样本，那么$1\%$就是$10,000$个样本，这对于开发集和测试集来说可能已经够了。所以在现代深度学习时代，有时我们拥有大得多的数据集，所以使用小于$20\%$的比例或者小于$30\%$比例的数据作为开发集和测试集也是合理的。而且因为深度学习算法对数据的胃口很大，我们可以看到那些有海量数据集的问题，有更高比例的数据划分到训练集里，那么测试集呢？   </p><p>&emsp;&emsp;<br>总结一下，在大数据时代旧的经验规则，这个$70/30$不再适用了。现在流行的是把大量数据分到训练集，然后少量数据分到开发集和测试集，特别是当你有一个非常大的数据集时。以前的经验法则其实是为了确保开发集足够大，能够达到它的目的，就是帮你评估不同的想法，然后选出还是更好。测试集的目的是评估你最终的成本偏差，你只需要设立足够大的测试集，可以用来这么评估就行了，可能只需要远远小于总体数据量的$30\%$。  </p><p>&emsp;&emsp;<br>所以我希望本视频能给你们一点指导和建议，让你们知道如何在深度学习时代设立开发和测试集。接下来，有时候在研究机器学习的问题途中，你可能需要更改评估指标，或者改动你的开发集和测试集，我们会讲什么时候需要这样做。</p><h2 id="13-22-什么时候该改变开发-测试集和指标？"><a href="#13-22-什么时候该改变开发-测试集和指标？" class="headerlink" title="13.22 什么时候该改变开发/测试集和指标？"></a>13.22 什么时候该改变开发/测试集和指标？</h2><p>&emsp;&emsp;<br>我们来看一个例子，假设你在构建一个猫分类器，试图找到很多猫的照片，向你的爱猫人士用户展示，你决定使用的指标是分类错误率。所以算法和分别有3％错误率和5％错误率，所以算法似乎做得更好。  </p><p>&emsp;&emsp;<br>但我们实际试一下这些算法，你观察一下这些算法，算法由于某些原因，把很多色情图像分类成猫了。如果你部署算法，那么用户就会看到更多猫图，因为它识别猫的错误率只有$3\%$，但它同时也会给用户推送一些色情图像，这是你的公司完全不能接受的，你的用户也完全不能接受。相比之下，算法有$5\%$的错误率，这样分类器就得到较少的图像，但它不会推送色情图像。所以从你们公司的角度来看，以及从用户接受的角度来看，算法实际上是一个更好的算法，因为它不让任何色情图像通过。  </p><p>&emsp;&emsp;<br>那么在这个例子中，发生的事情就是，算法A在评估指标上做得更好，它的错误率达到$3\%$，但实际上是个更糟糕的算法。在这种情况下，评估指标加上开发集它们都倾向于选择算法，因为它们会说，看算法A的错误率较低，这是你们自己定下来的指标评估出来的。但你和你的用户更倾向于使用算法，因为它不会将色情图像分类为猫。所以当这种情况发生时，当你的评估指标无法正确衡量算法之间的优劣排序时，在这种情况下，原来的指标错误地预测算法A是更好的算法这就发出了信号，你应该改变评估指标了，或者要改变开发集或测试集。在这种情况下，你用的分类错误率指标可以写成这样：  </p><p>&emsp;&emsp;<br>但粗略的结论是，如果你的评估指标无法正确评估好算法的排名，那么就需要花时间定义一个新的评估指标。这是定义评估指标的其中一种可能方式（上述加权法）。评估指标的意义在于，准确告诉你已知两个分类器，哪一个更适合你的应用。就这个视频的内容而言，我们不需要太注重新错误率指标是怎么定义的，关键在于，如果你对旧的错误率指标不满意，那就不要一直沿用你不满意的错误率指标，而应该尝试定义一个新的指标，能够更加符合你的偏好，定义出实际更适合的算法。  </p><p>&emsp;&emsp;<br>所以方针是，如果你在指标上表现很好，在当前开发集或者开发集和测试集分布中表现很好，但你的实际应用程序，你真正关注的地方表现不好，那么就需要修改指标或者你的开发测试集。换句话说，如果你发现你的开发测试集都是这些高质量图像，但在开发测试集上做的评估无法预测你的应用实际的表现。因为你的应用处理的是低质量图像，那么就应该改变你的开发测试集，让你的数据更能反映你实际需要处理好的数据。  </p><p>&emsp;&emsp;<br>但总体方针就是，如果你当前的指标和当前用来评估的数据和你真正关心必须做好的事情关系不大，那就应该更改你的指标或者你的开发测试集，让它们能更够好地反映你的算法需要处理好的数据。</p><h2 id="13-23-设置评估指标的意义？"><a href="#13-23-设置评估指标的意义？" class="headerlink" title="13.23 设置评估指标的意义？"></a>13.23 设置评估指标的意义？</h2><p>&emsp;&emsp;<br>评估指标的意义在于，准确告诉你已知两个分类器，哪一个更适合你的应用。就这个视频的内容而言，我们不需要太注重新错误率指标是怎么定义的，关键在于，如果你对旧的错误率指标不满意，那就不要一直沿用你不满意的错误率指标，而应该尝试定义一个新的指标，能够更加符合你的偏好，定义出实际更适合的算法。</p><h2 id="13-24-什么是可避免偏差？"><a href="#13-24-什么是可避免偏差？" class="headerlink" title="13.24 什么是可避免偏差？"></a>13.24 什么是可避免偏差？</h2><p>&emsp;&emsp;<br><a href="http://www.ai-start.com/dl2017/lesson3-week1.html" target="_blank" rel="noopener">http://www.ai-start.com/dl2017/lesson3-week1.html</a></p><p>&emsp;&emsp;<br>所以要给这些概念命名一下，这不是广泛使用的术语，但我觉得这么说思考起来比较流畅。就是把这个差值，贝叶斯错误率或者对贝叶斯错误率的估计和训练错误率之间的差值称为可避免偏差，你可能希望一直提高训练集表现，直到你接近贝叶斯错误率，但实际上你也不希望做到比贝叶斯错误率更好，这理论上是不可能超过贝叶斯错误率的，除非过拟合。而这个训练错误率和开发错误率之前的差值，就大概说明你的算法在方差问题上还有多少改善空间。  </p><p>&emsp;&emsp;<br>可避免偏差这个词说明了有一些别的偏差，或者错误率有个无法超越的最低水平，那就是说如果贝叶斯错误率是$7.5\%$。你实际上并不想得到低于该级别的错误率，所以你不会说你的训练错误率是$8\%$，然后$8\%$就衡量了例子中的偏差大小。你应该说，可避免偏差可能在$0.5\%$左右，或者$0.5\%$是可避免偏差的指标。而这个$2\%$是方差的指标，所以要减少这个$2\%$比减少这个$0.5\%$空间要大得多。而在左边的例子中，这$7\%$衡量了可避免偏差大小，而$2\%$衡量了方差大小。所以在左边这个例子里，专注减少可避免偏差可能潜力更大。</p><h2 id="13-25-什么是TOP5错误率？"><a href="#13-25-什么是TOP5错误率？" class="headerlink" title="13.25 什么是TOP5错误率？"></a>13.25 什么是TOP5错误率？</h2><p>&emsp;&emsp;<br>top1就是你预测的label取最后概率向量里面最大的那一个作为预测结果，你的预测结果中概率最大的那个类必须是正确类别才算预测正确。而top5就是最后概率向量最大的前五名中出现了正确概率即为预测正确。  </p><p>&emsp;&emsp;<br>ImageNet 项目是一个用于物体对象识别检索大型视觉数据库。截止$2016$年，ImageNet 已经对超过一千万个图像的url进行手动注释，标记图像的类别。在至少一百万张图像中还提供了边界框。自$2010$年以来，ImageNet 举办一年一度的软件竞赛，叫做 ImageNet 大尺度视觉识别挑战(ImageNet Large Scale Visual Recognition Challenge,ILSVRC)。主要内容是通过算法程序实现正确分类和探测识别物体与场景，评价标准就是Top-5 错误率。  </p><p>&emsp;&emsp;<br>Top-5 错误率<br>&emsp;&emsp;<br>ILSRVRC（ImageNet 图像分类大赛） 比赛设置如下：$1000$类图像分类问题，训练数据集$126$万张图像，验证集$5$万张，测试集$10$万张（标注未公布）。评价标准采用 top-5 错误率——即对一张图像预测$5$个类别，只要有一个和人工标注类别相同就算对，否则算错。</p><h2 id="13-26-什么是人类水平错误率？"><a href="#13-26-什么是人类水平错误率？" class="headerlink" title="13.26 什么是人类水平错误率？"></a>13.26 什么是人类水平错误率？</h2><p>&emsp;&emsp;<br>人类水平错误率的定义，就是如果你想要替代或估计贝叶斯错误率，那么一队经验丰富的医生讨论和辩论之后，可以达到$0.5\%$的错误率。我们知道贝叶斯错误率小于等于$0.5\%$，因为有些系统，这些医生团队可以达到$0.5\%$的错误率。所以根据定义，最优错误率必须在$0.5\%$以下。我们不知道多少更好，也许有一个更大的团队，更有经验的医生能做得更好，所以也许比$0.5\%$好一点。但是我们知道最优错误率不能高于$0.5\%$，那么在这个背景下，我就可以用$0.5\%$估计贝叶斯错误率。所以我将人类水平定义为$0.5\%$，至少如果你希望使用人类水平错误来分析偏差和方差的时候，就像上个视频那样。  </p><p>&emsp;&emsp;<br>现在，为了发表研究论文或者部署系统，也许人类水平错误率的定义可以不一样，你可以使用1%，只要你超越了一个普通医生的表现，如果能达到这种水平，那系统已经达到实用了。也许超过一名放射科医生，一名医生的表现，意味着系统在一些情况下可以有部署价值了。</p><h2 id="13-27-可避免偏差、几大错误率之间的关系？"><a href="#13-27-可避免偏差、几大错误率之间的关系？" class="headerlink" title="13.27 可避免偏差、几大错误率之间的关系？"></a>13.27 可避免偏差、几大错误率之间的关系？</h2><p>&emsp;&emsp;<br>要了解为什么这个很重要，我们来看一个错误率分析的例子。比方说，在医学图像诊断例子中，你的训练错误率是$5\%$，你的开发错误率是$6\%$。而在上一张幻灯片的例子中，我们的人类水平表现，我将它看成是贝叶斯错误率的替代品，取决于你是否将它定义成普通单个医生的表现，还是有经验的医生或医生团队的表现，你可能会用$1\%$或$0.7\%$或$0.5\%$。同时也回想一下，前面视频中的定义，贝叶斯错误率或者说贝叶斯错误率的估计和训练错误率直接的差值就衡量了所谓的可避免偏差，这（训练误差与开发误差之间的差值）可以衡量或者估计你的学习算法的方差问题有多严重。  </p><p>&emsp;&emsp;<br>所以在这个第一个例子中，无论你做出哪些选择，可避免偏差大概是$4\%$，这个值我想介于……，如果你取$1\%$就是$4\%$，如果你取$0.5\%$就是$4.5\%$，而这个差距（训练误差与开发误差之间的差值）是$1\%$。所以在这个例子中，我得说，不管你怎么定义人类水平错误率，使用单个普通医生的错误率定义，还是单个经验丰富医生的错误率定义或经验丰富的医生团队的错误率定义，这是$4\%$还是$4.5\%$，这明显比都比方差问题更大。所以在这种情况下，你应该专注于减少偏差的技术，例如培训更大的网络。</p><h2 id="13-28-怎样选取可避免偏差及贝叶斯错误率"><a href="#13-28-怎样选取可避免偏差及贝叶斯错误率" class="headerlink" title="13.28 怎样选取可避免偏差及贝叶斯错误率?"></a>13.28 怎样选取可避免偏差及贝叶斯错误率?</h2><p>&emsp;&emsp;<br>就是比如你的训练错误率是0.7%，所以你现在已经做得很好了，你的开发错误率是$0.8\%$。在这种情况下，你用$0.5\%$来估计贝叶斯错误率关系就很大。因为在这种情况下，你测量到的可避免偏差是$0.2\%$，这是你测量到的方差问题$0.1\%$的两倍，这表明也许偏差和方差都存在问题。但是，可避免偏差问题更严重。在这个例子中，我们在上一张幻灯片中讨论的是$0.5\%$，就是对贝叶斯错误率的最佳估计，因为一群人类医生可以实现这一目标。如果你用$0.7$代替贝叶斯错误率，你测得的可避免偏差基本上是$0\%$，那你就可能忽略可避免偏差了。实际上你应该试试能不能在训练集上做得更好。</p><h2 id="13-29-怎样减少方差？"><a href="#13-29-怎样减少方差？" class="headerlink" title="13.29 怎样减少方差？"></a>13.29 怎样减少方差？</h2><p>&emsp;&emsp;<br>如果你的算法方差较高，可以尝试下面的技巧：  </p><p>&emsp;&emsp;<br>（1）增加训练数据：只要你可以获得大量数据和足够的算力去处理数据，这就是一种解决高方差问题最简单，最可靠的方式。<br>&emsp;&emsp;<br>（2）正则化（L2, L1, dropout）：这种技巧减少方差的同时，增加了偏差。<br>&emsp;&emsp;<br>（3）提前停止（例如，根据开发集的错误率来提前停止梯度下降）：这种技巧减少方差的同时增加的偏差。提前停止技巧很像正则化方法，一些论文作者也叫他正则化技巧。<br>&emsp;&emsp;<br>（4）特征选择来减少输入特征的数量或类型：这种技巧可能会处理好方差问题，但是同时会增大偏差。稍微减少特征数量（比如从1000个特征减少到900个特征）不太可能对偏差产生大的影响。大量减少特征数量（比如从$1000$减少到$100-$减少$10$倍）可能产生较大偏差，因为去掉了很多有用的特征。（注：可能会欠拟合）。在现代的深度学习中，数据量很大，人们对待特征选择的态度出现了转变，现在我们更加倾向于使用全部的特征，让算法自己选择合适的特征。但是当训练集比较小时，特征选择非常有用。<br>&emsp;&emsp;<br>（5）缩小模型（例如减少网络层数和神经元数量）：谨慎使用。这种技巧可以减少方差，同时也可能增加偏差。然而，我并不推荐使用这种技巧来解决方差问题。添加正则化通常会获得更好的分类性能。缩小模型的优点在于减少计算成本，以更快的速度来训练模型。如果模型的训练速度非常重要，那么就想尽一切方法来缩小模型。但是如果目标是减少方差，不是那么在意计算成本，可以考虑添加正则化。</p><h2 id="13-30-贝叶斯错误率的最佳估计"><a href="#13-30-贝叶斯错误率的最佳估计" class="headerlink" title="13.30 贝叶斯错误率的最佳估计"></a>13.30 贝叶斯错误率的最佳估计</h2><p>&emsp;&emsp;<br>对于这样的问题，更好的估计贝叶斯错误率很有必要，可以帮助你更好地估计可避免偏差和方差，这样你就能更好的做出决策，选择减少偏差的策略，还是减少方差的策略。</p><h2 id="13-31-举机器学习超过单个人类表现几个例子？"><a href="#13-31-举机器学习超过单个人类表现几个例子？" class="headerlink" title="13.31 举机器学习超过单个人类表现几个例子？"></a>13.31 举机器学习超过单个人类表现几个例子？</h2><p>&emsp;&emsp;<br>现在，机器学习有很多问题已经可以大大超越人类水平了。例如，我想网络广告，估计某个用户点击广告的可能性，可能学习算法做到的水平已经超越任何人类了。还有提出产品建议，向你推荐电影或书籍之类的任务。我想今天的网站做到的水平已经超越你最亲近的朋友了。还有物流预测，从到开车需要多久，或者预测快递车从开到需要多少时间。或者预测某人会不会偿还贷款，这样你就能判断是否批准这人的贷款。我想这些问题都是今天的机器学习远远超过了单个人类的表现。  </p><p>&emsp;&emsp;<br>除了这些问题，今天已经有语音识别系统超越人类水平了，还有一些计算机视觉任务，一些图像识别任务，计算机已经超越了人类水平。但是由于人类对这种自然感知任务非常擅长，我想计算机达到那种水平要难得多。还有一些医疗方面的任务，比如阅读ECG或诊断皮肤癌，或者某些特定领域的放射科读图任务，这些任务计算机做得非常好了，也许超越了单个人类的水平。</p><h2 id="13-32如何改善你的模型？"><a href="#13-32如何改善你的模型？" class="headerlink" title="13.32如何改善你的模型？"></a>13.32如何改善你的模型？</h2><p>&emsp;&emsp;<br>你们学过正交化，如何设立开发集和测试集，用人类水平错误率来估计贝叶斯错误率以及如何估计可避免偏差和方差。我们现在把它们全部组合起来写成一套指导方针，如何提高学习算法性能的指导方针。  </p><p>&emsp;&emsp;<br>首先，你的算法对训练集的拟合很好，这可以看成是你能做到可避免偏差很低。还有第二件事你可以做好的是，在训练集中做得很好，然后推广到开发集和测试集也很好，这就是说方差不是太大。  </p><ol><li><p>总结一下前几段视频我们见到的步骤，如果你想提升机器学习系统的性能，我建议你们看看训练错误率和贝叶斯错误率估计值之间的距离，让你知道可避免偏差有多大。换句话说，就是你觉得还能做多好，你对训练集的优化还有多少空间。</p></li><li><p>然后看看你的开发错误率和训练错误率之间的距离，就知道你的方差问题有多大。换句话说，你应该做多少努力让你的算法表现能够从训练集推广到开发集，算法是没有在开发集上训练的。</p></li><li><p>用尽一切办法减少可避免偏差</p></li><li><p>比如使用规模更大的模型，这样算法在训练集上的表现会更好，或者训练更久。</p></li><li><p>使用更好的优化算法，比如说加入momentum或者RMSprop，或者使用更好的算法，比如Adam。你还可以试试寻找更好的新神经网络架构，或者说更好的超参数。这些手段包罗万有，你可以改变激活函数，改变层数或者隐藏单位数，虽然你这么做可能会让模型规模变大。</p></li><li><p>或者试用其他模型，其他架构，如循环神经网络和卷积神经网络。  </p></li></ol><p>&emsp;&emsp;<br>在之后的课程里我们会详细介绍的，新的神经网络架构能否更好地拟合你的训练集，有时也很难预先判断，但有时换架构可能会得到好得多的结果。</p><h2 id="13-33-理解误差分析"><a href="#13-33-理解误差分析" class="headerlink" title="13.33 理解误差分析"></a>13.33 理解误差分析</h2><p>&emsp;&emsp;<br>如果你希望让学习算法能够胜任人类能做的任务，但你的学习算法还没有达到人类的表现，那么人工检查一下你的算法犯的错误也许可以让你了解接下来应该做什么。这个过程称为错误分析，我们从一个例子开始讲吧。  </p><p>&emsp;&emsp;<br>假设你正在调试猫分类器，然后你取得了$90\%$准确率，相当于$10\%$错误，，在你的开发集上做到这样，这离你希望的目标还有很远。也许你的队员看了一下算法分类出错的例子，注意到算法将一些狗分类为猫，你看看这两只狗，它们看起来是有点像猫，至少乍一看是。所以也许你的队友给你一个建议，如何针对狗的图片优化算法。试想一下，你可以针对狗，收集更多的狗图，或者设计一些只处理狗的算法功能之类的，为了让你的猫分类器在狗图上做的更好，让算法不再将狗分类成猫。所以问题在于，你是不是应该去开始做一个项目专门处理狗？这项目可能需要花费几个月的时间才能让算法在狗图片上犯更少的错误，这样做值得吗？或者与其花几个月做这个项目，有可能最后发现这样一点用都没有。这里有个错误分析流程，可以让你很快知道这个方向是否值得努力。  </p><p>&emsp;&emsp;<br>那这个简单的人工统计步骤，错误分析，可以节省大量时间，可以迅速决定什么是最重要的，或者最有希望的方向。实际上，如果你观察$100$个错误标记的开发集样本，也许只需要$5$到$10$分钟的时间，亲自看看这$100$个样本，并亲自统计一下有多少是狗。根据结果，看看有没有占到$5\%$、$50\%$或者其他东西。这个在$5$到$10$分钟之内就能给你估计这个方向有多少价值，并且可以帮助你做出更好的决定，是不是把未来几个月的时间投入到解决错误标记的狗图这个问题。  </p><p>&emsp;&emsp;<br>所以总结一下，进行错误分析，你应该找一组错误样本，可能在你的开发集里或者测试集里，观察错误标记的样本，看看假阳性（false positives）和假阴性（false negatives），统计属于不同错误类型的错误数量。在这个过程中，你可能会得到启发，归纳出新的错误类型，就像我们看到的那样。如果你过了一遍错误样本，然后说，天，有这么多Instagram滤镜或Snapchat滤镜，这些滤镜干扰了我的分类器，你就可以在途中新建一个错误类型。总之，通过统计不同错误标记类型占总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你构思新优化方向的灵感。在做错误分析的时候，有时你会注意到开发集里有些样本被错误标记了，这时应该怎么做呢？我们下一个视频来讨论。</p><h2 id="13-34-为什么值得花时间查看错误标记数据？"><a href="#13-34-为什么值得花时间查看错误标记数据？" class="headerlink" title="13.34 为什么值得花时间查看错误标记数据？"></a>13.34 为什么值得花时间查看错误标记数据？</h2><p>&emsp;&emsp;<br>最后我讲几个建议：<br>&emsp;&emsp;<br>首先，深度学习研究人员有时会喜欢这样说：“我只是把数据提供给算法，我训练过了，效果拔群”。这话说出了很多深度学习错误的真相，更多时候，我们把数据喂给算法，然后训练它，并减少人工干预，减少使用人类的见解。但我认为，在构造实际系统时，通常需要更多的人工错误分析，更多的人类见解来架构这些系统，尽管深度学习的研究人员不愿意承认这点。<br>&emsp;&emsp;<br>其次，不知道为什么，我看一些工程师和研究人员不愿意亲自去看这些样本，也许做这些事情很无聊，坐下来看100或几百个样本来统计错误数量，但我经常亲自这么做。当我带领一个机器学习团队时，我想知道它所犯的错误，我会亲自去看看这些数据，尝试和一部分错误作斗争。我想就因为花了这几分钟，或者几个小时去亲自统计数据，真的可以帮你找到需要优先处理的任务，我发现花时间亲自检查数据非常值得，所以我强烈建议你们这样做，如果你在搭建你的机器学习系统的话，然后你想确定应该优先尝试哪些想法，或者哪些方向。</p><h2 id="13-35-快速搭建初始系统的意义？"><a href="#13-35-快速搭建初始系统的意义？" class="headerlink" title="13.35 快速搭建初始系统的意义？"></a>13.35 快速搭建初始系统的意义？</h2><p>&emsp;&emsp;<br>一般来说，对于几乎所有的机器学习程序可能会有$50$个不同的方向可以前进，并且每个方向都是相对合理的可以改善你的系统。但挑战在于，你如何选择一个方向集中精力处理。即使我已经在语音识别领域工作多年了，如果我要为一个新应用程序域构建新系统，我还是觉得很难不花时间去思考这个问题就直接选择方向。所以我建议你们，如果你想搭建全新的机器学习程序，就是快速搭好你的第一个系统，然后开始迭代。我的意思是我建议你快速设立开发集和测试集还有指标，这样就决定了你的目标所在，如果你的目标定错了，之后改也是可以的。但一定要设立某个目标，然后我建议你马上搭好一个机器学习系统原型，然后找到训练集，训练一下，看看效果，开始理解你的算法表现如何，在开发集测试集，你的评估指标上表现如何。当你建立第一个系统后，你就可以马上用到之前说的偏差方差分析，还有之前最后几个视频讨论的错误分析，来确定下一步优先做什么。特别是如果错误分析让你了解到大部分的错误的来源是说话人远离麦克风，这对语音识别构成特殊挑战，那么你就有很好的理由去集中精力研究这些技术，所谓远场语音识别的技术，这基本上就是处理说话人离麦克风很远的情况。</p><p>&emsp;&emsp;<br>建立这个初始系统的所有意义在于，它可以是一个快速和粗糙的实现（quick and dirty implementation），你知道的，别想太多。初始系统的全部意义在于，有一个学习过的系统，有一个训练过的系统，让你确定偏差方差的范围，就可以知道下一步应该优先做什么，让你能够进行错误分析，可以观察一些错误，然后想出所有能走的方向，哪些是实际上最有希望的方向。</p><h2 id="13-36-为什么要在不同的划分上训练及测试？"><a href="#13-36-为什么要在不同的划分上训练及测试？" class="headerlink" title="13.36 为什么要在不同的划分上训练及测试？"></a>13.36 为什么要在不同的划分上训练及测试？</h2><p>&emsp;&emsp;<br>深度学习算法对训练数据的胃口很大，当你收集到足够多带标签的数据构成训练集时，算法效果最好，这导致很多团队用尽一切办法收集数据，然后把它们堆到训练集里，让训练的数据量更大，即使有些数据，甚至是大部分数据都来自和开发集、测试集不同的分布。在深度学习时代，越来越多的团队都用来自和开发集、测试集分布不同的数据来训练，这里有一些微妙的地方，一些最佳做法来处理训练集和测试集存在差异的情况，我们来看看。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_36_1.png" alt=""></p><center>图 13.36 Cat app example</center><p>&emsp;&emsp;<br>假设你在开发一个手机应用，用户会上传他们用手机拍摄的照片，你想识别用户从应用中上传的图片是不是猫。现在你有两个数据来源，一个是你真正关心的数据分布，来自应用上传的数据，比如右边的应用，这些照片一般更业余，取景不太好，有些甚至很模糊，因为它们都是业余用户拍的。另一个数据来源就是你可以用爬虫程序挖掘网页直接下载，就这个样本而言，可以下载很多取景专业、高分辨率、拍摄专业的猫图片。如果你的应用用户数还不多，也许你只收集到$10,000$张用户上传的照片，但通过爬虫挖掘网页，你可以下载到海量猫图，也许你从互联网上下载了超过$20$万张猫图。而你真正关心的算法表现是你的最终系统处理来自应用程序的这个图片分布时效果好不好，因为最后你的用户会上传类似右边这些图片，你的分类器必须在这个任务中表现良好。现在你就陷入困境了，因为你有一个相对小的数据集，只有$10,000$个样本来自那个分布，而你还有一个大得多的数据集来自另一个分布，图片的外观和你真正想要处理的并不一样。但你又不想直接用这$10,000$张图片，因为这样你的训练集就太小了，使用这$20$万张图片似乎有帮助。但是，困境在于，这$20$万张图片并不完全来自你想要的分布，那么你可以怎么做呢？</p><p>&emsp;&emsp;<br>这里有一种选择，你可以做的一件事是将两组数据合并在一起，这样你就有$21$万张照片，你可以把这$21$万张照片随机分配到训练、开发和测试集中。为了说明观点，我们假设你已经确定开发集和测试集各包含$2500$个样本，所以你的训练集有$205000$个样本。现在这么设立你的数据集有一些好处，也有坏处。好处在于，你的训练集、开发集和测试集都来自同一分布，这样更好管理。但坏处在于，这坏处还不小，就是如果你观察开发集，看看这$2500$个样本其中很多图片都来自网页下载的图片，那并不是你真正关心的数据分布，你真正要处理的是来自手机的图片。</p><p>&emsp;&emsp;<br>我建议你走另外一条路，就是这样，训练集，比如说还是$205,000$张图片，我们的训练集是来自网页下载的$200,000$张图片，然后如果需要的话，再加上$5000$张来自手机上传的图片。然后对于开发集和测试集，这数据集的大小是按比例画的，你的开发集和测试集都是手机图。而训练集包含了来自网页的$20$万张图片，还有$5000$张来自应用的图片，开发集就是$2500$张来自应用的图片，测试集也是$2500$张来自应用的图片。这样将数据分成训练集、开发集和测试集的好处在于，现在你瞄准的目标就是你想要处理的目标，你告诉你的团队，我的开发集包含的数据全部来自手机上传，这是你真正关心的图片分布。我们试试搭建一个学习系统，让系统在处理手机上传图片分布时效果良好。缺点在于，当然了，现在你的训练集分布和你的开发集、测试集分布并不一样。但事实证明，这样把数据分成训练、开发和测试集，在长期能给你带来更好的系统性能。我们以后会讨论一些特殊的技巧，可以处理 训练集的分布和开发集和测试集分布不一样的情况。</p><h2 id="13-37-如何解决数据不匹配问题？"><a href="#13-37-如何解决数据不匹配问题？" class="headerlink" title="13.37 如何解决数据不匹配问题？"></a>13.37 如何解决数据不匹配问题？</h2><p>&emsp;&emsp;<br>如果您的训练集来自和开发测试集不同的分布，如果错误分析显示你有一个数据不匹配的问题该怎么办？这个问题没有完全系统的解决方案，但我们可以看看一些可以尝试的事情。如果我发现有严重的数据不匹配问题，我通常会亲自做错误分析，尝试了解训练集和开发测试集的具体差异。技术上，为了避免对测试集过拟合，要做错误分析，你应该人工去看开发集而不是测试集。</p><p>&emsp;&emsp;<br>但作为一个具体的例子，如果你正在开发一个语音激活的后视镜应用，你可能要看看……我想如果是语音的话，你可能要听一下来自开发集的样本，尝试弄清楚开发集和训练集到底有什么不同。所以，比如说你可能会发现很多开发集样本噪音很多，有很多汽车噪音，这是你的开发集和训练集差异之一。也许你还会发现其他错误，比如在你的车子里的语言激活后视镜，你发现它可能经常识别错误街道号码，因为那里有很多导航请求都有街道地址，所以得到正确的街道号码真的很重要。当你了解开发集误差的性质时，你就知道，开发集有可能跟训练集不同或者更难识别，那么你可以尝试把训练数据变得更像开发集一点，或者，你也可以收集更多类似你的开发集和测试集的数据。所以，比如说，如果你发现车辆背景噪音是主要的错误来源，那么你可以模拟车辆噪声数据，我会在下一张幻灯片里详细讨论这个问题。或者你发现很难识别街道号码，也许你可以有意识地收集更多人们说数字的音频数据，加到你的训练集里。</p><p>&emsp;&emsp;<br>现在我知道这张幻灯片只给出了粗略的指南，列出一些你可以做的尝试，这不是一个系统化的过程，我想，这不能保证你一定能取得进展。但我发现这种人工见解，我们可以一起尝试收集更多和真正重要的场合相似的数据，这通常有助于解决很多问题。所以，如果你的目标是让训练数据更接近你的开发集，那么你可以怎么做呢？</p><p>&emsp;&emsp;<br>你可以利用的其中一种技术是人工合成数据（artificial data synthesis），我们讨论一下。在解决汽车噪音问题的场合，所以要建立语音识别系统。也许实际上你没那么多实际在汽车背景噪音下录得的音频，或者在高速公路背景噪音下录得的音频。但我们发现，你可以合成。所以假设你录制了大量清晰的音频，不带车辆背景噪音的音频，“The quick brown fox jumps over the lazy dog”（音频播放），所以，这可能是你的训练集里的一段音频，顺便说一下，这个句子在AI测试中经常使用，因为这个短句包含了从a到z所有字母，所以你会经常见到这个句子。但是，有了这个“the quick brown fox jumps over the lazy dog”这段录音之后，你也可以收集一段这样的汽车噪音，（播放汽车噪音音频）这就是汽车内部的背景噪音，如果你一言不发开车的话，就是这种声音。如果你把两个音频片段放到一起，你就可以合成出”the quick brown fox jumps over the lazy dog”（带有汽车噪声），在汽车背景噪音中的效果，听起来像这样，所以这是一个相对简单的音频合成例子。在实践中，你可能会合成其他音频效果，比如混响，就是声音从汽车内壁上反弹叠加的效果。</p><p>&emsp;&emsp;<br>但是通过人工数据合成，你可以快速制造更多的训练数据，就像真的在车里录的那样，那就不需要花时间实际出去收集数据，比如说在实际行驶中的车子，录下上万小时的音频。所以，如果错误分析显示你应该尝试让你的数据听起来更像在车里录的，那么人工合成那种音频，然后喂给你的机器学习算法，这样做是合理的。</p><p>&emsp;&emsp;<br>现在我们要提醒一下，人工数据合成有一个潜在问题，比如说，你在安静的背景里录得$10,000$小时音频数据，然后，比如说，你只录了一小时车辆背景噪音，那么，你可以这么做，将这$1$小时汽车噪音回放$10,000$次，并叠加到在安静的背景下录得的$10,000$小时数据。如果你这么做了，人听起来这个音频没什么问题。但是有一个风险，有可能你的学习算法对这1小时汽车噪音过拟合。特别是，如果这组汽车里录的音频可能是你可以想象的所有汽车噪音背景的集合，如果你只录了一小时汽车噪音，那你可能只模拟了全部数据空间的一小部分，你可能只从汽车噪音的很小的子集来合成数据。</p><p>&emsp;&emsp;<br>所以，总而言之，如果你认为存在数据不匹配问题，我建议你做错误分析，或者看看训练集，或者看看开发集，试图找出，试图了解这两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像开发集的数据作训练。</p><p>&emsp;&emsp;<br>我们谈到其中一种办法是人工数据合成，人工数据合成确实有效。在语音识别中。我已经看到人工数据合成显著提升了已经非常好的语音识别系统的表现，所以这是可行的。但当你使用人工数据合成时，一定要谨慎，要记住你有可能从所有可能性的空间只选了很小一部分去模拟数据。</p><p>&emsp;&emsp;<br>所以这就是如何处理数据不匹配问题，接下来，我想和你分享一些想法就是如何从多种类型的数据同时学习。</p><h2 id="13-38-梯度检验注意事项？"><a href="#13-38-梯度检验注意事项？" class="headerlink" title="13.38 梯度检验注意事项？"></a>13.38 梯度检验注意事项？</h2><p>&emsp;&emsp;<br>首先，不要在训练中使用梯度检验，它只用于调试。我的意思是，计算所有值的是一个非常漫长的计算过程，为了实施梯度下降，你必须使用和 backprop来计算，并使用backprop来计算导数，只要调试的时候，你才会计算它，来确认数值是否接近。完成后，你会关闭梯度检验，梯度检验的每一个迭代过程都不执行它，因为它太慢了。</p><p>&emsp;&emsp;<br>第二点，如果算法的梯度检验失败，要检查所有项，检查每一项，并试着找出bug，也就是说，如果与$d\theta[i]$的值相差很大，我们要做的就是查找不同的$i$值，看看是哪个导致与的值相差这么多。举个例子，如果你发现，相对某些层或某层的或的值相差很大，但是的各项非常接近，注意的各项与和的各项都是一一对应的，这时，你可能会发现，在计算参数的导数的过程中存在bug。反过来也是一样，如果你发现它们的值相差很大，的值与的值相差很大，你会发现所有这些项目都来自于或某层的，可能帮你定位bug的位置，虽然未必能够帮你准确定位bug的位置，但它可以帮助你估测需要在哪些地方追踪bug。</p><p>&emsp;&emsp;<br>第三点，在实施梯度检验时，如果使用正则化，请注意正则项。如果代价函数，这就是代价函数J的定义，等于与相关的函数的梯度，包括这个正则项，记住一定要包括这个正则项。</p><p>&emsp;&emsp;<br>第四点，梯度检验不能与dropout同时使用，因为每次迭代过程中，dropout会随机消除隐藏层单元的不同子集，难以计算dropout在梯度下降上的代价函数J。因此dropout可作为优化代价函数的一种方法，但是代价函数J被定义为对所有指数极大的节点子集求和。而在任何迭代过程中，这些节点都有可能被消除，所以很难计算代价函数。你只是对成本函数做抽样，用dropout，每次随机消除不同的子集，所以很难用梯度检验来双重检验dropout的计算，所以我一般不同时使用梯度检验和dropout。如果你想这样做，可以把dropout中的keepprob设置为$1.0$，然后打开dropout，并寄希望于dropout的实施是正确的，你还可以做点别的，比如修改节点丢失模式确定梯度检验是正确的。实际上，我一般不这么做，我建议关闭dropout，用梯度检验进行双重检查，在没有dropout的情况下，你的算法至少是正确的，然后打开dropout。</p><p>&emsp;&emsp;<br>最后一点，也是比较微妙的一点，现实中几乎不会出现这种情况。当和接近0时，梯度下降的实施是正确的，在随机初始化过程中$……$，但是在运行梯度下降时，和变得更大。可能只有在和接近$0$时，backprop的实施才是正确的。但是当和变大时，它会变得越来越不准确。你需要做一件事，我不经常这么做，就是在随机初始化过程中，运行梯度检验，然后再训练网络，和会有一段时间远离$0$，如果随机初始化值比较小，反复训练网络之后，再重新运行梯度检验。</p><p>&emsp;&emsp;<br>这就是梯度检验，恭喜大家，这是本周最后一课了。回顾这一周，我们讲了如何配置训练集，验证集和测试集，如何分析偏差和方差，如何处理高偏差或高方差以及高偏差和高方差并存的问题，如何在神经网络中应用不同形式的正则化，如正则化和dropout，还有加快神经网络训练速度的技巧，最后是梯度检验。这一周我们学习了很多内容，你可以在本周编程作业中多多练习这些概念。祝你好运，期待下周再见。</p><h2 id="13-39什么是随机梯度下降？"><a href="#13-39什么是随机梯度下降？" class="headerlink" title="13.39什么是随机梯度下降？"></a>13.39什么是随机梯度下降？</h2><p>&emsp;&emsp;<br>随机梯度下降，简称SGD，是指梯度下降算法在训练集上，对每一个训练数据都计算误差并更新模型。<br>对每一个数据都进行模型更新意味着随机梯度下降是一种<a href="https://en.wikipedia.org/wiki/Online_machine_learning" target="_blank" rel="noopener">在线机器学习算法</a>。  </p><p>&emsp;&emsp;<br>优点:</p><ul><li>频繁的更新可以给我们一个模型表现和效率提升的即时反馈。</li><li>这可能是最容易理解和实现的一种方式，尤其对于初学者。</li><li>较高的模型更新频率在一些问题上可以快速的学习。</li><li>这种伴有噪声的更新方式能让模型避免局部最优（比如过早收敛）。</li></ul><p>&emsp;&emsp;<br>缺点:</p><ul><li>这种方式相比其他来说，计算消耗更大，在大数据集上花费的训练时间更多。</li><li>频繁的更新产生的噪声可能导致模型参数和模型误差来回跳动（更大的方差）。</li><li>这种伴有噪声的更新方式也能让算法难以稳定的收敛于一点。</li></ul><h2 id="13-40什么是批量梯度下降？"><a href="#13-40什么是批量梯度下降？" class="headerlink" title="13.40什么是批量梯度下降？"></a>13.40什么是批量梯度下降？</h2><p>&emsp;&emsp;<br>批量梯度下降对训练集上每一个数据都计算误差，但只在所有训练数据计算完成后才更新模型。<br>&emsp;&emsp;<br>对训练集上的一次训练过程称为一代（epoch）。因此，批量梯度下降是在每一个训练epoch之后更新模型。  </p><p>&emsp;&emsp;<br>优点：</p><ul><li>更少的模型更新意味着比SGD有更高的计算效率。</li><li>在一些问题上可以得到更稳定的误差梯度和更稳定的收敛点。</li><li>误差计算和模型更新过程的分离有利于并行算法的实现。</li></ul><p>&emsp;&emsp;<br>缺点：</p><ul><li>更稳定的误差梯度可能导致模型过早收敛于一个不是最优解的参数集。</li><li>每一次epoch之后才更新会增加一个累加所有训练数据误差的复杂计算。</li><li>通常来说，批量梯度下降算法需要把所有的训练数据都存放在内存中。</li><li>在大数据集上，训练速度会非常慢。</li></ul><h2 id="13-41什么是小批量梯度下降？"><a href="#13-41什么是小批量梯度下降？" class="headerlink" title="13.41什么是小批量梯度下降？"></a>13.41什么是小批量梯度下降？</h2><p>&emsp;&emsp;<br>小批量梯度下降把训练集划分为很多批，对每一批（batch）计算误差并更新参数。<br>&emsp;&emsp;<br>可以选择对batch的梯度进行累加，或者取平均值。取平均值可以减少梯度的方差。<br>&emsp;&emsp;<br>小批量梯度下降在随机梯度下降的鲁棒性和批量梯度下降的效率之间取得平衡。是如今深度学习领域最常见的实现方式。  </p><p>&emsp;&emsp;<br>优点：</p><ul><li>比批量梯度下降更快的更新频率有利于更鲁棒的收敛，避免局部最优。</li><li>相比随机梯度下降更具计算效率。</li><li>不需要把所有数据放入内存中。</li></ul><p>&emsp;&emsp;<br>缺点：</p><ul><li>小批量梯度下降给算法增加了一个超参数batch size。</li><li>和批量梯度下降一样，每一个batch上的误差需要累加。</li></ul><h2 id="13-42怎么配置mini-batch梯度下降"><a href="#13-42怎么配置mini-batch梯度下降" class="headerlink" title="13.42怎么配置mini-batch梯度下降"></a>13.42怎么配置mini-batch梯度下降</h2><p>&emsp;&emsp;<br>Mini-batch梯度下降对于深度学习大部分应用是最常用的方法。<br>&emsp;&emsp;<br>Mini-batch sizes，简称为 “batch sizes”，是算法设计中需要调节的参数。比如对应于不同GPU或CPU硬件$(32,64,128,256,\cdots)$的内存要求。<br>&emsp;&emsp;<br>batch size是学习过程中的“滑块”。  </p><p>&emsp;&emsp;<br>（1）较小的值让学习过程收敛更快，但是产生更多噪声。<br>&emsp;&emsp;<br>（2）较大的值让学习过程收敛较慢，但是准确的估计误差梯度。</p><p>&emsp;&emsp;<br><strong>建议1：batch size的默认值最好是$32$</strong><br>&emsp;&emsp;<br>batch size通常从1到几百之间选择，比如$32$是一个很好的默认值，超过$10$的值可以充分利用矩阵$<em>$矩阵相对于矩阵$</em>$向量的加速优势。<br><a href="https://arxiv.org/abs/1206.5533" target="_blank" rel="noopener">——Practical recommendations for gradient-based training of deep architectures, 2012</a></p><p>&emsp;&emsp;<br><strong>建议2：调节batch size时，最好观察模型在不同batch size下的训练时间和验证误差的学习曲线</strong><br>&emsp;&emsp;<br>相比于其他超参数，它可以被单独优化。在其他超参数（除了学习率）确定之后，在对比训练曲线（训练误差和验证误差对应于训练时间）。 </p><p>&emsp;&emsp;<br><strong>建议3：调整其他所有超参数之后再调整batch size和学习率</strong><br>&emsp;&emsp;<br>batch size和学习率几乎不受其他超参数的影响，因此可以放到最后再优化。batch size确定之后，可以被视为固定值，从而去优化其他超参数（如果使用了动量超参数则例外）。</p><h2 id="13-43-局部最优的问题"><a href="#13-43-局部最优的问题" class="headerlink" title="13.43 局部最优的问题"></a>13.43 局部最优的问题</h2><p>&emsp;&emsp;<br>在深度学习研究早期，人们总是担心优化算法会困在极差的局部最优，不过随着深度学习理论不断发展，我们对局部最优的理解也发生了改变。我向你展示一下现在我们怎么看待局部最优以及深度学习中的优化问题。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_43_1.png" alt=""></p><center>图 13.43.1 </center><p>&emsp;&emsp;<br>这是曾经人们在想到局部最优时脑海里会出现的图，也许你想优化一些参数，我们把它们称之为和，平面的高度<br>就是损失函数。在图中似乎各处都分布着局部最优。梯度下降法或者某个算法可能困在一个局部最优中，而不会抵达<br>全局最优。如果你要作图计算一个数字，比如说这两个维度，就容易出现有多个不同局部最优的图，而这些低维的图<br>曾经影响了我们的理解，但是这些理解并不正确。事实上，如果你要创建一个神经网络，通常梯度为零的点并不是这<br>个图中的局部最优点，实际上成本函数的零梯度点，通常是鞍点。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_43_2.png" alt=""></p><center>图 13.43.2 </center><p>&emsp;&emsp;<br>也就是在这个点，这里是和，高度即成本函数的值。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_43_3.png" alt=""></p><center>图 13.43.3 </center><p>&emsp;&emsp;<br>但是一个具有高维度空间的函数，如果梯度为$0$，那么在每个方向，它可能是凸函数，也可能是凹函数。如果你在$2$万维空间中，那么想要得到局部最优，所有的$2$万个方向都需要是这样，但发生的机率也许很小，也许是，你更有可能遇到有些方向的曲线会这样向上弯曲，另一些方向曲线向下弯，而不是所有的都向上弯曲，因此在高维度空间，你更可能碰到鞍点。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_43_4.png" alt=""></p><center>图 13.43.4 </center><p>&emsp;&emsp;<br>就像下面的这种：<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_43_5.png" alt=""></p><center>图 13.43.5 </center><p>&emsp;&emsp;<br>而不会碰到局部最优。至于为什么会把一个曲面叫做鞍点，你想象一下，就像是放在马背上的马鞍一样，如果这是马，这是马的头，这就是马的眼睛，画得不好请多包涵，然后你就是骑马的人，要坐在马鞍上，因此这里的这个点，导数为$0$的点，这个点叫做鞍点。我想那确实是你坐在马鞍上的那个点，而这里导数为$0$。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_43_6.png" alt=""></p><center>图 13.43.6 </center><p>&emsp;&emsp;<br>所以我们从深度学习历史中学到的一课就是，我们对低维度空间的大部分直觉，比如你可以画出上面的图，并不能应用到高维度空间中。适用于其它算法，因为如果你有$2$万个参数，那么函数有$2$万个维度向量，你更可能遇到鞍点，而不是局部最优点。</p><p>&emsp;&emsp;<br>如果局部最优不是问题，那么问题是什么？结果是平稳段会减缓学习，平稳段是一块区域，其中导数长时间接近于$0$，如果你在此处，梯度会从曲面从从上向下下降，因为梯度等于或接近$0$，曲面很平坦，你得花上很长时间慢慢抵达平稳段的这个点，因为左边或右边的随机扰动，我换个笔墨颜色，大家看得清楚一些，然后你的算法能够走出平稳段（红色笔）。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_43_7.png" alt=""></p><center>图 13.43.7 </center><p>&emsp;&emsp;<br>我们可以沿着这段长坡走，直到这里，然后走出平稳段。<br><img src="/2017/11/02/第十三章_优化算法/img/ch13/figure_13_43_8.png" alt=""></p><center>图 13.43.8 </center><p>&emsp;&emsp;<br>所以此次视频的要点是，首先，你不太可能困在极差的局部最优中，条件是你在训练较大的神经网络，存在大量参数，并且成本函数被定义在较高的维度空间。</p><p>&emsp;&emsp;<br>第二点，平稳段是一个问题，这样使得学习十分缓慢，这也是像Momentum或是RMSprop，Adam这样的算法，能够加速学习算法的地方。在这些情况下，更成熟的优化算法，如Adam算法，能够加快速度，让你尽早往下走出平稳段。</p><p>&emsp;&emsp;<br>因为你的网络要解决优化问题，说实话，要面临如此之高的维度空间，我觉得没有人有那么好的直觉，知道这些空间长什么样，而且我们对它们的理解还在不断发展，不过我希望这一点能够让你更好地理解优化算法所面临的问题。</p><h2 id="13-44-提升算法性能思路"><a href="#13-44-提升算法性能思路" class="headerlink" title="13.44 提升算法性能思路"></a>13.44 提升算法性能思路</h2><p>&emsp;&emsp;<br>这个列表里提到的思路并完全，但是一个好的开始。<br>&emsp;&emsp;<br>我的目的是给出很多可以尝试的思路，希望其中的一或两个你之前没有想到。你经常只需要一个好的想法就能得到性能提升。<br>&emsp;&emsp;<br>如果你能从其中一个思路中得到结果，请在评论区告诉我。我很高兴能得知这些好消息。<br>&emsp;&emsp;<br>如果你有更多的想法，或者是所列思路的拓展，也请告诉我，我和其他读者都将受益！有时候仅仅是一个想法或许就能使他人得到突破。</p><ol><li>通过数据提升性能 </li><li>通过算法提升性能 </li><li>通过算法调参提升性能 </li><li>通过嵌套模型提升性能</li></ol><p>&emsp;&emsp;<br>通常来讲，随着列表自上而下，性能的提升也将变小。例如，对问题进行新的架构或者获取更多的数据，通常比调整最优算法的参数能带来更好的效果。虽然并不总是这样，但是通常来讲是的。</p><p>&emsp;&emsp;<br>我已经把相应的链接加入了博客的教程中，相应网站的问题中，以及经典的Neural Net FAQ中。<br>&emsp;&emsp;<br>部分思路只适用于人工神经网络，但是大部分是通用的。通用到足够你用来配合其他技术来碰撞出提升模型性能的方法。<br>OK，现在让我们开始吧。</p><ol><li>通过数据提升性能 </li></ol><p>&emsp;&emsp;<br>对你的训练数据和问题定义进行适当改变，你能得到很大的性能提升。或许是最大的性能提升。  </p><p>&emsp;&emsp;<br>以下是我将要提到的思路：<br>&emsp;&emsp;<br>获取更多数据、创造更多数据、重放缩你的数据、转换你的数据、特征选取、重架构你的问题</p><p>&emsp;&emsp;<br>1）获取更多数据<br>&emsp;&emsp;<br>你能获取更多训练数据吗？<br>&emsp;&emsp;<br>你的模型的质量通常受到你的训练数据质量的限制。为了得到最好的模型，你首先应该想办法获得最好的数据。你也想尽可能多的获得那些最好的数据。<br>&emsp;&emsp;<br>有更多的数据，深度学习和其他现代的非线性机器学习技术有更全的学习源，能学得更好，深度学习尤为如此。这也是机器学习对大家充满吸引力的很大一个原因（世界到处都是数据）。  </p><p>&emsp;&emsp;<br>2） 创造更多数据<br>&emsp;&emsp;<br>上一小节说到了有了更多数据，深度学习算法通常会变的更好。有些时候你可能无法合理地获取更多数据，那你可以试试创造更多数据。<br>&emsp;&emsp;<br>如果你的数据是数值型向量，可以随机构造已有向量的修改版本。<br>&emsp;&emsp;<br>如果你的数据是图片，可以随机构造已有图片的修改版本(平移、截取、旋转等)。<br>&emsp;&emsp;<br>如果你的数据是文本，类似的操作……<br>&emsp;&emsp;<br>这通常被称作数据扩增（data augmentation）或者数据生成（data generation）。<br>&emsp;&emsp;<br>你可以利用一个生成模型。你也可以用一些简单的技巧。例如，针对图片数据，你可以通过随机地平移或旋转已有图片获取性能的提升。如果新数据中包含了这种转换，则提升了模型的泛化能力。<br>&emsp;&emsp;<br>这也与增加噪声是相关的，我们习惯称之为增加扰动。它起到了与正则化方法类似的作用，即抑制训练数据的过拟合。</p><p>&emsp;&emsp;<br>3）重缩放(rescale)你的数据<br>&emsp;&emsp;<br>这是一个快速获得性能提升的方法。 当应用神经网络时，一个传统的经验法则是：重缩放(rescale)你的数据至激活函数的边界。<br>&emsp;&emsp;<br>如果你在使用sigmoid激活函数，重缩放你的数据到0和1的区间里。如果你在使用双曲正切（tanh）激活函数，重缩放数据到－1和1的区间里。<br>&emsp;&emsp;<br>这种方法可以被应用到输入数据（x）和输出数据（y）。例如，如果你在输出层使用sigmoid函数去预测二元分类的结果，应当标准化y值，使之成为二元的。如果你在使用softmax函数，你依旧可以通过标准化y值来获益。<br>&emsp;&emsp;<br>这依旧是一个好的经验法则，但是我想更深入一点。我建议你可以参考下述方法来创造一些训练数据的不同的版本：<br>&emsp;&emsp;<br>归一化到0和1的区间。<br>&emsp;&emsp;<br>重放缩到－1和1的区间<br>&emsp;&emsp;<br>标准化（译者注：标准化数据使之成为零均值，单位标准差）<br>&emsp;&emsp;<br>然后对每一种方法，评估你的模型的性能，选取最好的进行使用。如果你改变了你的激活函数，重复这一过程。<br>&emsp;&emsp;<br>在神经网络中，大的数值累积效应(叠加叠乘)并不是好事，除上述方法之外，还有其他的方法来控制你的神经网络中数据的数值大小，譬如归一化激活函数和权重，我们会在以后讨论这些技术。  </p><p>&emsp;&emsp;<br>4）数据变换<br>&emsp;&emsp;<br>这里的数据变换与上述的重缩放方法类似，但需要更多工作。你必须非常熟悉你的数据。通过可视化来考察离群点。<br>&emsp;&emsp;<br>猜测每一列数据的单变量分布。<br>&emsp;&emsp;<br>列数据看起来像偏斜的高斯分布吗？考虑用Box-Cox变换调整偏态。<br>&emsp;&emsp;<br>列数据看起来像指数分布吗？考虑用对数变换。<br>&emsp;&emsp;<br>列数据看起来有一些特征，但是它们被一些明显的东西遮盖了，尝试取平方或者开平方根来转换数据<br>&emsp;&emsp;<br>你能离散化一个特征或者以某种方式组合特征，来更好地突出一些特征吗？<br>&emsp;&emsp;<br>依靠你的直觉，尝试以下方法。<br>&emsp;&emsp;<br>你能利用类似PCA的投影方法来预处理数据吗？<br>&emsp;&emsp;<br>你能综合多维特征至一个单一数值(特征)吗？<br>&emsp;&emsp;<br>你能用一个新的布尔标签去发现问题中存在一些有趣的方面吗？<br>&emsp;&emsp;<br>你能用其他方法探索出目前场景下的其他特殊结构吗？<br>&emsp;&emsp;<br>神经网层擅长特征学习(feature engineering)。它(自己)可以做到这件事。但是如果你能更好的发现问题到网络中的结构，神经网层会学习地更快。你可以对你的数据就不同的转换方式进行抽样调查，或者尝试特定的性质，来看哪些有用，哪些没用。  </p><p>&emsp;&emsp;<br>5）特征选择<br>&emsp;&emsp;<br>一般说来，神经网络对不相关的特征是具有鲁棒的(校对注：即不相关的特征不会很大影响神经网络的训练和效果)。它们会用近似于0的权重来弱化那些没有预测能力的特征的贡献。</p><p>&emsp;&emsp;<br>尽管如此，这些无关的数据特征，在训练周期依旧要耗费大量的资源。所以你能去除数据里的一些特征吗？<br>&emsp;&emsp;<br>有许多特征选择的方法和特征重要性的方法，这些方法能够给你提供思路，哪些特征该保留，哪些特征该剔除。最简单的方式就是对比所有特征和部分特征的效果。同样的，如果你有时间，我建议在同一个网络中尝试选择不同的视角来看待你的问题，评估它们，来看看分别有怎样的性能。<br>&emsp;&emsp;<br>或许你利用更少的特征就能达到同等甚至更好的性能。而且，这将使模型变得更快！<br>&emsp;&emsp;<br>或许所有的特征选择方法都剔除了同样的特征子集。很好，这些方法在没用的特征上达成了一致。<br>&emsp;&emsp;<br>或许筛选过后的特征子集，能带给特征工程的新思路。<br>&emsp;&emsp;</p><p>&emsp;&emsp;<br>6）重新架构你的问题<br>&emsp;&emsp;<br>有时候要试试从你当前定义的问题中跳出来，想想你所收集到的观察值是定义你问题的唯一方式吗？或许存在其他方法。或许其他构建问题的方式能够更好地揭示待学习问题的结构。<br>&emsp;&emsp;<br>我真的很喜欢这个尝试，因为它迫使你打开自己的思路。这确实很难，尤其是当你已经对当前的方法投入了大量的时间和金钱时。<br>&emsp;&emsp;<br>但是咱们这么想想，即使你列出了3-5个可供替代的建构方案，而且最终还是放弃了它们，但这至少说明你对当前的方案更加自信了。<br>&emsp;&emsp;<br>看看能够在一个时间窗（时间周期）内对已有的特征/数据做一个合并。<br>&emsp;&emsp;<br>或许你的分类问题可以成为一个回归问题(有时候是回归到分类)。<br>&emsp;&emsp;<br>或许你的二元输出可以变成softmax输出？<br>&emsp;&emsp;<br>或许你可以转而对子问题进行建模。<br>&emsp;&emsp;<br>仔细思考你的问题，最好在你选定工具之前就考虑用不同方法构建你的问题，因为此时你对解决方案并没有花费太多的投入。除此之外，如果你在某个问题上卡住了，这样一个简单的尝试能释放更多新的想法。  </p><ol start="2"><li>通过算法提升性能  </li></ol><p>&emsp;&emsp;<br>机器学习当然是用算法解决问题。<br>&emsp;&emsp;<br>所有的理论和数学都是描绘了应用不同的方法从数据中学习一个决策过程（如果我们这里只讨论预测模型）。<br>&emsp;&emsp;<br>你已经选择了深度学习来解释你的问题。但是这真的是最好的选择吗？在这一节中，我们会在深入到如何最大地发掘你所选择的深度学习方法之前，接触一些算法选择上的思路。  </p><p>下面是一个简要列表：</p><ul><li>对算法进行抽样调查</li><li>借鉴已有文献</li><li>重采样方法</li></ul><p>下面我解释下上面提到的几个方法:</p><p>&emsp;&emsp;<br>1）对算法进行抽样调查<br>&emsp;&emsp;<br>其实你事先无法知道，针对你的问题哪个算法是最优的。如果你知道，你可能就不需要机器学习了。那有没有什么数据(办法)可以证明你选择的方法是正确的？  </p><p>&emsp;&emsp;<br>让我们来解决这个难题。当从所有可能的问题中平均来看各算法的性能时，没有哪个算法能够永远胜过其他算法。所有的算法都是平等的，下面是在no free lunch theorem中的一个总结。 </p><p>&emsp;&emsp;<br>或许你选择的算法不是针对你的问题最优的那个<br>&emsp;&emsp;<br>我们不是在尝试解决所有问题，算法世界中有很多新热的方法，可是它们可能并不是针对你数据集的最优算法。<br>&emsp;&emsp;<br>我的建议是收集(证据)数据指标。接受更好的算法或许存在这一观点，并且给予其他算法在解决你的问题上“公平竞争”的机会。<br>&emsp;&emsp;<br>抽样调查一系列可行的方法，来看看哪些还不错，哪些不理想。<br>&emsp;&emsp;<br>首先尝试评估一些线性方法，例如逻辑回归（logistic regression）和线性判别分析（linear discriminate analysis）。<br>&emsp;&emsp;<br>评估一些树类模型，例如CART， 随机森林（Random Forest）和Gradient Boosting。<br>&emsp;&emsp;<br>评估一些实例方法，例如支持向量机（SVM）和K-近邻（kNN）。<br>&emsp;&emsp;<br>评估一些其他的神经网络方法，例如LVQ, MLP, CNN, LSTM, hybrids等  </p><p>&emsp;&emsp;<br>选取性能最好的算法，然后通过进一步的调参和数据准备来提升。尤其注意对比一下深度学习和其他常规机器学习方法，对上述结果进行排名，比较他们的优劣。</p><p>&emsp;&emsp;<br>很多时候你会发现在你的问题上可以不用深度学习，而是使用一些更简单，训练速度更快，甚至是更容易理解的算法。</p><p>&emsp;&emsp;<br>2）借鉴已有文献<br>&emsp;&emsp;<br>方法选择的一个捷径是借鉴已有的文献资料。可能有人已经研究过与你的问题相关的问题，你可以看看他们用的什么方法。<br>&emsp;&emsp;<br>你可以阅读论文，书籍，博客，问答网站，教程，以及任何能在谷歌搜索到的东西。<br>&emsp;&emsp;<br>写下所有的想法，然后用你的方式把他们研究一遍。<br>&emsp;&emsp;<br>这不是复制别人的研究，而是启发你想出新的想法，一些你从没想到但是却有可能带来性能提升的想法。<br>&emsp;&emsp;<br>发表的研究通常都是非常赞的。世界上有非常多聪明的人，写了很多有趣的东西。你应当好好挖掘这个“图书馆”，找到你想要的东西。  </p><p>&emsp;&emsp;<br>3）重采样方法<br>&emsp;&emsp;<br>你必须知道你的模型效果如何。你对模型性能的估计可靠吗？<br>&emsp;&emsp;<br>深度学习模型在训练阶段非常缓慢。这通常意味着，我们无法用一些常用的方法，例如k层交叉验证，去估计模型的性能。</p><p>&emsp;&emsp;<br>或许你在使用一个简单的训练集／测试集分割，这是常规套路。如果是这样，你需要确保这种分割针对你的问题具有代表性。单变量统计和可视化是一个好的开始。</p><p>&emsp;&emsp;<br>或许你能利用硬件来加速估计的过程。例如，如果你有集群或者AWS云端服务（Amazon Web Services）账号，你可以并行地训练n个模型，然后获取结果的均值和标准差来得到更鲁棒的估计。</p><p>&emsp;&emsp;<br>或许你可以利用hold-out验证方法来了解模型在训练后的性能（这在早停法（early stopping）中很有用，后面会讲到）。</p><p>&emsp;&emsp;<br>或许你可以先隐藏一个完全没用过的验证集，等到你已经完成模型选择之后再使用它。<br>&emsp;&emsp;<br>而有时候另外的方式，或许你能够让数据集变得更小，以及使用更强的重采样方法。<br>&emsp;&emsp;<br>有些情况下你会发现在训练集的一部分样本上训练得到的模型的性能，和在整个数据集上训练得到的模型的性能有很强的相关性。也许你可以先在小数据集上完成模型选择和参数调优，然后再将最终的方法扩展到全部数据集上。</p><p>&emsp;&emsp;<br>或许你可以用某些方式限制数据集，只取一部分样本，然后用它进行全部的建模过程。</p><ol start="3"><li>通过算法调参提升性能</li></ol><p>&emsp;&emsp;<br>这通常是工作的关键所在。你经常可以通过抽样调查快速地发现一个或两个性能优秀的算法。但是如果想得到最优的算法可能需要几天，几周，甚至几个月。</p><p>为了获得更优的模型，以下是对神经网络算法进行参数调优的几点思路：  </p><ul><li>诊断（Diagnostics）  </li><li>权重初始化（Weight Initialization）  </li><li>学习速率（Learning Rate）  </li><li>激活函数  </li><li>网络拓扑（Network Topology）  </li><li>批次和周期（Batches and Epochs）  </li><li>正则化  </li><li>优化和损失  </li><li>早停法</li></ul><p>&emsp;&emsp;<br>你可能需要训练一个给定“参数配置”的神经网络模型很多次（3-10次甚至更多），才能得到一个估计性能不错的参数配置。这一点几乎适用于这一节中你能够调参的所有方面。</p><p>&emsp;&emsp;<br>1）诊断<br>&emsp;&emsp;<br>如果你能知道为什么你的模型性能不再提高了，你就能获得拥有更好性能的模型。<br>&emsp;&emsp;<br>你的模型是过拟合还是欠拟合？永远牢记这个问题。永远。<br>&emsp;&emsp;<br>模型总是会遇到过拟合或者欠拟合，只是程度不同罢了。一个快速了解模型学习行为的方法是，在每个周期，评估模型在训练集和验证集上的表现，并作出图表。</p><p>&emsp;&emsp;<br>如果训练集上的模型总是优于验证集上的模型，你可能遇到了过拟合，你可以使用诸如正则化的方法。</p><p>&emsp;&emsp;<br>如果训练集和验证集上的模型都很差，你可能遇到了欠拟合，你可以提升网络的容量，以及训练更多或者更久。</p><p>&emsp;&emsp;<br>如果有一个拐点存在，在那之后训练集上的模型开始优于验证集上的模型，你可能需要使用早停法。<br>&emsp;&emsp;<br>经常画一画这些图表，学习它们来了解不同的方法，你能够提升模型的性能。这些图表可能是你能创造的最有价值的（模型状态）诊断信息。<br>&emsp;&emsp;<br>另一个有用的诊断是网络模型判定对和判定错的观察值。<br>&emsp;&emsp;<br>对于难以训练的样本，或许你需要更多的数据。<br>&emsp;&emsp;<br>或许你应该剔除训练集中易于建模的多余的样本。<br>&emsp;&emsp;<br>也许可以尝试对训练集划分不同的区域，在特定区域中用更专长的模型。</p><p>&emsp;&emsp;<br>2）权重初始化<br>&emsp;&emsp;<br>经验法则通常是：用小的随机数进行初始化。<br>&emsp;&emsp;<br>在实践中，这可能依旧效果不错，但是对于你的网络来说是最佳的吗？对于不同的激活函数也有一些启发式的初始化方法，但是在实践应用中并没有太多不同。<br>&emsp;&emsp;<br>固定你的网络，然后尝试多种初始化方式。<br>&emsp;&emsp;<br>记住，权重是你的模型真正的参数，你需要找到他们。有很多组权重都能有不错的性能表现，但我们要尽量找到最好的。  </p><p>&emsp;&emsp;<br>尝试所有不同的初始化方法，考察是否有一种方法在其他情况不变的情况下(效果)更优。</p><p>&emsp;&emsp;<br>尝试用无监督的方法，例如自动编码（autoencoder），来进行预先学习。</p><p>&emsp;&emsp;<br>尝试使用一个已经存在的模型，只是针对你的问题重新训练输入层和输出层（迁移学习（transfer learning））<br>&emsp;&emsp;<br>需要提醒的一点是，改变权重初始化方法和激活函数，甚至优化函数/损失函数紧密相关。</p><p>&emsp;&emsp;<br>3）学习率<br>&emsp;&emsp;<br>调整学习率很多时候也是行之有效的时段。  </p><p>以下是可供探索的一些想法：</p><p>&emsp;&emsp;<br>实验很大和很小的学习率</p><p>&emsp;&emsp;<br>格点搜索文献里常见的学习速率值，考察你能学习多深的网络。</p><p>&emsp;&emsp;<br>尝试随周期递减的学习率</p><p>&emsp;&emsp;<br>尝试经过固定周期数后按比例减小的学习率。</p><p>&emsp;&emsp;<br>尝试增加一个动量项（momentum term），然后对学习速率和动量同时进行格点搜索。 </p><p>&emsp;&emsp;<br>越大的网络需要越多的训练，反之亦然。如果你添加了太多的神经元和层数，适当提升你的学习速率。同时学习率需要和训练周期，batch size大小以及优化方法联系在一起考虑。  </p><p>&emsp;&emsp;<br>4）激活函数<br>&emsp;&emsp;<br>你或许应该使用修正激活函数（rectifier activation functions）。他们也许能提供更好的性能。<br>&emsp;&emsp;<br>在这之前，最早的激活函数是sigmoid和tanh，之后是softmax, 线性激活函数，或者输出层上的sigmoid函数。我不建议尝试更多的激活函数，除非你知道你自己在干什么。<br>&emsp;&emsp;<br>尝试全部三种激活函数，并且重缩放你的数据以满足激活函数的边界。<br>&emsp;&emsp;<br>显然，你想要为输出的形式选择正确的传递函数，但是可以考虑一下探索不同表示。例如，把在二元分类问题上使用的sigmoid函数切换到回归问题上使用的线性函数，然后后置处理你的输出。这可能需要改变损失函数使之更合适。详情参阅数据转换那一节。</p><p>&emsp;&emsp;<br>5）网络拓扑<br>&emsp;&emsp;<br>网络结构的改变能带来好处。<br>&emsp;&emsp;<br>你需要多少层以及多少个神经元？抱歉没有人知道。不要问这种问题…<br>&emsp;&emsp;<br>那怎么找到适用你的问题的配置呢？去实验吧。  </p><p>&emsp;&emsp;<br>尝试一个隐藏层和许多神经元（广度模型）。</p><p>&emsp;&emsp;<br>尝试一个深的网络，但是每层只有很少的神经元（深度模型）。</p><p>&emsp;&emsp;<br>尝试上述两种方法的组合。</p><p>&emsp;&emsp;<br>借鉴研究问题与你的类似的论文里面的结构。</p><p>&emsp;&emsp;<br>尝试拓扑模式（扇出（fan out）然后扇入（fan in））和书籍论文里的经验法则（下有链接）  </p><p>&emsp;&emsp;<br>选择总是很困难的。通常说来越大的网络有越强的代表能力，或许你需要它。越多的层数可以提供更强的从数据中学到的抽象特征的能力。或许需要它。<br>&emsp;&emsp;<br>深层的神经网络需要更多的训练，无论是训练周期还是学习率，都应该相应地进行调整。</p><p>&emsp;&emsp;<br>6）Batches和周期<br>&emsp;&emsp;<br>batch size大小会决定最后的梯度，以及更新权重的频度。一个周期(epoch)指的是神经网络看一遍全部训练数据的过程。<br>&emsp;&emsp;<br>你是否已经试验了不同的批次batch size和周期数？ 之前，我们已经讨论了学习率，网络大小和周期之间的关系。<br>&emsp;&emsp;<br>在很深的网络结构里你会经常看到：小的batch size配以大的训练周期。<br>&emsp;&emsp;<br>下面这些或许能有助于你的问题，也或许不能。你要在自己的数据上尝试和观察。</p><p>&emsp;&emsp;<br>尝试选取与训练数据同大小的batch size，但注意一下内存（批次学习（batch learning））</p><p>&emsp;&emsp;<br>尝试选取1作为batch size（在线学习（online learning））</p><p>&emsp;&emsp;<br>尝试用格点搜索不同的小的batch size（8，16，32，…）</p><p>&emsp;&emsp;<br>分别尝试训练少量周期和大量周期。</p><p>&emsp;&emsp;<br>考虑一个接近无穷的周期值(持续训练)，去记录到目前为止能得到的最佳的模型。<br>&emsp;&emsp;<br>一些网络结构对batch size更敏感。我知道多层感知器（Multilayer Perceptrons）通常对batch size是鲁棒的，而LSTM和CNNs比较敏感，但是这只是一个说法（仅供参考）。  </p><p>&emsp;&emsp;<br>7）正则化<br>正则化是一个避免模型在训练集上过拟合的好方法。<br>&emsp;&emsp;<br>神经网络里最新最热的正则化技术是dropout方法，你是否试过？dropout方法在训练阶段随机地跳过一些神经元，驱动这一层其他的神经元去捕捉松弛。简单而有效。你可以从dropout方法开始。  </p><p>&emsp;&emsp;<br>格点搜索不同的丢失比例。</p><p>&emsp;&emsp;<br>分别在输入，隐藏层和输出层中试验dropout方法</p><p>&emsp;&emsp;<br>dropout方法也有一些拓展，比如你也可以尝试drop connect方法。</p><p>&emsp;&emsp;<br>也可以尝试其他更传统的神经网络正则化方法，例如：</p><p>&emsp;&emsp;<br>权重衰减（Weight decay）去惩罚大的权重</p><p>&emsp;&emsp;<br>激活约束（Activation constraint）去惩罚大的激活值</p><p>&emsp;&emsp;<br>你也可以试验惩罚不同的方面，或者使用不同种类的惩罚/正则化（L1, L2, 或者二者同时）</p><p>&emsp;&emsp;<br>8）优化和损失<br>&emsp;&emsp;<br>最常见是应用随机梯度下降法（stochastic gradient descent），但是现在有非常多的优化器。你试验过不同的优化(方法)过程吗？随机梯度下降法是默认的选择。先好好利用它，配以不同的学习率和动量。  </p><p>&emsp;&emsp;<br>许多更高级的优化方法有更多的参数，更复杂，也有更快的收敛速度。 好与坏，是不是需要用，取决于你的问题。  </p><p>&emsp;&emsp;<br>为了更好的利用好一个给定的(优化)方法，你真的需要弄明白每个参数的意义，然后针对你的问题通过格点搜索不同的的取值。困难，消耗时间，但是值得。  </p><p>&emsp;&emsp;<br>我发现了一些更新更流行的方法，它们可以收敛的更快，并且针对一个给定网络的容量提供了一个快速了解的方式，例如：</p><ul><li>ADAM</li><li>RMSprop</li></ul><p>&emsp;&emsp;<br>你还可以探索其他优化算法，例如，更传统的（Levenberg-Marquardt）和不那么传统的（genetic algorithms）。其他方法能够为随机梯度下降法和其他类似方法提供好的出发点去改进。  </p><p>&emsp;&emsp;<br>要被优化的损失函数与你要解决的问题高度相关。然而，你通常还是有一些余地（可以做一些微调，例如回归问题中的均方误（MSE）和平均绝对误差（MAE）等），有时候变换损失函数还有可能获得小的性能提升，这取决于你输出数据的规模和使用的激活函数。  </p><p>&emsp;&emsp;<br>9）Early Stopping/早停法<br>&emsp;&emsp;<br>一旦训练过程中出现(验证集)性能开始下降，你可以停止训练与学习。这可以节省很多时间，而且甚至可以让你使用更详尽的重采样方法来评估你的模型的性能。  </p><p>&emsp;&emsp;<br>早停法是一种用来避免模型在训练数据上的过拟合的正则化方式，它需要你监测模型在训练集以及验证集上每一轮的效果。一旦验证集上的模型性能开始下降，训练就可以停止。</p><p>&emsp;&emsp;<br>如果某个条件满足（衡量准确率的损失），你还可以设置检查点(Checkpointing)来储存模型，使得模型能够继续学习。检查点使你能够早停而非真正的停止训练，因此在最后，你将有一些模型可供选择。</p><ol start="4"><li>通过嵌套模型提升性能  </li></ol><p>&emsp;&emsp;<br>你可以组合多个模型的预测能力。刚才提到了算法调参可以提高最后的性能，调参之后这是下一个可以提升的大领域。<br>&emsp;&emsp;<br>事实上，你可以经常通过组合多个“足够好的”模型来得到优秀的预测能力，而不是通过组合多个高度调参的（脆弱的）模型。  </p><p>你可以考虑以下三个方面的嵌套方式：</p><ul><li>组合模型</li><li>组合视角</li><li>堆叠（Stacking）</li></ul><p>&emsp;&emsp;<br>1）组合模型<br>&emsp;&emsp;<br>有时候我们干脆不做模型选择，而是直接组合它们。<br>&emsp;&emsp;<br>如果你有多个不同的深度学习模型，在你的研究问题上每一个都表现的还不错，你可以通过取它们预测的平均值来进行组合。<br>&emsp;&emsp;<br>模型差异越大，最终效果越好。例如，你可以应用非常不同的网络拓扑或者不同的技术。<br>&emsp;&emsp;<br>如果每个模型都效果不错但是不同的方法/方式，嵌套后的预测能力将更加鲁棒。<br>&emsp;&emsp;<br>每一次你训练网络，你初始化不同的权重，然后它会收敛到不同的最终权重。你可以多次重复这一过程去得到很多网络，然后把这些网络的预测值组合在一起。<br>&emsp;&emsp;<br>它们的预测将会高度相关，但是在那些难以预测的特征上，它会给你一个意外的小提升。</p><p>&emsp;&emsp;<br>2）组合视角<br>&emsp;&emsp;<br>同上述类似，但是从不同视角重构你的问题，训练你的模型。<br>&emsp;&emsp;<br>同样，目标得到的是效果不错但是不同的模型（例如，不相关的预测）。得到不同的模型的方法，你可以依赖我们在数据那一小节中罗列的那些非常不同的放缩和转换方法。<br>&emsp;&emsp;<br>你用来训练模型的转换方法越不同，你构建问题的方式越不同，你的结果被提升的程度就越高。<br>&emsp;&emsp;<br>简单使用预测的均值将会是一个好的开始。</p><p>&emsp;&emsp;<br>3）stacking/堆叠<br>&emsp;&emsp;<br>你还可以学习如何最佳地组合多个模型的预测。这称作堆叠泛化（stacked generalization），或者简短来说就叫堆叠。<br>&emsp;&emsp;<br>通常上，你使用简单线性回归方法就可以得到比取预测平均更好的结果，像正则化的回归（regularized regression），就会学习如何给不同的预测模型赋权重。基线模型是通过取子模型的预测均值得到的，但是应用学习了权重的模型会提升性能。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dpvywdzxv/image/upload/v1547297948/samples/java%20files/photo-1544728344-7efa025e5603.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://leesen998.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习基础" scheme="https://leesen998.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>机器学习算法优缺点对比及选择-小结</title>
    <link href="https://leesen998.github.io/2017/10/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%BC%98%E7%BC%BA%E7%82%B9%E5%AF%B9%E6%AF%94%E5%8F%8A%E9%80%89%E6%8B%A9/"/>
    <id>https://leesen998.github.io/2017/10/26/机器学习算法优缺点对比及选择/</id>
    <published>2017-10-26T11:48:29.000Z</published>
    <updated>2019-03-22T07:38:31.579Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><img src="https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0C/00/ChMlWVyA5JyIFsD7AArXsWw3WSoAAIp9gN0N1UACtfJ346.jpg" alt="" style="width:100%"></p><p>机器学习算法优缺点对比及选择</p><a id="more"></a><p>机器学习算法太多了，分类、回归、聚类、推荐、图像识别领域等等，要想找到一个合适算法真的不容易，所以在实际应用中，我们一般都是采用启发式学习方式来实验。通常最开始我们都会选择大家普遍认同的算法，诸如SVM，GBDT，Adaboost，现在深度学习很火热，神经网络也是一个不错的选择。</p><p>假如你在乎精度（accuracy）的话，最好的方法就是通过交叉验证（cross-validation）对各个算法一个个地进行测试，进行比较，然后调整参数确保每个算法达到最优解，最后选择最好的一个。但是如果你只是在寻找一个“足够好”的算法来解决你的问题，或者这里有些技巧可以参考，下面来分析下各个算法的优缺点，基于算法的优缺点，更易于我们去选择它。</p><h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h3><p>在机器学习领域，一个基本的定理就是“没有免费的午餐”。<strong>换言之，就是没有算法能完美地解决所有问题，尤其是对监督学习而言（例如预测建模）</strong>。</p><p>举例来说，你不能去说神经网络任何情况下都能比决策树更有优势，反之亦然。它们要受很多因素的影响，比如你的数据集的规模或结构。</p><p>其结果是，在用给定的测试集来评估性能并挑选算法时，你应当根据具体的问题来采用不同的算法。</p><p>当然，<strong>所选的算法必须要适用于你自己的问题，这就要求选择正确的机器学习任务。</strong>作为类比，如果你需要打扫房子，你可能会用到吸尘器、扫帚或是拖把，但你绝对不该掏出铲子来挖地。</p><h3 id="2-偏差-amp-方差"><a href="#2-偏差-amp-方差" class="headerlink" title="**2. 偏差&amp;方差"></a>**2. 偏差&amp;方差</h3><p>在统计学中，一个模型好坏，是根据偏差和方差来衡量的，所以我们先来普及一下偏差(bias)和方差(variance)：</p><ul><li><p>偏差：描述的是预测值（估计值）的期望E’与真实值Y之间的差距。偏差越大，越偏离真实数据。</p></li><li><p>方差：描述的是预测值P的变化范围，离散程度，是预测值的方差，也就是离其期望值E的距离。方差越大，数据的分布越分散。</p></li></ul><p>模型的真实误差是两者之和，如公式：</p><p>通常情况下，如果是<strong>小训练集，高偏差/低方差的分类器（例如，朴素贝叶斯NB）要比低偏差/高方差大分类的优势大（例如，KNN）</strong>，<strong>因为后者会发生过拟合（overfiting）</strong>。<br>然而，<strong>随着你训练集的增长，模型对于原数据的预测能力就越好，偏差就会降低，此时低偏差/高方差的分类器就会渐渐的表现其优势（因为它们有较低的渐近误差），而高偏差分类器这时已经不足以提供准确的模型了。</strong></p><p><strong>为什么说朴素贝叶斯是高偏差低方差?</strong></p><p>以下内容引自知乎：</p><p>首先，假设你知道训练集和测试集的关系。简单来讲是我们要在训练集上学习一个模型，然后拿到测试集去用，效果好不好要根据测试集的错误率来衡量。但很多时候，我们只能假设测试集和训练集的是符合同一个数据分布的，但却拿不到真正的测试数据。这时候怎么在只看到训练错误率的情况下，去衡量测试错误率呢？</p><p>由于训练样本很少（至少不足够多），所以通过训练集得到的模型，总不是真正正确的。（就算在训练集上正确率100%，也不能说明它刻画了真实的数据分布，要知道刻画真实的数据分布才是我们的目的，而不是只刻画训练集的有限的数据点）。而且，实际中，训练样本往往还有一定的噪音误差，所以如果太追求在训练集上的完美而采用一个很复杂的模型，会使得模型把训练集里面的误差都当成了真实的数据分布特征，从而得到错误的数据分布估计。这样的话，到了真正的测试集上就错的一塌糊涂了（这种现象叫过拟合）。但是也不能用太简单的模型，否则在数据分布比较复杂的时候，模型就不足以刻画数据分布了（体现为连在训练集上的错误率都很高，这种现象较欠拟合）。过拟合表明采用的模型比真实的数据分布更复杂，而欠拟合表示采用的模型比真实的数据分布要简单。</p><p><strong>在统计学习框架下，大家刻画模型复杂度的时候，有这么个观点，认为Error = Bias +<br>Variance。这里的Error大概可以理解为模型的预测错误率，是有两部分组成的，一部分是由于模型太简单而带来的估计不准确的部分（Bias），另一部分是由于模型太复杂而带来的更大的变化空间和不确定性（Variance）。</strong></p><p>所以，这样就容易分析朴素贝叶斯了。它简单的假设了各个数据之间是无关的，是一个被<strong>严重简化了的模型</strong>。所以，<strong>对于这样一个简单模型，大部分场合都会Bias部分大于Variance部分，也就是说高偏差而低方差</strong>。</p><p>在实际中，为了让Error尽量小，我们在选择模型的时候需要平衡Bias和Variance所占的比例，也就是平衡over-fitting和under-fitting。</p><p>当模型复杂度上升的时候，偏差会逐渐变小，而方差会逐渐变大。</p><h3 id="3-常见算法优缺点"><a href="#3-常见算法优缺点" class="headerlink" title="**3. 常见算法优缺点"></a>**3. 常见算法优缺点</h3><h4 id="3-1-朴素贝叶斯"><a href="#3-1-朴素贝叶斯" class="headerlink" title="3.1 朴素贝叶斯"></a><strong>3.1 朴素贝叶斯</strong></h4><p>朴素贝叶斯属于生成式模型（<strong>关于生成模型和判别式模型，主要还是在于是否需要求联合分布</strong>），比较简单，你只需做一堆计数即可。<strong>如果注有条件独立性假设（一个比较严格的条件），朴素贝叶斯分类器的收敛速度将快于判别模型，比如逻辑回归</strong>，所以你只需要较少的训练数据即可。即使NB条件独立假设不成立，NB分类器在实践中仍然表现的很出色。<strong>它的主要缺点是它不能学习特征间的相互作用</strong>——(<strong>不能处理冗余特征</strong>)，用mRMR中R来讲，就是<strong>特征冗余</strong>。引用一个比较经典的例子，比如，虽然你喜欢BradPitt和Tom Cruise的电影，但是它不能学习出你不喜欢他们在一起演的电影。</p><h4 id="优点："><a href="#优点：" class="headerlink" title="优点："></a><strong>优点</strong>：</h4><ul><li><p>朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以及<strong>稳定的分类效率。</strong></p></li><li><p>对<strong>大数量训练和查询时具有较高的速度</strong>。即使使用超大规模的训练集，针对每个项目通常也只会有相对较少的特征数，并且对项目的训练和分类也仅仅是特征概率的数学运算而已；</p></li><li><p>对<strong>小规模的数据表现很好</strong>，<strong>能处理多分类任务</strong>，<strong>适合增量式训练（即可以实时的对新增的样本进行训练）</strong>；</p></li><li><p><strong>对缺失数据不太敏感，</strong>算法也比较简单，常用于文本分类；</p></li><li><p>朴素贝叶斯对结果解释容易理解；</p></li></ul><h4 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a><strong>缺点</strong>：</h4><ul><li><p>需要计算先验概率；</p></li><li><p><strong> 分类决策存在错误率；</strong></p></li><li><p>对输入数据的表达形式很敏感；</p></li><li><p>由于<strong>使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好</strong>；</p></li></ul><h4 id="朴素贝叶斯应用领域"><a href="#朴素贝叶斯应用领域" class="headerlink" title="朴素贝叶斯应用领域"></a><strong>朴素贝叶斯应用领域</strong></h4><ul><li><p><strong> 欺诈检测中使用较多</strong></p></li><li><p>一封电子邮件是否是垃圾邮件</p></li><li><p>一篇文章应该分到科技、政治，还是体育类</p></li><li><p>一段文字表达的是积极的情绪还是消极的情绪？</p></li><li><p>人脸识别</p></li></ul><h3 id="3-2-Logistic-Regression（逻辑回归）"><a href="#3-2-Logistic-Regression（逻辑回归）" class="headerlink" title="**3.2 Logistic Regression（逻辑回归）"></a>**3.2 Logistic Regression（逻辑回归）</h3><p>逻辑回归属于判别式模型，同时伴有很多模型正则化的方法（L0，<br>L1，L2，etc），而且你不必像在用朴素贝叶斯那样担心你的特征是否相关。与决策树、SVM相比，你还会得到一个不错的概率解释，你甚至可以轻松地利用新数据来更新模型（使用在线梯度下降算法-online gradient descent）。如果你需要一个概率架构（比如，简单地调节分类阈值，指明不确定性，或者是要获得置信区间），或者你希望以后将更多的训练数据快速整合到模型中去，那么使用它吧。</p><p><strong>Sigmoid函数</strong>：表达式如下:</p><h4 id="优点：-1"><a href="#优点：-1" class="headerlink" title="优点："></a><strong>优点：</strong></h4><ul><li><p>实现简单，广泛的应用于工业问题上；</p></li><li><p>分类时计算量非常小，速度很快，存储资源低；</p></li><li><p>便利的观测样本概率分数；</p></li><li><p>对逻辑回归而言，多重共线性并不是问题，它可以结合L2正则化来解决该问题；</p></li><li><p>计算代价不高，易于理解和实现；</p></li></ul><h4 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a><strong>缺点</strong>：</h4><ul><li><p>当特征空间很大时，逻辑回归的性能不是很好；</p></li><li><p>容易<strong>欠拟合</strong>，一般准确度不太高</p></li><li><p>不能很好地处理大量多类特征或变量；</p></li><li><p>只能处理两分类问题（在此基础上衍生出来的softmax可以用于多分类），且必须<strong>线性可分</strong>；</p></li><li><p>对于非线性特征，需要进行转换；</p></li></ul><h4 id="logistic回归应用领域："><a href="#logistic回归应用领域：" class="headerlink" title="logistic回归应用领域："></a><strong>logistic回归应用领域：</strong></h4><ul><li><p>用于二分类领域，可以得出概率值，适用于根据分类概率排名的领域，如搜索排名等。</p></li><li><p>Logistic回归的扩展softmax可以应用于多分类领域，如手写字识别等。</p></li><li><p>信用评估</p></li><li><p>测量市场营销的成功度</p></li><li><p>预测某个产品的收益</p></li><li><p>特定的某天是否会发生地震</p></li></ul><h3 id="3-3-线性回归"><a href="#3-3-线性回归" class="headerlink" title="**3.3 线性回归"></a>**3.3 线性回归</h3><p>线性回归是用于回归的，它不像Logistic回归那样用于分类，其基本思想是用<strong>梯度下降法</strong>对最小二乘法形式的误差函数进行优化，当然也可以用normal equation直接求得参数的解，结果为： </p><p>而在LWLR（局部加权线性回归）中，参数的计算表达式为: </p><p>由此可见LWLR与LR不同，LWLR是一个非参数模型，因为每次进行回归计算都要遍历训练样本至少一次。</p><p><strong>优点</strong>： 实现简单，计算简单；</p><p><strong>缺点</strong>： 不能拟合非线性数据.</p><h3 id="3-4-最近邻算法——KNN"><a href="#3-4-最近邻算法——KNN" class="headerlink" title="**3.4 最近邻算法——KNN"></a>**3.4 最近邻算法——KNN</h3><p>KNN即最近邻算法，其主要过程为：</p><p>1.<br>计算训练样本和测试样本中每个样本点的距离（常见的距离度量有欧式距离，马氏距离等）；</p><ol start="2"><li><p>对上面所有的距离值进行排序(升序)；</p></li><li><p>选前k个最小距离的样本；</p></li><li><p>根据这k个样本的标签进行投票，得到最后的分类类别；</p></li></ol><p>如何选择一个最佳的K值，这取决于数据。一般情况下，在分类时较大的K值能够减小噪声的影响，但会使类别之间的界限变得模糊。一个较好的K值可通过各种启发式技术来获取，比如，交叉验证。另外噪声和非相关性特征向量的存在会使K近邻算法的准确性减小。近邻算法具有较强的一致性结果，<strong>随着数据趋于无限，算法保证错误率不会超过贝叶斯算法错误率的两倍。</strong>对于一些好的K值，K近邻保证错误率不会超过贝叶斯理论误差率。</p><h4 id="KNN算法的优点"><a href="#KNN算法的优点" class="headerlink" title="KNN算法的优点"></a><strong>KNN算法的优点</strong></h4><ul><li><p>理论成熟，思想简单，既可以<strong>用来做分类也可以用来做回归</strong>；</p></li><li><p>可用于非线性分类；</p></li><li><p>训练时间复杂度为O(n)；</p></li><li><p>对<strong>数据没有假设，准确度高，对outlier不敏感</strong>；</p></li><li><p>KNN是一种<strong>在线技术</strong>，新数据可以直接加入数据集而不必进行重新训练；</p></li><li><p>KNN理论简单，容易实现；</p></li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a><strong>缺点</strong></h4><ul><li><p><strong>样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）效果差</strong>；</p></li><li><p><strong>需要大量内存</strong>；</p></li><li><p>对于样本容量大的数据集计算量比较大（体现在距离计算上）；</p></li><li><p>样本不平衡时，预测偏差比较大。如：某一类的样本比较少，而其它类样本比较多；</p></li><li><p><strong>KNN每一次分类都会重新进行一次全局运算</strong>；</p></li><li><p><strong> k值大小的选择没有理论选择最优，往往是结合K-折交叉验证得到最优k值选择；</strong></p></li></ul><h4 id="KNN算法应用领域"><a href="#KNN算法应用领域" class="headerlink" title="KNN算法应用领域"></a><strong>KNN算法应用领域</strong></h4><p>文本分类、模式识别、聚类分析，多分类领域</p><h3 id="3-5-决策树"><a href="#3-5-决策树" class="headerlink" title="**3.5 决策树"></a>**3.5 决策树</h3><p>决策树的一大优势就是易于解释。它可以毫无压力地处理特征间的交互关系并且是非参数化的，因此你不必担心异常值或者数据是否线性可分（举个例子，决策树能轻松处理好类别A在某个特征维度x的末端，类别B在中间，然后类别A又出现在特征维度x前端的情况）。它的缺点之一就是不支持在线学习，于是在新样本到来后，决策树需要全部重建。另一个缺点就是容易出现过拟合，但这也就是诸如随机森林RF（或提升树boosted<br>tree）之类的集成方法的切入点。另外，随机森林经常是很多分类问题的赢家（通常比支持向量机好上那么一丁点），它训练快速并且可调，同时你无须担心要像支持向量机那样调一大堆参数，所以在以前都一直很受欢迎。</p><p>决策树中很重要的一点就是选择一个属性进行分枝，因此要注意一下信息增益的计算公式，并深入理解它。</p><p>信息熵的计算公式如下:</p><p>其中的n代表有n个分类类别（比如假设是二类问题，那么n=2）。分别计算这2类样本在总样本中出现的概率  和  ，这样就可以计算出未选中属性分枝前的信息熵。</p><p>现在选中一个属性  用来进行分枝，此时分枝规则是：如果  的话，将样本分到树的一个分支；如果不相等则进入另一个分支。很显然，分支中的样本很有可能包括2个类别，分别计算这2个分支的熵  和  ,计算出分枝后的总信息熵  ，则此时的信息增益  。以信息增益为原则，把所有的属性都测试一边，选择一个使增益最大的属性作为本次分枝属性。</p><h4 id="决策树自身的优点"><a href="#决策树自身的优点" class="headerlink" title="决策树自身的优点"></a><strong>决策树自身的优点</strong></h4><ul><li><p>决策树易于理解和解释，可以可视化分析，容易提取出规则；</p></li><li><p>可以同时处理标称型和数值型数据；</p></li><li><p>比较适合处理有缺失属性的样本；</p></li><li><p>能够处理不相关的特征；</p></li><li><p>测试数据集时，运行速度比较快；</p></li><li><p>在相对短的时间内能够对大型数据源做出可行且效果良好的结果。</p></li></ul><h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a><strong>缺点</strong></h4><ul><li><p>容易发生过拟合（随机森林可以很大程度上减少过拟合）；</p></li><li><p>容易忽略数据集中属性的相互关联；</p></li><li><p>对于那些各类别样本数量不一致的数据，在决策树中，进行属性划分时，不同的判定准则会带来不同的属性选择倾向；信息增益准则对可取数目较多的属性有所偏好（典型代表ID3算法），而增益率准则（CART）则对可取数目较少的属性有所偏好，但CART进行属性划分时候不再简单地直接利用增益率尽心划分，而是采用一种启发式规则）（只要是使用了信息增益，都有这个缺点，如RF）。</p></li><li><p>ID3算法计算信息增益时结果偏向数值比较多的特征。</p></li></ul><h4 id="改进措施"><a href="#改进措施" class="headerlink" title="改进措施"></a><strong>改进措施</strong></h4><ul><li><p>对决策树进行剪枝。可以采用交叉验证法和加入正则化的方法。</p></li><li><p>使用基于决策树的combination算法，如bagging算法，randomforest算法，可以解决过拟合的问题；</p></li></ul><h4 id="应用领域"><a href="#应用领域" class="headerlink" title="应用领域"></a><strong>应用领域</strong></h4><p>企业管理实践，企业投资决策，由于决策树很好的分析能力，在决策过程应用较多。</p><h3 id="3-5-1-ID3、C4-5算法"><a href="#3-5-1-ID3、C4-5算法" class="headerlink" title="**3.5.1 ID3、C4.5算法"></a>**3.5.1 ID3、C4.5算法</h3><p>ID3算法是以信息论为基础，以信息熵和信息增益度为衡量标准，从而实现对数据的归纳分类。ID3算法计算每个属性的信息增益，并选取具有最高增益的属性作为给定的测试属性。C4.5算法核心思想是ID3算法，是ID3算法的改进，改进方面有：</p><ul><li>用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足；</li><li>在树构造过程中进行剪枝； - 能处理非离散的数据； - 能处理不完整的数据。</li></ul><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a><strong>优点</strong></h4><ul><li>产生的分类规则易于理解，准确率较高。</li></ul><h4 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a><strong>缺点</strong></h4><ul><li><p>在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效；</p></li><li><p>C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。</p></li></ul><h3 id="3-5-2-CART分类与回归树"><a href="#3-5-2-CART分类与回归树" class="headerlink" title="**3.5.2 CART分类与回归树"></a>**3.5.2 CART分类与回归树</h3><p>是一种决策树分类方法，采用基于最小距离的基尼指数估计函数，用来决定由该子数据集生成的决策树的拓展形。如果目标变量是标称的，称为分类树；如果目标变量是连续的，称为回归树。分类树是使用树结构算法将数据分成离散类的方法。</p><h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a><strong>优点</strong></h4><p>1）非常灵活，可以允许有部分错分成本，还可指定先验概率分布，可使用自动的成本复杂性剪枝来得到归纳性更强的树。<br>2）在面对诸如存在缺失值、变量数多等问题时CART 显得非常稳健。</p><h3 id="3-6-Adaboosting"><a href="#3-6-Adaboosting" class="headerlink" title="**3.6 Adaboosting"></a>**3.6 Adaboosting</h3><p>Adaboost是一种加和模型，每个模型都是基于上一次模型的错误率来建立的，过分关注分错的样本，而对正确分类的样本减少关注度，逐次迭代之后，可以得到一个相对较好的模型。该算法是一种典型的boosting算法，其加和理论的优势可以使用Hoeffding不等式得以解释。有兴趣的同学可以阅读下自己之前写的这篇文章<em>AdaBoost算法详述</em>.下面总结下它的优缺点。</p><h4 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a><strong>优点</strong></h4><ul><li><p>Adaboost是一种有很高精度的分类器。</p></li><li><p>可以使用各种方法构建子分类器，Adaboost算法提供的是框架。</p></li><li><p>当使用简单分类器时，计算出的结果是可以理解的，并且弱分类器的构造极其简单。</p></li><li><p>简单，不用做特征筛选。</p></li><li><p>不易发生overfitting。</p></li></ul><p>关于Adaboost, GBDT 及 XGBoost<br>算法区别，参考这篇文章：<em>Adaboost、GBDT与XGBoost的区别</em></p><h4 id="缺点-3"><a href="#缺点-3" class="headerlink" title="缺点"></a><strong>缺点</strong></h4><ul><li>对outlier比较敏感</li></ul><h3 id="3-7-SVM支持向量机"><a href="#3-7-SVM支持向量机" class="headerlink" title="**3.7 SVM支持向量机"></a>**3.7 SVM支持向量机</h3><p>支持向量机，一个经久不衰的算法，高准确率，为避免过拟合提供了很好的理论保证，而且就算数据在原特征空间线性不可分，只要给个合适的核函数，它就能运行得很好。在动辄超高维的文本分类问题中特别受欢迎。可惜内存消耗大，难以解释，运行和调参也有些烦人，而随机森林却刚好避开了这些缺点，比较实用。</p><h4 id="优点-3"><a href="#优点-3" class="headerlink" title="优点"></a><strong>优点</strong></h4><ul><li><p>可以解决高维问题，即大型特征空间；</p></li><li><p>解决小样本下机器学习问题；</p></li><li><p>能够处理非线性特征的相互作用；</p></li><li><p>无局部极小值问题；（相对于神经网络等算法）</p></li><li><p>无需依赖整个数据；</p></li><li><p>泛化能力比较强；</p></li></ul><h4 id="缺点-4"><a href="#缺点-4" class="headerlink" title="缺点"></a><strong>缺点</strong></h4><ul><li><p>当观测样本很多时，效率并不是很高；</p></li><li><p>对非线性问题没有通用解决方案，有时候很难找到一个合适的核函数；</p></li><li><p>对于核函数的高维映射解释力不强，尤其是径向基函数；</p></li><li><p>常规SVM只支持二分类；</p></li><li><p><strong>对缺失数据敏感</strong>；</p></li></ul><p>对于核的选择也是有技巧的（libsvm中自带了四种核函数：线性核、多项式核、RBF以及sigmoid核）：</p><ul><li><p>第一，如果样本数量小于特征数，那么就没必要选择非线性核，简单的使用线性核就可以了；</p></li><li><p>第二，如果样本数量大于特征数目，这时可以使用非线性核，将样本映射到更高维度，一般可以得到更好的结果；</p></li><li><p>第三，如果样本数目和特征数目相等，该情况可以使用非线性核，原理和第二种一样。</p></li></ul><p>对于第一种情况，也可以先对数据进行降维，然后使用非线性核，这也是一种方法。</p><h4 id="SVM应用领域"><a href="#SVM应用领域" class="headerlink" title="SVM应用领域"></a><strong>SVM应用领域</strong></h4><p>文本分类、图像识别（主要二分类领域，毕竟常规SVM只能解决二分类问题）</p><h3 id="3-8-人工神经网络的优缺点"><a href="#3-8-人工神经网络的优缺点" class="headerlink" title="**3.8 人工神经网络的优缺点"></a>**3.8 人工神经网络的优缺点</h3><h4 id="人工神经网络的优点："><a href="#人工神经网络的优点：" class="headerlink" title="人工神经网络的优点："></a><strong>人工神经网络的优点：</strong></h4><ul><li><p>分类的准确度高；</p></li><li><p>并行分布处理能力强,分布存储及学习能力强，</p></li><li><p>对噪声神经有较强的鲁棒性和容错能力；</p></li><li><p>具备联想记忆的功能，能充分逼近复杂的非线性关系；</p></li></ul><h4 id="人工神经网络的缺点："><a href="#人工神经网络的缺点：" class="headerlink" title="人工神经网络的缺点："></a><strong>人工神经网络的缺点：</strong></h4><ul><li><p>神经网络需要大量的参数，如网络拓扑结构、权值和阈值的初始值；</p></li><li><p>黑盒过程，不能观察之间的学习过程，输出结果难以解释，会影响到结果的可信度和可接受程度；</p></li><li><p>学习时间过长，有可能陷入局部极小值，甚至可能达不到学习的目的。</p></li></ul><p><strong>人工神经网络应用领域：</strong></p><p>目前深度神经网络已经应用与计算机视觉，自然语言处理，语音识别等领域并取得很好的效果。</p><h3 id="3-9-K-Means聚类"><a href="#3-9-K-Means聚类" class="headerlink" title="**3.9 K-Means聚类"></a>**3.9 K-Means聚类</h3><p>是一个简单的聚类算法，把n的对象根据他们的属性分为k个分割，k\&lt; n。<br>算法的核心就是要优化失真函数J,使其收敛到局部最小值但不是全局最小值。</p><p>关于K-Means聚类的文章，参见<em>机器学习算法-K-means聚类</em>。关于K-Means的推导，里面可是有大学问的，蕴含着强大的EM思想。</p><h4 id="优点-4"><a href="#优点-4" class="headerlink" title="优点"></a><strong>优点</strong></h4><ul><li><p>算法简单，容易实现 ；</p></li><li><p>算法速度很快；</p></li><li><p>对处理大数据集，该算法是相对可伸缩的和高效率的，因为它的复杂度大约是O(nkt)，其中n是所有对象的数目，k是簇的数目,t是迭代的次数。通常k\&lt;\&lt;n。这个算法<strong>通常局部收敛</strong>。</p></li><li><p>算法尝试找出使平方误差函数值最小的k个划分。当簇是密集的、球状或团状的，且簇与簇之间区别明显时，聚类效果较好。</p></li></ul><h4 id="缺点-5"><a href="#缺点-5" class="headerlink" title="缺点"></a><strong>缺点</strong></h4><ul><li><p>对数据类型要求较高，适合数值型数据；</p></li><li><p>可能收敛到局部最小值，在大规模数据上收敛较慢</p></li><li><p>分组的数目k是一个输入参数，不合适的k可能返回较差的结果。</p></li><li><p>对初值的簇心值敏感，对于不同的初始值，可能会导致不同的聚类结果；</p></li><li><p>不适合于发现非凸面形状的簇，或者大小差别很大的簇。</p></li><li><p>对于”噪声”和孤立点数据敏感，少量的该类数据能够对平均值产生极大影响。</p></li></ul><h3 id="3-10-EM最大期望算法"><a href="#3-10-EM最大期望算法" class="headerlink" title="**3.10 EM最大期望算法"></a>**3.10 EM最大期望算法</h3><p>EM算法是基于模型的聚类方法，是在概率模型中寻找参数最大似然估计的算法，其中概率模型依赖于无法观测的隐藏变量。E步估计隐含变量，M步估计其他参数，交替将极值推向最大。</p><p>EM算法比K-means算法计算复杂，收敛也较慢，不适于大规模数据集和高维数据，但比K-means算法计算结果稳定、准确。EM经常用在机器学习和计算机视觉的数据集聚（Data<br>Clustering）领域。</p><h3 id="3-11-集成算法（AdaBoost算法）"><a href="#3-11-集成算法（AdaBoost算法）" class="headerlink" title="**3.11 集成算法（AdaBoost算法）"></a>**3.11 集成算法（AdaBoost算法）</h3><h4 id="AdaBoost算法优点："><a href="#AdaBoost算法优点：" class="headerlink" title="AdaBoost算法优点："></a><strong>AdaBoost算法优点：</strong></h4><ul><li><p>很好的利用了弱分类器进行级联；</p></li><li><p>可以将不同的分类算法作为弱分类器；</p></li><li><p>AdaBoost具有很高的精度；</p></li><li><p>相对于bagging算法和Random Forest算法，AdaBoost充分考虑的每个分类器的权重；</p></li></ul><h4 id="Adaboost算法缺点："><a href="#Adaboost算法缺点：" class="headerlink" title="Adaboost算法缺点："></a><strong>Adaboost算法缺点：</strong></h4><ul><li><p>AdaBoost迭代次数也就是弱分类器数目不太好设定，可以使用交叉验证来进行确定；</p></li><li><p>数据不平衡导致分类精度下降；</p></li><li><p>训练比较耗时，每次重新选择当前分类器最好切分点；</p></li></ul><h4 id="AdaBoost应用领域："><a href="#AdaBoost应用领域：" class="headerlink" title="AdaBoost应用领域："></a><strong>AdaBoost应用领域：</strong></h4><p>模式识别、计算机视觉领域，用于二分类和多分类场景</p><h3 id="3-12-排序算法（PageRank）"><a href="#3-12-排序算法（PageRank）" class="headerlink" title="**3.12 排序算法（PageRank）"></a>**3.12 排序算法（PageRank）</h3><p>PageRank是google的页面排序算法，是基于从许多优质的网页链接过来的网页，必定还是优质网页的回归关系，来判定所有网页的重要性。（也就是说，一个人有着越多牛X朋友的人，他是牛X的概率就越大。）</p><h4 id="PageRank优点"><a href="#PageRank优点" class="headerlink" title="PageRank优点"></a><strong>PageRank优点</strong></h4><ul><li>完全独立于查询，只依赖于网页链接结构，可以离线计算。</li></ul><h4 id="PageRank缺点"><a href="#PageRank缺点" class="headerlink" title="PageRank缺点"></a><strong>PageRank缺点</strong></h4><ul><li><p>PageRank算法忽略了网页搜索的时效性。</p></li><li><p>旧网页排序很高，存在时间长，积累了大量的in-links，拥有最新资讯的新网页排名却很低，因为它们几乎没有in-links。</p></li></ul><h3 id="3-13-关联规则算法（Apriori算法）"><a href="#3-13-关联规则算法（Apriori算法）" class="headerlink" title="**3.13 关联规则算法（Apriori算法）"></a>**3.13 关联规则算法（Apriori算法）</h3><p>Apriori算法是一种挖掘关联规则的算法，用于挖掘其内含的、未知的却又实际存在的数据关系，其核心是基于两阶段频集思想的递推算法<br>。</p><h4 id="Apriori算法分为两个阶段："><a href="#Apriori算法分为两个阶段：" class="headerlink" title="Apriori算法分为两个阶段："></a><strong>Apriori算法分为两个阶段：</strong></h4><ul><li><p>寻找频繁项集</p></li><li><p>由频繁项集找关联规则</p></li></ul><h4 id="算法缺点："><a href="#算法缺点：" class="headerlink" title="算法缺点："></a><strong>算法缺点：</strong></h4><ul><li><p>在每一步产生侯选项目集时循环产生的组合过多，没有排除不应该参与组合的元素；</p></li><li><p>每次计算项集的支持度时，都对数据库中<br>的全部记录进行了一遍扫描比较，需要很大的I/O负载。</p></li></ul><h3 id="4-算法选择参考"><a href="#4-算法选择参考" class="headerlink" title="**4. 算法选择参考"></a>**4. 算法选择参考</h3><p>之前笔者翻译过一些国外的文章，其中有一篇文章中给出了一个简单的算法选择技巧：</p><ol><li><p>首当其冲应该选择的就是逻辑回归，如果它的效果不怎么样，那么可以将它的结果作为基准来参考，在基础上与其他算法进行比较；</p></li><li><p>然后试试决策树（随机森林）看看是否可以大幅度提升你的模型性能。即便最后你并没有把它当做为最终模型，你也可以使用随机森林来移除噪声变量，做特征选择；</p></li><li><p>如果特征的数量和观测样本特别多，那么当资源和时间充足时（这个前提很重要），使用SVM不失为一种选择。</p></li></ol><p>通常情况下：【GBDT>=SVM>=RF>=Adaboost>=Other…】，现在深度学习很热门，很多领域都用到，它是以神经网络为基础的，目前笔者自己也在学习，只是理论知识不扎实，理解的不够深入，这里就不做介绍了，希望以后可以写一片抛砖引玉的文章。</p><p>算法固然重要，<strong>但好的数据却要优于好的算法</strong>，设计优良特征是大有裨益的。假如你有一个超大数据集，那么无论你使用哪种算法可能对分类性能都没太大影响（此时就可以根据速度和易用性来进行抉择）。</p>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://desk-fd.zol-img.com.cn/t_s1920x1080c5/g2/M00/0C/00/ChMlWVyA5JyIFsD7AArXsWw3WSoAAIp9gN0N1UACtfJ346.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;p&gt;机器学习算法优缺点对比及选择&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://leesen998.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习基础" scheme="https://leesen998.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
</feed>
