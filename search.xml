<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[推荐系统--神经协同过滤NCF原理及实战]]></title>
    <url>%2F2018%2F11%2F19%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F--%E7%A5%9E%E7%BB%8F%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4NCF%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[推荐系统–神经协同过滤NCF原理及实战论文地址：https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf 1、Neural Collaborative Filtering1.1 背景本文讨论的主要是隐性反馈协同过滤解决方案，先来明确两个概念：显性反馈和隐性反馈： 显性反馈行为包括用户明确表示对物品喜好的行为隐性反馈行为指的是那些不能明确反应用户喜好 举例来说： 很多应用场景，并没有显性反馈的存在。因为大部分用户是沉默的用户，并不会明确给系统反馈“我对这个物品的偏好值是多少”。因此，推荐系统可以根据大量的隐性反馈来推断用户的偏好值。 根据已得到的隐性反馈数据，我们将用户-条目交互矩阵Y定义为： 但是，Yui为1仅代表二者有交互记录，并不代表用户u真的喜欢项目i，同理，u和i没有交互记录也不能代表u不喜欢i。这对隐性反馈的学习提出了挑战，因为它提供了关于用户偏好的噪声信号。虽然观察到的条目至少反映了用户对项目的兴趣，但是未查看的条目可能只是丢失数据，并且这其中存在自然稀疏的负反馈。 在隐性反馈上的推荐问题可以表达为估算矩阵 Y中未观察到的条目的分数问题（这个分数被用来评估项目的排名）。形式上它可以被抽象为学习函数： 为了处理缺失数据，有两种常见的做法：要么将所有未观察到的条目视作负反馈，要么从没有观察到条目中抽样作为负反馈实例。 1.2 矩阵分解及其缺陷传统的求解方法是矩阵分解(MF,Matrix Factorization)，为每个user和item找到一个隐向量，问题变为： 这里的 K表示隐式空间（latent space）的维度。正如我们所看到的，MF模型是用户和项目的潜在因素的双向互动，它假设潜在空间的每一维都是相互独立的并且用相同的权重将它们线性结合。因此，MF可视为隐向量（latent factor）的线性模型。 论文中给出了一个例子来说明这种算法的局限性： 1(a)是user-item交互矩阵，1(b)是用户的隐式空间，论文中强调了两点来理解这张图片：1）MF将user和item分布到同样的隐式空间中，那么两个用户之间的相似性也可以用二者在隐式空间中的向量夹角来确定。2）使用Jaccard系数来作为真实的用户相似性。通过MF计算的相似性与Jaccard系数计算的相似性也可以用来评判MF的性能。我们先来看看Jaccard系数 上面的示例显示了MF因为使用一个简单的和固定的内积，来估计在低维潜在空间中用户-项目的复杂交互，从而所可能造成的限制。解决该问题的方法之一是使用大量的潜在因子 K (就是隐式空间向量的维度)。然而这可能对模型的泛化能力产生不利的影响（e.g. 数据的过拟合问题），特别是在稀疏的集合上。论文通过使用DNNs从数据中学习交互函数，突破了这个限制。 1.3 NCF本文先提出了一种通用框架： 针对这个通用框架，论文提出了三种不同的实现，三种实现可以用一张图来说明： GMF：上图中仅使用GMF layer，就得到了第一种实现方式GMF，GMF被称为广义矩阵分解，输出层的计算公式为： MLP上图中仅使用右侧的MLP Layers，就得到了第二种学习方式，通过多层神经网络来学习user和item的隐向量。这样，输出层的计算公式为： NeuMF结合GMF和MLP，得到的就是第三种实现方式，上图是该方式的完整实现，输出层的计算公式为： 1.4 模型实验论文通过三个角度进行了试验： RQ1 我们提出的NCF方法是否胜过 state-of-the-art 的隐性协同过滤方法？RQ2 我们提出的优化框架（消极样本抽样的logloss）怎样为推荐任务服务？RQ3 更深的隐藏单元是不是有助于对用户项目交互数据的学习？ 使用的数据集：MovieLens 和 Pinterest 两个数据集 评估方案：为了评价项目推荐的性能，论文采用了leave-one-out方法评估，即：对于每个用户，我们将其最近的一次交互作为测试集（数据集一般都有时间戳），并利用余下的培训作为训练集。由于在评估过程中为每个用户排列所有项目花费的时间太多，所以遵循一般的策略，随机抽取100个不与用户进行交互的项目，将测试项目排列在这100个项目中。排名列表的性能由命中率（HR）和归一化折扣累积增益（NDCG）来衡量。同时，论文将这两个指标的排名列表截断为10。如此一来，HR直观地衡量测试项目是否存在于前10名列表中，而NDCG通过将较高分数指定为顶级排名来计算命中的位置。本文计算每个测试用户的这两个指标，并求取了平均分。 Baselines，论文将NCF方法与下列方法进行了比较：ItemPop，ItemKNN，BPR，eALS。 以下是三个结果的贴图，关于试验结果的解读，由于篇幅的原因，大家可以查看原论文。 RQ1试验结果 简单的结论，即NCF效果好于BaseLine模型，如果不好的话论文也不用写了，哈哈。 RQ2试验结果 Figure 6 表示将模型看作一个二分类任务并使用logloss作为损失函数时的训练效果。Figure7 表示采样率对模型性能的影响（横轴是采样率，即负样本与正样本的比例）。 RQ3试验结果 上面的表格设置了两个变量，分别是Embedding的长度K和神经网络的层数，使用类似网格搜索的方式展示了在两个数据集上的结果。增加Embedding的长度和神经网络的层数是可以提升训练效果的。 2、NCF实战项目结构如下： 数据输入本文使用了一种新的数据处理方式，不过我们的输入就是三个：userid，itemid以及label，对训练集来说，label是0-1值，对测试集来说，是具体的itemid 12345def get_data(self): sample = self.iterator.get_next() self.user = sample['user'] self.item = sample['item'] self.label = tf.cast(sample['label'],tf.float32) 定义初始化方式、损失函数、优化器 123456789101112131415161718192021222324252627282930313233def inference(self): """ Initialize important settings """ self.regularizer = tf.contrib.layers.l2_regularizer(self.regularizer_rate) if self.initializer == 'Normal': self.initializer = tf.truncated_normal_initializer(stddev=0.01) elif self.initializer == 'Xavier_Normal': self.initializer = tf.contrib.layers.xavier_initializer() else: self.initializer = tf.glorot_uniform_initializer() if self.activation_func == 'ReLU': self.activation_func = tf.nn.relu elif self.activation_func == 'Leaky_ReLU': self.activation_func = tf.nn.leaky_relu elif self.activation_func == 'ELU': self.activation_func = tf.nn.elu if self.loss_func == 'cross_entropy': # self.loss_func = lambda labels, logits: -tf.reduce_sum( # (labels * tf.log(logits) + ( # tf.ones_like(labels, dtype=tf.float32) - labels) * # tf.log(tf.ones_like(logits, dtype=tf.float32) - logits)), 1) self.loss_func = tf.nn.sigmoid_cross_entropy_with_logits if self.optim == 'SGD': self.optim = tf.train.GradientDescentOptimizer(self.lr, name='SGD') elif self.optim == 'RMSProp': self.optim = tf.train.RMSPropOptimizer(self.lr, decay=0.9, momentum=0.0, name='RMSProp') elif self.optim == 'Adam': self.optim = tf.train.AdamOptimizer(self.lr, name='Adam') 得到embedding值分别得到GMF和MLP的embedding向量，当然也可以使用embedding_lookup方法： 12345678910111213141516171819202122232425262728293031with tf.name_scope('input'): self.user_onehot = tf.one_hot(self.user,self.user_size,name='user_onehot') self.item_onehot = tf.one_hot(self.item,self.item_size,name='item_onehot')with tf.name_scope('embed'): self.user_embed_GMF = tf.layers.dense(inputs = self.user_onehot, units = self.embed_size, activation = self.activation_func, kernel_initializer=self.initializer, kernel_regularizer=self.regularizer, name='user_embed_GMF') self.item_embed_GMF = tf.layers.dense(inputs=self.item_onehot, units=self.embed_size, activation=self.activation_func, kernel_initializer=self.initializer, kernel_regularizer=self.regularizer, name='item_embed_GMF') self.user_embed_MLP = tf.layers.dense(inputs=self.user_onehot, units=self.embed_size, activation=self.activation_func, kernel_initializer=self.initializer, kernel_regularizer=self.regularizer, name='user_embed_MLP') self.item_embed_MLP = tf.layers.dense(inputs=self.item_onehot, units=self.embed_size, activation=self.activation_func, kernel_initializer=self.initializer, kernel_regularizer=self.regularizer, name='item_embed_MLP') GMFGMF部分就是求两个embedding的内积： 12with tf.name_scope("GMF"): self.GMF = tf.multiply(self.user_embed_GMF,self.item_embed_GMF,name='GMF') MLP 123456789101112131415161718192021222324252627with tf.name_scope("MLP"): self.interaction = tf.concat([self.user_embed_MLP, self.item_embed_MLP], axis=-1, name='interaction') self.layer1_MLP = tf.layers.dense(inputs=self.interaction, units=self.embed_size * 2, activation=self.activation_func, kernel_initializer=self.initializer, kernel_regularizer=self.regularizer, name='layer1_MLP') self.layer1_MLP = tf.layers.dropout(self.layer1_MLP, rate=self.dropout) self.layer2_MLP = tf.layers.dense(inputs=self.layer1_MLP, units=self.embed_size, activation=self.activation_func, kernel_initializer=self.initializer, kernel_regularizer=self.regularizer, name='layer2_MLP') self.layer2_MLP = tf.layers.dropout(self.layer2_MLP, rate=self.dropout) self.layer3_MLP = tf.layers.dense(inputs=self.layer2_MLP, units=self.embed_size // 2, activation=self.activation_func, kernel_initializer=self.initializer, kernel_regularizer=self.regularizer, name='layer3_MLP') self.layer3_MLP = tf.layers.dropout(self.layer3_MLP, rate=self.dropout) 得到预测值 123456789101112with tf.name_scope('concatenation'): self.concatenation = tf.concat([self.GMF,self.layer3_MLP],axis=-1,name='concatenation') self.logits = tf.layers.dense(inputs= self.concatenation, units = 1, activation=None, kernel_initializer=self.initializer, kernel_regularizer=self.regularizer, name='predict') self.logits_dense = tf.reshape(self.logits,[-1]) 测试集构建这里只介绍几行关键的测试集构建代码，整个流程希望大家可以看一下完整的代码。需要明确的一点是，对于测试集，我们的评价不只是对错，还要关注排名，所以测试集的label不是0-1，而是具体的itemid首先，对每个user取最后一行作为测试集的正样本： 1234567891011split_train_test = []for i in range(len(user_set)): for _ in range(user_length[i] - 1): split_train_test.append('train') split_train_test.append('test')full_data['split'] = split_train_testtrain_data = full_data[full_data['split'] == 'train'].reset_index(drop=True)test_data = full_data[full_data['split'] == 'test'].reset_index(drop=True) 添加一些负采样的样本， 这里顺序是，1正样本-n负样本-1正样本-n负样本….，每个用户有n+1条数据，便于计算HR和NDCG： 12345678feature_user.append(user)feature_item.append(item)labels_add.append(label)for k in neg_samples: feature_user.append(user) feature_item.append(k) labels_add.append(k) 不打乱测试集的顺序，设置batch的大小为1+n: 12dataset = tf.data.Dataset.from_tensor_slices(data)dataset = dataset.batch(test_neg + 1) 计算HR和NDCG 1234567891011def hr(gt_item, pred_items): if gt_item in pred_items: return 1 return 0def ndcg(gt_item, pred_items): if gt_item in pred_items: index = np.where(pred_items == gt_item)[0][0] return np.reciprocal(np.log2(index + 2)) return 0]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统--DeepFM模型理论和实践]]></title>
    <url>%2F2018%2F10%2F08%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F--DeepFM%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[推荐系统–DeepFM模型理论和实践1、背景特征组合的挑战对于一个基于CTR预估的推荐系统，最重要的是学习到用户点击行为背后隐含的特征组合。在不同的推荐场景中，低阶组合特征或者高阶组合特征可能都会对最终的CTR产生影响。 之前介绍的因子分解机(Factorization Machines, FM)通过对于每一维特征的隐变量内积来提取特征组合。最终的结果也非常好。但是，虽然理论上来讲FM可以对高阶特征组合进行建模，但实际上因为计算复杂度的原因一般都只用到了二阶特征组合。 那么对于高阶的特征组合来说，我们很自然的想法，通过多层的神经网络即DNN去解决。 DNN的局限下面的图片来自于张俊林教授在AI大会上所使用的PPT。 我们之前也介绍过了，对于离散特征的处理，我们使用的是将特征转换成为one-hot的形式，但是将One-hot类型的特征输入到DNN中，会导致网络参数太多： 如何解决这个问题呢，类似于FFM中的思想，将特征分为不同的field： 再加两层的全链接层，让Dense Vector进行组合，那么高阶特征的组合就出来了 但是低阶和高阶特征组合隐含地体现在隐藏层中，如果我们希望把低阶特征组合单独建模，然后融合高阶特征组合。 即将DNN与FM进行一个合理的融合： 二者的融合总的来说有两种形式，一是串行结构，二是并行结构 而我们今天要讲到的DeepFM，就是并行结构中的一种典型代表。 2、DeepFM模型我们先来看一下DeepFM的模型结构： DeepFM包含两部分：神经网络部分与因子分解机部分，分别负责低阶特征的提取和高阶特征的提取。这两部分共享同样的输入。DeepFM的预测结果可以写为： FM部分 FM部分的详细结构如下： FM部分是一个因子分解机。关于因子分解机可以参阅文章[Rendle, 2010] Steffen Rendle. Factorization machines. In ICDM, 2010.。因为引入了隐变量的原因，对于几乎不出现或者很少出现的隐变量，FM也可以很好的学习。 FM的输出公式为： 深度部分 深度部分是一个前馈神经网络。与图像或者语音这类输入不同，图像语音的输入一般是连续而且密集的，然而用于CTR的输入一般是及其稀疏的。因此需要重新设计网络结构。具体实现中为，在第一层隐含层之前，引入一个嵌入层来完成将输入向量压缩到低维稠密向量。 嵌入层(embedding layer)的结构如上图所示。当前网络结构有两个有趣的特性，1）尽管不同field的输入长度不同，但是embedding之后向量的长度均为K。2)在FM里得到的隐变量Vik现在作为了嵌入层网络的权重。 这里的第二点如何理解呢，假设我们的k=5，首先，对于输入的一条记录，同一个field 只有一个位置是1，那么在由输入得到dense vector的过程中，输入层只有一个神经元起作用，得到的dense vector其实就是输入层到embedding层该神经元相连的五条线的权重，即vi1，vi2，vi3，vi4，vi5。这五个值组合起来就是我们在FM中所提到的Vi。在FM部分和DNN部分，这一块是共享权重的，对同一个特征来说，得到的Vi是相同的。 有关模型具体如何操作，我们可以通过代码来进一步加深认识。 3、相关知识我们先来讲两个代码中会用到的相关知识吧，代码是参考的github上星数最多的DeepFM实现代码。 Gini Normalization代码中将CTR预估问题设定为一个二分类问题，绘制了Gini Normalization来评价不同模型的效果。这个是什么东西，不太懂，百度了很多，发现了一个比较通俗易懂的介绍。 假设我们有下面两组结果，分别表示预测值和实际值： 12predictions = [0.9, 0.3, 0.8, 0.75, 0.65, 0.6, 0.78, 0.7, 0.05, 0.4, 0.4, 0.05, 0.5, 0.1, 0.1]actual = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] 然后我们将预测值按照从小到大排列，并根据索引序对实际值进行排序： 1Sorted Actual Values [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1] 然后，我们可以画出如下的图片： 接下来我们将数据Normalization到0，1之间。并画出45度线。 橙色区域的面积，就是我们得到的Normalization的Gini系数。 这里，由于我们是将预测概率从小到大排的，所以我们希望实际值中的0尽可能出现在前面，因此Normalization的Gini系数越大，分类效果越好。 embedding_lookup在tensorflow中有个embedding_lookup函数，我们可以直接根据一个序号来得到一个词或者一个特征的embedding值，那么他内部其实是包含一个网络结构的，如下图所示： 假设我们想要找到2的embedding值，这个值其实是输入层第二个神经元与embedding层连线的权重值。 之前有大佬跟我探讨word2vec输入的问题，现在也算是有个比较明确的答案，输入其实就是one-hot Embedding，而word2vec要学习的是new Embedding。 4、代码解析好，一贯的风格，先来介绍几个地址：原代码地址：https://github.com/ChenglongChen/tensorflow-DeepFM 项目结构项目结构如下： 其实还应该有一个存放data的路径。config.py保存了我们模型的一些配置。DataReader对数据进行处理，得到模型可以使用的输入。DeepFM是我们构建的模型。main是项目的入口。metrics是计算normalized gini系数的代码。 模型输入 模型的输入主要有下面几个部分： 12345678910self.feat_index = tf.placeholder(tf.int32, shape=[None,None], name='feat_index')self.feat_value = tf.placeholder(tf.float32, shape=[None,None], name='feat_value')self.label = tf.placeholder(tf.float32,shape=[None,1],name='label')self.dropout_keep_fm = tf.placeholder(tf.float32,shape=[None],name='dropout_keep_fm')self.dropout_keep_deep = tf.placeholder(tf.float32,shape=[None],name='dropout_deep_deep') feat_index是特征的一个序号，主要用于通过embedding_lookup选择我们的embedding。feat_value是对应的特征值，如果是离散特征的话，就是1，如果不是离散特征的话，就保留原来的特征值。label是实际值。还定义了两个dropout来防止过拟合。 权重构建权重的设定主要有两部分，第一部分是从输入到embedding中的权重，其实也就是我们的dense vector。另一部分就是深度神经网络每一层的权重。第二部分很好理解，我们主要来看看第一部分： 12345#embeddingsweights['feature_embeddings'] = tf.Variable( tf.random_normal([self.feature_size,self.embedding_size],0.0,0.01), name='feature_embeddings')weights['feature_bias'] = tf.Variable(tf.random_normal([self.feature_size,1],0.0,1.0),name='feature_bias') weights[‘feature_embeddings’] 存放的每一个值其实就是FM中的vik，所以它是F * K的。其中，F代表feture的大小(将离散特征转换成one-hot之后的特征总量),K代表dense vector的大小。 weights[‘feature_bias’]是FM中的一次项的权重。 Embedding part这个部分很简单啦，是根据feat_index选择对应的weights[‘feature_embeddings’]中的embedding值，然后再与对应的feat_value相乘就可以了： 1234# modelself.embeddings = tf.nn.embedding_lookup(self.weights['feature_embeddings'],self.feat_index) # N * F * Kfeat_value = tf.reshape(self.feat_value,shape=[-1,self.field_size,1])self.embeddings = tf.multiply(self.embeddings,feat_value) FM part首先来回顾一下我们之前对FM的化简公式，之前去今日头条面试还问到过公式的推导。 所以我们的二次项可以根据化简公式轻松的得到，再加上我们的一次项，FM的part就算完了。同时更为方便的是，由于权重共享，我们这里可以直接用Embedding part计算出的embeddings来得到我们的二次项： 1234567891011121314151617# first order termself.y_first_order = tf.nn.embedding_lookup(self.weights['feature_bias'],self.feat_index)self.y_first_order = tf.reduce_sum(tf.multiply(self.y_first_order,feat_value),2)self.y_first_order = tf.nn.dropout(self.y_first_order,self.dropout_keep_fm[0])# second order term# sum-square-partself.summed_features_emb = tf.reduce_sum(self.embeddings,1) # None * kself.summed_features_emb_square = tf.square(self.summed_features_emb) # None * K# squre-sum-partself.squared_features_emb = tf.square(self.embeddings)self.squared_sum_features_emb = tf.reduce_sum(self.squared_features_emb, 1) # None * K#second orderself.y_second_order = 0.5 * tf.subtract(self.summed_features_emb_square,self.squared_sum_features_emb)self.y_second_order = tf.nn.dropout(self.y_second_order,self.dropout_keep_fm[1]) DNN partDNNpart的话，就是将Embedding part的输出再经过几层全链接层： 12345678# Deep componentself.y_deep = tf.reshape(self.embeddings,shape=[-1,self.field_size * self.embedding_size])self.y_deep = tf.nn.dropout(self.y_deep,self.dropout_keep_deep[0])for i in range(0,len(self.deep_layers)): self.y_deep = tf.add(tf.matmul(self.y_deep,self.weights["layer_%d" %i]), self.weights["bias_%d"%I]) self.y_deep = self.deep_layers_activation(self.y_deep) self.y_deep = tf.nn.dropout(self.y_deep,self.dropout_keep_deep[i+1]) 最后，我们要将DNN和FM两部分的输出进行结合： 1concat_input = tf.concat([self.y_first_order, self.y_second_order, self.y_deep], axis=1) 损失及优化器我们可以使用logloss(如果定义为分类问题)，或者mse(如果定义为预测问题)，以及多种的优化器去进行尝试，这些根据不同的参数设定得到： 123456789101112131415161718192021222324252627# lossif self.loss_type == "logloss": self.out = tf.nn.sigmoid(self.out) self.loss = tf.losses.log_loss(self.label, self.out)elif self.loss_type == "mse": self.loss = tf.nn.l2_loss(tf.subtract(self.label, self.out))# l2 regularization on weightsif self.l2_reg &gt; 0: self.loss += tf.contrib.layers.l2_regularizer( self.l2_reg)(self.weights["concat_projection"]) if self.use_deep: for i in range(len(self.deep_layers)): self.loss += tf.contrib.layers.l2_regularizer( self.l2_reg)(self.weights["layer_%d" % I])if self.optimizer_type == "adam": self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8).minimize(self.loss)elif self.optimizer_type == "adagrad": self.optimizer = tf.train.AdagradOptimizer(learning_rate=self.learning_rate, initial_accumulator_value=1e-8).minimize(self.loss)elif self.optimizer_type == "gd": self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate).minimize(self.loss)elif self.optimizer_type == "momentum": self.optimizer = tf.train.MomentumOptimizer(learning_rate=self.learning_rate, momentum=0.95).minimize( self.loss) 模型效果前面提到了，我们用logloss作为损失函数去进行模型的参数更新，但是代码中输出了模型的 Normalization 的 Gini值来进行模型评价，我们可以对比一下(记住，Gini值越大越好呦)：]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统--FFM模型理论和实践]]></title>
    <url>%2F2018%2F09%2F15%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F--FFM%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[推荐系统–FFM模型理论和实践1、FFM理论在CTR预估中，经常会遇到one-hot类型的变量，one-hot类型变量会导致严重的数据特征稀疏的情况，为了解决这一问题，在上一讲中，我们介绍了FM算法。这一讲我们介绍一种在FM基础上发展出来的算法-FFM（Field-aware Factorization Machine）。 FFM模型中引入了类别的概念，即field。还是拿上一讲中的数据来讲，先看下图： 在上面的广告点击案例中，“Day=26/11/15”、“Day=1/7/14”、“Day=19/2/15”这三个特征都是代表日期的，可以放到同一个field中。同理，Country也可以放到一个field中。简单来说，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个field，包括用户国籍，广告类型，日期等等。 在FFM中，每一维特征 xi，针对其它特征的每一种field fj，都会学习一个隐向量 v_i,fj。因此，隐向量不仅与特征相关，也与field相关。也就是说，“Day=26/11/15”这个特征与“Country”特征和“Ad_type”特征进行关联的时候使用不同的隐向量，这与“Country”和“Ad_type”的内在差异相符，也是FFM中“field-aware”的由来。 假设样本的 n个特征属于 f个field，那么FFM的二次项有 nf个隐向量。而在FM模型中，每一维特征的隐向量只有一个。FM可以看作FFM的特例，是把所有特征都归属到一个field时的FFM模型。根据FFM的field敏感特性，可以导出其模型方程。 可以看到，如果隐向量的长度为 k，那么FFM的二次参数有 nfk 个，远多于FM模型的 nk个。此外，由于隐向量与field相关，FFM二次项并不能够化简，其预测复杂度是 O(kn^2)。 下面以一个例子简单说明FFM的特征组合方式。输入记录如下： 这条记录可以编码成5个特征，其中“Genre=Comedy”和“Genre=Drama”属于同一个field，“Price”是数值型，不用One-Hot编码转换。为了方便说明FFM的样本格式，我们将所有的特征和对应的field映射成整数编号。 那么，FFM的组合特征有10项，如下图所示。 其中，红色是field编号，蓝色是特征编号。 2、FFM实现细节这里讲得只是一种FFM的实现方式，并不是唯一的。 损失函数FFM将问题定义为分类问题，使用的是logistic loss，同时加入了正则项 什么，这是logisitc loss？第一眼看到我是懵逼的，逻辑回归的损失函数我很熟悉啊，不是长这样的啊？其实是我目光太短浅了。逻辑回归其实是有两种表述方式的损失函数的，取决于你将类别定义为0和1还是1和-1。大家可以参考下下面的文章：https://www.cnblogs.com/ljygoodgoodstudydaydayup/p/6340129.html。当我们将类别设定为1和-1的时候，逻辑回归的损失函数就是上面的样子。 随机梯度下降 训练FFM使用的是随机梯度下降方法，即每次只选一条数据进行训练，这里还有必要补一补梯度下降的知识，梯度下降是有三种方式的，截图取自参考文献3： 3、tensorflow实现代码生成数据这里我没有找到合适的数据，就自己产生了一点数据，数据涉及20维特征，前十维特征是一个field，后十维是一个field: 123456def gen_data(): labels = [-1,1] y = [np.random.choice(labels,1)[0] for _ in range(all_data_size)] x_field = [i // 10 for i in range(input_x_size)] x = np.random.randint(0,2,size=(all_data_size,input_x_size)) return x,y,x_field 定义权重项在ffm中，有三个权重项，首先是bias，然后是一维特征的权重，最后是交叉特征的权重： 12345678910111213141516def createTwoDimensionWeight(input_x_size,field_size,vector_dimension): weights = tf.truncated_normal([input_x_size,field_size,vector_dimension]) tf_weights = tf.Variable(weights) return tf_weightsdef createOneDimensionWeight(input_x_size): weights = tf.truncated_normal([input_x_size]) tf_weights = tf.Variable(weights) return tf_weightsdef createZeroDimensionWeight(): weights = tf.truncated_normal([1]) tf_weights = tf.Variable(weights) return tf_weights 计算估计值估计值的计算这里不能项FM一样先将公式化简再来做，对于交叉特征，只能写两重循环，所以对于特别多的特征的情况下，真的计算要爆炸呀！ 123456789101112131415161718192021222324252627282930313233343536373839def inference(input_x,input_x_field,zeroWeights,oneDimWeights,thirdWeight): """计算回归模型输出的值""" secondValue = tf.reduce_sum(tf.multiply(oneDimWeights,input_x,name='secondValue')) firstTwoValue = tf.add(zeroWeights, secondValue, name="firstTwoValue") thirdValue = tf.Variable(0.0,dtype=tf.float32) input_shape = input_x_size for i in range(input_shape): featureIndex1 = I fieldIndex1 = int(input_x_field[I]) for j in range(i+1,input_shape): featureIndex2 = j fieldIndex2 = int(input_x_field[j]) vectorLeft = tf.convert_to_tensor([[featureIndex1,fieldIndex2,i] for i in range(vector_dimension)]) weightLeft = tf.gather_nd(thirdWeight,vectorLeft) weightLeftAfterCut = tf.squeeze(weightLeft) vectorRight = tf.convert_to_tensor([[featureIndex2,fieldIndex1,i] for i in range(vector_dimension)]) weightRight = tf.gather_nd(thirdWeight,vectorRight) weightRightAfterCut = tf.squeeze(weightRight) tempValue = tf.reduce_sum(tf.multiply(weightLeftAfterCut,weightRightAfterCut)) indices2 = [I] indices3 = [j] xi = tf.squeeze(tf.gather_nd(input_x, indices2)) xj = tf.squeeze(tf.gather_nd(input_x, indices3)) product = tf.reduce_sum(tf.multiply(xi, xj)) secondItemVal = tf.multiply(tempValue, product) tf.assign(thirdValue, tf.add(thirdValue, secondItemVal)) return tf.add(firstTwoValue,thirdValue) 定义损失函数损失函数我们就用逻辑回归损失函数来算，同时加入正则项： 1234567891011121314151617181920212223lambda_w = tf.constant(0.001, name='lambda_w')lambda_v = tf.constant(0.001, name='lambda_v')zeroWeights = createZeroDimensionWeight()oneDimWeights = createOneDimensionWeight(input_x_size)thirdWeight = createTwoDimensionWeight(input_x_size, # 创建二次项的权重变量 field_size, vector_dimension) # n * f * ky_ = inference(input_x, trainx_field,zeroWeights,oneDimWeights,thirdWeight)l2_norm = tf.reduce_sum( tf.add( tf.multiply(lambda_w, tf.pow(oneDimWeights, 2)), tf.reduce_sum(tf.multiply(lambda_v, tf.pow(thirdWeight, 2)),axis=[1,2]) ))loss = tf.log(1 + tf.exp(input_y * y_)) + l2_normtrain_step = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(loss) 训练接下来就是训练了，每次只用喂一个数据就好： 1234input_x_batch = trainx[t]input_y_batch = trainy[t]predict_loss,_, steps = sess.run([loss,train_step, global_step], feed_dict=&#123;input_x: input_x_batch, input_y: input_y_batch&#125;)]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强化学习-MADDPG算法原理及简单实现]]></title>
    <url>%2F2018%2F06%2F19%2F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-MADDPG%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8A%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[强化学习-MADDPG算法原理及简单实现之前接触的强化学习算法都是单个智能体的强化学习算法，但是也有很多重要的应用场景牵涉到多个智能体之间的交互，比如说，多个机器人的控制，语言的交流，多玩家的游戏等等。本文，就带你简单了解一下Open-AI的MADDPG(Multi-Agent Deep Deterministic Policy Gradient)算法，来共同体验一下多智能体强化学习的魅力。 论文全称：Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments下载地址：https://arxiv.org/pdf/1706.02275.pdf 1、引言强化学习中很多场景涉及多个智能体的交互，比如多个机器人的控制，语言的交流，多玩家的游戏等等。不过传统的RL方法，比如Q-Learning或者policy gradient都不适用于多智能体环境。主要的问题是，在训练过程中，每个智能体的策略都在变化，因此从每个智能体的角度来看，环境变得十分不稳定(其他智能体的行动带来环境变化)。对DQN来说，经验重放的方法变的不再适用(如果不知道其他智能体的状态，那么不同情况下自身的状态转移会不同），而对PG的方法来说，环境的不断变化导致了学习的方差进一步增大。 因此，本文提出了MADDPG(Multi-Agent Deep Deterministic Policy Gradient)方法。为什么要使用DDPG方法作为基准模型呢？主要是集中训练和分散执行的策略。 本文提出的方法框架是集中训练，分散执行的。我们先回顾一下DDPG的方式，DDPG本质上是一个AC方法。训练时，Actor根据当前的state选择一个action，然后Critic可以根据state-action计算一个Q值，作为对Actor动作的反馈。Critic根据估计的Q值和实际的Q值来进行训练，Actor根据Critic的反馈来更新策略。测试时，我们只需要Actor就可以完成，此时不需要Critic的反馈。因此，在训练时，我们可以在Critic阶段加上一些额外的信息来得到更准确的Q值，比如其他智能体的状态和动作等，这也就是集中训练的意思，即每个智能体不仅仅根据自身的情况，还根据其他智能体的行为来评估当前动作的价值。分散执行指的是，当每个Agent都训练充分之后，每个Actor就可以自己根据状态采取合适的动作，此时是不需要其他智能体的状态或者动作的。DQN不适合这么做，因为DQN训练和预测是同一个网络，二者的输入信息必须保持一致，我们不能只在训练阶段加入其他智能体的信息。 2、DDPG算法的简单回顾什么是DDPG什么是DDPG呢？一句话描述，它是Actor-Critic 和 DQN 算法的结合体。 DDPG的全称是Deep Deterministic Policy Gradient。 我们首先来看Deep，正如Q-learning加上一个Deep就变成了DQN一样，这里的Deep即同样使用DQN中的经验池和双网络结构来促进神经网络能够有效学习。 再来看Deterministic，即我们的Actor不再输出每个动作的概率，而是一个具体的动作，这更有助于我们连续动作空间中进行学习。 DDPG的网络结构盗用莫烦老师的一张图片来形象的表示DDPG的网络结构，同图片里一样，我们称Actor里面的两个网络分别是动作估计网络和动作现实网络，我们称Critic中的两个网络分别是状态现实网络和状态估计网络： image 我们采用了类似DQN的双网络结构，而且Actor和Critic都有target-net和eval-net。我们需要强调一点的事，我们只需要训练动作估计网络和状态估计网络的参数，而动作现实网络和状态现实网络的参数是由前面两个网络每隔一定的时间复制过去的。 我们先来说说Critic这边，Critic这边的学习过程跟DQN类似，我们都知道DQN根据下面的损失函数来进行网络学习，即现实的Q值和估计的Q值的平方损失： 上面式子中Q(S,A)是根据状态估计网络得到的，A是动作估计网络传过来的动作。而前面部分R + gamma * maxQ(S’,A’)是现实的Q值，这里不一样的是，我们计算现实的Q值，不在使用贪心算法，来选择动作A’,而是动作现实网络得到这里的A’。总的来说，Critic的状态估计网络的训练还是基于现实的Q值和估计的Q值的平方损失，估计的Q值根据当前的状态S和动作估计网络输出的动作A输入状态估计网络得到，而现实的Q值根据现实的奖励R，以及将下一时刻的状态S’和动作现实网络得到的动作A’ 输入到状态现实网络 而得到的Q值的折现值加和得到(这里运用的是贝尔曼方程)。 我们再来说一下Actor这边，论文中，我们基于下面的式子进行动作估计网络的参数： 这个式子看上去很吓人，但是其实理解起来很简单。假如对同一个状态，我们输出了两个不同的动作a1和a2，从状态估计网络得到了两个反馈的Q值，分别是Q1和Q2，假设Q1&gt;Q2,即采取动作1可以得到更多的奖励，那么Policy gradient的思想是什么呢，就是增加a1的概率，降低a2的概率，也就是说，Actor想要尽可能的得到更大的Q值。所以我们的Actor的损失可以简单的理解为得到的反馈Q值越大损失越小，得到的反馈Q值越小损失越大，因此只要对状态估计网络返回的Q值取个负号就好啦。是不是很简单。 DDPG学习中的小trick 与传统的DQN不同的是，传统的DQN采用的是一种被称为’hard’模式的target-net网络参数更新，即每隔一定的步数就将eval-net中的网络参数赋值过去，而在DDPG中，采用的是一种’soft’模式的target-net网络参数更新，即每一步都对target-net网络中的参数更新一点点，这种参数更新方式经过试验表明可以大大的提高学习的稳定性。’soft’模式到底是如何更新网络的？我们可以通过代码更好的理解。 论文中提到的另一个小trick是对采取的动作增加一定的噪声： DDPG的完整流程 介绍了这么多，我们也就能顺利理解原文中的DDPG算法的流程： 3、MADDPG算法简介算法流程 理解了DDPG的算法过程，那么MADDPG的过程也是不难理解的，我们一起来看一下吧。 每个Agent的训练同单个DDPG算法的训练过程类似，不同的地方主要体现在Critic的输入上：在单个Agent的DDPG算法中，Critic的输入是一个state-action对信息，但是在MADDPG中，每个Agent的Critic输入除自身的state-action信息外，还可以有额外的信息，比如其他Agent的动作。 多Agent之间的关系形式 不同的Agent之间的关系大体可以分为三种，合作型，对抗性，半合作半对抗型。我们可以根据不同的合作关系来设计我们的奖励函数。 4、模型实验文章中设置了多组实验环境，有合作型的，有对抗型的也有半合作半对抗型的。如下图所示： 这里只重点讲我们后面代码中实现的实验。 实验的名称为Predator-prey。其英文解释为Good agents (green) are faster and want to avoid being hit by adversaries (red). Adversaries are slower and want to hit good agents. Obstacles (large black circles) block the way. 不过我们在代码中只实现了三个Adversaries，而Good agents处于随机游走状态。 在合作交流的环境下，论文中将MADDPG与传统的算法进行了对比，得到的结果如下： 可以看到，MADDPG与传统的RL算法相比，在多智能体的环境下，能够取得更加突出的效果。 5、MADDPG算法的简单实现本文实践了Predator-prey这一环境，如下图所示： 绿色的球为目标，在二维空间中随机游走，躲避红色的球的攻击。三个红色的球是我们定义的Agent，它们处在互相对抗的环境中，想要击中绿色的球，从而获得奖励。黑色的地方时障碍。 实验环境安装 下载https://github.com/openai/multiagent-particle-envs中的代码。 进入到代码主路径中，执行命令安装所需的环境 1pip install -e . 代码结构本项目的代码结构如下： model_agent_maddpg.py:该文件定义了单个Agent的DDPG结构，及一些函数replay_buffer.py：定义了两种不同的经验池，一种是普通的经验池，一种是优先采样经验池segment_tree.py :只有在使用优先采样经验池的时候才用到。定义一种树结构根据经验的优先级进行采样test_three_agent_maddpg.py:对训练好的模型进行测试three_agent_maddpg.py:模型训练的主代码 DDPG-Actor实现我们首先来实现单个的DDPG结构Actor的输入是一个具体的状态，经过两层的全链接网络输出选择的Action。 1234567891011121314151617def actor_network(name): with tf.variable_scope(name) as scope: x = state_input x = tf.layers.dense(x, 64) if self.layer_norm: x = tc.layers.layer_norm(x, center=True, scale=True) x = tf.nn.relu(x) x = tf.layers.dense(x, 64) if self.layer_norm: x = tc.layers.layer_norm(x, center=True, scale=True) x = tf.nn.relu(x) x = tf.layers.dense(x, self.nb_actions, kernel_initializer=tf.random_uniform_initializer(minval=-3e-3, maxval=3e-3)) x = tf.nn.tanh(x) return x DDPG-Critic实现 Critic的输入是state，以及所有Agent当前的action信息： 12345678910111213141516171819def critic_network(name, action_input, reuse=False): with tf.variable_scope(name) as scope: if reuse: scope.reuse_variables() x = state_input x = tf.layers.dense(x, 64) if self.layer_norm: x = tc.layers.layer_norm(x, center=True, scale=True) x = tf.nn.relu(x) x = tf.concat([x, action_input], axis=-1) x = tf.layers.dense(x, 64) if self.layer_norm: x = tc.layers.layer_norm(x, center=True, scale=True) x = tf.nn.relu(x) x = tf.layers.dense(x, 1, kernel_initializer=tf.random_uniform_initializer(minval=-3e-3, maxval=3e-3)) return x 训练Actor和Critic Actor的训练目标是Q值的最大化，而Critic的训练目标是最小化Q估计值和Q实际值之间的差距： 123456789101112self.actor_optimizer = tf.train.AdamOptimizer(1e-4)self.critic_optimizer = tf.train.AdamOptimizer(1e-3)# 最大化Q值self.actor_loss = -tf.reduce_mean( critic_network(name + '_critic', action_input=tf.concat([self.action_output, other_action_input], axis=1), reuse=True))self.actor_train = self.actor_optimizer.minimize(self.actor_loss)self.target_Q = tf.placeholder(shape=[None, 1], dtype=tf.float32)self.critic_loss = tf.reduce_mean(tf.square(self.target_Q - self.critic_output))self.critic_train = self.critic_optimizer.minimize(self.critic_loss) 定义三个Agent 随后，我们分别建立三个Agent，每个Agent对应两个DDPG结构，一个是eval-net，一个是target-net： 12345678agent1_ddpg = MADDPG('agent1')agent1_ddpg_target = MADDPG('agent1_target')agent2_ddpg = MADDPG('agent2')agent2_ddpg_target = MADDPG('agent2_target')agent3_ddpg = MADDPG('agent3')agent3_ddpg_target = MADDPG('agent3_target') 模型训练 在训练过程中，假设当前的状态是o_n，我们首先通过Actor得到每个Agent的动作，这里我们将动作定义为一个二维的向量，不过根据OpenAi的环境设置，我们需要将动作展开成一个五维的向量，同时绿色的球也需要定义动作，因此一共将四组动作输入到我们的环境中，可以得到奖励及下一个时刻的状态o_n_next以及当前的奖励r_n： 12345678agent1_action, agent2_action, agent3_action = get_agents_action(o_n, sess, noise_rate=0.2)#三个agent的行动a = [[0, i[0][0], 0, i[0][1], 0] for i in [agent1_action, agent2_action, agent3_action]]#绿球的行动a.append([0, np.random.rand() * 2 - 1, 0, np.random.rand() * 2 - 1, 0])o_n_next, r_n, d_n, i_n = env.step(a) 随后，我们需要将经验存放到经验池中，供Critic反馈和训练： 1234567891011agent1_memory.add(np.vstack([o_n[0], o_n[1], o_n[2]]), np.vstack([agent1_action[0], agent2_action[0], agent3_action[0]]), r_n[0], np.vstack([o_n_next[0], o_n_next[1], o_n_next[2]]), False)agent2_memory.add(np.vstack([o_n[1], o_n[2], o_n[0]]), np.vstack([agent2_action[0], agent3_action[0], agent1_action[0]]), r_n[1], np.vstack([o_n_next[1], o_n_next[2], o_n_next[0]]), False)agent3_memory.add(np.vstack([o_n[2], o_n[0], o_n[1]]), np.vstack([agent3_action[0], agent1_action[0], agent2_action[0]]), r_n[2], np.vstack([o_n_next[2], o_n_next[0], o_n_next[1]]), False) 当经验池中存储了一定的经验之后，我们就可以根据前文介绍过的双网络结构和损失函数来训练每个Agent的Actor和Critic： 12345678train_agent(agent1_ddpg, agent1_ddpg_target, agent1_memory, agent1_actor_target_update, agent1_critic_target_update, sess, [agent2_ddpg_target, agent3_ddpg_target])train_agent(agent2_ddpg, agent2_ddpg_target, agent2_memory, agent2_actor_target_update, agent2_critic_target_update, sess, [agent3_ddpg_target, agent1_ddpg_target])train_agent(agent3_ddpg, agent3_ddpg_target, agent3_memory, agent3_actor_target_update, agent3_critic_target_update, sess, [agent1_ddpg_target, agent2_ddpg_target]]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度强化学习-DDPG算法原理和实现]]></title>
    <url>%2F2018%2F06%2F01%2F%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-DDPG%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[深度强化学习-DDPG算法原理和实现1、DDPG原理什么是DDPG呢 什么是DDPG呢？前面我们介绍过了，它是Actor-Critic 和 DQN 算法的结合体。 DDPG的全称是Deep Deterministic Policy Gradient。 我们首先来看Deep，正如Q-learning加上一个Deep就变成了DQN一样，这里的Deep即同样使用DQN中的经验池和双网络结构来促进神经网络能够有效学习。 再来看Deterministic，即我们的Actor不再输出每个动作的概率，而是一个具体的动作，这更有助于我们连续动作空间中进行学习。之前不太理解这个连续动作空间是什么意思，既然policy gradient和dqn都是输出每个动作的概率和q值，那么我们为什么还要用policy gradient呢？这个连续动作空间的例子可以举一个么？既然已经诚心诚意的发问了，那么我就班门弄斧回答一下。假如想要通过强化学习得到一个词的32维词向量，哇，这个词向量的动作空间可是无限大的呀，[1,0….0]是一个动作，[0,1…0]是一个动作，如果加上小数，那更是数不过来啦，这时候我们根本不可能去计算每个动作的概率或者q值，我们只能给定状态即一个单词，直接输出一个合适的词向量。类似于这种情况，DDPG就可以大显神威了。 DDPG的网络结构盗用莫烦老师的一张图片来形象的表示DDPG的网络结构，同图片里一样，我们称Actor里面的两个网络分别是动作估计网络和动作现实网络，我们称Critic中的两个网络分别是状态现实网络和状态估计网络： 我们采用了类似DQN的双网络结构，而且Actor和Critic都有target-net和eval-net。我们需要强调一点的事，我们只需要训练动作估计网络和状态估计网络的参数，而动作现实网络和状态现实网络的参数是由前面两个网络每隔一定的时间复制过去的。 我们先来说说Critic这边，Critic这边的学习过程跟DQN类似，我们都知道DQN根据下面的损失函数来进行网络学习，即现实的Q值和估计的Q值的平方损失： 上面式子中Q(S,A)是根据状态估计网络得到的，A是动作估计网络传过来的动作。而前面部分R + gamma * maxQ(S’,A’)是现实的Q值，这里不一样的是，我们计算现实的Q值，不在使用贪心算法，来选择动作A’,而是动作现实网络得到这里的A’。总的来说，Critic的状态估计网络的训练还是基于现实的Q值和估计的Q值的平方损失，估计的Q值根据当前的状态S和动作估计网络输出的动作A输入状态估计网络得到，而现实的Q值根据现实的奖励R，以及将下一时刻的状态S’和动作现实网络得到的动作A’ 输入到状态现实网络 而得到的Q值的折现值加和得到(这里运用的是贝尔曼方程)。 我们再来说一下Actor这边，论文中，我们基于下面的式子进行动作估计网络的参数： 这个式子看上去很吓人，但是其实理解起来很简单。假如对同一个状态，我们输出了两个不同的动作a1和a2，从状态估计网络得到了两个反馈的Q值，分别是Q1和Q2，假设Q1&gt;Q2,即采取动作1可以得到更多的奖励，那么Policy gradient的思想是什么呢，就是增加a1的概率，降低a2的概率，也就是说，Actor想要尽可能的得到更大的Q值。所以我们的Actor的损失可以简单的理解为得到的反馈Q值越大损失越小，得到的反馈Q值越小损失越大，因此只要对状态估计网络返回的Q值取个负号就好啦。是不是很简单。 DDPG学习中的小trick 与传统的DQN不同的是，传统的DQN采用的是一种被称为’hard’模式的target-net网络参数更新，即每隔一定的步数就将eval-net中的网络参数赋值过去，而在DDPG中，采用的是一种’soft’模式的target-net网络参数更新，即每一步都对target-net网络中的参数更新一点点，这种参数更新方式经过试验表明可以大大的提高学习的稳定性。’soft’模式到底是如何更新网络的？我们可以通过代码更好的理解。 论文中提到的另一个小trick是对采取的动作增加一定的噪声： DDPG的完整流程 介绍了这么多，我们也就能顺利理解原文中的DDPG算法的流程： 2、DDPG算法实现好了，原理介绍的差不多了，我们来看一下代码的实现。本文的代码仍然参考的是莫烦老师的代码。 定义超参数我们首先定义网络中的超参数，比如经验池的大小，两个网络的学习率等等: 1234567891011MAX_EPISODES = 200MAX_EP_STEPS = 200LR_A = 0.001 # learning rate for actorLR_C = 0.002 # learning rate for criticGAMMA = 0.9 # reward discountTAU = 0.01 # soft replacementMEMORY_CAPACITY = 10000BATCH_SIZE = 32RENDER = FalseENV_NAME = 'Pendulum-v0' 定义网络输入我们需要定义的placeholder包括当前的状态S，下一时刻的状态S’,以及对应的奖励R，而动作A由Actor得到，因此不需要再定义： 123self.S = tf.placeholder(tf.float32, [None, s_dim], 's')self.S_ = tf.placeholder(tf.float32, [None, s_dim], 's_')self.R = tf.placeholder(tf.float32, [None, 1], 'r') 构建两个网络两个网络都是两层全链接的神经网络，Actor输出一个具体的动作，而Critic网络输出一个具体的Q值 1234567891011121314def _build_a(self, s, scope, trainable): with tf.variable_scope(scope): net = tf.layers.dense(s, 30, activation=tf.nn.relu, name='l1', trainable=trainable) a = tf.layers.dense(net, self.a_dim, activation=tf.nn.tanh, name='a', trainable=trainable) return tf.multiply(a, self.a_bound, name='scaled_a')def _build_c(self, s, a, scope, trainable): with tf.variable_scope(scope): n_l1 = 30 w1_s = tf.get_variable('w1_s', [self.s_dim, n_l1], trainable=trainable) w1_a = tf.get_variable('w1_a', [self.a_dim, n_l1], trainable=trainable) b1 = tf.get_variable('b1', [1, n_l1], trainable=trainable) net = tf.nn.relu(tf.matmul(s, w1_s) + tf.matmul(a, w1_a) + b1) return tf.layers.dense(net, 1, trainable=trainable) # Q(s,a) soft模式参数更新可以看到，我们这里进行的是soft模式的参数更新，每次在原来target-net参数的基础上，改变一丢丢，增加一点点eval-net的参数信息。 123456789# networks parametersself.ae_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Actor/eval')self.at_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Actor/target')self.ce_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Critic/eval')self.ct_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Critic/target')# target net replacementself.soft_replace = [[tf.assign(ta, (1 - TAU) * ta + TAU * ea), tf.assign(tc, (1 - TAU) * tc + TAU * ec)] for ta, ea, tc, ec in zip(self.at_params, self.ae_params, self.ct_params, self.ce_params)] 定义两个网络的损失关于两个网络的损失，我们之前已经详细介绍过了，这里只是对刚才思路的一个代码实现。 1234567q_target = self.R + GAMMA * q_# in the feed_dic for the td_error, the self.a should change to actions in memorytd_error = tf.losses.mean_squared_error(labels=q_target, predictions=q)self.ctrain = tf.train.AdamOptimizer(LR_C).minimize(td_error, var_list=self.ce_params)a_loss = - tf.reduce_mean(q) # maximize the qself.atrain = tf.train.AdamOptimizer(LR_A).minimize(a_loss, var_list=self.ae_params) 学习我们首先要从经验池中取出一个batch的数据，然后训练我们的Actor和Critic 12345678910111213def learn(self): # soft target replacement self.sess.run(self.soft_replace) indices = np.random.choice(MEMORY_CAPACITY, size=BATCH_SIZE) bt = self.memory[indices, :] bs = bt[:, :self.s_dim] ba = bt[:, self.s_dim: self.s_dim + self.a_dim] br = bt[:, -self.s_dim - 1: -self.s_dim] bs_ = bt[:, -self.s_dim:] self.sess.run(self.atrain, &#123;self.S: bs&#125;) self.sess.run(self.ctrain, &#123;self.S: bs, self.a: ba, self.R: br, self.S_: bs_&#125;) 存储经验 12345def store_transition(self, s, a, r, s_): transition = np.hstack((s, a, [r], s_)) index = self.pointer % MEMORY_CAPACITY # replace the old memory with new memory self.memory[index, :] = transition self.pointer += 1]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度强化学习-Actor-Critic算法原理和实现]]></title>
    <url>%2F2018%2F05%2F19%2F%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-Actor-Critic%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[深度强化学习-Actor-Critic算法原理和实现1、Actor-Critic算法原理我们为什么要有Actor-Critic呢，下面的话摘自莫烦老师的文章： 我们有了像 Q-learning这么伟大的算法, 为什么还要瞎折腾出一个 Actor-Critic? 原来 Actor-Critic 的 Actor 的前生是 Policy Gradients, 这能让它毫不费力地在连续动作中选取合适的动作, 而 Q-learning 做这件事会瘫痪. 那为什么不直接用 Policy Gradients 呢? 原来 Actor Critic 中的 Critic 的前生是 Q-learning 或者其他的 以值为基础的学习法 , 能进行单步更新, 而传统的 Policy Gradients 则是回合更新, 这降低了学习效率. 上面的一段话不仅解释了为什么会有Actor-Critic这么一个算法，同时也告诉了我们，这个算法具体是怎么做的。如果大家已经心中有数并且想马上看代码的话，这一段是可以直接跳过的。既然Actor其实是一个Policy Network ,那么他就需要奖惩信息来进行调节不同状态下采取各种动作的概率，在传统的Policy Gradient算法中，这种奖惩信息是通过走完一个完整的episode来计算得到的。这不免导致了学习速率很慢，需要很长时间才可以学到东西。既然Critic是一个以值为基础的学习法，那么他可以进行单步更新，计算每一步的奖惩值。那么二者相结合，Actor来选择动作，Critic来告诉Actor它选择的动作是否合适。在这一过程中，Actor不断迭代，得到每一个状态下选择每一动作的合理概率，Critic也不断迭代，不断完善每个状态下选择每一个动作的奖惩值。 下图就简单的介绍了Actor-Critic算法的流程： 但Actor-Critic并不是一个完善的算法， 后面还会提到进一步的改进: Actor-Critic 涉及到了两个神经网络, 而且每次都是在连续状态中更新参数, 每次参数更新前后都存在相关性, 导致神经网络只能片面的看待问题, 甚至导致神经网络学不到东西。 2、代码解析2.1 Actor定义Actor输入在这里，由于我们的Actor可以进行单次训练，所以我们的输入只需要是一个状态，一个动作和一个奖励： 123self.s = tf.placeholder(tf.float32,[1,n_features],name='state')self.a = tf.placeholder(tf.int32,None,name='act')self.td_error = tf.placeholder(tf.float32,None,"td_error") Actor的网络定义Actor的神经网络结构和我们的Policy Gradient定义的是一样的，是一个双层的全链接神经网络： 123456789101112131415161718with tf.variable_scope('Actor'): l1 = tf.layers.dense( inputs = self.s, units = 20, activation = tf.nn.relu, kernel_initializer = tf.random_normal_initializer(mean=0,stddev=0.1), bias_initializer = tf.constant_initializer(0.1), name = 'l1' ) self.acts_prob = tf.layers.dense( inputs = l1, units = n_actions, activation = tf.nn.softmax, kernel_initializer = tf.random_normal_initializer(mean=0,stddev=0.1), bias_initializer = tf.constant_initializer(0.1), name = 'acts_prob' ) 损失函数损失函数还是使用的Policy Gradient中提到过的loss= -log(prob)*vt,只不过这里的vt换成了由Critic计算出的时间差分误差td_error 1234567with tf.variable_scope('exp_v'): log_prob = tf.log(self.acts_prob[0,self.a]) self.exp_v = tf.reduce_mean(log_prob * self.td_error)with tf.variable_scope('train'): self.train_op = tf.train.AdamOptimizer(lr).minimize(-self.exp_v) Actor训练Actor的训练只需要将状态，动作以及时间差分值喂给网络就可以。 12345def learn(self,s,a,td): s = s[np.newaxis,:] feed_dict = &#123;self.s:s,self.a:a,self.td_error:td&#125; _,exp_v = self.sess.run([self.train_op,self.exp_v],feed_dict=feed_dict) return exp_v 选择动作 选择动作和Policy Gradient一样，根据计算出的softmax值来选择动作 1234def choose_action(self,s): s = s[np.newaxis,:] probs = self.sess.run(self.acts_prob,feed_dict=&#123;self.s:s&#125;) return np.random.choice(np.arange(probs.shape[1]),p=probs.ravel()) 2.2 Critic定义Critic输入 Critic要反馈给Actor一个时间差分值，来决定Actor选择动作的好坏，如果时间差分值大的话，说明当前Actor选择的这个动作的惊喜度较高，需要更多的出现来使得时间差分值减小。考虑时间差分的计算：TD = r + gamma * f(s’) - f(s),这里f(s)代表将s状态输入到Critic神经网络中得到的Q值。所以Critic的输入也分三个，首先是当前状态，当前的奖励，以及下一个时刻的奖励折现值。为什么没有动作A呢？动作A是确定的呀，是Actor选的呀，对不对！还有为什么不是下一时刻的Q值而不是下一个时刻的状态，因为我们已经在计算TD时已经把状态带入到神经网络中得到Q值了。相信你看代码就明白了。 123self.s = tf.placeholder(tf.float32,[1,n_features],name='state')self.v_ = tf.placeholder(tf.float32,[1,1],name='v_next')self.r = tf.placeholder(tf.float32,None,name='r') 定义网络结构 同Actor一样，我们的Critic也是一个双层的神经网络结构。 123456789101112131415161718with tf.variable_scope('Critic'): l1 = tf.layers.dense( inputs = self.s, units = 20, activation = tf.nn.relu, kernel_initializer = tf.random_normal_initializer(0,0.1), bias_initializer = tf.constant_initializer(0.1), name = 'l1' ) self.v = tf.layers.dense( inputs = l1, units = 1, activation = None, kernel_initializer=tf.random_normal_initializer(0,0.1), bias_initializer = tf.constant_initializer(0.1), name = 'V' ) 定义损失Critic的损失定义为时间差分值的平方值 1234567with tf.variable_scope('squared_TD_error'): self.td_error = self.r + gamma * self.v_ - self.v self.loss = tf.square(self.td_error)with tf.variable_scope('train'): self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss) 训练CriticCritic的任务就是告诉Actor当前选择的动作好不好，所以我们只要训练得到TD并返回给Actor就好： 123456789def learn(self,s,r,s_): s,s_ = s[np.newaxis,:],s_[np.newaxis,:] v_ = self.sess.run(self.v,feed_dict = &#123;self.s:s_&#125;) td_error,_ = self.sess.run([self.td_error,self.train_op], feed_dict=&#123;self.s:s,self.v_:v_,self.r:r&#125;) return td_error 2.3 整体模型训练有了Critic之后，Actor就可以进行单步训练和更新了，所以训练中的关键的代码如下： 123456while True: a = actor.choose_action(s) s_,r,done,info = env.step(a) td_error = critic.learn(s,r,s_) actor.learn(s,a,td_error) s = s_]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度强化学习-Policy Gradient基本实现]]></title>
    <url>%2F2018%2F05%2F05%2F%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-Policy%20Gradient%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[深度强化学习-Policy Gradient基本实现1、什么是 Policy Gradients其实在引言部分我们已经介绍了策略梯度的基本思想，就是直接根据状态输出动作或者动作的概率。那么怎么输出呢，最简单的就是使用神经网络啦！我们使用神经网络输入当前的状态，网络就可以输出我们在这个状态下采取每个动作的概率，那么网络应该如何训练来实现最终的收敛呢？我们之前在训练神经网络时，使用最多的方法就是反向传播算法，我们需要一个误差函数，通过梯度下降来使我们的损失最小。但对于强化学习来说，我们不知道动作的正确与否，只能通过奖励值来判断这个动作的相对好坏。基于上面的想法，我们有个非常简单的想法： 如果一个动作得到的reward多，那么我们就使其出现的概率增加，如果一个动作得到的reward少，我们就使其出现的概率减小。 根据这个思想，我们构造如下的损失函数：loss= -log(prob)*vt 我们简单用白话介绍一下上面这个损失函数的合理性，那么至于从数学角度上为什么要使用上面的损失函数，可以参考：Why we consider log likelihood instead of Likelihood in Gaussian Distribution。 上式中log(prob)表示在状态 s 对所选动作 a 的吃惊度, 如果概率越小, 反向的log(prob) 反而越大. 而vt代表的是当前状态s下采取动作a所能得到的奖励，这是当前的奖励和未来奖励的贴现值的求和。也就是说，我们的策略梯度算法必须要完成一个完整的eposide才可以进行参数更新，而不是像值方法那样，每一个(s,a,r,s’)都可以进行参数更新。如果在prob很小的情况下, 得到了一个大的Reward, 也就是大的vt, 那么-log(prob)*vt就更大, 表示更吃惊, (我选了一个不常选的动作, 却发现原来它能得到了一个好的 reward, 那我就得对我这次的参数进行一个大幅修改)。 这就是 -log(prob)*vt的物理意义啦.Policy Gradient的核心思想是更新参数时有两个考虑：如果这个回合选择某一动作，下一回合选择该动作的概率大一些，然后再看奖惩值，如果奖惩是正的，那么会放大这个动作的概率，如果奖惩是负的，就会减小该动作的概率。 策略梯度的过程如下图所示： 我们在介绍代码实战之前，最后在强调Policy Gradient的一些细节： 算法输出的是动作的概率，而不是Q值。 损失函数的形式为：loss= -log(prob)*vt 需要一次完整的episode才可以进行参数的更新 2、Policy Gradient算法实现我们通过Policy Gradient算法来实现让钟摆倒立的过程。 本文的代码思路完全按照policy gradient的过程展开。 定义参数首先，我们定义了一些模型的参数： self.ep_obs,self.ep_as,self.ep_rs分别存储了当前episode的状态，动作和奖励。 123456self.n_actions = n_actionsself.n_features = n_featuresself.lr = learning_rateself.gamma = reward_decayself.ep_obs,self.ep_as,self.ep_rs = [],[],[] 定义模型输入模型的输入包括三部分，分别是观察值，动作和奖励值。 1234with tf.name_scope('inputs'): self.tf_obs = tf.placeholder(tf.float32,[None,self.n_features],name='observation') self.tf_acts = tf.placeholder(tf.int32,[None,],name='actions_num') self.tf_vt = tf.placeholder(tf.float32,[None,],name='actions_value') 构建模型我们的模型定义了两层的神经网络，网络的输入是每次的观测值，而输出是该状态下采取每个动作的概率，这些概率在最后会经过一个softmax处理 12345678910111213141516171819layer = tf.layers.dense( inputs = self.tf_obs, units = 10, activation= tf.nn.tanh, kernel_initializer=tf.random_normal_initializer(mean=0,stddev=0.3), bias_initializer= tf.constant_initializer(0.1), name='fc1')all_act = tf.layers.dense( inputs = layer, units = self.n_actions, activation = None, kernel_initializer=tf.random_normal_initializer(mean=0,stddev=0.3), bias_initializer = tf.constant_initializer(0.1), name='fc2')self.all_act_prob = tf.nn.softmax(all_act,name='act_prob') 模型的损失我们之前介绍过了，模型的损失函数计算公式为：loss= -log(prob)*vt，我们可以直接使用tf.nn.sparse_softmax_cross_entropy_with_logits 来计算前面一部分，即-log(prob)，不过为了更清楚的显示我们的计算过程，我们使用了如下的方式： 12345with tf.name_scope('loss'): #neg_log_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.all_act_prob,labels =self.tf_acts) neg_log_prob = tf.reduce_sum(-tf.log(self.all_act_prob) * tf.one_hot(indices=self.tf_acts,depth=self.n_actions),axis=1) loss = tf.reduce_mean(neg_log_prob * self.tf_vt) 而我们选择AdamOptimizer优化器进行参数的更新： 12with tf.name_scope('train'): self.train_op = tf.train.AdamOptimizer(self.lr).minimize(loss) 动作选择我们这里动作的选择不再根据贪心的策略来选择了，而是根据输出动作概率的softmax值： 1234def choose_action(self,observation): prob_weights = self.sess.run(self.all_act_prob,feed_dict=&#123;self.tf_obs:observation[np.newaxis,:]&#125;) action = np.random.choice(range(prob_weights.shape[1]),p=prob_weights.ravel()) return action 存储经验之前说过，policy gradient是在一个完整的episode结束后才开始训练的，因此，在一个episode结束前，我们要存储这个episode所有的经验，即状态，动作和奖励。 1234def store_transition(self,s,a,r): self.ep_obs.append(s) self.ep_as.append(a) self.ep_rs.append(r) 计算奖励的贴现值我们之前存储的奖励是当前状态s采取动作a获得的即时奖励，而当前状态s采取动作a所获得的真实奖励应该是即时奖励加上未来直到episode结束的奖励贴现和。 1234567891011def _discount_and_norm_rewards(self): discounted_ep_rs = np.zeros_like(self.ep_rs) running_add = 0 # reserved 返回的是列表的反序，这样就得到了贴现求和值。 for t in reversed(range(0,len(self.ep_rs))): running_add = running_add * self.gamma + self.ep_rs[t] discounted_ep_rs[t] = running_add discounted_ep_rs -= np.mean(discounted_ep_rs) discounted_ep_rs /= np.std(discounted_ep_rs) return discounted_ep_rs 模型训练在定义好上面所有的部件之后，我们就可以编写模型训练函数了，这里需要注意的是，我们喂给模型的并不是我们存储的奖励值，而是在经过上一步计算的奖励贴现和。另外，我们需要在每一次训练之后清空我们的经验池。 1234567891011def learn(self): discounted_ep_rs_norm = self._discount_and_norm_rewards() self.sess.run(self.train_op,feed_dict=&#123; self.tf_obs:np.vstack(self.ep_obs), self.tf_acts:np.array(self.ep_as), self.tf_vt:discounted_ep_rs_norm, &#125;) self.ep_obs,self.ep_as,self.ep_rs = [],[],[] return discounted_ep_rs_norm 好了，模型相关的代码我们就介绍完了，如何调用这个模型的代码相信大家一看便明白，我们就不再介绍啦。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SA-ABR Code]]></title>
    <url>%2F2018%2F04%2F26%2FSA-ABR%20Code%2F</url>
    <content type="text"><![CDATA[这部分详细讲解我们实现的自适应算法的代码实现部分，主要包括系统信息获取部分、网络部分以及网络更新部分。其中系统信息获取部分包括导入训练数据及数据预处理、得到网络输入、更新视频缓存、获取奖励等；网络部分主要是上一节提到的actor-critic网络的搭建；网络更新部分主要是根据强化学习算法部分多网络进行优化更新，这也是我们的重点。我们在实际实现时，采取了CNN、CNN+传感器、RNN+传感器三种方式的网络，三者在大体上差不多，因此在这我们仅介绍前面谈到过的CNN+传感器的网络实现。如果想看完整的代码和采集的无人机飞行中吞吐量与速度、加速度、距离之间的数据信息，请查看allData目录.下面是我们系统部分部分代码的结构： 其中文件夹train_data里面是采集的数据，readData、py导入训练数据及数据预处理，helperwithspeed、py包含系统网络输入获取、缓存更新、获取奖励等功能、train_with_speed、py主要是网络的搭建以及网络的更新。下面将详细讲解每个部分的具体功能以及实现。 1、数据部分：包括测量的吞吐量throughput.txt以及对应的速度信息speed.txt、距离信息distance.txt、加速度信息acce.txt.后续数据还在继续扩充。 吞吐量中一共95组数据，每一组数据包括50s的吞吐量大小，大小在0到16Mps之间。 加速度一共95组，每一组是与吞吐量相对应的50s的加速度大小，通过预处理，我们将加速度分为0和1两个等级，当实际加速度超过18.5m/s^2的时候将加速度置为1，反之则为0. 距离一共95组，每一组是与吞吐量对应的50m的距离大小，通过预处理，将加速度分为0和1两个等级，当与接收端距离超过50m时将距离置为1，反之则为0 速度也是95组，每一组是与吞吐量对应的50s的速度大小，通过预处理，将速度划分为三个等级，速度不超过8m/s的置为0，8-12m/s的置为1，超过12m/s的置为2. 2、数据导入及预处理这部分主要是从txt中导入数据以及进行数据归一化预处理。 数据的读取比较简单，用np.loadtxt()就可以直接将txt读取为numpy数组。 接下来是数据的归一化，在这里我们将吞吐量归一化到0.5-2.5之间。 最后，我们将数据进行重复，得到N组数据，即train_throughput、train_speed、train_distance、train_acce,他们都是维数为N*50的二维数组，其中，N为我们训练的次数，在实验中我们可以根据需要进行自行调整，在这里，我们暂取N=10000. 3.网络搭建网络的搭建和深度学习中的网络类似，唯一需要注意的是在这里两个有两个独立的网络：actor和critic网络。前面已经谈到过，这两个网络的输入部分相同，都是输入的相应的状态，即一个1x13的numpy数组。具体网络搭建的代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class ActorNetwork(nn.Module): def __init__(self): super(ActorNetwork, self).__init__() self.rnn = nn.LSTM( input_size=2, hidden_size=64, num_layers=2, batch_first=True, ) self.fc1 = nn.Linear(69, 30) self.fc2 = nn.Linear(30, 10) self.fc3 = nn.Linear(10, 4) self.relu = nn.ReLU() def forward(self, x): # x shape(1x1x13) x1 = np.zeros([8], dtype=np.float32) # 代表throughput for i in range(8): x1[i] = x[i] x2 = np.array([x[8]], dtype=np.float32) # 代表buffersize x3 = np.array([x[9]], dtype=np.float32) # 代表lastAction x4 = np.array([x[10]], dtype=np.float32) # 代表speed x5 = np.array([x[11]], dtype=np.float32) # 代表distance x6 = np.array([x[12]], dtype=np.float32) # 代表acce x1 = Variable(torch.from_numpy(x1)) x2 = Variable(torch.from_numpy(x2)) x3 = Variable(torch.from_numpy(x3)) x4 = Variable(torch.from_numpy(x4)) x5 = Variable(torch.from_numpy(x5)) x6 = Variable(torch.from_numpy(x6)) x1 = x1.view(-1, 4, 2) x2 = x2.view(1, -1) x3 = x3.view(1, -1) x4 = x4.view(1, -1) x5 = x5.view(1, -1) x6 = x6.view(1, -1) r_out, (h_n, h_c) = self.rnn(x1, None) #r_out = r_out.view(-1, num_flat_features(r_out)) datain = torch.cat((r_out[:,-1,:], x2), 1) datain = torch.cat((datain, x3), 1) datain = torch.cat((datain, x4), 1) datain = torch.cat((datain, x5), 1) datain = torch.cat((datain, x6), 1) out = self.relu(self.fc1(datain)) out = self.relu(self.fc2(out)) out = self.fc3(out) return F.log_softmax(out) 上面是actor网络部分的实现，网络的输入是每时刻的状态，是一个1x13维的numpy数组，输出为1x4维的tesnor，标识的是状态动作概率。需要注意的是，这里输出的是log_softmax处理后的概率，在具体使用时需要进行指数处理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class ValueNetwork(nn.Module): def __init__(self,input_channels=1,output_channels=128,output_size=1): super(ValueNetwork ,self ).__init__() self.cov1 = nn.Conv1d(input_channels, 64, kernel_size=3) self.cov2 = nn.Conv1d(64, output_channels, kernel_size=3) self.fc1 = nn.Linear(517, 128) self.fc2 = nn.Linear(128, 30) self.fc3 = nn.Linear(30, 8) self.fc4 = nn.Linear(8, output_size) self.drop = nn.Dropout(p=0.5) def forward(self,x):#输入1x1x13 #in_size=x.size(0) x1 = np.zeros([8], dtype=np.float32) #代表throughput for i in range(8): x1[i] = x[i] x2 = np.array([x[8]], dtype=np.float32) #代表buffersize x3 = np.array([x[9]], dtype=np.float32) #代表lastAction x4 = np.array([x[10]],dtype=np.float32) #代表speed x5 =np.array([[x[11]]],dtype=np.float32) #代表distance x6 =np.array([x[12]],dtype=np.float32) #代表acce x1 = Variable(torch.from_numpy(x1)) x2 = Variable(torch.from_numpy(x2)) x3 = Variable(torch.from_numpy(x3)) x4= Variable(torch.from_numpy(x4)) x5 = Variable(torch.from_numpy(x5)) x6 = Variable(torch.from_numpy(x6)) x1 = x1.view(1, 1, -1) x2 = x2.view(1, -1) x3 = x3.view(1, -1) x4 = x4.view(1, -1) x5 = x5.view(1, -1) x6 = x6.view(1, -1) x1 = self.cov1(x1) x1= self.cov2(x1) x1 = x1.view(-1, num_flat_features(x1)) datain = torch.cat((x1, x2), 1) datain = torch.cat((datain, x3), 1) datain = torch.cat((datain, x4), 1) datain = torch.cat((datain, x5), 1) datain = torch.cat((datain, x6), 1) out = F.relu(self.fc1(datain)) out = self.drop(F.relu(self.fc2(out))) out = F.relu(self.fc3(out)) out = self.fc4(out) return out 上面是critic网路部分的实现，输入的也是每时刻的1x13维的状态矩阵，输出的是1x1维的tesnor，表示的是每个状态下的状态价值V(s). 从结构上来说，actor网络和critic网络的输入以及网络结构都是相同的，均是2层1维CNN后在连接三层全连层网络。需要注意并不是将输入直接进行卷积处理，因为我们卷积的只是输入的一部分，因此需要进行数据的拆分和合并处理。在这里，还需要注意的是tensor,variable以及numpy数组的转换。 4、系统状态获取及更新系统状态获取以及更新也是整个系统比较重要的部分，其中主要包括获训练数据，获取送入网络的数据，状态更新以及计算奖励。下面我主要介绍这部分的相关函数。 1 函数getThroughput比较简单，输入参数是训练的epoch，返回参数是这次训练整个过程中的吞吐量以及对应的速度、加速度以及距离信息。代码如下： def getThroughputData(epoch): global train_throughput global train_speed global train_distance global train_acce return train_throughput[epoch],train_speed[epoch],train_distance[epoch],train_acce[epoch] 2 函数Input实现的是根据上面得到的每个epoch的数据，在每个视频块需要播放的时候送往actor-critic网络的表示状态的1x13维的numpy数组。状态是由过去八个视频块的吞吐量、此刻的视频缓存、上一视频块的比特率、此刻的速度、距离以及加速度组成。具体实现的代码如下： def Input(SyntheticData,TestSpeed,TestDistance,TestAcce,BufferSize,BitRate,TrainTime): ThroughPut = SyntheticData[TrainTime - 1:TrainTime + 7] ThroughPut =np.array(ThroughPut,dtype=np.float32) speed=np.array(TestSpeed[TrainTime+7:TrainTime+8],dtype=np.float32) distance = np.array(TestDistance[TrainTime + 7: TrainTime + 8], dtype=np.float32) acce = np.array(TestAcce[TrainTime + 7 :TrainTime + 8], dtype=np.float32) buffer=np.array([BufferSize],dtype=np.float32) action=np.array([BitRate],dtype=np.float32) networkIn= np.append(ThroughPut,buffer) networkIn = np.append(networkIn, action) networkIn =np.append(networkIn,speed) networkIn =np.append(networkIn,distance) networkIn =np.append(networkIn,acce) return networkIn 3 函数UpdateBuffer实现的是在状态s下，选择特定比特率action之后到达下一个状态，此过程中buffer的更新以及此action导致的卡顿时间rebuffering.需要注意的是我们在这里提到的action都是用{0，1，2，3}来表示{300kbps,750kpbs,1850kbps,2850kbps}的视频比特率的，在具体计算的时候需要通过函数BiterateTransform来进行转换一下，这一函数很简单，我们就不做描述。具体代码如下： def updateBuffer(buffer,action,throughput): if 2*BitrateTransform(action)/throughput &lt; buffer : #不卡 newbuffer =buffer +2- 2*BitrateTransform(action)/throughput rebuffering = 0 elif 2*BitrateTransform(action)/throughput &gt;buffer and buffer+2 &gt; 2*BitrateTransform(action)/throughput: #不卡 newbuffer = buffer +2- 2*BitrateTransform(action)/throughput rebuffering = 0 else: newbuffer = 0 rebuffering = (math.ceil((2*BitrateTransform(action)/throughput -2-buffer)/0.5))*0.5 return newbuffer, rebuffering 4 函数Reward是根据选择视频块的BitRate以及这一BitRate造成的卡顿时间rebuffering和上一视频块的比特率来计算的，计算的是根据下面公式算出的视频的QoE,也就是我们系统中的奖励值。 具体实现的代码如下，实现思路就是比较视频缓存大小和下载该视频块的时间进行比较来分类讨论进行的。 def updateBuffer(buffer,action,throughput): if 2*BitrateTransform(action)/throughput &lt; buffer : #不卡 newbuffer =buffer +2- 2*BitrateTransform(action)/throughput rebuffering = 0 elif 2*BitrateTransform(action)/throughput &gt;buffer and buffer+2 &gt; 2*BitrateTransform(action)/throughput: #不卡 newbuffer = buffer +2- 2*BitrateTransform(action)/throughput rebuffering = 0 else: newbuffer = 0 rebuffering = (math.ceil((2*BitrateTransform(action)/throughput -2-buffer)/0.5))*0.5 return newbuffer, rebuffering 4.1 函数discount_reward是根据某次播放一段视频每个状态选择动作后得到的奖励值r、最后一步的奖励值final_r以及折扣因子gama来计算这段视频中每个状态的动作价值函数的，计算的依据是下面动作价值函数的定义： 具体实现的代码如下： def discount_reward(r,gama,final_r): discounted_r =np.zeros_like(r) running_add =final_r for t in reversed(range(0,len(r))): running_add=running_add*gama+r[t] discounted_r[t]=running_add return discounted_r 5.网络优化更新前面我们已经做好了所有的准备工作，我们大致实现了如下功能： 每一次你训练时得到一段50s包含吞吐量以及对应速度、加速度、距离的训练数据。这一组数据对应一段完整的视频播放过程，需要进行42次视频比特率的选择。 对于每一组训练数据，我们在每个视频块需要选择比特率的时候得到此刻的状态信息，将它合并在一个1x13维的numpy数组中。搭建好actor-critic网络，对于每一个视频块，输入此刻的状态，actor网络可以输出动作概率用来选择概率，value网络输出此状态下的状态价值V(st)。选择比特率后，我们能达到下一状态并进行状态的更新以及获得即时奖励r。计算每一个状态的动作价值函数Q(st,at)接下来我们需要做的是根据这一过程进行网络的优化更新，这也是我们的重中之重。更新过程主要分为两部分，第一部分是根据每个epoch得到的数据进行一次完整的视频播放。具体代码如下： def roll_out(actor_network,value_network,TestThroughput,TestSpeed,TestDistance,TestAcce): #initial CurrentBufferSize =0 LastBitRate = 0 train_time =1 initial_state=Input(TestThroughput,TestSpeed,TestDistance,TestAcce, CurrentBufferSize, LastBitRate, train_time) state=initial_state #return data states=[] actions =[] rewards =[] buffers=[] rebuffer_all=[] action_all=[] buffers.append(CurrentBufferSize) #is_done =False final_r =0 for j in range(total_times-1): states.append(state) log_softmax_action =actor_network(state) softmax_action =torch.exp(log_softmax_action) action=np.random.choice(4,p=softmax_action.cpu().data.numpy()[0]) #action=makeChoice(softmax_action.cpu().data.numpy()[0]) print(action) action_all.append(action) one_hot_action=[int (k==action) for k in range(4)] throughput=TestThroughput[train_time+8] CurrentBufferSize,rebuffer =updateBuffer(CurrentBufferSize,action,throughput) rebuffer_all.append(rebuffer) buffers.append(CurrentBufferSize) reward=Reward(action,LastBitRate,rebuffer) LastBitRate = action train_time =train_time+1 next_state =Input(TestThroughput,TestSpeed,TestDistance,TestAcce, CurrentBufferSize, LastBitRate, train_time) final_state=next_state state=next_state actions.append(one_hot_action) rewards.append(reward) if (j == total_times - 1): last_softmax_action = actor_network(final_state) last_action = torch.exp(last_softmax_action) last_choose_action = np.random.choice(4, p=last_action.cpu().data.numpy()[0]) last_throughput = TestThroughput[train_time + 8] last_buffer, last_rebuffer = updateBuffer(CurrentBufferSize, last_choose_action, last_throughput) final_r = Reward(last_action, LastBitRate, last_rebuffer) return states,actions,rewards,buffers,final_r,action_all,rebuffer_all 这一部分的思路是在每个视频快获取到状态信息，然后送入actor网络根据网络输出选择特定的比特率,然后更新到下一个状态并计算出此选择的奖励值，这样循环下去直到这个视频播放完毕。在这个过程中我们只进行选择但不进行网络更新，返回值主要包括以下参数： 这一段视频中的所有状态信息（以矩阵的形式存储在states中）、每个状态下选择的动作的one_hot编码表示（以矩阵的形式存储在actions中，每个元素都是用[1，0，0，0]、[0，1，0，0]、[0，0，1，0]、[0，0，0，1]表示）、每个状态下的动作（以矩阵的形式存储在action_all中，每个元素都是0，1，2，3来表示不同的比特率)、每个状态下做出动作后的奖励（以矩阵形式存储在rewards中）、最后一个状态的奖励（final_r）以及每个状态下的卡段时间（以矩阵形式存储在rebuffer_all中。 上面得到了一个完整视频播放的所有信息，接下来就可以进行一次更新了。更新分为actor网络的更新和value网络的更新。更新的核心代码如下： train_throughput,train_speed,train_distance,train_acce= getThroughputData(step) value_network_optim = torch.optim.Adam(value_network.parameters(), lr=decayed_learning_rate_value) actor_network_optim = torch.optim.Adam(actor_network.parameters(), lr=decayed_learning_rate_actor) states, actions, rewards, buffers, final_r, _,_ = roll_out(actor_network, value_network, train_throughput,train_speed,train_distance,train_acce) data=sum(rewards) total_reward.append(data) new_states=np.zeros([len(states),len(states[0])],dtype=np.float32) for i in range(len(states)): for j in range(len(states[i])): new_states[i][j]=states[i][j] actions_var=Variable(torch.Tensor(actions).view(-1,4)) states_var= Variable(torch.from_numpy(new_states)) #train actor_network actor_network_optim.zero_grad() log_softmax_actions=actor_network(states[0]) for i in range(1,len(states)): log_softmax_actions=torch.cat((log_softmax_actions,actor_network(states[i])),0) vs=value_network(states[0] for i in range(1,len(states)): vs=torch.cat((vs,value_network(states[i])),0) vs=vs.detach() qs=Variable(torch.Tensor(discount_reward(rewards,0.99,final_r))) advantages= qs-vs actor_network_loss=-torch.mean(torch.sum(log_softmax_actions*actions_var,1)*advantages) total_actorloss.append(actor_network_loss.cpu().data.numpy()) actor_network_loss.backward() torch.nn.utils.clip_grad_norm(actor_network.parameters(),0.5) actor_network_optim.step() #train value_network value_network_optim.zero_grad() target_value =qs values=value_network(states[0]) for i in range(1,len(states)): values=torch.cat((values,value_network(states[i])),0) criterion =nn.MSELoss() target_value = target_value.view(-1,1) #print(target_value.size()) value_network_loss=criterion(values,target_value) value_network_loss.backward() torch.nn.utils.clip_grad_norm(value_network.parameters(),0.5) value_network_optim.step() total_valueloss.append(value_network_loss.cpu().data.numpy()) actor网络是根据梯度上升来进行更新的。 actor网络更新需要log_sofmax动作概率以及优势函数A(st,at)=Q(st,at)-V(st,w).其中log_softmax动作概率由action网络得到，Q(st,at)由实际选择获得的即时奖励与折扣因子计算得到，V（st,w）由critic网络得到。 critic网络根据梯度下降来进行更新的。 critic网络更新需要即时奖励rt，下一个状态的价值函数V(st+1)以及这个状态的状态价值V(st).其中rt是根据实际值得到的QoE,V(st+1)和V(st)是根据critic网络得到的。 上面完成的就是一次完整的视频播放及更新过程。在设置好训练次数进行多次的更新即可达到稳定值。在这个心目中，我们大概训练15000次左右就能达到稳定的reward值。我们在训练过程中主要是根据actor-loss和value-loss来进行网络参数的调整，经过尝试，对网络效果影响最大的参数是actor和value网络的学习率，最终，我们发现两者在0.00003和0.01左右事能达到较好的效果。 在下一节，我们主要展示训练得到的结果以及将要介绍一下其他自适应比特率算法。 本节是项目的重点，中间网络的训练我们采取了较为简单的actor-critic网络来训练，后续我们将在网络结构以及考虑用异步actor-critic（A3C）算法来提升训练速度和效果。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实战深度强化学习DQN-理论和实践]]></title>
    <url>%2F2018%2F04%2F19%2F%E5%AE%9E%E6%88%98%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0DQN-%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[1、Q-learning回顾Q-learning 的 算法过程如下图所示： 在Q-learning中，我们维护一张Q值表，表的维数为：状态数S * 动作数A，表中每个数代表在当前状态S下可以采用动作A可以获得的未来收益的折现和。我们不断的迭代我们的Q值表使其最终收敛，然后根据Q值表我们就可以在每个状态下选取一个最优策略。 Q值表的更新公式为： 公式中，Q(S,A) 我们可以称做Q估计值，即我们当前估计的Q值，而： 称为Q-target，即我们使用贝尔曼方程加贪心策略认为实际应该得到的奖励，我们的目标就是使我们的Q值不断的接近Q-target值。 2、深度Q网络(Deep - Q - Network)2.1 DQN简介为什么会出现DQN呢 在普通的Q-learning中，当状态和动作空间是离散且维数不高时可使用Q-Table储存每个状态动作对的Q值，而当状态和动作空间是高维连续时，使用Q-Table不现实。 两篇DQN奠基之作 [1]Playing Atari with Deep Reinforcement Learning [2]Human-level control through deep reinforcement learning 如何将原始的Q-learning转换成深度学习问题 将Q-Table的更新问题变成一个函数拟合问题，相近的状态得到相近的输出动作。如下式，通过更新参数 θ 使Q函数逼近最优Q值 。因此，DQN就是要设计一个神经网络结构，通过函数来拟合Q值，即： 2.2 DL和RL结合带来的问题1、DL需要大量带标签的样本进行监督学习；RL只有reward返回值，而且伴随着噪声，延迟（过了几十毫秒才返回），稀疏（很多State的reward是0）等问题； 2、DL的样本独立；RL前后state状态相关； 3、DL目标分布固定；RL的分布一直变化，比如你玩一个游戏，一个关卡和下一个关卡的状态分布是不同的，所以训练好了前一个关卡，下一个关卡又要重新训练； 4、过往的研究表明，使用非线性网络表示值函数时出现不稳定等问题。 2.3 DQN解决问题方法那么DQN是如何解决上述问题的呢？ 1、通过Q-Learning使用reward来构造标签（对应问题1） 2、通过experience replay（经验池）的方法来解决相关性及非静态分布问题（对应问题2、3） 3、使用一个神经网络产生当前Q值，使用另外一个神经网络产生Target Q值（对应问题4） 构造标签 对于函数优化问题，监督学习的一般方法是先确定Loss Function，然后求梯度，使用随机梯度下降等方法更新参数。DQN则基于Q-Learning来确定Loss Function。我们想要使q-target值和q-eval值相差越小越好。DQN中的损失函数是： 这里yi是根据上一个迭代周期或者说target-net网络的参数计算出的q-target值，跟当前网络结构中的参数无关，yi的计算如下： 这样，整个目标函数就可以通过随机梯度下降方法来进行优化： 经验回放 经验池的功能主要是解决相关性及非静态分布问题。具体做法是把每个时间步agent与环境交互得到的转移样本 (st,at,rt,st+1) 储存到回放记忆单元，要训练时就随机拿出一些（minibatch）来训练。（其实就是将游戏的过程打成碎片存储，训练时随机抽取就避免了相关性问题） 双网络结构 在Nature 2015版本的DQN中提出了这个改进，使用另一个网络（这里称为target_net）产生Target Q值。具体地，Q(s,a;θi) 表示当前网络eval_net的输出，用来评估当前状态动作对的值函数；Q(s,a;θ−i) 表示target_net的输出，代入上面求 TargetQ 值的公式中得到目标Q值。根据上面的Loss Function更新eval_net的参数，每经过N轮迭代，将MainNet的参数复制给target_net。 引入target_net后，再一段时间里目标Q值使保持不变的，一定程度降低了当前Q值和目标Q值的相关性，提高了算法稳定性。 2.4 DQN算法流程NIPS 2013版 Nature 2015版 可以看到，两版的DQN都使用了经验池，而2015版的DQN增加了target-net，提高了算法稳定性。 3、DQN实现DEMO找了很多DQN的例子，有原版的实现Atari的，也有Flappy Bird的，但是最简单的还是莫烦大神的Demo，github地址是：https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow。 在介绍整个Demo前，我们介绍两种DQN的实现方式，一种是将s和a输入到网络，得到q值，另一种是只将s输入到网络，输出为s和每个a结合的q值。这里莫烦大神的代码采取了后一种方式。 如果你对DQN的原理有比较深刻的认识，那么读莫烦大神的代码也并不是十分困难。这里我们想要实现的效果类似于寻宝。 其中，红色的方块代表寻宝人，黑色的方块代表陷阱，黄色的方块代表宝藏，我们的目标就是让寻宝人找到最终的宝藏。 这里，我们的状态可以用横纵坐标表示，而动作有上下左右四个动作。使用tkinter来做这样一个动画效果。宝藏的奖励是1，陷阱的奖励是-1，而其他时候的奖励都为0。 接下来，我们重点看一下我们DQN相关的代码。 定义相关输入 这了，我们用s代表当前状态，用a代表当前状态下采取的动作，r代表获得的奖励，s_代表转移后的状态。 1234self.s = tf.placeholder(tf.float32,[None,self.n_features],name='s')self.s_ = tf.placeholder(tf.float32,[None,self.n_features],name='s_')self.r = tf.placeholder(tf.float32,[None,],name='r')self.a = tf.placeholder(tf.int32,[None,],name='a') 经验池 12345678def store_transition(self,s,a,r,s_): if not hasattr(self, 'memory_counter'): self.memory_counter = 0 # hstack:Stack arrays in sequence horizontally transition = np.hstack((s,[a,r],s_)) index = self.memory_counter % self.memory_size self.memory[index,:] = transition self.memory_counter += 1 双网络结构 target_net和eval_net的网络结构必须保持一致，这里我们使用的是两层全链接的神经网络，值得注意的一点是对于eval_net来说，网络的输入是当前的状态s，而对target_net网络来说，网络的输入是下一个状态s_，因为target_net的输出要根据贝尔曼公式计算q-target值，即 代码如下： 123456789101112131415161718w_initializer, b_initializer = tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1)# ------------------ build evaluate_net ------------------with tf.variable_scope('eval_net'): e1 = tf.layers.dense(self.s,20,tf.nn.relu,kernel_initializer=w_initializer, bias_initializer=b_initializer,name='e1' ) self.q_eval = tf.layers.dense(e1,self.n_actions,kernel_initializer=w_initializer, bias_initializer=b_initializer,name='q')# ------------------ build target_net ------------------with tf.variable_scope('target_net'): t1 = tf.layers.dense(self.s_, 20, tf.nn.relu, kernel_initializer=w_initializer, bias_initializer=b_initializer, name='t1') self.q_next = tf.layers.dense(t1, self.n_actions, kernel_initializer=w_initializer, bias_initializer=b_initializer, name='t2') 每隔一定的步数，我们就要将target_net中的参数复制到eval_net中： 12345t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope='target_net')e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope='eval_net')with tf.variable_scope('soft_replacement'): self.target_replace_op = [tf.assign(t,e) for t,e in zip(t_params,e_params)] 计算损失并优化 首先，对于eval_net来说，我们只要得到当前的网络输出即可，但是我们定义的网络输出是四个动作对应的q-eval值，我们要根据实际的a来选择对应的q-eval值，这一部分的代码如下： 123456789101112131415with tf.variable_scope('q_eval'): # tf.stack #a = tf.constant([1,2,3]) # b = tf.constant([4,5,6]) # c = tf.stack([a,b],axis=1) # [[1 4] # [2 5] # [3 6]] a_indices = tf.stack([tf.range(tf.shape(self.a)[0], dtype=tf.int32), self.a], axis=1) # 用indices从张量params得到新张量 # indices = [[0, 0], [1, 1]] # params = [['a', 'b'], ['c', 'd']] # output = ['a', 'd'] # 这里self.q_eval是batch * action_number,a_indices是batch * 1，也就是说选择当前估计每个动作的Q值 self.q_eval_wrt_a = tf.gather_nd(params=self.q_eval, indices=a_indices) 中间有几个函数不太了解的，上面都有详细的注释，如果还不是很理解的话，大家可以百度或者阅读相应函数的源码。 对于target_net网络来说，我们要根据下面的式子来计算q-target值： 第一部分的R我们是已经得到了的，剩下的就是根据贪心策略选择四个输出中最大的一个即可： 1234with tf.variable_scope('q_target'): q_target = self.r + self.gamma * tf.reduce_max(self.q_next,axis=1,name='Qmax_s_') # 一个节点被 stop之后，这个节点上的梯度，就无法再向前BP了 self.q_target = tf.stop_gradient(q_target) 接下来，我们就可以定义我们的损失函数并选择优化器进行优化： 12345with tf.variable_scope('loss'): self.loss = tf.reduce_mean(tf.squared_difference(self.q_target,self.q_eval_wrt_a,name='TD_error'))with tf.variable_scope('train'): self._train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss) 网络的训练 每隔一定的步数，我们就要将eval_net中的参数复制到target_net中，同时我们要从经验池中选择batch大小的数据输入到网络中进行训练。 123456789101112131415161718192021def learn(self): if self.learn_step_counter % self.replace_target_iter == 0: self.sess.run(self.target_replace_op) print('\ntarget_params_replaced\n') if self.memory_counter &gt; self.memory_size: sample_index = np.random.choice(self.memory_size,size=self.batch_size) else: sample_index = np.random.choice(self.memory_counter,size = self.batch_size) batch_memory = self.memory[sample_index,:] _,cost = self.sess.run( [self._train_op,self.loss], feed_dict=&#123; self.s:batch_memory[:,:self.n_features], self.a:batch_memory[:,self.n_features], self.r:batch_memory[:,self.n_features+1], self.s_:batch_memory[:,-self.n_features:] &#125; ) 剩下的代码就不介绍啦，跟着进行练习，相信会对DQN的原理有一个更进一步的认识。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DQN三大改进(二)-Prioritised replay]]></title>
    <url>%2F2018%2F03%2F19%2FDQN%E4%B8%89%E5%A4%A7%E6%94%B9%E8%BF%9B(%E4%BA%8C)-Prioritised%20replay%2F</url>
    <content type="text"><![CDATA[DQN三大改进(二)-Prioritised replay1、背景我们简单回顾一下DQN的过程(这里是2015版的DQN)： DQN中有两个关键的技术，叫做经验回放和双网络结构。 DQN中的损失函数定义为： 其中，yi也被我们称为q-target值，而后面的Q(s,a)我们称为q-eval值，我们希望q-target和q-eval值越接近越好。 q-target如何计算呢？根据下面的公式： 上面的两个公式分别截取自两篇不同的文章，所以可能有些出入。我们之前说到过，我们有经验池存储的历史经验，经验池中每一条的结构是(s,a,r,s’)，我们的q-target值根据该轮的奖励r以及将s’输入到target-net网络中得到的Q(s’,a’)的最大值决定。 经验回放的功能主要是解决相关性及非静态分布问题。具体做法是把每个时间步agent与环境交互得到的转移样本 (st,at,rt,st+1) 储存到回放记忆单元，要训练时就随机拿出一些（minibatch）来训练。（其实就是将游戏的过程打成碎片存储，训练时随机抽取就避免了相关性问题） 但是经验回放也存在一定的问题，在奖励十分少的时候，会出现学习速度非常慢的问题。在新的文章中，提出了一种“Blind Cliffwalk”的环境。来示例说明当奖赏非常rare的时候，探索所遇到的挑战。假设仅有 n 个状态，这个环境就要求足够的随机步骤知道得到第一个非零奖励；确切的讲，随机的选择动作序列就会有 2−n的概率才能得到第一个非零奖赏。此外，最相关的 transitions 却藏在大量的失败的尝试当中。“Blind Cliffwalk”环境如下图所示： 为了有效的解决上述的问题，提出了Prioritized replay的做法，我们先看看文中给出的算法流程： 这一套算法重点就在我们 batch 抽样的时候并不是随机抽样, 而是按照 Memory 中的样本优先级来抽. 所以这能更有效地找到我们需要学习的样本. 样本的优先级如何确定？我们可以用到 TD-error, 也就是 q-target - q-eval 来规定优先学习的程度. 如果 TD-error 越大, 就代表我们的预测精度还有很多上升空间, 那么这个样本就越需要被学习, 也就是优先级 p 越高. 优先级的计算基于如下公式： 式中的pi即我们计算的TD-error。 有了 TD-error 就有了优先级 p, 那我们如何有效地根据 p 来抽样呢? 如果每次抽样都需要针对 p 对所有样本排序, 这将会是一件非常消耗计算能力的事. 文中提出了一种被称作SumTree的方法。 SumTree 是一种树形结构, 每片树叶存储每个样本的优先级 p, 每个树枝节点只有两个分叉, 节点的值是两个分叉的合, 所以 SumTree 的顶端就是所有 p 的合. 如下图所示。最下面一层树叶存储样本的 p, 叶子上一层最左边的 13 = 3 + 10, 按这个规律相加, 顶层的 root 就是全部 p 的合了. 抽样时, 我们会将 p 的总合 除以 batch size, 分成 batch size 那么多区间, (n=sum(p)/batch_size). 如果将所有 node 的 priority 加起来是42的话, 我们如果抽6个样本, 这时的区间拥有的 priority 可能是这样. [0-7], [7-14], [14-21], [21-28], [28-35], [35-42] 然后在每个区间里随机选取一个数. 比如在第区间 [21-28] 里选到了24, 就按照这个 24 从最顶上的42开始向下搜索. 首先看到最顶上 42 下面有两个 child nodes, 拿着手中的24对比左边的 child 29, 如果 左边的 child 比自己手中的值大, 那我们就走左边这条路, 接着再对比 29 下面的左边那个点 13, 这时, 手中的 24 比 13 大, 那我们就走右边的路, 并且将手中的值根据 13 修改一下, 变成 24-13 = 11. 接着拿着 11 和 13 左下角的 12 比, 结果 12 比 11 大, 那我们就选 12 当做这次选到的 priority, 并且也选择 12 对应的数据. 2、代码实现 其中，红色的方块代表寻宝人，黑色的方块代表陷阱，黄色的方块代表宝藏，我们的目标就是让寻宝人找到最终的宝藏。 这里，我们的状态可以用横纵坐标表示，而动作有上下左右四个动作。使用tkinter来做这样一个动画效果。宝藏的奖励是1，陷阱的奖励是-1，而其他时候的奖励都为0。 接下来，我们重点看一下我们Prioritised replay Double-DQN相关的代码。 定义输入 在通过梯度下降法进行参数更新时，由于需要加入权重项，因此增加了ISWeigths这一个输入。 1234567#---------------------input----------------------self.s = tf.placeholder(tf.float32,[None,self.n_features],name='s')self.q_target = tf.placeholder(tf.float32,[None,self.n_actions],name='Q_target')self.s_ = tf.placeholder(tf.float32, [None, self.n_features], name='s_')if self.prioritized: self.ISWeights = tf.placeholder(tf.float32,[None,1],name='IS_weights') 定义双网络结构这里我们的双网络结构都简单的采用简单的全链接神经网络，包含一个隐藏层。这里我们得到的输出是一个向量，表示该状态才取每个动作可以获得的Q值： 1234567891011def build_layers(s, c_names, n_l1, w_initializer, b_initializer, trainable): with tf.variable_scope('l1'): w1 = tf.get_variable('w1', [self.n_features, n_l1], initializer=w_initializer, collections=c_names, trainable=trainable) b1 = tf.get_variable('b1', [1, n_l1], initializer=b_initializer, collections=c_names, trainable=trainable) l1 = tf.nn.relu(tf.matmul(s, w1) + b1) with tf.variable_scope('l2'): w2 = tf.get_variable('w2', [n_l1, self.n_actions], initializer=w_initializer, collections=c_names, trainable=trainable) b2 = tf.get_variable('b2', [1, self.n_actions], initializer=b_initializer, collections=c_names, trainable=trainable) out = tf.matmul(l1, w2) + b2 return out 接下来，我们定义两个网络： 123456789101112# ---------------------eval net -----------------with tf.variable_scope('eval_net'): c_names, n_l1, w_initializer, b_initializer = \ ['eval_net_params', tf.GraphKeys.GLOBAL_VARIABLES], 20, \ tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1) # config of layers self.q_eval = build_layers(self.s, c_names, n_l1, w_initializer, b_initializer, True)# --------------------target net----------------with tf.variable_scope('target_net'): c_names = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES] self.q_next = build_layers(self.s_, c_names, n_l1, w_initializer, b_initializer, False) 定义损失和优化器接下来，我们定义我们的损失，和DQN一样，我们使用的是平方损失，但是此时我们的损失是有权重的！： 123456789# --------------------loss and train -----------with tf.variable_scope('loss'): if self.prioritized: self.abs_errors = tf.reduce_sum(tf.abs(self.q_target - self.q_eval), axis=1) # for updating Sumtree self.loss = tf.reduce_mean(self.ISWeights * tf.squared_difference(self.q_target, self.q_eval)) else: self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval))with tf.variable_scope('train'): self._train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss) 定义SumTree类定义完我们的网络结构之后，我们介绍两个辅助类，一个是用于Sample的SumTree类，另一个是用于记忆存储和读取的Memory类。 在初始化我们的SumTree类时，我们要定义好树的容量，即经验池的容量，以及用于存储优先级的tree结构和存储数据的data。tree结构我们使用一维数组实现，采取从上往下，从左往右的层次结构进行存储,同时，我们定义一个返回树根节点也就是树中叶子结点总优先级的函数。 123456789def __init__(self,capacity): self.capacity = capacity self.data_pointer = 0 self.tree = np.zeros(2 * capacity - 1) self.data = np.zeros(capacity,dtype=object)@propertydef total_p(self): return self.tree[0] # the root 接下来，我们定义一个用于添加数据的add函数，在添加数据的时候会触发我们的update函数，用于更新树中节点的值。 12345678def add(self,p,data): tree_idx = self.data_pointer + self.capacity - 1 self.data[self.data_pointer] = data self.update(tree_idx,p) self.data_pointer += 1 if self.data_pointer &gt;= self.capacity: # replace when exceed the capacity self.data_pointer = 0 刚才提到了，在添加数据的时候，由于某个叶子结点的数值改变了，那么它的一系列父节点的数值也会发生改变，所以我们定义了一个update函数如下： 1234567def update(self,tree_idx,p): change = p - self.tree[tree_idx] self.tree[tree_idx] = p while tree_idx!=0: tree_idx = (tree_idx - 1) // 2 self.tree[tree_idx] += change 最后，我们要定义一个根据数字来采样节点的算法，如何采样我们刚才已经介绍过了，即从头节点开始，每次决定往左还是往右，直到到达叶子结点为止，并返回叶子结点的id，优先级以对应的转移数据： 12345678910111213141516def get_leaf(self,v): parent_idx = 0 while True: cl_idx = 2 * parent_idx + 1 cr_idx = cl_idx + 1 if cl_idx &gt;= len(self.tree): leaf_idx = parent_idx break else: if v &lt;= self.tree[cl_idx]: parent_idx = cl_idx else: v -= self.tree[cl_idx] parent_idx = cr_idx data_idx = leaf_idx - self.capacity + 1 return leaf_idx,self.tree[leaf_idx],self.data[data_idx] 定义Memory类在初始化时，我们首先要定义好我们的参数： 1234567def __init__(self, capacity): self.tree = SumTree(capacity) self.epsilon = 0.01 # small amount to avoid zero priority self.alpha = 0.6 # [0~1] convert the importance of TD error to priority self.beta = 0.4 # importance-sampling, from initial value increasing to 1 self.beta_increment_per_sampling = 0.001 self.abs_err_upper = 1. # clipped abs error 接下来，我们定义一个store函数，用于将新的经验数据存储到Sumtree中，我们定义了一个abs_err_upper和epsilon ，表明p的范围在[epsilon,abs_err_upper]之间，对于第一条存储的数据，我们认为它的优先级P是最大的，同时，对于新来的数据，我们也认为它的优先级与当前树中优先级最大的经验相同。 12345def store(self, transition): max_p = np.max(self.tree.tree[-self.tree.capacity:]) if max_p == 0: max_p = self.abs_err_upper self.tree.add(max_p, transition) # set the max p for new p 随后，我们定义了一个采样函数,根据batch的大小对经验进行采样，采样的过程如我们上面所讲的，调用的是tree.get_leaf方法。同时在采样的过程中，我们还要计算在进行参数更新时每条数据的权重，代码之中权重的计算是对原文中的公式进行了修改，如下图所示： 因此，我们的代码如下所示： 1234567891011121314151617def sample(self,n): b_idx,b_memory,ISWeights = np.empty((n,),dtype=np.int32),np.empty((n,self.tree.data[0].size)),np.empty((n,1)) pri_seg = self.tree.total_p / n self.beta = np.min([1., self.beta + self.beta_increment_per_sampling]) min_prob = np.min(self.tree.tree[-self.tree.capacity:]) / self.tree.total_p # for later calculate ISweight for i in range(n): a, b = pri_seg * i, pri_seg * (i + 1) v = np.random.uniform(a, b) idx, p, data = self.tree.get_leaf(v) prob = p / self.tree.total_p ISWeights[i, 0] = np.power(prob/min_prob, -self.beta) b_idx[i], b_memory[i, :] = idx, data return b_idx, b_memory, ISWeights 最后，我们还定义了一个更新树中权重的方法： 123456def batch_update(self, tree_idx, abs_errors): abs_errors += self.epsilon # convert to abs and avoid 0 clipped_errors = np.minimum(abs_errors, self.abs_err_upper) ps = np.power(clipped_errors, self.alpha) for ti, p in zip(tree_idx, ps): self.tree.update(ti, p) 选择action选择action的代码没有变化，仍然采用e-greedy算法 12345678def choose_action(self, observation): observation = observation[np.newaxis, :] if np.random.uniform() &lt; self.epsilon: actions_value = self.sess.run(self.q_eval, feed_dict=&#123;self.s: observation&#125;) action = np.argmax(actions_value) else: action = np.random.randint(0, self.n_actions) return action 存储经验由于我们定义了专门的Memory类，因此在存储经验的时候，直接调用该类的store方法即可。 123456789101112def store(self,s,a,r,s_): if self.prioritized: transition = np.hstack((s, [a, r], s_)) self.memory.store(transition) else: # random replay if not hasattr(self, 'memory_counter'): self.memory_counter = 0 transition = np.hstack((s, [a, r], s_)) index = self.memory_counter % self.memory_size self.memory[index, :] = transition self.memory_counter += 1 更新target-net 12345678t_params = tf.get_collection('target_net_params')e_params = tf.get_collection('eval_net_params')self.replace_target_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)]if self.learn_step_counter % self.replace_target_iter == 0: self.sess.run(self.replace_target_op) print('\ntarget_params_replaced\n') 选择batch 12345if self.prioritized: tree_idx, batch_memory, ISWeights = self.memory.sample(self.batch_size)else: sample_index = np.random.choice(self.memory_size, size=self.batch_size) batch_memory = self.memory[sample_index, :] 更新网络参数这里我们采用double-dqn的网络参数更新方法，这里有三点更新，首先，我们在训练的时候要同时计算我们的td-error，其次，每次训练之后，要根据td-error对树进行更新，最后，在计算误差的时候要考虑权重项。 12345678910111213141516171819202122232425262728q_next, q_eval = self.sess.run( [self.q_next, self.q_eval], feed_dict=&#123;self.s_: batch_memory[:, -self.n_features:], self.s: batch_memory[:, :self.n_features]&#125;)q_target = q_eval.copy()batch_index = np.arange(self.batch_size, dtype=np.int32)eval_act_index = batch_memory[:, self.n_features].astype(int)reward = batch_memory[:, self.n_features + 1]q_target[batch_index, eval_act_index] = reward + self.gamma * np.max(q_next, axis=1)if self.prioritized: _, abs_errors, self.cost = self.sess.run([self._train_op, self.abs_errors, self.loss], feed_dict=&#123;self.s: batch_memory[:, :self.n_features], self.q_target: q_target, self.ISWeights: ISWeights&#125;) self.memory.batch_update(tree_idx, abs_errors) # update priorityelse: _, self.cost = self.sess.run([self._train_op, self.loss], feed_dict=&#123;self.s: batch_memory[:, :self.n_features], self.q_target: q_target&#125;)self.cost_his.append(self.cost)self.epsilon = self.epsilon + self.epsilon_increment if self.epsilon &lt; self.epsilon_max else self.epsilon_maxself.learn_step_counter += 1]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[后端架构选型、离线及实时计算]]></title>
    <url>%2F2018%2F03%2F16%2F%E7%AC%AC%E5%8D%81%E5%85%AB%E7%AB%A0_%E5%90%8E%E7%AB%AF%E6%9E%B6%E6%9E%84%E9%80%89%E5%9E%8B%E3%80%81%E7%A6%BB%E7%BA%BF%E5%8F%8A%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%2F</url>
    <content type="text"><![CDATA[Markdown Revision 1; Date: 2018/11/11 Editor: 梁志成 Contact: superzhicheng@foxmail.com 18.1 为什么需要分布式计算？&emsp;&emsp;在这个数据爆炸的时代，产生的数据量不断地在攀升，从GB,TB,PB,ZB.挖掘其中数据的价值也是企业在不断地追求的终极目标。但是要想对海量的数据进行挖掘，首先要考虑的就是海量数据的存储问题，比如Tb量级的数据。 &emsp;&emsp;谈到数据的存储，则不得不说的是磁盘的数据读写速度问题。早在上个世纪90年代初期，普通硬盘的可以存储的容量大概是1G左右，硬盘的读取速度大概为4.4MB/s.读取一张硬盘大概需要5分钟时间，但是如今硬盘的容量都在1TB左右了,相比扩展了近千倍。但是硬盘的读取速度大概是100MB/s。读完一个硬盘所需要的时间大概是2.5个小时。所以如果是基于TB级别的数据进行分析的话，光硬盘读取完数据都要好几天了，更谈不上计算分析了。那么该如何处理大数据的存储，计算分析呢？ &emsp;&emsp;一个很简单的减少数据读写时间的方法就是同时从多个硬盘上读写数据，比如，如果我们有100个硬盘，每个硬盘存储1%的数据 ，并行读取，那么不到两分钟就可以完成之前需要2.5小时的数据读写任务了。这就是大数据中的分布式存储的模型。当然实现分布式存储还需要解决很多问题，比如硬件故障的问题，使用多台主机进行分布式存储时，若主机故障，会出现数据丢失的问题，所以有了副本机制：系统中保存数据的副本。一旦有系统发生故障，就可以使用另外的副本进行替换（著名的RAID冗余磁盘阵列就是按这个原理实现的）。其次比如一个很大的文件如何进行拆分存储，读取拆分以后的文件如何进行校验都是要考虑的问题。比如我们使用Hadoop中的HDFS也面临这个问题，只是框架给我们实现了这些问题的解决办法，开发中开发者不用考虑这些问题，底层框架已经实现了封装。 &emsp;&emsp;同样假如有一个10TB的文件，我们要统计其中某个关键字的出现次数，传统的做法是遍历整个文件，然后统计出关键字的出现次数，这样效率会特别特别低。基于分布式存储以后，数据被分布式存储在不同的服务器上，那么我们就可以使用分布式计算框架（比如MapReduce,Spark等）来进行并行计算（或者说是分布式计算），即：每个服务器上分别统计自己存储的数据中关键字出现的次数，最后进行一次汇总，那么假如数据分布在100台服务器上，即同时100台服务器同时进行关键字统计工作，效率一下子可以提高几十倍。 18.2 目前有哪些深度学习分布式计算框架？18.2.1 PaddlePaddle&emsp;&emsp;PaddlePaddle【1】是百度开源的一个深度学习平台。PaddlePaddle为深度学习研究人员提供了丰富的API，可以轻松地完成神经网络配置，模型训练等任务。官方文档中简易介绍了如何使用框架在 线性回归 识别数字 图像分类 词向量 个性化推荐 情感分析 语义角色标注 机器翻译 等方面的应用 &emsp;&emsp;Github地址：https://github.com/PaddlePaddle/Paddle 18.2.2 Deeplearning4j&emsp;&emsp;DeepLearning4J（DL4J）【2】是一套基于Java语言的神经网络工具包，可以构建、定型和部署神经网络。DL4J与Hadoop和Spark集成，支持分布式CPU和GPU。 &emsp;&emsp;Deeplearning4j包括了分布式、多线程的深度学习框架，以及普通的单线程深度学习框架。定型过程以集群进行，也就是说，Deeplearning4j可以快速处理大量数据。Deeplearning4j在开放堆栈中作为模块组件的功能，使之成为为微服务架构打造的深度学习框架。 &emsp;&emsp;Deeplearning4j从各类浅层网络出发，设计深层神经网络。这一灵活性使用户可以根据所需，在分布式、生产级、能够在分布式CPU或GPU的基础上与Spark和Hadoop协同工作的框架内，整合受限玻尔兹曼机、其他自动编码器、卷积网络或递归网络。 &emsp;&emsp;Deeplearning4j在已建立的各个库及其在系统整体中的所处位置 &emsp;&emsp;Github地址：https://github.com/deeplearning4j/deeplearning4j 18.2.3 Mahout&emsp;&emsp;Mahout【3】是基于Hadoop的机器学习和数据挖掘的一个分布式框架。Mahout用MapReduce实现了部分数据挖掘算法，解决了并行挖掘的问题。 &emsp;&emsp;Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘等。 &emsp;&emsp;Mahout算法库： &emsp;&emsp;Mahout应用场景： &emsp;&emsp;Github地址：https://github.com/apache/mahout 18.2.4 Spark MLllib&emsp;&emsp;MLlib(Machine Learnig lib) 【4】是Spark对常用的机器学习算法的实现库，同时包括相关的测试和数据生成器。 &emsp;&emsp;MLlib是MLBase一部分，其中MLBase分为四部分：MLlib、MLI、ML Optimizer和MLRuntime。 ML Optimizer会选择它认为最适合的已经在内部实现好了的机器学习算法和相关参数，来处理用户输入的数据，并返回模型或别的帮助分析的结果； MLI 是一个进行特征抽取和高级ML编程抽象的算法实现的API或平台； MLlib是Spark实现一些常见的机器学习算法和实用程序，包括分类、回归、聚类、协同过滤、降维以及底层优化，该算法可以进行可扩充； MLRuntime 基于Spark计算框架，将Spark的分布式计算应用到机器学习领域。 &emsp;&emsp;MLlib主要包含三个部分： 底层基础：包括Spark的运行库、矩阵库和向量库 算法库：包含广义线性模型、推荐系统、聚类、决策树和评估的算法 实用程序：包括测试数据的生成、外部数据的读入等功能 架构图 &emsp;&emsp;MLlib目前支持4种常见的机器学习问题: 分类、回归、聚类和协同过滤，MLlib在Spark整个生态系统中的位置如图下图所示。 18.2.5 Ray&emsp;&emsp;Ray【5】是加州大学伯克利分校实时智能安全执行实验室(RISELab)的研究人员针对机器学习领域开发的一种新的分布式计算框架，该框架旨在让基于Python的机器学习和深度学习工作负载能够实时执行，并具有类似消息传递接口(MPI)的性能和细粒度。 &emsp;&emsp;增强学习的场景，按照原理定义，因为没有预先可用的静态标签信息，所以通常需要引入实际的目标系统（为了加快训练，往往是目标系统的模拟环境）来获取反馈信息，用做损失/收益判断，进而完成整个训练过程的闭环反馈。典型的步骤是通过观察特定目标系统的状态，收集反馈信息，判断收益，用这些信息来调整参数，训练模型，并根据新的训练结果产出可用于调整目标系统的行为Action，输出到目标系统，进而影响目标系统状态变化，完成闭环，如此反复迭代，最终目标是追求某种收益的最大化（比如对AlphoGo来说，收益是赢得一盘围棋的比赛）。 &emsp;&emsp;在这个过程中，一方面，模拟目标系统，收集状态和反馈信息，判断收益，训练参数，生成Action等等行为可能涉及大量的任务和计算（为了选择最佳Action，可能要并发模拟众多可能的行为）。而这些行为本身可能也是千差万别的异构的任务，任务执行的时间也可能长短不一，执行过程有些可能要求同步，也有些可能更适合异步。 &emsp;&emsp;另一方面，整个任务流程的DAG图也可能是动态变化的，系统往往可能需要根据前一个环节的结果，调整下一个环节的行为参数或者流程。这种调整，可能是目标系统的需要（比如在自动驾驶过程中遇到行人了，那么我们可能需要模拟计算刹车的距离来判断该采取的行动是刹车还是拐弯，而平时可能不需要这个环节），也可能是增强学习特定训练算法的需要（比如根据多个并行训练的模型的当前收益，调整模型超参数，替换模型等等）。 &emsp;&emsp;此外，由于所涉及到的目标系统可能是具体的，现实物理世界中的系统，所以对时效性也可能是有强要求的。举个例子，比如你想要实现的系统是用来控制机器人行走，或者是用来打视频游戏的。那么整个闭环反馈流程就需要在特定的时间限制内完成（比如毫秒级别）。 &emsp;&emsp;总结来说，就是增强学习的场景，对分布式计算框架的任务调度延迟，吞吐量和动态修改DAG图的能力都可能有很高的要求。按照官方的设计目标，Ray需要支持异构计算任务，动态计算链路，毫秒级别延迟和每秒调度百万级别任务的能力。 &emsp;&emsp;Ray的目标问题，主要是在类似增强学习这样的场景中所遇到的工程问题。那么增强学习的场景和普通的机器学习，深度学习的场景又有什么不同呢？简单来说，就是对整个处理链路流程的时效性和灵活性有更高的要求。 Ray框架优点 海量任务调度能力 毫秒级别的延迟 异构任务的支持 任务拓扑图动态修改的能力 &emsp;&emsp;Ray没有采用中心任务调度的方案，而是采用了类似层级（hierarchy）调度的方案，除了一个全局的中心调度服务节点（实际上这个中心调度节点也是可以水平拓展的），任务的调度也可以在具体的执行任务的工作节点上，由本地调度服务来管理和执行。与传统的层级调度方案，至上而下分配调度任务的方式不同的是，Ray采用了至下而上的调度策略。也就是说，任务调度的发起，并不是先提交给全局的中心调度器统筹规划以后再分发给次级调度器的。而是由任务执行节点直接提交给本地的调度器，本地的调度器如果能满足该任务的调度需求就直接完成调度请求，在无法满足的情况下，才会提交给全局调度器，由全局调度器协调转发给有能力满足需求的另外一个节点上的本地调度器去调度执行。 &emsp;&emsp;架构设计一方面减少了跨节点的RPC开销，另一方面也能规避中心节点的瓶颈问题。当然缺点也不是没有，由于缺乏全局的任务视图，无法进行全局规划，因此任务的拓扑逻辑结构也就未必是最优的了。 架构图 任务调度图 &emsp;&emsp;Ray架构现状： API层以上 的部分还比较薄弱，Core模块核心逻辑估需要时间打磨。 国内目前除了蚂蚁金服和RISELab有针对性的合作以外，关注程度还很低，没有实际的应用实例看到，整体来说还处于比较早期的框架构建阶段。 &emsp;&emsp;Github地址：https://github.com/ray-project/ray 18.2.6 Spark stream&emsp;&emsp;随着大数据的发展，人们对大数据的处理要求也越来越高，原有的批处理框架MapReduce适合离线计算，却无法满足实时性要求较高的业务，如实时推荐、用户行为分析等。 Spark Streaming是建立在Spark上的实时计算框架，通过它提供的丰富的API、基于内存的高速执行引擎，用户可以结合流式、批处理和交互试查询应用。 &emsp;&emsp;Spark是一个类似于MapReduce的分布式计算框架，其核心是弹性分布式数据集，提供了比MapReduce更丰富的模型，可以在快速在内存中对数据集进行多次迭代，以支持复杂的数据挖掘算法和图形计算算法。Spark Streaming【6】是一种构建在Spark上的实时计算框架，它扩展了Spark处理大规模流式数据的能力。 &emsp;&emsp;Spark Streaming的优势在于： 能运行在100+的结点上，并达到秒级延迟。 使用基于内存的Spark作为执行引擎，具有高效和容错的特性。 能集成Spark的批处理和交互查询。 为实现复杂的算法提供和批处理类似的简单接口。 Spark Streaming架构图 &emsp;&emsp;Spark Streaming把实时输入数据流以时间片Δt （如1秒）为单位切分成块。Spark Streaming会把每块数据作为一个RDD，并使用RDD操作处理每一小块数据。每个块都会生成一个Spark Job处理，最终结果也返回多块。 Spark Streaming基本原理图 &emsp;&emsp;正如Spark Streaming最初的目标一样，它通过丰富的API和基于内存的高速计算引擎让用户可以结合流式处理，批处理和交互查询等应用。因此Spark Streaming适合一些需要历史数据和实时数据结合分析的应用场合。当然，对于实时性要求不是特别高的应用也能完全胜任。另外通过RDD的数据重用机制可以得到更高效的容错处理。 18.2.7 Horovod&emsp;&emsp;Horovod【7】 是 Uber 开源的又一个深度学习工具，它的发展吸取了 Facebook「一小时训练 ImageNet 论文」与百度 Ring Allreduce 的优点，可为用户实现分布式训练提供帮助。 &emsp;&emsp;Horovod 支持通过用于高性能并行计算的低层次接口 – 消息传递接口 (MPI) 进行分布式模型训练。有了 MPI，就可以利用分布式 Kubernetes 集群来训练 TensorFlow 和 PyTorch 模型。 &emsp;&emsp;分布式 TensorFlow 的参数服务器模型（parameter server paradigm）通常需要对大量样板代码进行认真的实现。但是 Horovod 仅需要几行。下面是一个分布式 TensorFlow 项目使用 Horovod 的示例：1234567891011121314151617181920212223242526import tensorflow as tfimport horovod.tensorflow as hvd# Initialize Horovodhvd.init()# Pin GPU to be used to process local rank (one GPU per process)config = tf.ConfigProto()config.gpu_options.visible_device_list = str(hvd.local_rank())# Build model…loss = …opt = tf.train.AdagradOptimizer(0.01)# Add Horovod Distributed Optimizeropt = hvd.DistributedOptimizer(opt)# Add hook to broadcast variables from rank 0 to all other processes during# initialization.hooks = [hvd.BroadcastGlobalVariablesHook(0)]# Make training operationtrain_op = opt.minimize(loss)# The MonitoredTrainingSession takes care of session initialization,# restoring from a checkpoint, saving to a checkpoint, and closing when done# or an error occurs.with tf.train.MonitoredTrainingSession(checkpoint_dir=“/tmp/train_logs”, config=config, hooks=hooks) as mon_sess: while not mon_sess.should_stop(): # Perform synchronous training. mon_sess.run(train_op) &emsp;&emsp;在该示例中，粗体文字指进行单个 GPU 分布式项目时必须做的改变： hvd.init() 初始化 Horovod。 config.gpu_options.visible_device_list = str(hvd.local_rank()) 向每个 TensorFlow 流程分配一个 GPU。 opt=hvd.DistributedOptimizer(opt) 使用 Horovod 优化器包裹每一个常规 TensorFlow 优化器，Horovod 优化器使用 ring-allreduce 平均梯度。 hvd.BroadcastGlobalVariablesHook(0) 将变量从第一个流程向其他流程传播，以实现一致性初始化。如果该项目无法使用 MonitoredTrainingSession，则用户可以运行 hvd.broadcast_global_variables(0)。 &emsp;&emsp;之后，可以使用 mpirun 命令使该项目的多个拷贝在多个服务器中运行： 12$ mpirun -np 16 -x LD_LIBRARY_PATH -H server1:4,server2:4,server3:4,server4:4 python train.py &emsp;&emsp;mpirun 命令向四个节点分布 train.py，然后在每个节点的四个 GPU 上运行 train.py。 &emsp;&emsp;Github地址：https://github.com/uber/horovod 18.2.8 BigDL&emsp;&emsp;BigDL【9】是一种基于Apache Spark的分布式深度学习框架。它可以无缝的直接运行在现有的Apache Spark和Hadoop集群之上。BigDL的设计吸取了Torch框架许多方面的知识，为深度学习提供了全面的支持；包括数值计算和高级神经网络；借助现有的Spark集群来运行深度学习计算，并简化存储在Hadoop中的大数据集的数据加载。 &emsp;&emsp;BigDL优点： 丰富的深度学习支持。模拟Torch之后，BigDL为深入学习提供全面支持，包括数字计算（通过Tensor）和高级神经网络 ; 此外，用户可以使用BigDL将预先训练好的Caffe或Torch模型加载到Spark程序中。 极高的性能。为了实现高性能，BigDL在每个Spark任务中使用英特尔MKL和多线程编程。因此，在单节点Xeon（即与主流GPU 相当）上，它比开箱即用开源Caffe，Torch或TensorFlow快了数量级。 有效地横向扩展。BigDL可以通过利用Apache Spark（快速分布式数据处理框架），以及高效实施同步SGD和全面减少Spark的通信，从而有效地扩展到“大数据规模”上的数据分析 &emsp;&emsp;BigDL缺点： 对机器要求高 jdk7上运行性能差 在CentOS 6和7上，要将最大用户进程增加到更大的值（例如514585）; 否则，可能会看到错误，如“无法创建新的本机线程”。 训练和验证的数据会加载到内存，挤占内存 &emsp;&emsp;BigDL满足的应用场景： 直接在Hadoop/Spark框架下使用深度学习进行大数据分析（即将数据存储在HDFS、HBase、Hive等数据库上）； 在Spark程序中/工作流中加入深度学习功能； 利用现有的 Hadoop/Spark 集群来运行深度学习程序，然后将代码与其他的应用场景进行动态共享，例如ETL（Extract、Transform、Load，即通常所说的数据抽取）、数据仓库（data warehouse）、功能引擎、经典机器学习、图表分析等。 18.2.9 Petastorm&emsp;&emsp;Petastorm是一个由 Uber ATG 开发的开源数据访问库。这个库可以直接基于数 TB Parquet 格式的数据集进行单机或分布式训练和深度学习模型评估。Petastorm 支持基于 Python 的机器学习框架，如 Tensorflow、Pytorch 和 PySpark，也可以直接用在 Python 代码中。 深度学习集群 &emsp;&emsp;即使是在现代硬件上训练深度模型也很耗时，而且在很多情况下，很有必要在多台机器上分配训练负载。典型的深度学习集群需要执行以下几个步骤： 一台或多台机器读取集中式或本地数据集。 每台机器计算损失函数的值，并根据模型参数计算梯度。在这一步通常会使用 GPU。 通过组合估计的梯度（通常由多台机器以分布式的方式计算得出）来更新模型系数。 &emsp;&emsp;通常，一个数据集是通过连接多个数据源的记录而生成的。这个由 Apache Spark 的 Python 接口 PySpark 生成的数据集稍后将被用在机器学习训练中。Petastorm 提供了一个简单的功能，使用 Petastorm 特定的元数据对标准的 Parquet 进行了扩展，从而让它可以与 Petastorm 兼容。有了 Petastorm，消费数据就像在 HDFS 或文件系统中创建和迭代读取对象一样简单。Petastorm 使用 PyArrow 来读取 Parquet 文件。 &emsp;&emsp;将多个数据源组合到单个表格结构中，从而生成数据集。可以多次使用相同的数据集进行模型训练和评估。 深度学习集群 &emsp;&emsp;为分布式训练进行分片在分布式训练环境中，每个进程通常负责训练数据的一个子集。一个进程的数据子集与其他进程的数据子集正交。Petastorm 支持将数据集的读时分片转换为正交的样本集。 Petastorm 将数据集的非重叠子集提供给参与分布式训练的不同机器 &emsp;&emsp;本地缓存Petastorm 支持在本地存储中缓存数据。当网络连接速度较慢或带宽很昂贵时，这会派上用场。 Github地址：https://github.com/uber/petastorm 18.2.10 TensorFlowOnSpark&emsp;&emsp;TensorFlowOnSpark【10】为 Apache Hadoop 和 Apache Spark 集群带来可扩展的深度学习。 通过结合深入学习框架 TensorFlow 和大数据框架 Apache Spark 、Apache Hadoop 的显着特征，TensorFlowOnSpark 能够在 GPU 和 CPU 服务器集群上实现分布式深度学习。 &emsp;&emsp;满足的应用场景：为了利用TensorFlow在现有的Spark和Hadoop集群上进行深度学习。而不需要为深度学习设置单独的集群。 架构图 运行流程图 &emsp;&emsp;优点： 轻松迁移所有现有的TensorFlow程序，&lt;10行代码更改; 支持所有TensorFlow功能：同步/异步训练，模型/数据并行，推理和TensorBoard; 服务器到服务器的直接通信在可用时实现更快的学习; 允许数据集在HDFS和由Spark推动的其他来源或由TensorFlow拖动; 轻松集成您现有的数据处理流水线和机器学习算法（例如，MLlib，CaffeOnSpark）; 轻松部署在云或内部部署：CPU和GPU，以太网和Infiniband。 TensorFlowOnSpark是基于google的TensorFlow的实现，而TensorFlow有着一套完善的教程，内容丰富。 &emsp;&emsp;劣势： 开源时间不长，未得到充分的验证。 &emsp;&emsp;Github 地址:https://github.com/yahoo/TensorFlowOnSpark 18.3 如何选择合适的分布式计算框架进行模型训练？18.4 如何进行实时计算？18.4.1 什么是实时流计算？&emsp;&emsp;所谓实时流计算，就是近几年由于数据得到广泛应用之后，在数据持久性建模不满足现状的情况下，急需数据流的瞬时建模或者计算处理。这种实时计算的应用实例有金融服务、网络监控、电信数据管理、 Web 应用、生产制造、传感检测，等等。在这种数据流模型中，单独的数据单元可能是相关的元组（Tuple），如网络测量、呼叫记录、网页访问等产生的数据。但是，这些数据以大量、快速、时变（可能是不可预知）的数据流持续到达，由此产生了一些基础性的新的研究问题——实时计算。实时计算的一个重要方向就是实时流计算。 18.4.2 实时流计算过程 &emsp;&emsp;我们以热卖产品的统计为例，看下传统的计算手段： 将用户行为、log等信息清洗后保存在数据库中. 将订单信息保存在数据库中. 利用触发器或者协程等方式建立本地索引，或者远程的独立索引. join订单信息、订单明细、用户信息、商品信息等等表，聚合统计20分钟内热卖产品，并返回top-10. web或app展示. &emsp;&emsp;这是一个假想的场景，但假设你具有处理类似场景的经验，应该会体会到这样一些问题和难处： 水平扩展问题（scale-out）显然，如果是一个具有一定规模的电子商务网站，数据量都是很大的。而交易信息因为涉及事务，所以很难直接舍弃关系型数据库的事务能力，迁移到具有更好的scale-out能力的NoSQL数据库中。 &emsp;&emsp;那么，一般都会做sharding。历史数据还好说，我们可以按日期来归档，并可以通过批处理式的离线计算，将结果缓存起来。但是，这里的要求是20分钟内，这很难。 性能问题这个问题，和scale-out是一致的，假设我们做了sharding，因为表分散在各个节点中，所以我们需要多次入库，并在业务层做聚合计算。 &emsp;&emsp;问题是，20分钟的时间要求，我们需要入库多少次呢？10分钟呢？5分钟呢？实时呢？ &emsp;&emsp;而且，业务层也同样面临着单点计算能力的局限，需要水平扩展，那么还需要考虑一致性的问题。所以，到这里一切都显得很复杂。 业务扩展问题 &emsp;&emsp;假设我们不仅仅要处理热卖商品的统计，还要统计广告点击、或者迅速根据用户的访问行为判断用户特征以调整其所见的信息，更加符合用户的潜在需求等，那么业务层将会更加复杂。也许你有更好的办法，但实际上，我们需要的是一种新的认知：这个世界发生的事，是实时的。所以我们需要一种实时计算的模型，而不是批处理模型。我们需要的这种模型，必须能够处理很大的数据，所以要有很好的scale-out能力，最好是，我们都不需要考虑太多一致性、复制的问题。 &emsp;&emsp;那么，这种计算模型就是实时计算模型，也可以认为是流式计算模型。现在假设我们有了这样的模型，我们就可以愉快地设计新的业务场景： 转发最多的微博是什么？ 最热卖的商品有哪些？ 大家都在搜索的热点是什么？ 我们哪个广告，在哪个位置，被点击最多？或者说，我们可以问：&emsp;&emsp;这个世界，在发生什么？ &emsp;&emsp;最热的微博话题是什么？我们以一个简单的滑动窗口计数的问题，来揭开所谓实时计算的神秘面纱。假设，我们的业务要求是：统计20分钟内最热的10个微博话题。 &emsp;&emsp;解决这个问题，我们需要考虑： 数据源 &emsp;&emsp;这里，假设我们的数据，来自微博长连接推送的话题。 问题建模 &emsp;&emsp;我们认为的话题是#号扩起来的话题，最热的话题是此话题出现的次数比其它话题都要多。比如：@foreach_break : 你好,#世界#,我爱你，#微博#。“世界”和“微博”就是话题。 计算引擎采用storm 定义时间 &emsp;&emsp;时间的定义是一件很难的事情，取决于所需的精度是多少。根据实际，我们一般采用tick来表示时刻这一概念。在storm的基础设施中，executor启动阶段，采用了定时器来触发“过了一段时间”这个事件。如下所示：12345678910111213141516171819(defn setup-ticks! [worker executor-data] (let [storm-conf (:storm-conf executor-data) tick-time-secs (storm-conf TOPOLOGY-TICK-TUPLE-FREQ-SECS) receive-queue (:receive-queue executor-data) context (:worker-context executor-data)] (when tick-time-secs (if (or (system-id? (:component-id executor-data)) (and (= false (storm-conf TOPOLOGY-ENABLE-MESSAGE-TIMEOUTS)) (= :spout (:type executor-data)))) (log-message &quot;Timeouts disabled for executor &quot; (:component-id executor-data) &quot;:&quot; (:executor-id executor-data)) (schedule-recurring (:user-timer worker) tick-time-secs tick-time-secs (fn [] (disruptor/publish receive-queue [[nil (TupleImpl. context [tick-time-secs] Constants/SYSTEM_TASK_ID Constants/SYSTEM_TICK_STREAM_ID)]] ))))))) 之前的博文中，已经详细分析了这些基础设施的关系，不理解的童鞋可以翻看前面的文章。每隔一段时间，就会触发这样一个事件，当流的下游的bolt收到一个这样的事件时，就可以选择是增量计数还是将结果聚合并发送到流中。bolt如何判断收到的tuple表示的是“tick”呢？负责管理bolt的executor线程，从其订阅的消息队列消费消息时，会调用到bolt的execute方法，那么，可以在execute中这样判断：12345public static boolean isTick(Tuple tuple) &#123; return tuple != null &amp;&amp; Constants.SYSTEM_COMPONENT_ID .equals(tuple.getSourceComponent()) &amp;&amp; Constants.SYSTEM_TICK_STREAM_ID.equals(tuple.getSourceStreamId());&#125; 结合上面的setup-tick!的clojure代码，我们可以知道SYSTEM_TICK_STREAM_ID在定时事件的回调中就以构造函数的参数传递给了tuple，那么SYSTEM_COMPONENT_ID是如何来的呢？可以看到，下面的代码中，SYSTEM_TASK_ID同样传给了tuple：;; 请注意SYSTEM_TASK_ID和SYSTEM_TICK_STREAM_ID(TupleImpl. context [tick-time-secs] Constants/SYSTEM_TASK_ID Constants/SYSTEM_TICK_STREAM_ID)然后利用下面的代码，就可以得到SYSTEM_COMPONENT_ID：1234567public String getComponentId(int taskId) &#123; if(taskId==Constants.SYSTEM_TASK_ID) &#123; return Constants.SYSTEM_COMPONENT_ID; &#125; else &#123; return _taskToComponent.get(taskId); &#125;&#125; 滑动窗口有了上面的基础设施，我们还需要一些手段来完成“工程化”，将设想变为现实。这里，我们看看Michael G. Noll的滑动窗口设计。 Topology 12345678910111213String spoutId = &quot;wordGenerator&quot;;String counterId = &quot;counter&quot;;String intermediateRankerId = &quot;intermediateRanker&quot;;String totalRankerId = &quot;finalRanker&quot;;// 这里，假设TestWordSpout就是我们发送话题tuple的源builder.setSpout(spoutId, new TestWordSpout(), 5);// RollingCountBolt的时间窗口为9秒钟，每3秒发送一次统计结果到下游builder.setBolt(counterId, new RollingCountBolt(9, 3), 4).fieldsGrouping(spoutId, new Fields(&quot;word&quot;));// IntermediateRankingsBolt，将完成部分聚合，统计出top-n的话题builder.setBolt(intermediateRankerId, new IntermediateRankingsBolt(TOP_N), 4).fieldsGrouping(counterId, new Fields( &quot;obj&quot;)); // TotalRankingsBolt， 将完成完整聚合，统计出top-n的话题builder.setBolt(totalRankerId, new TotalRankingsBolt(TOP_N)).globalGrouping(intermediateRankerId); 上面的topology设计如下： 将聚合计算与时间结合起来前文，我们叙述了tick事件，回调中会触发bolt的execute方法，那可以这么做： 123456789101112131415161718192021222324252627282930313233RollingCountBolt: @Override public void execute(Tuple tuple) &#123; if (TupleUtils.isTick(tuple)) &#123; LOG.debug(&quot;Received tick tuple, triggering emit of current window counts&quot;); // tick来了，将时间窗口内的统计结果发送，并让窗口滚动 emitCurrentWindowCounts(); &#125; else &#123; // 常规tuple，对话题计数即可 countObjAndAck(tuple); &#125; &#125; // obj即为话题，增加一个计数 count++ // 注意，这里的速度基本取决于流的速度，可能每秒百万，也可能每秒几十. // 内存不足？ bolt可以scale-out. private void countObjAndAck(Tuple tuple) &#123; Object obj = tuple.getValue(0); counter.incrementCount(obj); collector.ack(tuple); &#125; // 将统计结果发送到下游 private void emitCurrentWindowCounts() &#123; Map&lt;Object, Long&gt; counts = counter.getCountsThenAdvanceWindow(); int actualWindowLengthInSeconds = lastModifiedTracker.secondsSinceOldestModification(); lastModifiedTracker.markAsModified(); if (actualWindowLengthInSeconds != windowLengthInSeconds) &#123; LOG.warn(String.format(WINDOW_LENGTH_WARNING_TEMPLATE, actualWindowLengthInSeconds, windowLengthInSeconds)); &#125; emit(counts, actualWindowLengthInSeconds); &#125; 上面的代码可能有点抽象，看下这个图就明白了，tick一到，窗口就滚动： 123456789101112IntermediateRankingsBolt &amp; TotalRankingsBolt： public final void execute(Tuple tuple, BasicOutputCollector collector) &#123; if (TupleUtils.isTick(tuple)) &#123; getLogger().debug(&quot;Received tick tuple, triggering emit of current rankings&quot;); // 将聚合并排序的结果发送到下游 emitRankings(collector); &#125; else &#123; // 聚合并排序 updateRankingsWithTuple(tuple); &#125; &#125; &emsp;&emsp;其中，IntermediateRankingsBolt和TotalRankingsBolt的聚合排序方法略有不同： IntermediateRankingsBolt的聚合排序方法： 1234567@Overridevoid updateRankingsWithTuple(Tuple tuple) &#123; // 这一步，将话题、话题出现的次数提取出来 Rankable rankable = RankableObjectWithFields.from(tuple); // 这一步，将话题出现的次数进行聚合，然后重排序所有话题 super.getRankings().updateWith(rankable);&#125; TotalRankingsBolt的聚合排序方法： 123456789@Overridevoid updateRankingsWithTuple(Tuple tuple) &#123;// 提出来自IntermediateRankingsBolt的中间结果 Rankings rankingsToBeMerged = (Rankings) tuple.getValue(0);// 聚合并排序 super.getRankings().updateWith(rankingsToBeMerged);// 去0，节约内存 super.getRankings().pruneZeroCounts();&#125; 而重排序方法比较简单粗暴，因为只求前N个，N不会很大： private void rerank() { Collections.sort(rankedItems); Collections.reverse(rankedItems); } &emsp;&emsp;结语 &emsp;&emsp;下图可能就是我们想要的结果，我们完成了t0 - t1时刻之间的热点话题统计. 18.5 如何进行离线计算？18.6 如何使用分布式框架提高模型训练速度？18.7 深度学习分布式计算框架如何在移动互联网中应用？18.8 如何在个性化推荐中应用深度学习分布式框架？18.9 如何评价个性化推荐系统的效果？18.9.1 准确率与召回率（Precision &amp; Recall）&emsp;&emsp;准确率和召回率是广泛用于信息检索和统计学分类领域的两个度量值，用来评价结果的质量。其中精度是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的查准率；召回率是指检索出的相关文档数和文档库中所有的相关文档数的比率，衡量的是检索系统的查全率。 &emsp;&emsp;一般来说，Precision就是检索出来的条目（比如：文档、网页等）有多少是准确的，Recall就是所有准确的条目有多少被检索出来了。 &emsp;&emsp;正确率、召回率和 F 值是在鱼龙混杂的环境中，选出目标的重要评价指标。不妨看看这些指标的定义先： 正确率 = 提取出的正确信息条数 / 提取出的信息条数 召回率 = 提取出的正确信息条数 / 样本中的信息条数 &emsp;&emsp;两者取值在0和1之间，数值越接近1，查准率或查全率就越高。 F值 = 正确率 * 召回率 * 2 / (正确率 + 召回率) （F 值即为正确率和召回率的调和平均值） &emsp;&emsp;不妨举这样一个例子：某池塘有1400条鲤鱼，300只虾，300只鳖。现在以捕鲤鱼为目的。撒一大网，逮着了700条鲤鱼，200只虾，100只鳖。那么，这些指标分别如下： 正确率 = 700 / (700 + 200 + 100) = 70% 召回率 = 700 / 1400 = 50% F值 = 70% * 50% * 2 / (70% + 50%) = 58.3% &emsp;&emsp;不妨看看如果把池子里的所有的鲤鱼、虾和鳖都一网打尽，这些指标又有何变化： 正确率 = 1400 / (1400 + 300 + 300) = 70% 召回率 = 1400 / 1400 = 100% F值 = 70% * 100% * 2 / (70% + 100%) = 82.35% &emsp;&emsp;由此可见，正确率是评估捕获的成果中目标成果所占得比例；召回率，顾名思义，就是从关注领域中，召回目标类别的比例；而F值，则是综合这二者指标的评估指标，用于综合反映整体的指标。 &emsp;&emsp;当然希望检索结果Precision越高越好，同时Recall也越高越好，但事实上这两者在某些情况下有矛盾的。比如极端情况下，我们只搜索出了一个结果，且是准确的，那么Precision就是100%，但是Recall就很低；而如果我们把所有结果都返回，那么比如Recall是100%，但是Precision就会很低。因此在不同的场合中需要自己判断希望Precision比较高或是Recall比较高。如果是做实验研究，可以绘制Precision-Recall曲线来帮助分析。 18.9.2 综合评价指标（F-Measure）&emsp;&emsp;P和R指标有时候会出现的矛盾的情况，这样就需要综合考虑他们，最常见的方法就是F-Measure（又称为F-Score）。 &emsp;&emsp;F-Measure是Precision和Recall加权调和平均： &emsp;&emsp;当参数α=1时，就是最常见的F1，也即 &emsp;&emsp;可知F1综合了P和R的结果，当F1较高时则能说明试验方法比较有效。 18.9.3 E值&emsp;&emsp;E值表示查准率P和查全率R的加权平均值，当其中一个为0时，E值为1，其计算公式： &emsp;&emsp;b越大，表示查准率的权重越大。 18.9.4 平均正确率（Average Precision）&emsp;&emsp;平均正确率表示不同查全率的点上的正确率的平均。 18.10 参考文献【1】http://www.paddlepaddle.org/documentation/book/zh/0.11.0/05.recommender_system/index.cn.html 【2】https://deeplearning4j.org/cn/compare-dl4j-torch7-pylearn.html 【3】http://mahout.apache.org/ 【4】http://spark.apache.org/docs/1.1.0/mllib-guide.html 【5】https://ray.readthedocs.io/en/latest/tutorial.html 【6】http://spark.apache.org/streaming/ 【7】https://github.com/uber/horovod 【8】https://software.intel.com/en-us/articles/bigdl-distributed-deep-learning-on-apache-spark 【9】https://eng.uber.com/petastorm/ 【10】https://yahoo.github.io/TensorFlowOnSpark/# …. 未完待续！]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DQN三大改进(三)-Dueling Network]]></title>
    <url>%2F2018%2F03%2F12%2FDQN%E4%B8%89%E5%A4%A7%E6%94%B9%E8%BF%9B(%E4%B8%89)-Dueling%20Network%2F</url>
    <content type="text"><![CDATA[DQN三大改进(三)-Dueling Network1、Dueling Network什么是Dueling Deep Q Network呢？看下面的图片 上面是我们传统的DQN，下面是我们的Dueling DQN。在原始的DQN中，神经网络直接输出的是每种动作的 Q值, 而 Dueling DQN 每个动作的 Q值 是有下面的公式确定的： 它分成了这个 state 的值, 加上每个动作在这个 state 上的 advantage。我们通过下面这张图来解释一下： 在这款赛车游戏中。左边是 state value, 发红的部分证明了 state value 和前面的路线有关, 右边是 advantage, 发红的部分说明了 advantage 很在乎旁边要靠近的车子, 这时的动作会受更多 advantage 的影响. 发红的地方左右了自己车子的移动原则。 但是，利用上面的式子计算Q值会出现一个unidentifiable问题：给定一个Q，是无法得到唯一的V和A的。比如，V和A分别加上和减去一个值能够得到同样的Q，但反过来显然无法由Q得到唯一的V和A。 解决方法强制令所选择贪婪动作的优势函数为0： 则我们能得到唯一的值函数： 解决方法的改进使用优势函数的平均值代替上述的最优值 采用这种方法，虽然使得值函数V和优势函数A不再完美的表示值函数和优势函数(在语义上的表示)，但是这种操作提高了稳定性。而且，并没有改变值函数V和优势函数A的本质表示。 2、代码实现这里我们想要实现的效果类似于寻宝。 其中，红色的方块代表寻宝人，黑色的方块代表陷阱，黄色的方块代表宝藏，我们的目标就是让寻宝人找到最终的宝藏。 这里，我们的状态可以用横纵坐标表示，而动作有上下左右四个动作。使用tkinter来做这样一个动画效果。宝藏的奖励是1，陷阱的奖励是-1，而其他时候的奖励都为0。 接下来，我们重点看一下我们Dueling-DQN相关的代码。 定义输入 1234# ------------------------input---------------------------self.s = tf.placeholder(tf.float32, [None, self.n_features], name='s')self.q_target = tf.placeholder(tf.float32, [None, self.n_actions], name='Q-target')self.s_ = tf.placeholder(tf.float32,[None,self.n_features],name='s_') 定义网络结构根据Dueling DQN的网络结构，我们首先定义一个隐藏层，针对隐藏层的输出，我们将此输出分别作为两个隐藏层的输入，分别输出state的Value，和每个action的Advantage，最后， 根据Q = V+A得到每个action的Q值： 1234567891011121314151617181920212223242526def build_layers(s, c_names, n_l1, w_initializer, b_initializer): with tf.variable_scope('l1'): w1 = tf.get_variable('w1', [self.n_features, n_l1], initializer=w_initializer, collections=c_names) b1 = tf.get_variable('b1', [1, n_l1], initializer=b_initializer, collections=c_names) l1 = tf.nn.relu(tf.matmul(s, w1) + b1) if self.dueling: with tf.variable_scope('Value'): w2 = tf.get_variable('w2',[n_l1,1],initializer=w_initializer,collections=c_names) b2 = tf.get_variable('b2',[1,1],initializer=b_initializer,collections=c_names) self.V = tf.matmul(l1,w2) + b2 with tf.variable_scope('Advantage'): w2 = tf.get_variable('w2',[n_l1,self.n_actions],initializer=w_initializer,collections=c_names) b2 = tf.get_variable('b2',[1,self.n_actions],initializer=b_initializer,collections=c_names) self.A = tf.matmul(l1,w2) + b2 with tf.variable_scope('Q'): out = self.V + self.A - tf.reduce_mean(self.A,axis=1,keep_dims=True) else: with tf.variable_scope('Q'): w2 = tf.get_variable('w2', [n_l1, self.n_actions], initializer=w_initializer, collections=c_names) b2 = tf.get_variable('b2', [1, self.n_actions], initializer=b_initializer, collections=c_names) out = tf.matmul(l1, w2) + b2 return out 接下来，我们定义我们的eval-net和target-net 12345678910111213# -----------------------------eval net ---------------------with tf.variable_scope('eval_net'): c_names, n_l1, w_initializer, b_initializer = \ ['eval_net_params', tf.GraphKeys.GLOBAL_VARIABLES], 20, \ tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1) # config of layers self.q_eval = build_layers(self.s, c_names, n_l1, w_initializer, b_initializer)# ------------------ build target_net ------------------with tf.variable_scope('target_net'): c_names = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES] self.q_next = build_layers(self.s_, c_names, n_l1, w_initializer, b_initializer) 定义损失和优化器接下来，我们定义我们的损失，和DQN一样，我们使用的是平方损失： 12345with tf.variable_scope('loss'): self.loss = tf.reduce_mean(tf.squared_difference(self.q_target,self.q_eval))with tf.variable_scope('train'): self.train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss) 定义经验池我们使用一个函数定义我们的经验池，经验池每一行的长度为 状态feature * 2 + 2。 1234567def store_transition(self,s,a,r,s_): if not hasattr(self, 'memory_counter'): self.memory_counter = 0 transition = np.hstack((s, [a, r], s_)) index = self.memory_counter % self.memory_size self.memory[index, :] = transition self.memory_counter += 1 选择action我们仍然使用的是e-greedy的选择动作策略，即以e的概率选择随机动作，以1-e的概率通过贪心算法选择能得到最多奖励的动作a。 12345678def choose_action(self,observation): observation = observation[np.newaxis,:] actions_value = self.sess.run(self.q_eval,feed_dict=&#123;self.s:observation&#125;) action = np.argmax(actions_value) if np.random.random() &gt; self.epsilon: action = np.random.randint(0,self.n_actions) return action 选择数据batch我们从经验池中选择我们训练要使用的数据。 123456if self.memory_counter &gt; self.memory_size: sample_index = np.random.choice(self.memory_size, size=self.batch_size)else: sample_index = np.random.choice(self.memory_counter, size=self.batch_size)batch_memory = self.memory[sample_index,:] 更新target-net这里，每个一定的步数，我们就更新target-net中的参数： 12345678t_params = tf.get_collection('target_net_params')e_params = tf.get_collection('eval_net_params')self.replace_target_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)]if self.learn_step_counter % self.replace_target_iter == 0: self.sess.run(self.replace_target_op) print('\ntarget_params_replaced\n') 更新网络参数我们使用DQN的做法来更新网络参数： 123456789101112131415161718q_next = self.sess.run(self.q_next, feed_dict=&#123;self.s_: batch_memory[:, -self.n_features:]&#125;) # next observationq_eval = self.sess.run(self.q_eval, &#123;self.s: batch_memory[:, :self.n_features]&#125;)q_target = q_eval.copy()batch_index = np.arange(self.batch_size, dtype=np.int32)eval_act_index = batch_memory[:, self.n_features].astype(int)reward = batch_memory[:, self.n_features + 1]q_target[batch_index, eval_act_index] = reward + self.gamma * np.max(q_next, axis=1)_, self.cost = self.sess.run([self._train_op, self.loss], feed_dict=&#123;self.s: batch_memory[:, :self.n_features], self.q_target: q_target&#125;)self.cost_his.append(self.cost)self.epsilon = self.epsilon + self.epsilon_increment if self.epsilon &lt; self.epsilon_max else self.epsilon_maxself.learn_step_counter += 1]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DQN改进-Double DQN]]></title>
    <url>%2F2018%2F03%2F05%2FDQN%E4%B8%89%E5%A4%A7%E6%94%B9%E8%BF%9B(%E4%B8%80)-Double%20DQN%2F</url>
    <content type="text"><![CDATA[DQN三大改进(一)-Double DQN1、背景我们简单回顾一下DQN的过程(这里是2015版的DQN)： DQN中有两个关键的技术，叫做经验回放和双网络结构。 DQN中的损失函数定义为： 其中，yi也被我们称为q-target值，而后面的Q(s,a)我们称为q-eval值，我们希望q-target和q-eval值越接近越好。 q-target如何计算呢？根据下面的公式： 上面的两个公式分别截取自两篇不同的文章，所以可能有些出入。我们之前说到过，我们有经验池存储的历史经验，经验池中每一条的结构是(s,a,r,s’)，我们的q-target值根据该轮的奖励r以及将s’输入到target-net网络中得到的Q(s’,a’)的最大值决定。 我们进一步展开我们的q-target计算公式： 也就是说，我们根据状态s’选择动作a’的过程,以及估计Q(s’,a’)使用的是同一张Q值表，或者说使用的同一个网络参数，这可能导致选择过高的估计值，从而导致过于乐观的值估计。为了避免这种情况的出现，我们可以对选择和衡量进行解耦，从而就有了双Q学习，在Double DQN中，q-target的计算基于如下的公式： 我们根据一张Q表或者网络参数来选择我们的动作a’,再用另一张Q值表活着网络参数来衡量Q(s’,a’)的值。 2、代码实现本文的代码还是根据莫烦大神的代码，它的github地址为：https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow 这里我们想要实现的效果类似于寻宝。 其中，红色的方块代表寻宝人，黑色的方块代表陷阱，黄色的方块代表宝藏，我们的目标就是让寻宝人找到最终的宝藏。 这里，我们的状态可以用横纵坐标表示，而动作有上下左右四个动作。使用tkinter来做这样一个动画效果。宝藏的奖励是1，陷阱的奖励是-1，而其他时候的奖励都为0。 接下来，我们重点看一下我们Double-DQN相关的代码。 定义输入 1234# ------------------------input---------------------------self.s = tf.placeholder(tf.float32, [None, self.n_features], name='s')self.q_target = tf.placeholder(tf.float32, [None, self.n_actions], name='Q-target')self.s_ = tf.placeholder(tf.float32,[None,self.n_features],name='s_') 定义双网络结构 这里我们的双网络结构都简单的采用简单的全链接神经网络，包含一个隐藏层。这里我们得到的输出是一个向量，表示该状态才取每个动作可以获得的Q值： 12345678910def build_layers(s,c_name,n_l1,w_initializer,b_initializer): with tf.variable_scope('l1'): w1 = tf.get_variable(name='w1',shape=[self.n_features,n_l1],initializer=w_initializer,collections=c_name) b1 = tf.get_variable(name='b1',shape=[1,n_l1],initializer=b_initializer,collections=c_name) l1 = tf.nn.relu(tf.matmul(s,w1)+b1) with tf.variable_scope('l2'): w2 = tf.get_variable(name='w2',shape=[n_l1,self.n_actions],initializer=w_initializer,collections=c_name) b2 = tf.get_variable(name='b2',shape=[1,self.n_actions],initializer=b_initializer,collections=c_name) out = tf.matmul(l1,w2) + b2 return out 接下来，我们定义两个网络： 12345678910111213# ------------------ build evaluate_net ------------------with tf.variable_scope('eval_net'): c_names = ['eval_net_params',tf.GraphKeys.GLOBAL_VARIABLES] n_l1 = 20 w_initializer = tf.random_normal_initializer(0,0.3) b_initializer =tf.constant_initializer(0.1) self.q_eval = build_layers(self.s,c_names,n_l1,w_initializer,b_initializer)# ------------------ build target_net ------------------with tf.variable_scope('target_net'): c_names = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES] self.q_next = build_layers(self.s_, c_names, n_l1, w_initializer, b_initializer) 定义损失和优化器接下来，我们定义我们的损失，和DQN一样，我们使用的是平方损失： 12345with tf.variable_scope('loss'): self.loss = tf.reduce_mean(tf.squared_difference(self.q_target,self.q_eval))with tf.variable_scope('train'): self.train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss) 定义我们的经验池我们使用一个函数定义我们的经验池，经验池每一行的长度为 状态feature * 2 + 2。 1234567def store_transition(self,s,a,r,s_): if not hasattr(self, 'memory_counter'): self.memory_counter = 0 transition = np.hstack((s, [a, r], s_)) index = self.memory_counter % self.memory_size self.memory[index, :] = transition self.memory_counter += 1 选择action我们仍然使用的是e-greedy的选择动作策略，即以e的概率选择随机动作，以1-e的概率通过贪心算法选择能得到最多奖励的动作a。 12345678def choose_action(self,observation): observation = observation[np.newaxis,:] actions_value = self.sess.run(self.q_eval,feed_dict=&#123;self.s:observation&#125;) action = np.argmax(actions_value) if np.random.random() &gt; self.epsilon: action = np.random.randint(0,self.n_actions) return action 选择数据batch我们从经验池中选择我们训练要使用的数据。 123456if self.memory_counter &gt; self.memory_size: sample_index = np.random.choice(self.memory_size, size=self.batch_size)else: sample_index = np.random.choice(self.memory_counter, size=self.batch_size)batch_memory = self.memory[sample_index,:] 更新target-net这里，每个一定的步数，我们就更新target-net中的参数： 12345678t_params = tf.get_collection('target_net_params')e_params = tf.get_collection('eval_net_params')self.replace_target_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)]if self.learn_step_counter % self.replace_target_iter == 0: self.sess.run(self.replace_target_op) print('\ntarget_params_replaced\n') 更新网络参数根据Double DQN的做法，我们需要用两个网络的来计算我们的q-target值，同时通过最小化损失来更新网络参数。这里的做法是，根据eval-net的值来选择动作，然后根据target-net的值来计算Q值。 123q_next,q_eval4next = self.sess.run([self.q_next, self.q_eval], feed_dict=&#123;self.s_: batch_memory[:, -self.n_features:], self.s: batch_memory[:, -self.n_features:]&#125;) q_next是根据经验池中下一时刻状态输入到target-net计算得到的q值，而q_eval4next是根据经验池中下一时刻状态s’输入到eval-net计算得到的q值，这个q值主要用来选择动作。 下面的动作用来得到我们batch中的实际动作和奖励 123batch_index = np.arange(self.batch_size, dtype=np.int32)eval_act_index = batch_memory[:, self.n_features].astype(int)reward = batch_memory[:, self.n_features + 1] 接下来，我们就要来选择动作并计算该动作的q值了,如果是double dqn的话，我们是根据刚刚计算的q_eval4next来选择动作，然后根据q_next来得到q值的。而原始的dqn直接通过最大的q_next来得到q值： 12345if self.double_q: max_act4next = np.argmax(q_eval4next, axis=1) # the action that brings the highest value is evaluated by q_eval selected_q_next = q_next[batch_index, max_act4next] # Double DQN, select q_next depending on above actionselse: selected_q_next = np.max(q_next, axis=1) # the natural DQN 那么我们的q-target值就可以计算得到了： 12q_target = q_eval.copy()q_target[batch_index, eval_act_index] = reward + self.gamma * selected_q_next 有了q-target值，我们就可以结合eval-net计算的q-eval值来更新网络参数了： 1234567_, self.cost = self.sess.run([self.train_op, self.loss], feed_dict=&#123;self.s: batch_memory[:, :self.n_features], self.q_target: q_target&#125;)self.cost_his.append(self.cost)self.epsilon = self.epsilon + self.epsilon_increment if self.epsilon &lt; self.epsilon_max else self.epsilon_maxself.learn_step_counter += 1]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模型压缩及移动端部署]]></title>
    <url>%2F2018%2F01%2F15%2F%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[Markdown Revision 1; Editor: 谈继勇 Contact: scutjy2015@163.com updata:张达峰 17.1 为什么需要模型压缩和加速？（1）随着AI技术的飞速发展，越来越多的公司希望在自己的移动端产品中注入AI能力 （2）对于在线学习和增量学习等实时应用而言，如何减少含有大量层级及结点的大型神经网络所需要的内存和计算量显得极为重要。（3）智能设备的流行提供了内存、CPU、能耗和宽带等资源，使得深度学习模型部署在智能移动设备上变得可行。（4）高效的深度学习方法可以有效的帮助嵌入式设备、分布式系统完成复杂工作，在移动端部署深度学习有很重要的意义。 17.2 目前有哪些深度学习模型压缩方法？https://blog.csdn.net/wspba/article/details/75671573https://blog.csdn.net/Touch_Dream/article/details/78441332 17.2.1 前端压缩（1）知识蒸馏（简单介绍）一个复杂的模型可以认为是由多个简单模型或者强约束条件训练而来，具有很好的性能，但是参数量很大，计算效率低，而小模型计算效率高，但是其性能较差。知识蒸馏是让复杂模型学习到的知识迁移到小模型当中,使其保持其快速的计算速度前提下，同时拥有复杂模型的性能，达到模型压缩的目的。但与剪枝、量化等方法想比，效果较差。(https://blog.csdn.net/Lucifer_zzq/article/details/79489248)（2）紧凑的模型结构设计（简单介绍）紧凑的模型结构设计主要是对神经网络卷积的方式进行改进，比如使用两个3x3的卷积替换一个5x5的卷积、使用深度可分离卷积等等方式降低计算参数量。（3）滤波器层面的剪枝（简单介绍）参考链接 https://blog.csdn.net/JNingWei/article/details/79218745 补充优缺点滤波器层面的剪枝属于非结构花剪枝，主要是对较小的权重矩阵整个剔除，然后对整个神经网络进行微调。此方式由于剪枝过于粗放，容易导致精度损失较大，而且部分权重矩阵中会存留一些较小的权重造成冗余，剪枝不彻底。 17.2.2 后端压缩（1）低秩近似 （简单介绍，参考链接补充优缺点）在卷积神经网络中，卷积运算都是以矩阵相乘的方式进行。对于复杂网络，权重矩阵往往非常大，非常消耗存储和计算资源。低秩近似就是用若干个低秩矩阵组合重构大的权重矩阵，以此降低存储和计算资源消耗。优点： 可以降低存储和计算消耗； 一般可以压缩2-3倍；精度几乎没有损失； 缺点： 模型越复杂，权重矩阵越大，利用低秩近似重构参数矩阵不能保证模型的性能 （2）未加限制的剪枝 （简单介绍，参考链接补充优缺点）剪枝操作包括：非结构化剪枝和结构化剪枝。非结构化剪枝是对神经网络中权重较小的权重或者权重矩阵进剔除，然后对整个神经网络进行微调；结构化剪枝是在网络优化目标中加入权重稀疏正则项，使部分权重在训练时趋于0。 优点： 保持模型性能不损失的情况下，减少参数量9-11倍； 剔除不重要的权重，可以加快计算速度，同时也可以提高模型的泛化能力； 缺点： 非结构化剪枝会增加内存访问成本； 极度依赖专门的运行库和特殊的运行平台，不具有通用性； 压缩率过大时，破坏性能； （3）参数量化 （简单介绍，参考链接补充优缺点）神经网络的参数类型一般是32位浮点型，使用较小的精度代替32位所表示的精度。或者是将多个权重映射到同一数值，权重共享优点： 模型性能损失很小，大小减少8-16倍； 缺点： 压缩率大时，性能显著下降； 依赖专门的运行库，通用性较差； （4）二值网络 （简单介绍，参考链接补充优缺点）对于32bit浮点型数用1bit二进制数-1或者1表示。优点： 网络体积小，运算速度快 目前深度学习模型压缩方法的研究主要可以分为以下几个方向：（1）更精细模型的设计。目前很多网络基于模块化设计思想，在深度和宽度两个维度上都很大，导致参数冗余。因此有很多关于模型设计的研究，如SqueezeNet、MobileNet等，使用更加细致、高效的模型设计，能够很大程度的减少模型尺寸，并且也具有不错的性能。（2）模型裁剪。结构复杂的网络具有非常好的性能，其参数也存在冗余，因此对于已训练好的模型网络，可以寻找一种有效的评判手段，将不重要的connection或者filter进行裁剪来减少模型的冗余。（3）核的稀疏化。在训练过程中，对权重的更新进行诱导，使其更加稀疏，对于稀疏矩阵，可以使用更加紧致的存储方式，如CSC，但是使用稀疏矩阵操作在硬件平台上运算效率不高，容易受到带宽的影响，因此加速并不明显。（4）量化（5）Low-rank分解（6）迁移学习 17.3 目前有哪些深度学习模型优化加速方法？https://blog.csdn.net/nature553863/article/details/81083955模型优化加速能够提升网络的计算效率，具体包括：（1）Op-level的快速算法：FFT Conv2d (7x7, 9x9), Winograd Conv2d (3x3, 5x5) 等；（2）Layer-level的快速算法：Sparse-block net [1] 等；（3）优化工具与库：TensorRT (Nvidia), Tensor Comprehension (Facebook) 和 Distiller (Intel) 等； 原文：https://blog.csdn.net/nature553863/article/details/81083955 17.4 影响神经网络速度的4个因素（再稍微详细一点） FLOPs(FLOPs就是网络执行了多少multiply-adds操作)； MAC(内存访问成本)； 并行度(如果网络并行度高，速度明显提升)； 计算平台(GPU，ARM) 17.5 改变网络结构设计为什么会实现模型压缩、加速？1. Group convolutionGroup convolution最早出现在AlexNet中，是为了解决单卡显存不够，将网络部署到多卡上进行训练。Group convolution可以减少单个卷积1/g的参数量。假设输入特征的的维度为H * W * c1；卷积核的维度为h1 * w1 * c1，共c2个；输出特征的维度为 H1 * W1 * c2。传统卷积计算方式如下：传统卷积运算量为： 1A = H * W * h1 * w1 * c1 * c2 Group convolution是将输入特征的维度c1分成g份，每个group对应的channel数为c1/g，特征维度H * W * c1/g；，每个group对应的卷积核的维度也相应发生改变为h1 * w1 * c1/9，共c2/g个；每个group相互独立运算，最后将结果叠加在一起。Group convolution计算方式如下：Group convolution运算量为： 1B = H * W * h1 * w1 * c1/g * c2/g * g Group卷积相对于传统卷积的运算量：1\dfrac&#123;B&#125;&#123;A&#125; = \dfrac&#123; H * W * h1 * w1 * c1/g * c2/g * g&#125;&#123;H * W * h1 * w1 * c1 * c2&#125; = \dfrac&#123;1&#125;&#123;g&#125; 由此可知：group卷积相对于传统卷积减少了1/g的参数量。 2. Depthwise separable convolutionDepthwise separable convolution是由depthwise conv和pointwise conv构成。depthwise conv(DW)有效减少参数数量并提升运算速度。但是由于每个feature map只被一个卷积核卷积，因此经过DW输出的feature map不能只包含输入特征图的全部信息，而且特征之间的信息不能进行交流，导致“信息流通不畅”。pointwise conv(PW)实现通道特征信息交流，解决DW卷积导致“信息流通不畅”的问题。假设输入特征的的维度为H * W * c1；卷积核的维度为h1 * w1 * c1，共c2个；输出特征的维度为 H1 * W1 * c2。传统卷积计算方式如下：传统卷积运算量为：1A = H * W * h1 * w1 * c1 * c2 DW卷积的计算方式如下：DW卷积运算量为：1B_DW = H * W * h1 * w1 * 1 * c1 PW卷积的计算方式如下：1B_PW = H_m * W_m * 1 * 1 * c1 * c2 Depthwise separable convolution运算量为：1B = B_DW + B_PW Depthwise separable convolution相对于传统卷积的运算量：123\dfrac&#123;B&#125;&#123;A&#125; = \dfrac&#123; H * W * h1 * w1 * 1 * c1 + H_m * W_m * 1 * 1 * c1 * c2&#125;&#123;H * W * h1 * w1 * c1 * c2&#125; = \dfrac&#123;1&#125;&#123;c2&#125; + \dfrac&#123;1&#125;&#123;h1 * w1&#125; 由此可知，随着卷积通道数的增加，Depthwise separable convolution的运算量相对于传统卷积更少。 3. 输入输出的channel相同时，MAC最小卷积层的输入和输出特征通道数相等时MAC最小，此时模型速度最快。假设feature map的大小为h*w，输入通道c1，输出通道c2。已知：123456789FLOPs = B = h * w * c1 * c2=&gt; c1 * c2 = \dfrac&#123;B&#125;&#123;h * w&#125;MAC = h * w * (c1 + c2) + c1 * c2c1 + c2 \geq 2 * \sqrt&#123;c1 * c2&#125;=&gt; MAC \geq 2 * h * w \sqrt&#123;\dfrac&#123;B&#125;&#123;h * w&#125;&#125; + \dfrac&#123;B&#125;&#123;h * w&#125; 根据均值不等式得到(c1-c2)^2&gt;=0，等式成立的条件是c1=c2，也就是输入特征通道数和输出特征通道数相等时，在给定FLOPs前提下，MAC达到取值的下界。 4. 减少组卷积的数量过多的group操作会增大MAC，从而使模型速度变慢由以上公式可知，group卷积想比与传统的卷积可以降低计算量，提高模型的效率；如果在相同的FLOPs时，group卷积为了满足FLOPs会是使用更多channels，可以提高模型的精度。但是随着channel数量的增加，也会增加MAC。FLOPs：1B = \dfrac&#123;h * w * c1 * c2&#125;&#123;g&#125; MAC：1MAC = h * w * (c1 + c2) + \dfrac&#123;c1 * c2&#125;&#123;g&#125; 由MAC，FLOPs可知：1MAC = h * w * c1 + \dfrac&#123;B*g&#125;&#123;c1&#125; + \dfrac&#123;B&#125;&#123;h * w&#125; 当FLOPs固定(B不变)时，g越大，MAC越大。 5. 减少网络碎片化程度(分支数量)模型中分支数量越少，模型速度越快此结论主要是由实验结果所得。以下为网络分支数和各分支包含的卷积数目对神经网络速度的影响。实验中使用的基本网络结构，分别将它们重复10次，然后进行实验。实验结果如下：由实验结果可知，随着网络分支数量的增加，神经网络的速度在降低。网络碎片化程度对GPU的影响效果明显，对CPU不明显，但是网络速度同样在降低。 6. 减少元素级操作元素级操作所带来的时间消耗也不能忽视ReLU ，Tensor 相加，Bias相加的操作，分离卷积（depthwise convolution）都定义为元素级操作。FLOPs大多数是对于卷积计算而言的，因为元素级操作的FLOPs相对要低很多。但是过的元素级操作也会带来时间成本。ShuffleNet作者对ShuffleNet v1和MobileNet v2的几种层操作的时间消耗做了分析，发现元素级操作对于网络速度的影响也很大。 17.6 常用的轻量级网络有哪些？（再琢磨下语言和排版） SqueezeNet MobileNet ShuffleNet Xception 1. SequeezeNetSqueenzeNet出自F. N. Iandola, S.Han等人发表的论文《SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt; 0.5MB model size》，作者在保证精度不损失的同时，将原始AlexNet压缩至原来的510倍。 1.1 设计思想在网络结构设计方面主要采取以下三种方式： 用1*1卷积核替换3*3卷积 理论上一个1*1卷积核的参数是一个3*3卷积核的1/9，可以将模型尺寸压缩9倍。 减小3*3卷积的输入通道数 根据上述公式，减少输入通道数不仅可以减少卷积的运算量，而且输入通道数与输出通道数相同时还可以减少MAC。 延迟降采样 分辨率越大的输入能够提供更多特征的信息，有利于网络的训练判断，延迟降采样可以提高网络精度。1.2 网络架构SqueezeNet提出一种多分支结构——fire model，其中是由Squeeze层和expand层构成。Squeeze层是由s1个1*1卷积组成，主要是通过1*1的卷积降低expand层的输入维度；expand层利用e1个1*1和e3个3*3卷积构成多分支结构提取输入特征，以此提高网络的精度(其中e1=e3=4*s1)。SqueezeNet整体网络结构如下图所示：1.3实验结果不同压缩方法在ImageNet上的对比实验结果由实验结果可知，SqueezeNet不仅保证了精度，而且将原始AlexNet从240M压缩至4.8M，压缩50倍，说明此轻量级网络设计是可行。 2. MobileNetMobileNet 是Google团队于CVPR-2017的论文《MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications》中针对手机等嵌入式设备提出的一种轻量级的深层神经网络，该网络结构在VGG的基础上使用DW+PW的组合，在保证不损失太大精度的同时，降低模型参数量。 2.1 设计思想 采用深度可分离卷积代替传统卷积 采用DW卷积在减少参数数量的同时提升运算速度。但是由于每个feature map只被一个卷积核卷积，因此经过DW输出的feature map不能只包含输入特征图的全部信息，而且特征之间的信息不能进行交流，导致“信息流通不畅”。 采用PW卷积实现通道特征信息交流，解决DW卷积导致“信息流通不畅”的问题。 使用stride=2的卷积替换pooling 直接在卷积时利用stride=2完成了下采样，从而节省了需要再去用pooling再去进行一次下采样的时间，可以提升运算速度。同时，因为pooling之前需要一个stride=1的 conv，而与stride=2 conv的计算量想比要高近4倍(个人理解)。2.2 网络架构 DW conv和PW convMobileNet的网络架构主要是由DW conv和PW conv组成，相比于传统卷积可以降低$\dfrac{1}{N} + \dfrac{1}{Dk}$倍的计算量。标准卷积与DW conv和PW conv如图所示:深度可分离卷积与传统卷积运算量对比：网络结构： MobileNets的架构 2.3 实验结果由上表可知，使用相同的结构，深度可分离卷积虽然准确率降低1%，但是参数量减少了6/7。 3. MobileNet-v2MobileNet-V2是2018年1月公开在arXiv上论文《Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation》，是对MobileNet-V1的改进，同样是一个轻量化卷积神经网络。 3.1 设计思想 采用Inverted residuals 为了保证网络可以提取更多的特征，在residual block中第一个1*1 Conv和3*3 DW Conv之前进行通道扩充 Linear bottlenecks 为了避免Relu对特征的破坏，在residual block的Eltwise sum之前的那个 1*1 Conv 不再采用Relu stride=2的conv不使用shot-cot，stride=1的conv使用shot-cut 3.2 网络架构 Inverted residualsResNet中Residuals block先经过1*1的Conv layer，把feature map的通道数降下来，再经过3*3 Conv layer，最后经过一个1*1 的Conv layer，将feature map 通道数再“扩张”回去。即采用先压缩，后扩张的方式。而 inverted residuals采用先扩张，后压缩的方式。MobileNet采用DW conv提取特征，由于DW conv本身提取的特征数就少，再经过传统residuals block进行“压缩”，此时提取的特征数会更少，因此inverted residuals对其进行“扩张”，保证网络可以提取更多的特征。 Linear bottlenecksReLu激活函数会破坏特征。ReLu对于负的输入，输出全为0，而本来DW conv特征通道已经被“压缩”，再经过ReLu的话，又会损失一部分特征。采用Linear，目的是防止Relu破坏特征。 shortcutstride=2的conv不使用shot-cot，stride=1的conv使用shot-cut 网络架构 4. XceptionXception是Google提出的，arXiv 的V1 于2016年10月公开《Xception: Deep Learning with Depthwise Separable Convolutions 》，Xception是对Inception v3的另一种改进，主要是采用depthwise separable convolution来替换原来Inception v3中的卷积操作。 4.1设计思想 采用depthwise separable convolution来替换原来Inception v3中的卷积操作 与原版的Depth-wise convolution有两个不同之处： 第一个：原版Depth-wise convolution，先逐通道卷积，再11卷积; 而Xception是反过来，先1\1卷积，再逐通道卷积； 第二个：原版Depth-wise convolution的两个卷积之间是不带激活函数的，而Xception在经过1*1卷积之后会带上一个Relu的非线性激活函数； 4.2网络架构feature map在空间和通道上具有一定的相关性，通过Inception模块和非线性激活函数实现通道之间的解耦。增多3*3的卷积的分支的数量，使它与1*1的卷积的输出通道数相等，此时每个3*3的卷积只作用与一个通道的特征图上，作者称之为“极致的Inception（Extream Inception）”模块，这就是Xception的基本模块。 5. ShuffleNet-v1ShuffleNet 是Face++团队提出的，晚于MobileNet两个月在arXiv上公开《ShuffleNet： An Extremely Efficient Convolutional Neural Network for Mobile Devices 》用于移动端前向部署的网络架构。ShuffleNet基于MobileNet的group思想，将卷积操作限制到特定的输入通道。而与之不同的是，ShuffleNet将输入的group进行打散，从而保证每个卷积核的感受野能够分散到不同group的输入中，增加了模型的学习能力。 5.1 设计思想 采用group conv减少大量参数 roup conv与DW conv存在相同的“信息流通不畅”问题 采用channel shuffle解决上述问题 MobileNet中采用PW conv解决上述问题，SheffleNet中采用channel shuffle 采用concat替换add操作 avg pooling和DW conv(s=2)会减小feature map的分辨率，采用concat增加通道数从而弥补分辨率减小而带来信息的损失 5.2 网络架构MobileNet中1*1卷积的操作占据了约95%的计算量，所以作者将1*1也更改为group卷积，使得相比MobileNet的计算量大大减少。group卷积与DW存在同样使“通道信息交流不畅”的问题，MobileNet中采用PW conv解决上述问题，SheffleNet中采用channel shuffle。ShuffleNet的shuffle操作如图所示avg pooling和DW conv(s=2)会减小feature map的分辨率，采用concat增加通道数从而弥补分辨率减小而带来信息的损失；实验表明：多多使用通道(提升通道的使用率)，有助于提高小模型的准确率。网络结构： 6. ShuffleNet-v2huffleNet-v2 是Face++团队提出的《ShuffleNet V2: Practical Guidelines for Ecient CNN Architecture Design》，旨在设计一个轻量级但是保证精度、速度的深度网络。 6.1 设计思想 文中提出影响神经网络速度的4个因素： a. FLOPs(FLOPs就是网络执行了多少multiply-adds操作) b. MAC(内存访问成本) c. 并行度(如果网络并行度高，速度明显提升) d. 计算平台(GPU，ARM) ShuffleNet-v2 提出了4点网络结构设计策略： G1.输入输出的channel相同时，MAC最小 G2.过度的组卷积会增加MAC G3.网络碎片化会降低并行度 G4.元素级运算不可忽视 6.2 网络结构depthwise convolution 和 瓶颈结构增加了 MAC，用了太多的 group，跨层连接中的 element-wise Add 操作也是可以优化的点。所以在 shuffleNet V2 中增加了几种新特性。所谓的 channel split 其实就是将通道数一分为2，化成两分支来代替原先的分组卷积结构（G2），并且每个分支中的卷积层都是保持输入输出通道数相同（G1），其中一个分支不采取任何操作减少基本单元数（G3），最后使用了 concat 代替原来的 elementy-wise add，并且后面不加 ReLU 直接（G4），再加入channle shuffle 来增加通道之间的信息交流。 对于下采样层，在这一层中对通道数进行翻倍。 在网络结构的最后，即平均值池化层前加入一层 1x1 的卷积层来进一步的混合特征。网络结构 6.4 ShuffleNet-v2具有高精度的原因 由于高效，可以增加更多的channel，增加网络容量 采用split使得一部分特征直接与下面的block相连，特征复用(DenseNet) 17.7 现有移动端开源框架及其特点17.7.1 NCNN１、开源时间：2017年7月 ２、开源用户：腾讯优图 ３、GitHub地址：https://github.com/Tencent/ncnn 4、特点： 1）NCNN考虑了手机端的硬件和系统差异以及调用方式，架构设计以手机端运行为主要原则。 2）无第三方依赖，跨平台，手机端 CPU 的速度快于目前所有已知的开源框架（以开源时间为参照对象）。 3）基于 ncnn，开发者能够将深度学习算法轻松移植到手机端高效执行，开发出人工智能 APP。 5、功能： 1、NCNN支持卷积神经网络、多分支多输入的复杂网络结构，如vgg、googlenet、resnet、squeezenet 等。 2、NCNN无需依赖任何第三方库。 3、NCNN全部使用C/C++实现，以及跨平台的cmake编译系统，可轻松移植到其他系统和设备上。 4、汇编级优化，计算速度极快。使用ARM NEON指令集实现卷积层，全连接层，池化层等大部分 CNN 关键层。 5、精细的数据结构设计，没有采用需消耗大量内存的通常框架——im2col + 矩阵乘法，使得内存占用极低。 6、支持多核并行计算，优化CPU调度。 7、整体库体积小于500K，可精简到小于300K。 8、可扩展的模型设计，支持8bit 量化和半精度浮点存储。 9、支持直接内存引用加载网络模型。 10、可注册自定义层实现并扩展。 6、NCNN在Android端部署示例 1）选择合适的Android Studio版本并安装。 2）根据需求选择NDK版本并安装。 3）在Android Studio上配置NDK的环境变量。 4）根据自己需要编译NCNN sdk 1mkdir build-android cd build-android cmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake \ -DANDROID_ABI=&quot;armeabi-v7a&quot; -DANDROID_ARM_NEON=ON \ -DANDROID_PLATFORM=android-14 .. make make install ​ 安装完成之后，install下有include和lib两个文件夹。 ​ 备注： 123ANDROID_ABI 是架构名字，&quot;armeabi-v7a&quot; 支持绝大部分手机硬件 ANDROID_ARM_NEON 是否使用 NEON 指令集，设为 ON 支持绝大部分手机硬件 ANDROID_PLATFORM 指定最低系统版本，&quot;android-14&quot; 就是 android-4.0 5）进行NDK开发。 123456789101）assets文件夹下放置你的bin和param文件。2）jni文件夹下放置你的cpp和mk文件。3）修改你的app gradle文件。4）配置Android.mk和Application.mk文件。5）进行java接口的编写。6）读取拷贝bin和param文件（有些则是pb文件，根据实际情况）。7）进行模型的初始化和执行预测等操作。8）build。9）cd到src/main/jni目录下，执行ndk-build，生成.so文件。10）接着就可写自己的操作处理需求。 17.7.2 QNNPACK全称：Quantized Neural Network PACKage（量化神经网络包） １、开源时间：2018年10月 ２、开源用户：Facebook ３、GitHub地址：https://github.com/pytorch/QNNPACK ４、特点： ​ １）低密度卷积优化函数库； ２）可在手机上实时运行Mask R-CNN 和 DensePose; ​ ３） 能在性能受限的移动设备中用 100ms 以内的时间实施图像分类； 5、QNNPACK 如何提高效率？ 1)QNNPACK 使用与安卓神经网络 API 兼容的线性量化方案 QNNPACK 的输入矩阵来自低精度、移动专用的计算机视觉模型。其它库在计算A和B矩阵相乘时，重新打包 A 和 B 矩阵以更好地利用缓存层次结构，希望在大量计算中分摊打包开销，QNNPACK 删除所有计算非必需的内存转换，针对 A和B矩阵相乘适用于一级缓存的情况进行了优化。 ​ 在量化矩阵-矩阵乘法中，8 位整数的乘积通常会被累加至 32 位的中间结果中，随后重新量化以产生 8 位的输出。常规的实现会对大矩阵尺寸进行优化——有时 K 太大无法将 A 和 B 的面板转入缓存中。为了有效利用缓存层次结构，传统的 GEMM 实现将 A 和 B 的面板沿 K 维分割成固定大小的子面板，从而每个面板都适应 L1 缓存，随后为每个子面板调用微内核。这一缓存优化需要 PDOT 为内核输出 32 位中间结果，最终将它们相加并重新量化为 8 位整数。 ​ 由于 ONNPACK 对于面板 A 和 B 总是适应 L1 缓存的移动神经网络进行了优化，因此它在调用微内核时处理整个 A 和 B 的面板。而由于无需在微内核之外积累 32 位的中间结果，QNNPACK 会将 32 位的中间结果整合进微内核中并写出 8 位值，这节省了内存带宽和缓存占用。 使整个 A、B 面板适配缓存帮助实现了 QNNPACK 中的另一个优化：取消了矩阵 A 的重新打包。矩阵 B 包含静态权重，可以一次性转换成任何内存布局，但矩阵 A 包含卷积输入，每次推理运行都会改变。因此，重新打包矩阵 A 在每次运行时都会产生开销。尽管存在开销，传统的 GEMM 实现还是出于以下两个原因对矩阵 A 进行重新打包：缓存关联性及微内核效率受限。如果不重新打包，微内核将不得不读取被潜在的大跨距隔开的几行 A。如果这个跨距恰好是 2 的许多次幂的倍数，面板中不同行 A 的元素可能会落入同一缓存集中。如果冲突的行数超过了缓存关联性，它们就会相互驱逐，性能也会大幅下降。幸运的是，当面板适配一级缓存时，这种情况不会发生，就像 QNNPACK 优化的模型一样。 打包对微内核效率的影响与当前所有移动处理器支持的 SIMD 向量指令的使用密切相关。这些指令加载、存储或者计算小型的固定大小元素向量，而不是单个标量（scalar）。在矩阵相乘中，充分利用向量指令达到高性能很重要。在传统的 GEMM 实现中，微内核把 MR 元素重新打包到向量暂存器里的 MR 线路中。在 QNNPACK 实现中，MR 元素在存储中不是连续的，微内核需要把它们加载到不同的向量暂存器中。越来越大的暂存器压力迫使 QNNPACK 使用较小的 MRxNR 拼贴，但实际上这种差异很小，而且可以通过消除打包开销来补偿。例如，在 32 位 ARM 架构上，QNNPACK 使用 4×8 微内核，其中 57% 的向量指令是乘-加；另一方面，gemmlowp 库使用效率稍高的 4×12 微内核，其中 60% 的向量指令是乘-加。 微内核加载 A 的多个行，乘以 B 的满列，结果相加，然后完成再量化并记下量化和。A 和 B 的元素被量化为 8 位整数，但乘积结果相加到 32 位。大部分 ARM 和 ARM64 处理器没有直接完成这一运算的指令，所以它必须分解为多个支持运算。QNNPACK 提供微内核的两个版本，其不同之处在于用于乘以 8 位值并将它们累加到 32 位的指令序列。 2)从矩阵相乘到卷积 简单的 1×1 卷积可直接映射到矩阵相乘，但对于具备较大卷积核、padding 或子采样（步幅）的卷积而言则并非如此。但是，这些较复杂的卷积能够通过记忆变换 im2col 映射到矩阵相乘。对于每个输出像素，im2col 复制输入图像的图像块并将其计算为 2D 矩阵。由于每个输出像素都受 KHxKWxC 输入像素值的影响（KH 和 KW 分别指卷积核的高度和宽度，C 指输入图像中的通道数），因此该矩阵的大小是输入图像的 KHxKW 倍，im2col 给内存占用和性能都带来了一定的开销。和 Caffe 一样，大部分深度学习框架转而使用基于 im2col 的实现，利用现有的高度优化矩阵相乘库来执行卷积操作。 Facebook 研究者在 QNNPACK 中实现了一种更高效的算法。他们没有变换卷积输入使其适应矩阵相乘的实现，而是调整 PDOT 微内核的实现，在运行中执行 im2col 变换。这样就无需将输入张量的实际输入复制到 im2col 缓存，而是使用输入像素行的指针设置 indirection buffer，输入像素与每个输出像素的计算有关。研究者还修改了矩阵相乘微内核，以便从 indirection buffer 加载虚构矩阵（imaginary matrix）A 的行指针，indirection buffer 通常比 im2col buffer 小得多。此外，如果两次推断运行的输入张量存储位置不变，则 indirection buffer 还可使用输入张量行的指针进行初始化，然后在多次推断运行中重新使用。研究者观察到具备 indirection buffer 的微内核不仅消除了 im2col 变换的开销，其性能也比矩阵相乘微内核略好（可能由于输入行在计算不同输出像素时被重用）。 3)深度卷积 分组卷积（grouped convolution）将输入和输出通道分割成多组，然后对每个组进行分别处理。在有限条件下，当组数等于通道数时，该卷积就是深度卷积，常用于当前的神经网络架构中。深度卷积对每个通道分别执行空间滤波，展示了与正常卷积非常不同的计算模式。因此，通常要向深度卷积提供单独实现，QNNPACK 包括一个高度优化版本 3×3 深度卷积。 深度卷积的传统实现是每次都在卷积核元素上迭代，然后将一个卷积核行和一个输入行的结果累加到输出行。对于一个 3×3 的深度卷积，此类实现将把每个输出行更新 9 次。在 QNNPACK 中，研究者计算所有 3×3 卷积核行和 3×3 输入行的结果，一次性累加到输出行，然后再处理下个输出行。 QNNPACK 实现高性能的关键因素在于完美利用通用暂存器（GPR）来展开卷积核元素上的循环，同时避免在 hot loop 中重新加载地址寄存器。32-bit ARM 架构将实现限制在 14 个 GPR。在 3×3 深度卷积中，需要读取 9 个输入行和 9 个卷积核行。这意味着如果想完全展开循环必须存储 18 个地址。然而，实践中推断时卷积核不会发生变化。因此 Facebook 研究者使用之前在 CxKHxKW 中的滤波器，将它们封装进 [C/8]xKWxKHx8，这样就可以仅使用具备地址增量（address increment）的一个 GPR 访问所有滤波器。（研究者使用数字 8 的原因在于，在一个命令中加载 8 个元素然后减去零，在 128-bit NEON 暂存器中生成 8 个 16-bit 值。）然后使用 9 个输入行指针，指针将滤波器重新装进 10 个 GPR，完全展开滤波器元素上的循环。64-bit ARM 架构相比 32-bit 架构，GPR 的数量翻了一倍。QNNPACK 利用额外的 ARM64 GPR，一次性存储 3×5 输入行的指针，并计算 3 个输出行。 7、性能优势： ​ 测试结果显示出 QNNPACK 在端到端基准上的性能优势。在量化当前最优 MobileNetV2 架构上，基于QNNPACK 的 Caffe2 算子的速度大约是 TensorFlow Lite 速度的 2 倍，在多种手机上都是如此。除了 QNNPACK 之外，Facebook 还开源了 Caffe2 quantized MobileNet v2 模型，其 top-1 准确率比相应的 TensorFlow 模型高出 1.3%。 MobileNetV1 MobileNetV1 架构在使用深度卷积（depthwise convolution）使模型更适合移动设备方面具备开创性。MobileNetV1 包括几乎整个 1×1 卷积和 3×3 卷积。Facebook 研究者将量化 MobileNetV1 模型从 TensorFlow Lite 转换而来，并在 TensorFlow Lite 和 QNNPACK 的 32-bit ARM 设备上对 MobileNetV1 进行基准测试。二者运行时均使用 4 线程，研究者观察到 QNNPACK 的运行速度几何平均值是 TensorFlow Lite 的 1.8 倍。 MobileNetV2 作为移动视觉任务的当前最优架构之一，MobileNetV2 引入了瓶颈构造块和瓶颈之间的捷径连接。研究者在 MobileNetV2 分类模型的量化版上对比基于 QNNPACK 的 Caffe2 算子和 TensorFlow Lite 实现。使用的量化 Caffe2 MobileNetV2 模型已开源，量化 TensorFlow Lite 模型来自官方库：https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md。下表展示了二者在常用测试集上的 top1 准确率： ​ Facebook 研究者利用这些模型建立了 Facebook AI 性能评估平台（https://github.com/facebook/FAI-PEP）的基准，该基准基于 32-bit ARM 环境的大量手机设备。对于 TensorFlow Lite 线程设置，研究者尝试了一到四个线程，并报告了最快速的结果。结果显示 TensorFlow Lite 使用四线程的性能最优，因此后续研究中使用四线程来对比 TensorFlow Lite 和 QNNPACK。下表展示了结果，以及在典型智能手机和高端机上，基于 QNNPACK 的算子速度比 TensorFlow Lite 快得多。 Facebook开源高性能内核库QNNPACKhttps://baijiahao.baidu.com/s?id=1615725346726413945&amp;wfr=spider&amp;for=pchttp://www.sohu.com/a/272158070_610300 支持移动端深度学习的几种开源框架https://blog.csdn.net/zchang81/article/details/74280019 17.7.3 Prestissimo１、开源时间：2017年11月 ２、开源用户：九言科技 ３、GitHub地址：https://github.com/in66-dev/In-Prestissimo ４、功能特点： 基础功能 支持卷积神经网络，支持多输入和多分支结构 精炼简洁的API设计，使用方便 提供调试接口，支持打印各个层的数据以及耗时 不依赖任何第三方计算框架，整体库体积 500K 左右（32位 约400k，64位 约600k） 纯 C++ 实现，跨平台，支持 android 和 ios 模型为纯二进制文件，不暴露开发者设计的网络结构 极快的速度 大到框架设计，小到汇编书写上全方位的优化，iphone7 上跑 SqueezeNet 仅需 26ms（单线程） 支持浮点(float)和整型(int)两种运算模式，float模式精度与caffe相同，int模式运算速度快，大部分网络用int的精度便已经足够 以巧妙的内存布局提升cpu的cache命中率，在中低端机型上性能依然强劲 针对 float-arm32, float-arm64, int-arm32, int-arm64 四个分支均做了细致的优化，保证arm32位和arm64位版本都有非常好的性能 SqueezeNet-v1.1 测试结果 Note: 手机测试性能存在一定的抖动，连续多次运算取平均时间 Note: 像华为mate8, mate9，Google nexus 6 虽然是64位的CPU，但测试用的是 32位的库，因此cpu架构依然写 arm-v7a CPU架构 机型 CPU ncnn（4线程） mdl Prestissimo_float(单线程) Prestissimo_int(单线程) arm-v7a 小米2 高通APQ8064 1.5GHz 185 ms 370 ms 184 ms 115 ms arm-v7a 小米2s 四核 骁龙APQ8064 Pro 1.7GHz 166 ms - 136 ms 96 ms arm-v7a 红米Note 4x 骁龙625 四核2.0GHz 124 ms 306 ms 202 ms 110 ms arm-v7a Google Nexus 6 骁龙805 四核 2.7GHz 84 ms 245 ms 103 ms 63 ms arm-v7a Vivo x6d 联发科 MT6752 1.7GHz 245 ms 502 ms 370 ms 186 ms arm-v7a 华为 Mate 8 海思麒麟950 4大4小 2.3GHz 1.8GHz 75 ms 180 ms 95 ms 57 ms arm-v7a 华为 Mate 9 海思麒麟960 4大4小 2.4GHz 1.8GHz 61 ms 170 ms 94 ms 48 ms arm-v8 iphone7 Apple A10 Fusion 2.34GHz - - 27 ms 26 ms 未开放特性 多核并行加速（多核机器可以再提升30%-100% 的速度） depthwise卷积运算（支持mobilenet） 模型压缩功能，压缩后的模型体积可缩小到20%以下 GPU 运算模式（Android 基于opengl es 3.1，ios 基于metal） 同类框架对比 框架 caffe tensorflow mdl-android mdl-ios ncnn CoreML Prestissimo 计算硬件 cpu cpu cpu gpu cpu gpu cpu （gpu版本未开放） 计算速度 慢 慢 慢 很快 很快 极快 极快 库大小 大 较大 中等 小 小 小 小 兼容性 好 好 好 限ios8以上 很好 仅支持 ios11 很好 模型支持度 很好 好 - 差（仅限指定模型） 较好 - 中等（当前版本不支持mobilenet） 使用方法-模型转换 绝影支持的是私有的模型文件格式，需要把 caffe 训练出来的模型转换为 .prestissimo 格式，模型转换工具为 caffe2Prestissimo.out。caffe2Prestissimo.out 依赖 protobuf 3.30。将 XXX.prototxt 和 YYY.caffemodel 转化为 Prestissimo 模型 ZZZ.prestissimo：（得到）./caffe2Prestissimo.out XXX.prototxt YYY.caffemodel ZZZ.prestissimo 17.7.4 MDL（mobile-deep-learning）１、开源时间：2017年9月（已暂停更新） ２、开源用户：百度 ３、GitHub地址：https://github.com/allonli/mobile-deep-learning ４、功能特点： 一键部署，脚本参数就可以切换ios或者android 支持iOS gpu运行MobileNet、squeezenet模型 已经测试过可以稳定运行MobileNet、GoogLeNet v1、squeezenet、ResNet-50模型 体积极小，无任何第三方依赖。纯手工打造。 提供量化函数，对32位float转8位uint直接支持，模型体积量化后4M上下 与ARM相关算法团队线上线下多次沟通，针对ARM平台会持续优化 NEON使用涵盖了卷积、归一化、池化所有方面的操作 汇编优化，针对寄存器汇编操作具体优化 loop unrolling 循环展开，为提升性能减少不必要的CPU消耗，全部展开判断操作 将大量繁重的计算任务前置到overhead过程 5、框架结构 MDL 框架主要包括：模型转换模块（MDL Converter）、模型加载模块（Loader）、网络管理模块（Net）、矩阵运算模块（Gemmers）及供 Android 端调用的 JNI 接口层（JNI Interfaces）。 ​ 其中，模型转换模块主要负责将Caffe 模型转为 MDL 模型，同时支持将 32bit 浮点型参数量化为 8bit 参数，从而极大地压缩模型体积；模型加载模块主要完成模型的反量化及加载校验、网络注册等过程，网络管理模块主要负责网络中各层 Layer 的初始化及管理工作；MDL 提供了供 Android 端调用的 JNI 接口层，开发者可以通过调用 JNI 接口轻松完成加载及预测过程。 6、MDL 的性能及兼容性 体积 armv7 300k+ 速度 iOS GPU mobilenet 可以达到 40ms、squeezenet 可以达到 30ms ​ MDL 从立项到开源，已经迭代了一年多。移动端比较关注的多个指标都表现良好，如体积、功耗、速度。百度内部产品线在应用前也进行过多次对比，和已开源的相关项目对比，MDL 能够在保证速度和能耗的同时支持多种深度学习模型，如 mobilenet、googlenet v1、squeezenet 等，且具有 iOS GPU 版本，squeezenet 一次运行最快可以达到 3-40ms。 同类框架对比 ​ 框架Caffe2TensorFlowncnnMDL(CPU)MDL(GPU)硬件CPUCPUCPUCPUGPU速度慢慢快快极快体积大大小小小兼容Android&amp;iOSAndroid&amp;iOSAndroid&amp;iOSAndroid&amp;iOSiOS ​ 与支持 CNN 的移动端框架对比，MDL 速度快、性能稳定、兼容性好、demo 完备。 兼容性 ​ MDL 在 iOS 和 Android 平台均可以稳定运行，其中 iOS10 及以上平台有基于 GPU 运算的 API，性能表现非常出色，在 Android 平台则是纯 CPU 运行。高中低端机型运行状态和手机百度及其他 App 上的覆盖都有绝对优势。 ​ MDL 同时也支持 Caffe 模型直接转换为 MDL 模型。 17.7.5 Paddle-Mobile１、开源时间：持续更新，已到3.0版本 ２、开源用户：百度 ３、GitHub地址：https://github.com/PaddlePaddle/paddle-mobile ４、功能特点： 功能特点 高性能支持ARM CPU 支持Mali GPU 支持Andreno GPU 支持苹果设备的GPU Metal实现 支持ZU5、ZU9等FPGA开发板 支持树莓派等arm-linux开发板 17.7.6 MACE（ Mobile AI Compute Engine）１、开源时间：2018年4月(持续更新，v0.9.0 (2018-07-20)) ２、开源用户：小米 ３、GitHub地址：https://github.com/XiaoMi/mace ４、简介：Mobile AI Compute Engine (MACE) 是一个专为移动端异构计算设备优化的深度学习前向预测框架。MACE覆盖了常见的移动端计算设备（CPU，GPU和DSP），并且提供了完整的工具链和文档，用户借助MACE能够很方便地在移动端部署深度学习模型。MACE已经在小米内部广泛使用并且被充分验证具有业界领先的性能和稳定性。 5、MACE的基本框架： MACE Model MACE定义了自有的模型格式（类似于Caffe2），通过MACE提供的工具可以将Caffe和TensorFlow的模型 转为MACE模型。 MACE Interpreter MACE Interpreter主要负责解析运行神经网络图（DAG）并管理网络中的Tensors。 Runtime CPU/GPU/DSP Runtime对应于各个计算设备的算子实现。 6、MACE使用的基本流程 1. 配置模型部署文件(.yml) 模型部署文件详细描述了需要部署的模型以及生成库的信息，MACE根据该文件最终生成对应的库文件。 2.编译MACE库 编译MACE的静态库或者动态库。 3.转换模型 将TensorFlow 或者 Caffe的模型转为MACE的模型。 4.1. 部署 根据不同使用目的集成Build阶段生成的库文件，然后调用MACE相应的接口执行模型。 4.2. 命令行运行 MACE提供了命令行工具，可以在命令行运行模型，可以用来测试模型运行时间，内存占用和正确性。 4.3. Benchmark MACE提供了命令行benchmark工具，可以细粒度的查看模型中所涉及的所有算子的运行时间。 7、MACE在哪些角度进行了优化? MACE 专为移动端异构计算平台优化的神经网络计算框架。主要从以下的角度做了专门的优化： 性能 代码经过NEON指令，OpenCL以及Hexagon HVX专门优化，并且采用Winograd算法来进行卷积操作的加速。此外，还对启动速度进行了专门的优化。 功耗 支持芯片的功耗管理，例如ARM的big.LITTLE调度，以及高通Adreno GPU功耗选项。 系统响应 支持自动拆解长时间的OpenCL计算任务，来保证UI渲染任务能够做到较好的抢占调度，从而保证系统UI的相应和用户体验。 内存占用 通过运用内存依赖分析技术，以及内存复用，减少内存的占用。另外，保持尽量少的外部依赖，保证代码尺寸精简。 模型加密与保护 模型保护是重要设计目标之一。支持将模型转换成C++代码，以及关键常量字符混淆，增加逆向的难度。 硬件支持范围 支持高通，联发科，以及松果等系列芯片的CPU，GPU与DSP(目前仅支持Hexagon)计算加速。 同时支持在具有POSIX接口的系统的CPU上运行。 8、性能对比： MACE 支持 TensorFlow 和 Caffe 模型，提供转换工具，可以将训练好的模型转换成专有的模型数据文件，同时还可以选择将模型转换成C++代码，支持生成动态库或者静态库，提高模型保密性。 17.7.7 FeatherCNN１、开源时间：持续更新，已到3.0版本 ２、开源用户：腾讯AI ３、GitHub地址：https://github.com/Tencent/FeatherCNN ４、功能特点： FeatherCNN 是由腾讯 AI 平台部研发的基于 ARM 架构的高效 CNN 推理库，该项目支持 Caffe 模型，且具有高性能、易部署、轻量级三大特性。 该项目具体特性如下： 高性能：无论是在移动设备（iOS / Android），嵌入式设备（Linux）还是基于 ARM 的服务器（Linux）上，FeatherCNN 均能发挥最先进的推理计算性能； 易部署：FeatherCNN 的所有内容都包含在一个代码库中，以消除第三方依赖关系。因此，它便于在移动平台上部署。FeatherCNN 自身的模型格式与 Caffe 模型完全兼容。 轻量级：编译后的 FeatherCNN 库的体积仅为数百 KB。 17.7.8 TensorFlow Lite１、开源时间：2017年11月 ２、开源用户：谷歌 ３、GitHub地址：https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite ４、简介： Google 表示 Lite 版本 TensorFlow 是 TensorFlow Mobile 的一个延伸版本。此前，通过TensorFlow Mobile API，TensorFlow已经支持手机上的模型嵌入式部署。TensorFlow Lite应该被视为TensorFlow Mobile的升级版。 TensorFlow Lite可以与Android 8.1中发布的神经网络API完美配合，即便在没有硬件加速时也能调用CPU处理，确保模型在不同设备上的运行。 而Android端版本演进的控制权是掌握在谷歌手中的，从长期看，TensorFlow Lite会得到Android系统层面上的支持。 5、架构： 其组件包括： TensorFlow 模型（TensorFlow Model）：保存在磁盘中的训练模型。 TensorFlow Lite 转化器（TensorFlow Lite Converter）：将模型转换成 TensorFlow Lite 文件格式的项目。 TensorFlow Lite 模型文件（TensorFlow Lite Model File）：基于 FlatBuffers，适配最大速度和最小规模的模型。 6、移动端开发步骤： Android Studio 3.0, SDK Version API26, NDK Version 14 步骤： 将此项目导入到Android Studio：https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/java/demo 下载移动端的模型（model）和标签数据（lables）：https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_224_android_quant_2017_11_08.zip 下载完成解压mobilenet_v1_224_android_quant_2017_11_08.zip文件得到一个xxx.tflite和labes.txt文件，分别是模型和标签文件，并且把这两个文件复制到assets文件夹下。 构建app，run…… 17.7.9 TensorFlow Lite和TensorFlow Mobile的区别？ TensorFlow Lite是TensorFlow Mobile的进化版。 在大多数情况下，TensorFlow Lite拥有跟小的二进制大小，更少的依赖以及更好的性能。 相比TensorFlow Mobile是对完整TensorFlow的裁减，TensorFlow Lite基本就是重新实现了。从内部实现来说，在TensorFlow内核最基本的OP，Context等数据结构，都是新的。从外在表现来说，模型文件从PB格式改成了FlatBuffers格式，TensorFlow的size有大幅度优化，降至300K，然后提供一个converter将普通TensorFlow模型转化成TensorFlow Lite需要的格式。因此，无论从哪方面看，TensorFlow Lite都是一个新的实现方案。 17.7.9 PocketFlow１、开源时间：2018年9月 ２、开源用户：腾讯 ３、GitHub地址：https://github.com/Tencent/PocketFlow ４、简介： 全球首个自动模型压缩框架 一款面向移动端AI开发者的自动模型压缩框架，集成了当前主流的模型压缩与训练算法，结合自研超参数优化组件实现了全程自动化托管式的模型压缩与加速。开发者无需了解具体算法细节，即可快速地将AI技术部署到移动端产品上，实现了自动托管式模型压缩与加速，实现用户数据的本地高效处理。 5、框架介绍 PocketFlow 框架主要由两部分组件构成，分别是模型压缩/加速算法组件和超参数优化组件，具体结构如下图所示。 ​ 开发者将未压缩的原始模型作为 PocketFlow 框架的输入，同时指定期望的性能指标，例如模型的压缩和/或加速倍数；在每一轮迭代过程中，超参数优化组件选取一组超参数取值组合，之后模型压缩/加速算法组件基于该超参数取值组合，对原始模型进行压缩，得到一个压缩后的候选模型；基于对候选模型进行性能评估的结果，超参数优化组件调整自身的模型参数，并选取一组新的超参数取值组合，以开始下一轮迭代过程；当迭代终止时，PocketFlow 选取最优的超参数取值组合以及对应的候选模型，作为最终输出，返回给开发者用作移动端的模型部署。 6、PocketFlow如何实现模型压缩与加速？ ​ 具体地，PocketFlow 通过下列各个算法组件的有效结合，实现了精度损失更小、自动化程度更高的深度学习模型的压缩与加速： a) 通道剪枝（channel pruning）组件：在CNN网络中，通过对特征图中的通道维度进行剪枝，可以同时降低模型大小和计算复杂度，并且压缩后的模型可以直接基于现有的深度学习框架进行部署。在CIFAR-10图像分类任务中，通过对 ResNet-56 模型进行通道剪枝，可以实现2.5倍加速下分类精度损失0.4%，3.3倍加速下精度损失0.7%。 b) 权重稀疏化（weight sparsification）组件：通过对网络权重引入稀疏性约束，可以大幅度降低网络权重中的非零元素个数；压缩后模型的网络权重可以以稀疏矩阵的形式进行存储和传输，从而实现模型压缩。对于 MobileNet 图像分类模型，在删去50%网络权重后，在 ImageNet 数据集上的 Top-1 分类精度损失仅为0.6%。 c) 权重量化（weight quantization）组件：通过对网络权重引入量化约束，可以降低用于表示每个网络权重所需的比特数；团队同时提供了对于均匀和非均匀两大类量化算法的支持，可以充分利用 ARM 和 FPGA 等设备的硬件优化，以提升移动端的计算效率，并为未来的神经网络芯片设计提供软件支持。以用于 ImageNet 图像分类任务的 ResNet-18 模型为例，在8比特定点量化下可以实现精度无损的4倍压缩。 d)网络蒸馏（network distillation）组件：对于上述各种模型压缩组件，通过将未压缩的原始模型的输出作为额外的监督信息，指导压缩后模型的训练，在压缩/加速倍数不变的前提下均可以获得0.5%-2.0%不等的精度提升。 e) 多GPU训练（multi-GPU training）组件：深度学习模型训练过程对计算资源要求较高，单个GPU难以在短时间内完成模型训练，因此团队提供了对于多机多卡分布式训练的全面支持，以加快使用者的开发流程。无论是基于 ImageNet 数据的Resnet-50图像分类模型还是基于 WMT14 数据的 Transformer 机器翻译模型，均可以在一个小时内训练完毕。[1] f) 超参数优化（hyper-parameter optimization）组件：多数开发者对模型压缩算法往往不甚了解，但超参数取值对最终结果往往有着巨大的影响，因此团队引入了超参数优化组件，采用了包括强化学习等算法以及 AI Lab 自研的 AutoML 自动超参数优化框架来根据具体性能需求，确定最优超参数取值组合。例如，对于通道剪枝算法，超参数优化组件可以自动地根据原始模型中各层的冗余程度，对各层采用不同的剪枝比例，在保证满足模型整体压缩倍数的前提下，实现压缩后模型识别精度的最大化。 7、PocketFlow 性能 ​ 通过引入超参数优化组件，不仅避免了高门槛、繁琐的人工调参工作，同时也使得 PocketFlow 在各个压缩算法上全面超过了人工调参的效果。以图像分类任务为例，在 CIFAR-10 和 ImageNet 等数据集上，PocketFlow 对 ResNet 和 MobileNet 等多种 CNN 网络结构进行有效的模型压缩与加速。 ​ 在 CIFAR-10 数据集上，PocketFlow 以 ResNet-56 作为基准模型进行通道剪枝，并加入了超参数优化和网络蒸馏等训练策略，实现了 2.5 倍加速下分类精度损失 0.4%，3.3 倍加速下精度损失 0.7%，且显著优于未压缩的 ResNet-44 模型； 在 ImageNet 数据集上，PocketFlow 可以对原本已经十分精简的 MobileNet 模型继续进行权重稀疏化，以更小的模型尺寸取得相似的分类精度；与 Inception-V1、ResNet-18 等模型相比，模型大小仅为后者的约 20~40%，但分类精度基本一致（甚至更高）。 相比于费时费力的人工调参，PocketFlow 框架中的 AutoML 自动超参数优化组件仅需 10余次迭代就能达到与人工调参类似的性能，在经过 100 次迭代后搜索得到的超参数组合可以降低约 0.6%的精度损失；通过使用超参数优化组件自动地确定网络中各层权重的量化比特数，PocketFlow 在对用于 ImageNet 图像分类任务的ResNet-18 模型进行压缩时，取得了一致性的性能提升；当平均量化比特数为 4 比特时，超参数优化组件的引入可以将分类精度从 63.6%提升至 68.1%（原始模型的分类精度为 70.3%）。 参考文献 [1] Zhuangwei Zhuang, Mingkui Tan, Bohan Zhuang, Jing Liu, Jiezhang Cao, Qingyao Wu, Junzhou Huang, Jinhui Zhu,「Discrimination-aware Channel Pruning for Deep Neural Networks”, In Proc. of the 32nd Annual Conference on Neural Information Processing Systems, NIPS ‘18, Montreal, Canada, December 2018. [2] Jiaxiang Wu, Weidong Huang, Junzhou Huang, Tong Zhang,「Error Compensated Quantized SGD and its Applications to Large-scale Distributed Optimization」, In Proc. of the 35th International Conference on Machine Learning, ICML’18, Stockholm, Sweden, July 2018. 17.7.10 其他几款支持移动端深度学习的开源框架https://blog.csdn.net/zchang81/article/details/74280019 17.7.11 MDL、NCNN和 TFLite比较百度-MDL框架、腾讯-NCNN框架和谷歌TFLite框架比较。 MDL NCNN TFLite 代码质量 中 高 很高 跨平台 √ √ √ 支持caffe模型 √ √ × 支持TensorFlow模型 × × √ CPU NEON指令优化 √ √ √ GPU加速 √ × × 相同点： 只含推理（inference）功能，使用的模型文件需要通过离线的方式训练得到。 最终生成的库尺寸较小，均小于500kB。 为了提升执行速度，都使用了ARM NEON指令进行加速。 跨平台，iOS和Android系统都支持。 不同点： MDL和NCNN均是只支持Caffe框架生成的模型文件，而TfLite则毫无意外的只支持自家大哥TensorFlow框架生成的模型文件。 MDL支持利用iOS系统的Matal框架进行GPU加速，能够显著提升在iPhone上的运行速度，达到准实时的效果。而NCNN和TFLite还没有这个功能。 17.8 移动端开源框架部署17.8.1 以NCNN为例部署步骤 17.8.2 以QNNPACK为例部署步骤 17.8.4 在Android手机上使用MACE实现图像分类17.8.3 在Android手机上使用PaddleMobile实现图像分类编译paddle-mobile库 1）编译Android能够使用的CPP库：编译Android的paddle-mobile库，可选择使用Docker编译和Ubuntu交叉编译，这里介绍使用Ubuntu交叉编译paddle-mobile库。 注：在Android项目，Java代码调用CPP代码，CPP的函数需要遵循一定的命名规范，比如Java_包名_类名_对应的Java的方法名。 ​ 目前官方提供了5个可以给Java调用的函数，该代码在：paddle-mobile/src/jni/paddle_mobile_jni.cpp，如果想要让这些函数能够在自己的包名下的类调用，就要修改CPP的函数名称修改如下： 123456JNIEXPORT jboolean JNICALL Java_com_baidu_paddle_PML_load(JNIEnv *env, jclass thiz, jstring modelPath) &#123; ANDROIDLOGI("load invoked"); bool optimize = true; return getPaddleMobileInstance()-&gt;Load(jstring2cppstring(env, modelPath), optimize); &#125; ​ 笔者项目的包名为com.example.paddlemobile1，在这个包下有一个ImageRecognition.java的程序来对应这个CPP程序，那么修改load函数如下： 12345678JNIEXPORT jboolean JNICALL Java_com_example_paddlemobile1_ImageRecognition_load(JNIEnv *env, jclass thiz, jstring modelPath) &#123; ANDROIDLOGI("load invoked"); bool optimize = true; return getPaddleMobileInstance()-&gt;Load(jstring2cppstring(env, modelPath), optimize);&#125; 使用Ubuntu交叉编译paddle-mobile库 1、下载和解压NDK。 12wget https://dl.google.com/android/repository/android-ndk-r17b-linux-x86_64.zipunzip android-ndk-r17b-linux-x86_64.zip 2、设置NDK环境变量，目录是NDK的解压目录。 1export NDK_ROOT=&quot;/home/test/paddlepaddle/android-ndk-r17b&quot; 设置好之后，可以使用以下的命令查看配置情况。 root@test:/home/test/paddlepaddle# echo $NDK_ROOT /home/test/paddlepaddle/android-ndk-r17b 3、安装cmake，需要安装较高版本的，笔者的cmake版本是3.11.2。 下载cmake源码 1wget https://cmake.org/files/v3.11/cmake-3.11.2.tar.gz 解压cmake源码 1tar -zxvf cmake-3.11.2.tar.gz 进入到cmake源码根目录，并执行bootstrap。 12cd cmake-3.11.2./bootstrap 最后执行以下两条命令开始安装cmake。 12makemake install 安装完成之后，可以使用cmake –version是否安装成功. 1234root@test:/home/test/paddlepaddle# cmake --versioncmake version 3.11.2CMake suite maintained and supported by Kitware (kitware.com/cmake). 4、克隆paddle-mobile源码。 1git clone https://github.com/PaddlePaddle/paddle-mobile.git 5、进入到paddle-mobile的tools目录下，执行编译。 12cd paddle-mobile/tools/sh build.sh android （可选）如果想编译针对某一个网络编译更小的库时，可以在命令后面加上相应的参数，如下： 1sh build.sh android googlenet 6、最后会在paddle-mobile/build/release/arm-v7a/build目录下生产paddle-mobile库。 12root@test:/home/test/paddlepaddle/paddle-mobile/build/release/arm-v7a/build# lslibpaddle-mobile.so libpaddle-mobile.so就是我们在开发Android项目的时候使用到的paddle-mobile库。 创建Android项目 1、首先使用Android Studio创建一个普通的Android项目，包名为com.example.paddlemobile1 2、在main目录下创建l两个assets/paddle_models文件夹，这个文件夹存放PaddleFluid训练好的预测模型。PaddleMobile支持量化模型，使用模型量化可以把模型缩小至原来的四分之一，如果使用量化模型，那加载模型的接口也有修改一下，使用以下的接口加载模型： 1public static native boolean loadQualified(String modelDir); 3、在main目录下创建一个jniLibs文件夹，这个文件夹是存放CPP编译库的，在本项目中就存放上一部分编译的libpaddle-mobile.so 4、在Android项目的配置文件夹中加上权限声明，因为我们要使用到读取相册和使用相机，所以加上以下的权限声明： 123&lt;uses-permission android:name="android.permission.CAMERA" /&gt;&lt;uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" /&gt;&lt;uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE" /&gt; 5、修改activity_main.xml界面，修改成如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;RelativeLayout xmlns:android="http://schemas.android.com/apk/res/android" xmlns:app="http://schemas.android.com/apk/res-auto" xmlns:tools="http://schemas.android.com/tools" android:layout_width="match_parent" android:layout_height="match_parent" tools:context=".MainActivity"&gt;&lt;LinearLayout android:id="@+id/btn_ll" android:layout_alignParentBottom="true" android:layout_width="match_parent" android:layout_height="wrap_content" android:orientation="horizontal"&gt; &lt;Button android:id="@+id/use_photo" android:layout_weight="1" android:layout_width="0dp" android:layout_height="wrap_content" android:text="相册" /&gt; &lt;Button android:id="@+id/start_camera" android:layout_weight="1" android:layout_width="0dp" android:layout_height="wrap_content" android:text="拍照" /&gt;&lt;/LinearLayout&gt;&lt;TextView android:layout_above="@id/btn_ll" android:id="@+id/result_text" android:textSize="16sp" android:layout_width="match_parent" android:hint="预测结果会在这里显示" android:layout_height="100dp" /&gt;&lt;ImageView android:layout_alignParentTop="true" android:layout_above="@id/result_text" android:id="@+id/show_image" android:layout_width="match_parent" android:layout_height="match_parent" /&gt;&lt;/RelativeLayout&gt; 6、创建一个ImageRecognition.java的Java程序，这个程序的作用就是调用paddle-mobile/src/jni/paddle_mobile_jni.cpp的函数，对应的是里面的函数。目前支持一下几个接口。 123456789101112131415161718192021222324252627package com.example.paddlemobile1;public class ImageRecognition &#123; // set thread num public static native void setThread(int threadCount);//Load seperated parameterspublic static native boolean load(String modelDir);// load qualified modelpublic static native boolean loadQualified(String modelDir);// Load combined parameterspublic static native boolean loadCombined(String modelPath, String paramPath);// load qualified modelpublic static native boolean loadCombinedQualified(String modelPath, String paramPath);// object detectionpublic static native float[] predictImage(float[] buf, int[]ddims);// predict yuv imagepublic static native float[] predictYuv(byte[] buf, int imgWidth, int imgHeight, int[] ddims, float[]meanValues);// clear modelpublic static native void clear();&#125; 7、然后编写一个PhotoUtil.java的工具类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124package com.example.paddlemobile1;import android.app.Activity;import android.content.Context;import android.content.Intent;import android.database.Cursor;import android.graphics.Bitmap;import android.graphics.BitmapFactory;import android.net.Uri;import android.os.Build;import android.provider.MediaStore;import android.support.v4.content.FileProvider;import android.util.Log;import java.io.File;import java.io.IOException;import java.util.Arrays;public class PhotoUtil &#123;// start camerapublic static Uri start_camera(Activity activity, int requestCode) &#123; Uri imageUri; // save image in cache path File outputImage = new File(activity.getExternalCacheDir(), "out_image.jpg"); try &#123; if (outputImage.exists()) &#123; outputImage.delete(); &#125; outputImage.createNewFile(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; if (Build.VERSION.SDK_INT &gt;= 24) &#123; // compatible with Android 7.0 or over imageUri = FileProvider.getUriForFile(activity, "com.example.paddlemobile1", outputImage); &#125; else &#123; imageUri = Uri.fromFile(outputImage); &#125; // set system camera Action Intent intent = new Intent(MediaStore.ACTION_IMAGE_CAPTURE); // set save photo path intent.putExtra(MediaStore.EXTRA_OUTPUT, imageUri); // set photo quality, min is 0, max is 1 intent.putExtra(MediaStore.EXTRA_VIDEO_QUALITY, 0); activity.startActivityForResult(intent, requestCode); return imageUri;&#125;// get picture in photopublic static void use_photo(Activity activity, int requestCode)&#123; Intent intent = new Intent(Intent.ACTION_PICK); intent.setType("image/*"); activity.startActivityForResult(intent, requestCode);&#125;// get photo from Uripublic static String get_path_from_URI(Context context, Uri uri) &#123; String result; Cursor cursor = context.getContentResolver().query(uri, null, null, null, null); if (cursor == null) &#123; result = uri.getPath(); &#125; else &#123; cursor.moveToFirst(); int idx = cursor.getColumnIndex(MediaStore.Images.ImageColumns.DATA); result = cursor.getString(idx); cursor.close(); &#125; return result;&#125;// Compress the image to the size of the training image，and change RGBpublic static float[] getScaledMatrix(Bitmap bitmap, int desWidth, int desHeight) &#123; float[] dataBuf = new float[3 * desWidth * desHeight]; int rIndex; int gIndex; int bIndex; int[] pixels = new int[desWidth * desHeight]; Bitmap bm = Bitmap.createScaledBitmap(bitmap, desWidth, desHeight, false); bm.getPixels(pixels, 0, desWidth, 0, 0, desWidth, desHeight); int j = 0; int k = 0; for (int i = 0; i &lt; pixels.length; i++) &#123; int clr = pixels[i]; j = i / desHeight; k = i % desWidth; rIndex = j * desWidth + k; gIndex = rIndex + desHeight * desWidth; bIndex = gIndex + desHeight * desWidth; dataBuf[rIndex] = (float) ((clr &amp; 0x00ff0000) &gt;&gt; 16) - 148; dataBuf[gIndex] = (float) ((clr &amp; 0x0000ff00) &gt;&gt; 8) - 148; dataBuf[bIndex] = (float) ((clr &amp; 0x000000ff)) - 148; &#125; if (bm.isRecycled()) &#123; bm.recycle(); &#125; return dataBuf;&#125;// compress picturepublic static Bitmap getScaleBitmap(String filePath) &#123; BitmapFactory.Options opt = new BitmapFactory.Options(); opt.inJustDecodeBounds = true; BitmapFactory.decodeFile(filePath, opt); int bmpWidth = opt.outWidth; int bmpHeight = opt.outHeight; int maxSize = 500; // compress picture with inSampleSize opt.inSampleSize = 1; while (true) &#123; if (bmpWidth / opt.inSampleSize &lt; maxSize || bmpHeight / opt.inSampleSize &lt; maxSize) &#123; break; &#125; opt.inSampleSize *= 2; &#125; opt.inJustDecodeBounds = false; return BitmapFactory.decodeFile(filePath, opt);&#125;&#125; start_camera()方法是启动相机并返回图片的URI。 use_photo()方法是打开相册，获取到的图片URI在回到函数中获取。 get_path_from_URI()方法是把图片的URI转换成绝对路径。 getScaledMatrix()方法是把图片压缩成跟训练时的大小，并转换成预测需要用的数据格式浮点数组。 getScaleBitmap()方法是对图片进行等比例压缩，减少内存的支出。 8、最后修改MainActivity.java，修改如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package com.example.paddlemobile1;import android.Manifest;import android.annotation.SuppressLint;import android.app.Activity;import android.content.Context;import android.content.Intent;import android.content.pm.PackageManager;import android.graphics.Bitmap;import android.net.Uri;import android.os.Bundle;import android.os.Environment;import android.support.annotation.NonNull;import android.support.annotation.Nullable;import android.support.v4.app.ActivityCompat;import android.support.v4.content.ContextCompat;import android.support.v7.app.AppCompatActivity;import android.util.Log;import android.view.View;import android.widget.Button;import android.widget.ImageView;import android.widget.TextView;import android.widget.Toast;import com.bumptech.glide.Glide;import com.bumptech.glide.load.engine.DiskCacheStrategy;import com.bumptech.glide.request.RequestOptions;import java.io.File;import java.io.FileOutputStream;import java.io.InputStream;import java.util.ArrayList;import java.util.Arrays;import java.util.List;public class MainActivity extends AppCompatActivity &#123; private static final String TAG = MainActivity.class.getName(); private static final int USE_PHOTO = 1001; private static final int START_CAMERA = 1002; private Uri image_uri; private ImageView show_image; private TextView result_text; private String assets_path = "paddle_models"; private boolean load_result = false; private int[] ddims = &#123;1, 3, 224, 224&#125;;private static final String[] PADDLE_MODEL = &#123; "lenet", "alexnet", "vgg16", "resnet", "googlenet", "mobilenet_v1", "mobilenet_v2", "inception_v1", "inception_v2", "squeezenet"&#125;;// load paddle-mobile apistatic &#123; try &#123; System.loadLibrary("paddle-mobile"); &#125; catch (SecurityException e) &#123; e.printStackTrace(); &#125; catch (UnsatisfiedLinkError e) &#123; e.printStackTrace(); &#125; catch (NullPointerException e) &#123; e.printStackTrace(); &#125;&#125; 123456789101112131415161718192021222324@Overrideprotected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); init();&#125;// initialize viewprivate void init() &#123; request_permissions(); show_image = (ImageView) findViewById(R.id.show_image); result_text = (TextView) findViewById(R.id.result_text); Button use_photo = (Button) findViewById(R.id.use_photo); Button start_photo = (Button) findViewById(R.id.start_camera); // use photo click use_photo.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View view) &#123; PhotoUtil.use_photo(MainActivity.this, USE_PHOTO); // load_model(); &#125; &#125;); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192 // start camera click start_photo.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View view) &#123; image_uri = PhotoUtil.start_camera(MainActivity.this, START_CAMERA); &#125; &#125;); // copy file from assets to sdcard String sdcard_path = Environment.getExternalStorageDirectory() + File.separator + assets_path; copy_file_from_asset(this, assets_path, sdcard_path); // load model load_model();&#125;// load infer modelprivate void load_model() &#123; String model_path = Environment.getExternalStorageDirectory() + File.separator + assets_path + File.separator + PADDLE_MODEL[4]; Log.d(TAG, model_path); load_result = ImageRecognition.load(model_path); if (load_result) &#123; Log.d(TAG, "model load success"); &#125; else &#123; Log.d(TAG, "model load fail"); &#125;&#125;// clear infer modelprivate void clear_model() &#123; ImageRecognition.clear(); Log.d(TAG, "model is clear");&#125;// copy file from asset to sdcardpublic void copy_file_from_asset(Context context, String oldPath, String newPath) &#123; try &#123; String[] fileNames = context.getAssets().list(oldPath); if (fileNames.length &gt; 0) &#123; // directory File file = new File(newPath); if (!file.exists()) &#123; file.mkdirs(); &#125; // copy recursivelyC for (String fileName : fileNames) &#123; copy_file_from_asset(context, oldPath + "/" + fileName, newPath + "/" + fileName); &#125; Log.d(TAG, "copy files finish"); &#125; else &#123; // file File file = new File(newPath); // if file exists will never copy if (file.exists()) &#123; return; &#125; // copy file to new path InputStream is = context.getAssets().open(oldPath); FileOutputStream fos = new FileOutputStream(file); byte[] buffer = new byte[1024]; int byteCount; while ((byteCount = is.read(buffer)) != -1) &#123; fos.write(buffer, 0, byteCount); &#125; fos.flush(); is.close(); fos.close(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125;@Overrideprotected void onActivityResult(int requestCode, int resultCode, @Nullable Intent data) &#123; String image_path; RequestOptions options = new RequestOptions().skipMemoryCache(true).diskCacheStrategy(DiskCacheStrategy.NONE); if (resultCode == Activity.RESULT_OK) &#123; switch (requestCode) &#123; case USE_PHOTO: if (data == null) &#123; Log.w(TAG, "user photo data is null"); return; &#125; image_uri = data.getData(); Glide.with(MainActivity.this).load(image_uri).apply(options).into(show_image); // get image path from uri image_path = PhotoUtil.get_path_from_URI(MainActivity.this, image_uri); // show result result_text.setText(image_path); // predict image predict_image(PhotoUtil.get_path_from_URI(MainActivity.this, image_uri)); break; case START_CAMERA: // show photo Glide.with(MainActivity.this).load(image_uri).apply(options).into(show_image); // get image path from uri image_path = PhotoUtil.get_path_from_URI(MainActivity.this, image_uri); // show result result_text.setText(image_path); // predict image predict_image(PhotoUtil.get_path_from_URI(MainActivity.this, image_uri)); break; &#125; &#125;&#125;@SuppressLint("SetTextI18n")private void predict_image(String image_path) &#123; // picture to float array Bitmap bmp = PhotoUtil.getScaleBitmap(image_path); float[] inputData = PhotoUtil.getScaledMatrix(bmp, ddims[2], ddims[3]); try &#123; long start = System.currentTimeMillis(); // get predict result float[] result = ImageRecognition.predictImage(inputData, ddims); Log.d(TAG, "origin predict result:" + Arrays.toString(result)); long end = System.currentTimeMillis(); long time = end - start; Log.d("result length", String.valueOf(result.length)); // show predict result and time int r = get_max_result(result); String show_text = "result：" + r + "\nprobability：" + result[r] + "\ntime：" + time + "ms"; result_text.setText(show_text); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125;private int get_max_result(float[] result) &#123; float probability = result[0]; int r = 0; for (int i = 0; i &lt; result.length; i++) &#123; if (probability &lt; result[i]) &#123; probability = result[i]; r = i; &#125; &#125; return r;&#125;// request permissionsprivate void request_permissions() &#123; List&lt;String&gt; permissionList = new ArrayList&lt;&gt;(); if (ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) &#123; permissionList.add(Manifest.permission.CAMERA); &#125; if (ContextCompat.checkSelfPermission(this, Manifest.permission.WRITE_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED) &#123; permissionList.add(Manifest.permission.WRITE_EXTERNAL_STORAGE); &#125; if (ContextCompat.checkSelfPermission(this, Manifest.permission.READ_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED) &#123; permissionList.add(Manifest.permission.READ_EXTERNAL_STORAGE); &#125; // if list is not empty will request permissions if (!permissionList.isEmpty()) &#123; ActivityCompat.requestPermissions(this, permissionList.toArray(new String[permissionList.size()]), 1); &#125;&#125;@Overridepublic void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) &#123; super.onRequestPermissionsResult(requestCode, permissions, grantResults); switch (requestCode) &#123; case 1: if (grantResults.length &gt; 0) &#123; for (int i = 0; i &lt; grantResults.length; i++) &#123; int grantResult = grantResults[i]; if (grantResult == PackageManager.PERMISSION_DENIED) &#123; String s = permissions[i]; Toast.makeText(this, s + " permission was denied", Toast.LENGTH_SHORT).show(); &#125; &#125; &#125; break; &#125;&#125;@Overrideprotected void onDestroy() &#123; // clear model before destroy app clear_model(); super.onDestroy();&#125;&#125; load_model()方法是加载预测模型的。 clear_model()方法是清空预测模型的。 copy_file_from_asset()方法是把预测模型复制到内存卡上。 predict_image()方法是预测图片的。 get_max_result()方法是获取概率最大的预测结果。 request_permissions()方法是动态请求权限的。 因为使用到图像加载框架Glide，所以要在build.gradle加入以下的引用。 1implementation &apos;com.github.bumptech.glide:glide:4.3.1&apos; 8、最后运行项目，选择图片预测就会得到结果。 17.9 移动端开源框架部署疑难增加常见的几个问题]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习 NLP]]></title>
    <url>%2F2017%2F12%2F29%2F%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0_NLP%2F</url>
    <content type="text"><![CDATA[123Markdown Revision 1;Editor: 盛泳潘-电子科技大学;何建宏-学生Contact: shengyp2011@163.com;Bonopengate@gmail.com 16.0 NLP 发展史简述50多年来 NLP 的历史发展可以分为三个浪潮，前两波以理性主义和经验主义的形式出现，为当前的深度学习浪潮铺平了道路。NLP的深层学习革命的主要支柱是: （1）语言嵌入实体的分布式表征，（2）由于嵌入而产生的语义泛化， （3）自然语言的大跨度深序列建模，（4）能够从低到高表示语言层次的分层网络，以及（5）解决许多联合 NLP 问题的端对端深度学习方法。 第一个浪潮：理性主义在第一个浪潮中，NLP的实验持续了很长一段时间，可以追溯到20世纪50年代。1950年，阿兰·图灵提出了图灵测试，以评估计算机表现出与人类无法区分的智能行为的能力。这项测试是基于人类和计算机之间的自然语言对话，旨在生成类似人类的反应。1954年，George-IBM 实验产出了能够将60多个俄语句子翻译成英语的rrst机器翻译系统。 这些方法是基于这样一种信念，即人类思维中的语言知识是由泛型继承提前进行的，而这种信念，在大约1960年至1980年代后期，占据了NLP的大部分研究中的主导地位。这些方法被称为理性主义方法（Church 2007）。理性主义方法在 NLP 中的主导地位主要是由于诺姆·乔姆斯基（Noam Chomsky）关于先天语言结构的论点被广泛接受以及他对 N-grams 方法的批评（Chomsky 1957）。理性主义者一般假设语言的关键部分在出生时就被硬连接到大脑中，作为人类遗传遗传的一部分，因此他们试图设计手工制作的规则，将知识和推理机制纳入智能 NLP 系统。直到20世纪80年代，最著名的成功的NLP系统，如为模拟 Rogerian psychotherapist 的 ELIZA 系统和为了规则化真实世界信息为规则本体的 MARGIE 系统，都是基于复杂的手写规则。 这一时期恰逢以专家知识工程为特点的早期智能的早期发展，即领域专家根据其所掌握的（非常狭窄的）应用领域的知识设计计算机程序（Nilsson 1982; Winston 1993）。专家们使用符号逻辑规则设计了这些程序，这些规则基于对这些知识的仔细表征和工程。这些以知识为基础的智能系统往往通过检测”Head”或最重要的参数，并就每种特殊情况采取特定的解决办法，而这在解决狭义问题方面往往是有效的。这些“Head”参数由人类专家预先确定，使“tail”参数和案例不受影响。由于缺乏学习能力，他们有必要将解决方案推广到新的情况和领域。这一时期的典型方法是专家系统所提供的证据，这是一个模拟人类专家决策能力的计算机系统。这种系统旨在通过知识推理来解决复杂的问题（Nilsson 1982）。第一个专家系统建立于1970年代，然后在1980年代推广。使用的主要”算法”是以”if-then-else”为形式的推断规则（Jackson 1998）。这些智能系统的主要优点是其在进行逻辑推理方面（有限）能力的透明度和可解释性。像NLP系统，如 ELIZA 和 MARGIE ，一般专家系统在早期使用手工制作的专家知识，这往往是有效的狭隘的问题，虽然推理无法处理不确定性，是普遍存在的实际应用。 同样，语音识别研究和系统设计，这又是另一个长期存在的 NLP 和反智能挑战，在这个理性主义时代，主要基于专家知识工程的范式，如elegantly analyzed in（Church and Mercer 1993）。在1970年代和1980年代初，专家系统的语音识别方法相当流行（Reddy 1976; Zue 1985）。然而，研究人员敏锐地认识到，缺乏从数据中学习和处理推理不确定性的能力，导致了接下来描述的第二波语音识别、NLP和对于文本的人工智能浪潮也走向失败。 第二波浪潮：经验主义第二波 NLP 浪潮的特点是利用语料库数据以及基于（浅层）机器学习、统计学等来利用这些数据（Manning and Schtze 1999）。由于许多自然语言的结构和理论都被贬低或抛弃，而倾向于数据驱动的方法，这个时代发展的主要方法被称为经验或务实的方法（ChurchandMercer 1993;Church 2014）。NLP 的一个主要会议甚至被命名为“自然语言处理的经验方法（Empirical Methods in Natural Language Processing）（EMNLP）”，最直接地反映了NLP研究人员在那个时代对经验方法的强烈积极情绪。 与理性主义方法相反，经验方法认为人类的思维只是从关联、模式识别和泛化的常规操作开始。丰富的感官输入需要使大脑学习自然语言的详细结构。经验主义盛行于1920年至1960年间，自1990年以来一直在兴起。NLP的早期经验方法主要是开发生成模型，如隐马尔可夫模型 （HMM） （Baum and Petrie 1966）， IBM 翻译模型 （Brown et al. 1993）， 和 head-driven parsing 模型（Collins 1997），以发现大型语料库的规律性。自1990年代后期以来，在各种NLP任务中，歧视性模式已成为事实上的做法。NLP的典型判别模型和方法包括最大熵模型（ratnaparkhi 1997）、支持向量机（Vapnik 1998）、条件随机（Lafferty et al. 2001）、最大相互信息和最小区分器错误（He et al. 2008）还有感知器（Collins 2002）。 在这种经验主义时代中、NLP 与同样的智能方法如语音识别和计算机视觉是平行的。这是在明确的证据表明，学习和感知能力对复杂的智能系统至关重要，但在前一波流行的专家系统中却不存在。例如，当 DARPA 开始对自动驾驶提出重大挑战时，大多数车辆随后依赖于基于知识的智能智能。正如语音识别和NLP 一样，自主驾驶和计算机视觉研究人员意识到基于知识的范式的局限性，因为机器学习需要进行不确定性处理和泛化能力。 在第二波浪潮中，NLP的经验主义和语音识别是基于数据密集型机器学习的，我们现在称之为“shallow”，因为在下一节中描述的第三波浪潮中，数据的多层或“deep”表征通常缺乏抽象结构。在机器学习中，在第一次浪潮中，研究人员不需要考虑构造精确规则，为知识为基础的 NLP 和语音系统。相反，他们把重点放在统计模型（Bishop 2006; Murphy 2012）或作为一个基本引擎的简单的神经网络（Bishop 1995）。然后，他们使用足够的训练数据进行自动学习或“tune（调整）”系统的参数，使它们能够处理不确定性，并尝试从一个条件泛化到另一个条件，从一个领域泛化到另一个领域。机器学习的关键算法和方法包括EM （期望最大化）、贝叶斯网络、支持向量机、决策树以及神经网络的反向传播算法。 一般来说，基于机器学习的NLP、语音和其他智能系统的性能比早期的基于知识的智能系统要好得多。成功的例子包括语音识别 （Jelinek 1998）， 脸部识别 （Viola and Jones 2004）， 实体识别 （Fei-Fei and Perona 2005）， 手写字体识别 （Plamondon and Srihari 2000）， 以及机器翻译 （Och 2003）。 在语音识别方面，从20世纪80年代初到2010年前后近30年，利用基于 HMM 与高斯混合模型相结合的统计生成模型，以及其推广的各种版本（Baker et al. 2009a，b; Deng and O’Shaughnessy 2003; Rabiner and Juang 1993）的统计生成模式。泛化 HMM 的许多版本都是基于统计和神经网络的隐动态模型（Deng 1998; Bridle et al. 1998; Deng and Yu 2007）。前者采用 EM 和 switching extended Kalman ﬁlter 算法学习模型参数（Ma and Deng 2004; Lee et al. 2004），后者采用反向传播（Picone et al. 1999），两者都广泛地利用多个潜在层表示法进行语音分析的生成过程。将这种“深度”生成过程转化为端到端过程的对应方案，导致了深度学习的工业化成功（Deng et al. 2010， 2013; Hinton et al. 2012） ，从而形成了第三波浪潮的驱动力。 第三波浪潮：深度学习在第二波浪潮中开发的 NLP 系统，包括语音识别、语言理解和机器翻译，表现得比在第一波浪潮时更好，鲁棒性更高，但它们远远没有达到人的水平，而这留下了很多需求。除了少数例外，NLP的（浅层）机器学习模型通常没有足够的容量来吸收大量的训练数据。此外，学习算法、方法和基础设施也都不够强大。所有这一切都在几年前发生了变化，而这导致了第三波 NLP 浪潮，这股浪潮是由深层机器学习或深度学习的新范式推动的（Bengio 2009; Deng and Yu 2014; LeCun et al. 2015; Goodfellow et al. 2016）。 深度学习起源于人工神经网络，它可以被看作是受生物神经系统启发的细胞类型的级联模型。随着反向传播算法的出现（Rumelhart et al. 1986），90年代对深度神经网络的训练引起了广泛关注。在没有大量训练数据和没有适当的设计和学习范式的情况下，在神经网络训练过程中，学习信号随着层次数（或更严格的信用分配深度）在层层传播时呈指数形式消失，使得调整深层神经网络特别是递归的版本的连接权重变得异常艰难。Hinton 等人（2006）克服了这个问题，使用无人监督的预训练模型来进行学习有用的特征探测器。然后，通过监督学习进一步训练网络，对标记数据进行分类。因此，可以学习使用低维表征的方式来学习高维的表征的分布。这项开创性的工作标志着神经网络的复兴。此后提出和发展了各种网络结构，包括 Deep Belief 网络（Hinton et al.2006）、堆积自编码器（Vincent et al.2010）、深层玻尔兹曼机（Hinton and Salakhutdinov 2012）、深度卷积神经网络（Krizhevsky et al. 2012），深层堆积网络 （Deng et al. 2012），和深层 Q-networks （Mnih et al. 2015）。深度学习自2010年以来已成功地应用于实际智能领域的实际任务，包括语音识别（Yu et al. 2010; Hinton et al. 2012），图像识别（Krizhevsky et al. 2012; He et al. 2016），以及 NLP 绝大多数领域。 其中由于微软公司在工业化上的成功，以及愈来愈高的准确率等迹象，这些2010-2011年语音识别的惊人成功预示着 NLP 的第三波浪潮和人工智能的到来。随着深度学习在语音识别方面取得成功，计算机视觉（Krizhevsky et al. 2012）和机器翻译（Bahdanau et al. 2015）被类似的深度学习范式所取代。特别是，虽然 Bengio 等人在2001的工作，在2011年就开发了强大的神经词嵌入技术（Bengio et al. 2001），但由于大数据的可用性和更快的计算，它直到10多年后才被证明在一个大规模和实际有用的规模上才能够实际有用（Mikolov et al. 2013）。此外，许多其他现实世界的NLP应用，如图像字幕（Karpathy and Fei-Fei 2015; Fang et al. 2015; Gan et al. 2017），视觉问题回答（Fei-Fei and Perona 2016），语音理解系统（Mesnil et al. 2013），网络搜索（Huang et al. 2013b）和推荐系统由于深度学习而取得成功，此外还有许多非NLP任务，包括药物发现和药理学、客户关系管理、推荐系统、手势识别、医学信息、广告投放、医学图像分析、机器人、自动驾驶车辆、纸板和电子游戏（例如 Atari， Go， Poker， and the latest， DOTA2）等。详情请参阅维基上的深度学习领域。 在更多基于文本的应用领域中，机器翻译可能受到深度学习的影响最大。从 NLP 第二波浪潮中发展起来的浅层——统计机器翻译开始看起的话，目前在实际应用中最好的机器翻译系统是基于深神经网络的。例如，谷歌在2016年9月宣布了其转向神经机器翻译的阶段，两个月后微软也发布了类似的声明。Facebook已经进行了大约一年的机器神经网络翻译的转换工作，到2017年8月它已经完全将这个系统部署成功。 在口语理解和对话系统领域，深度学习也正在产生巨大影响。目前流行的技术以多种方式维护和扩展了第二波时代浪潮中发展起来的统计方法。与经验（浅层）机器学习方法一样，深度学习也是基于数据密集型方法，以降低手工制作规则的成本，对噪声环境下的语音识别错误和语言理解错误具有很强的鲁棒性，并利用决策过程和强化学习的力量来设计对话策略，例如（Gasic et al. 2017; Dhingra et al. 2017）。与早期的方法相比，深度神经网络模型和表征方法更强大，它们使端到端学习成为可能。然而，深度学习也没有解决可解释性和领域泛化问题。 将深度学习应用于 NLP 问题方面的最近的两个重要技术突破是序列到序列学习（Sutskevar et al. 2014）和注意力机制建模（Bahdanau et al. 2015），以及最近的 BERT模型（Jacob el al.2018） 。序列到序列学习引入了一个强大的学习范式，即使用递归神经网络以端到端的方式进行编码和解码。注意力机制建模最初是为了克服编码一个长序列的难度而开发的，后来的持续发展又扩展了它的能力，提供了两个任意序列的高度可塑对齐能力，而其两个可以同时学习神经网络参数。而 BERT 则是实现了双向建模获取以得到更好的语言表征能力。序列到序列学习和注意力机制的关键概念在基于统计学习和词局部表征的最佳系统上提高了基于分布式单词嵌入的神经机器翻译的性能，而 BERT 更重要的意义是双向获取同一文段的高维意义。在这一成功之后，这些概念也被成功地应用到许多其他与NLP相关的任务中，如图像字幕（Karpathy and Fei-Fei 2015; Devlin et al. 2015）、语音识别（Chorowski et al. 2015）、一次性学习、句法分析、唇读、文本理解、摘要以及问答系统等。撇开他们巨大的经验成功不谈，基于神经网络的深度学习模型往往比早期浪潮中的传统机器学习模型更简单、更容易设计。在许多应用中，在端到端的任务中，模型的所有部分都同时进行深度学习，从特征抽取到预测。导致神经网络模型相对简单的另一个因素是，相同的模型构建成的块（即不同类型的层）通常在许多不同的应用中使用。为多种任务使用相同的构建块，这种方法使得模型更容易迁移到其它任务和数据上。此外，谷歌等公司还开发了软件工具包，以便更快、更有效地实现这些模型。由于以上这些原因，神经网络在数据量大而且基于云的方式上，是更常用的。 尽管深度学习在重塑语音、图像和视频的处理方面被证明是有效的，而且具有它的革命性，但在将深度学习与基于文本的 NLP 相结合方面的有效性并不那么明确，尽管它在一些实用的 NLP 任务中取得了经验上的成功。在语音、图像和视频处理中，深度学习通过直接从原始数据学习规律来解决语义差距问题。然而，在 NLP 中，人们提出了更强的理论和结构化模型，即语音、语法和语义，来提取理解和生成自然语言的基本机制，这些机制与神经网络不那么容易兼容。与语音、图像和视频信号相比，从文本数据中学习的神经表征可以对自然语言提供同样直接的见解，但是这个也不够直接。因此，将神经网络，特别是那些具有复杂层次结构的神经网络应用于 NLP，已成为 NLP 和深度学习社区中最活跃的领域，近年来取得了非常显著的进展（Deng 2016; Manning and Socher 2017;Jacob el al.2018）。 16.1 如何理解序列到序列模型？16.2 序列到序列模型有什么限制吗？16.3 如果不采用序列到序列模型，可以考虑用其它模型方法吗？16.4 如何理解词向量？16.5 词向量哪家好？16.6 解释一下注意力机制的原理？16.7 注意力机制是不是适用于所有场景呢？它的鲁棒性如何？16.8 怎么将原有的模型加上注意力机制呢？16.9 通俗地解释一下词法分析是什么？有什么应用场景？16.10 深度学习中的词法分析有哪些常见模型呢？16.11 通俗地解释一下知识图谱是什么？有什么应用场景？16.12 深度学习中的知识图谱有哪些常见模型呢？16.13 深度学习中的机器翻译有哪些常见模型呢？16.14 机器翻译的通俗实现以及部署过程是怎样的呢？16.15 通俗地解释一下文本情感分析是什么？常见的应用场景是？16.16 最常用的情感分析模型是什么呢？如何快速部署呢？16.17 通俗地解释一下问答系统？它涵盖哪些领域？常见的应用场景是？16.18 常见的问答系统模型是什么？如何快速部署呢？16.19 图像文字生成是什么？它的技术原理是什么？16.20 常见的图像文字生成模型是什么？16.21 NLP 的无监督学习发展动态是怎样的？有哪些领域在尝试无监督学习？16.22 NLP 和强化学习的结合方式是怎样的？有哪些方向在尝试强化学习？16.23 NLP 和元学习？元学习如何能够和 NLP 结合起来？16.24 能说一下各自领域最常用且常见的基准模型有哪些吗？]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异构计算， GPU和框架选型指南]]></title>
    <url>%2F2017%2F12%2F20%2F%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0_%E5%BC%82%E6%9E%84%E8%BF%90%E7%AE%97%E3%80%81GPU%E5%8F%8A%E6%A1%86%E6%9E%B6%E9%80%89%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[深度学习训练和推理的过程中，会涉及到大量的向量(vector)，矩阵(matrix)和张量(tensor)操作，通常需要大量的浮点计算，包括高精度（在训练的时候）和低精度（在推理和部署的时候）。GPU， 作为一种通用可编程的加速器，最初设计是用来进行图形处理和渲染功能，但是从2007年开始，英伟达(NVIDIA)公司提出了第一个可编程通用计算平台（GPGPU），同时提出了CUDA框架，从此开启了GPU用于通用计算的新纪元。此后，不计其数的科研人员和开发者，对各种不同类型的算法用CUDA进行（部分）改写，从而达到几倍到数百倍的加速效果。尤其是在机器学习，特别是深度学习的浪潮来临后，GPU加速已经是各类工具实现的基本底层构架之一。本章里，会简单介绍GPU的基本架构，性能指标，框架选择等等和深度学习相关的内容。 15.1 什么是异构计算？异构计算是基于一个更加朴素的概念，”异构现象“，也就是不同计算平台之间，由于硬件结构（包括计算核心和内存），指令集和底层软件实现等方面的不同而有着不同的特性。异构计算就是使用结合了两个或者多个不同的计算平台，并进行协同运算。比如，比较常见的，在深度学习和机器学习中已经比较成熟的架构：CPU和GPU的异构计算;此外还有比较新的Google推出的协处理器（TPU），根据目的而定制的ASIC，可编程的FPGA等也都是现在在异构计算中使用比较多的协处理器。而，本章中会着重介绍和深度学习共同繁荣的图形加算器，也就是常说的GPU。 15.2 什么是GPGPU？GPU,就如名字所包含的内容，原本开发的目的是为了进行计算机图形渲染，而减少对于CPU的负载。由于图像的原始特性，也就是像素间的独立性，所以GPU在设计的时候就遵从了“单指令流多数据流（SIMD）”架构，使得同一个指令（比如图像的某种变换），可以同时在多一个像素点上进行计算，从而得到比较大的吞吐量，才能使得计算机可以实时渲染比较复杂的2D/3D场景。在最初的应用场景里，GPU并不是作为一种通用计算平台出现的，直到2007年左右，一家伟大的公司—NVIDIA将GPU带到通用计算的世界里，使得其可以在相对比较友好的编程环境（CUDA/OpenCL）里加速通用程序成了可能。从此之后，GPU通用计算(General Purpose Computing on GPU)，也就是GPGPU就成了学界和工业界都频繁使用的技术，在深度学习爆发的年代里，GPGPU成了推动这股浪潮非常重要的力量。 15.3 GPU架构简介GPU，图形显示芯片作为不同于CPU的设计逻辑和应用场景，有着非常不同的架构，理解 GPU 和 CPU 之间区别的一种简单方式是比较它们如何处理任务。CPU 由专为顺序串行处理而优化的几个核心组成，而 GPU 则拥有一个由数以千计的更小、更高效的核心（专为同时处理多重任务而设计）组成的大规模并行计算架构。本部分将简单介绍GPU究竟是如何架构，其中的计算核心有哪些特性。 15.3.1 如何通俗理解GPU的架构？首先，下图简单地展示了几个GPU不同于CPU的特性： 计算核心： 图中的CPU,i7-5960X，Intel的第五代Broadwell架构，其中包括了8个CPU核心(支持16线程)，也就是理论上可以有16个不同的运算同时进行。除了8个核心计算单元，大部分的芯片面积是被3级缓存，内存和控制电路占据了。同样的，来自NVIDIA的GTX980GPU，在差不多的芯片面积上，大部分是计算单元，16个SM，也就是流处理单元，每个流处理单元中包含着128个CUDA计算核心，所以总共来说，有2048个GPU运算单元，相应地这颗GPU理论上可以在一个时钟周期内可以进行2048次单精度运算。 计算核心频率：时钟频率，代表每一秒中内能进行同步脉冲次数，也是从一个侧面反映一个计算元件的工作速度。下图中对比了个别早期产品，比如Intel的X5650和几款NVIDIA的GPU。可以看出核心频率而言，CPU要远高于GPU。对于CPU而言，在不考虑能源消耗和制程工艺限制的情况下，追求更高的主频。但在GPU的设计中，采用了多核心设计，即使是提高一些频率，其实对于总体性能影像不会特别大。当然，其中还有能耗方面的考虑，避免发热过高，也进行了权衡。还有一个可能的原因是，在一个流处理器中的每个核心（CUDA核心）的运行共享非常有限的缓存和寄存器，由于共享内存也是有性能极限的，所以即使每个GPU核心频率提高，如果被缓存等拖累也是无法展现出高性能的。 内存架构：GPU的多层内存架构包括全局内存（也就是通常意义上大部分比较关注的内存，在若干到16GB之间，截至到当前最新），2级缓存，和芯片上的存储（包括寄存器，和1级缓存共用的共享内存，只读/纹理缓存和常量缓存）。通常来说，最高速的共享内存/缓存和寄存器都是非常有限的，比如在Tesla的K20中，只有48K的缓存可以作为共享内存或者1级缓存使用，所以在很多用GPU加速算法实现的过程中，有效地利用这些高速缓存是使得性能提升的非常重要的方面。 15.3.2 CUDA 核心是什么？上面提到在一个GPU芯片里，会很几千个CUDA核心，被分布在多个流处理单元（SM）中，比如上面提到早期的GTX980中的16个SM中各包含了128个CUDA核心。如下图所示，作为GPU架构中的最小单元，其实它的设计和CPU有着非常类似的结构，其中包括了一个浮点运算单元和整型运算单元，和控制单元。同一个流处理器中，所有的CUDA核心将同步执行同一个指令，但是作用于不同的数据点上。 一般来说，更加多的CUDA核心意味着有更多的并行执行单元，所以也就可以片面地认为是有更加高的性能。但是，其实这个也是取决于很多方面，最重要的是算法在并行实现的时候有没有高效地调度和内存的使用优化。在现在我们使用的大部分GPU加速的深度学习框架里，包括Tensorflow，PyTorch等都是依赖于底层的GPU的矩阵加速代码的实现。为此Nvidia公司也是制定和实现了统一的接口，比如cuDNN，方便上层框架更好的利用GPU的性能。 15.3.3 为什么要使用GPU？对于并行计算来说，可以非常粗略地分为： 并行指令： 也就是多个指令可以同时分配到不同的计算核心上同时进行，而他们的操作是不同的，并且他们之间相互独立，不需要额外的同步和信息共享。 并行数据流： 如果数据本身存在的天然的独立性，比如图像中的每一个像素，那么在对这个图像做处理的过程中，同一个指令可以同时作用于每一个像素。在这种情况下，这个对于完整图像的操作可以并行化。理论上，如果内存不是问题，并且计算单元的数量大于整个图像中总像素点的话，这个操作可以在一个时钟周期内完成。 GPU整体的架构而言，某种意义上是同时支持以上两种并行模式。在同一个流处理器中，采用了“单一指令并行数据流的模式”，而在多个流处理器中，同一时间可以派发不同的指令。从这一点出发，GPU芯片算是一个非常灵活的架构。一个芯片中，流处理器的个数和其中包含的CUDA核心的数量也是一种面向应用设计时候找到的一个平衡点。 基于深度学习中大部分的操作的天然并行性（大量的矩阵操作），GPU在当下还是一种非常适合的计算平台。一个非常典型的例子就是常见的矩阵相乘（如下图），要计算Z = X×Y，通过并行计算，X和Y中的行向量和列向量的逐元素相乘就可以同时进行，只要得到结果后再进行累加，而且累加的过程中也是可以进行并行化，使得效率有非常大的提高。Nvidia也是制定和开发了一套底层类库，CUBlas方便开发者。我们熟悉的几大框架(e.g. Tensorflow, PyTorch等)也是遵循和使用了这些并行类库，所以才使得训练和部署性能有了非常多的提高。 15.3.4 深度学习中的GPU应用深度学习在最近几年内出现的井喷现象背后也是GPU的存在和发展作为坚实的推动力量。 哪些场景使用GPU在涉及大型矩阵运算的时候使用GPU可以显著加速处理速度，由于GPU架构的独特设计，针对矩阵运算可以实现高速并行计算，极大提高计算速度。一般在高性能计算，机器学习，深度学习，图像渲染等等场景中会比较多的使用矩阵运算，使用GPU可以显著加快处理速度。在一般的深度学习训练中，通常来说使用GPU比使用CPU都有10倍以上的速度提升，所以几乎所有深度学习的研究者几乎都是在使用GPU进行训练。 ImageNet的例子 15.3.5 新图灵架构里的tensor core对深度学习有什么作用？我们知道在深度学习中,矩阵-矩阵乘法运算（BLAS GEMM）是神经网络训练和推理的核心，并且矩阵乘法运算占据了所有计算量的大部分，而Tensor core就是为了解决这个问题而推出的，它的出现极大的提高了计算效率，大大加速了深度学习的计算速度，对深度学习的发展具有极大意义。 Tensor Core是Volta架构最重磅特性，是专门针对Deep Learning应用而设计的专用ASIC单元，实际上是一种矩阵乘累加的计算单元。（矩阵乘累加计算在Deep Learning网络层算法中，比如卷积层、全连接层等是最重要、最耗时的一部分。）Tensor Core可以在一个时钟周期内实现两个4×4矩阵乘法以及与另一个4×4矩阵加法。整个计算的个数，就是在一个时钟周期内可以实现64次乘和64次加。 所以Tensor Core就是为了矩阵乘法的加速而设计的，使用具有Tensor Core的GPU来进行深度学习的训练会极大的提高训练速度。 15.4 CUDA 框架15.4.1 做CUDA编程难不难？15.4.2 cuDNN15.5 GPU硬件环境配置推荐15.5.1 GPU主要性能指标GPU的性能主要由以下三个参数构成： 计算能力。通常我们关心的是32位浮点计算能力。16位浮点训练也开始流行，如果只做预测的话也可以用8位整数。 显存大小。当模型越大，或者训练时的批量越大时，所需要的GPU显存就越多。 显存带宽。只有当显存带宽足够时才能充分发挥计算能力。 对于大部分用户来说，只要考虑计算能力就可以了。GPU显存尽量不小于4GB。但如果GPU要同时显示图形界面，那么推荐的显存大小至少为6GB。显存带宽通常相对固定，选择空间较小。 下图描绘了GTX 900和1000系列里各个型号的32位浮点计算能力和价格的对比。其中价格为Wikipedia的建议价格。 我们可以从图中读出两点信息： 在同一个系列里面，价格和性能大体上成正比。但后发布的型号性价比更高，例如980 Ti和1080 Ti。 GTX 1000系列比900系列在性价比上高出2倍左右。 如果大家继续比较GTX较早的系列，也可以发现类似的规律。据此，我们推荐大家在能力范围内尽可能买较新的GPU。 15.5.2 购买建议首先给出一些总体的建议最好的GPU整体（小幅度）：Titan Xp综合性价比高，但略贵：GTX 1080 Ti，GTX 1070，GTX 1080性价比还不错且便宜：GTX 1060（6GB） 当使用数据集&gt; 250GB：GTX Titan X（Maxwell） ，NVIDIA Titan X Pascal或NVIDIA Titan Xp 没有足够的钱：GTX 1060（6GB） 几乎没有钱，入门级：GTX 1050 Ti（4GB） 做Kaggle比赛：GTX 1060（6GB）适用于任何“正常”比赛，或GTX 1080 Ti用于“深度学习竞赛” 计算机视觉研究员：NVIDIA Titan Xp；不要买现在新出的Titan X（Pascal或Maxwell） 一名研究员人员：GTX 1080 Ti。在某些情况下，如自然语言处理，一个GTX 1070或GTX 1080已经足够了-检查你现在模型的内存需求 搭建一个GPU集群：这个有点复杂，另做探讨。 刚开始进行深度学习研究：从GTX 1060（6GB）开始。根据你下一步兴趣（入门，Kaggle比赛，研究，应用深度学习）等等，在进行选择。目前，GTX 1060更合适。 想尝试下深度学习，但没有过多要求：GTX 1050 Ti（4或2GB） 目前独立GPU主要有AMD和NVIDIA两家厂商。其中NVIDIA在深度学习布局较早，对深度学习框架支持更好。因此，目前大家主要会选择NVIDIA的GPU。 NVIDIA有面向个人用户（例如GTX系列）和企业用户（例如Tesla系列）的两类GPU。这两类GPU的计算能力相当。然而，面向企业用户的GPU通常使用被动散热并增加了内存校验，从而更适合数据中心，并通常要比面向个人用户的GPU贵上10倍。 如果你是拥有100台机器以上的大公司用户，通常可以考虑针对企业用户的NVIDIA Tesla系列。如果你是拥有10到100台机器的实验室和中小公司用户，预算充足的情况下可以考虑NVIDIA DGX系列，否则可以考虑购买如Supermicro之类的性价比比较高的服务器，然后再购买安装GTX系列的GPU。 NVIDIA一般每一两年发布一次新版本的GPU，例如2016年发布的是GTX 1000系列。每个系列中会有数个不同的型号，分别对应不同的性能。 15.6 软件环境搭建深度学习其实就是指基于一套完整的软件系统来构建算法，训练模型。如何搭建一套完整的软件系统，比如操作系统的选择？安装环境中遇到的问题等等，本节做一个简单的总结。 15.6.1 操作系统选择？针对硬件厂商来说，比如NVIDIA，对各个操作系统的支持都是比较好的 ，比如Windows系列,Linux系列，但是由于Linux系统对专业技术人员比较友好，所以目前几乎所有的深度学习系统构建都是基于Linux的，比较常用的系统如Ubuntu系列，CentOS系列等等。在构建系统的时候，如何选择合适的操作系是一个刚刚入门深度学习的工作者面临的问题，在这里给出几点建议：（1）刚刚入门，熟悉Windows系统，但是对Linux和深度学习都不太熟，这个时候可以基于windows系列系统来做入门学习（2）简单了解Linux的使用，不太懂深度学习相关知识，可以直接基于Linux系统来搭建框架，跑一些开源的项目，慢慢深入研究学习（3）熟悉Linux，不熟悉深度学习理论，毫无疑问，强烈推荐使用Linux系统，安装软件简单，工作效率高总之一句话，如果不熟悉Linux，就先慢慢熟悉，最终还是要回归到Linux系统来构建深度学习系统 15.6.2 常用基础软件安装？目前有众多深度学习框架可供大家使用，但是所有框架基本都有一个共同的特点，目前几乎都是基于Nvidia的GPU来训练模型，要想更好的使用NVIDIA的GPU，cuda和cudnn就是必备的软件安装。 安装cuda上文中有关于cuda的介绍，这里只是简单介绍基于Linux系统安装cuda的具体步骤，可以根据自己的需要安装cuda8.0或者cuda9.0，这两种版本的安装步骤基本一致，这里以最常用的ubuntu 16.04 lts版本为例： 官网下载，地址cuda8.0https://developer.nvidia.com/cuda-80-ga2-download-archivecuda9.0https://developer.nvidia.com/cuda-90-download-archive进入网址之后选择对应的系统版本即可，如下图所示： 命令行中进入到cuda所在的位置，授予运行权限：cuda8.0: sudo chmod +x cuda_8.0.61_375.26_linux.runcuda9.0:sudo chmod +x cuda_9.0.176_384.81_linux.run 执行命令安装cuda：cuda8.0:sudo sh cuda_8.0.61_375.26_linux.runcuda9.0:sudo sh cuda_9.0.176_384.81_linux.run之后命令之后下面就是安装步骤，cuda8.0和cuda9.0几乎一致： 首先出现cuda软件的版权说明，可以直接按q键跳过阅读 Do you accept the previously read EULA?​accept/decline/quit: accept Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 384.81?​(y)es/(n)o/(q)uit:no Install the CUDA 9.0 Toolkit?​(y)es/(n)o/(q)uit:yes Enter Toolkit Location​ [ default is /usr/local/cuda-9.0 ]:直接按enter键即可 Do you want to install a symbolic link at /usr/local/cuda?​(y)es/(n)o/(q)uit:yes Install the CUDA 9.0 Samples?​ (y)es/(n)o/(q)uit:yes 以上步骤基本就是cuda的安装步骤。 安装cudnncudnn是Nvidia的专门针对深度学习的加速库。。。 15.6.3 本机安装还是使用docker？15.6.4 GPU驱动问题15.7 框架选择15.7.1 主流框架比较（一个大表格比较） 15.7.2 框架详细信息 TensorflowTensorflow是Google于2015年开源的基于数据流编程的深度学习框架，得益于Google强大的技术实力和品牌背书，目前Tensorflow发展迅猛，其用户量远远超过其它框架用户。优点： 由谷歌开发、维护，因此可以保障支持、开发的持续性 巨大、活跃的社区 网络训练的低级、高级接口 「TensorBoard」是一款强大的可视化套件，旨在跟踪网络拓扑和性能，使调试更加简单 TensorFlow 不仅支持深度学习，还有支持强化学习和其他算法的工具缺点： 计算图是纯 Python 的，因此速度较慢 图构造是静态的，意味着图必须先被「编译」再运行 PyTorchpytorch是Facebook于2017年才推出的深度学习框架，相对于其它框架，算是比较晚的了，但是这个同时也是优势，在设计的时候就会避免很多之前框架的问题，所以一经推出，就收到大家极大的欢迎优点： 接口简洁且规范，文档齐全，和python无缝结合， 社区非常活跃，开源实现较多 提供动态计算图（意味着图是在运行时生成的），允许你处理可变长度的输入和输出，例如，在使用 RNN 时非常有用 易于编写自己的图层类型，易于在 GPU 上运行 「TensorBoard」缺少一些关键功能时，「Losswise」可以作为 Pytorch 的替代品 缺点: 模型部署相对其它框架稍有劣势，不过后续的pytorch1.0版本应该会有很大改善，和caffe2合并后，caffe2的优秀的模型部署能力可以弥补这个不足 相关资源链接： 官网教程：https://pytorch.org/tutorials/ 基于pytorch的开源项目汇总：https://github.com/bharathgs/Awesome-pytorch-list3. KerasKeras 是一个更高级、对用户最友好的 API，具有可配置的后端，由 Google Brain 团队成员 Francis Chollet 编写和维护优点： 提供高级 API 来构建深度学习模型，使其易于阅读和使用 编写规范的文档 大型、活跃的社区 位于其他深度学习库（如 Theano 和 TensorFlow，可配置）之上 使用面向对象的设计，因此所有内容都被视为对象（如网络层、参数、优化器等）。所有模型参数都可以作为对象属性进行访问缺点： 由于用途非常普遍，所以在性能方面比较欠缺 与 TensorFlow 后端配合使用时会出现性能问题（因为并未针对其进行优化），但与 Theano 后端配合使用时效果良好 不像 TensorFlow 或 PyTorch 那样灵活 Sonnet Caffecaffe是第一个主流产品级深度学习库，于 2014 年由 UC Berkeley 发布开源优点： 简单网络结构无需编写代码，可快速实现 漂亮的 Matlab 和 Python 接口 完全由c++编程实现，部署方便 缺点： 不灵活。在 Caffe 中，每个节点被当做一个层，因此如果你想要一种新的层类型，你需要定义完整的前向、后向和梯度更新过程。这些层是网络的构建模块，你需要在无穷无尽的列表中进行选择。（相反，在 TensorFlow 中，每个节点被当做一个张量运算例如矩阵相加、相乘或卷积。你可以轻易地定义一个层作为这些运算的组合。因此 TensorFlow 的构建模块更小巧，允许更灵活的模块化。） 需要大量的非必要冗长代码。如果你希望同时支持 CPU 和 GPU，你需要为每一个实现额外的函数。你还需要使用普通的文本编辑器来定义你的模型。真令人头疼！几乎每个人都希望程序化地定义模型，因为这有利于不同组件之间的模块化。有趣的是，Caffe 的主要架构师现在在 TensorFlow 团队工作 专一性。仅定位在计算机视觉（但做得很不错） 不是以 Python 编写！如果你希望引入新的变动，你需要在 C++和 CUDA 上编程（对于更小的变动，你可以使用它的 Python 和 Matlab 接口） 糟糕的文档 安装比较困难！有大量的依赖包 Caffe2 MxNetMxNet是dmlc社区推出的深度学习框架，MXNet由学术界发起，包括数个顶尖大学的多个学科的研究人员的贡献，在2017年被亚马逊指定为官方框架。mxnet的最知名的优点就是其对多GPU的支持和扩展性强，其优秀的性能使之在工业界占有一席之地，在amazon支持之后，其文档和开发进度明显好很多。除了高可扩展性，MXNet 还提供混合编程模型（命令式和声明式），同时兼容多种编程语言（包括 Python、C ++、R、Scala、Julia、Matlab 和 JavaScript）的代码，目前主要在推python高层接口gluon 优点： 多GPU支持好，扩展性强，支持多种编程语言接口，主要是由华人团队开发，中文社区活跃，中文文档资源和课程丰富 针对两大热门领域推出gluoncv和gluonNLP模块，复现经典论文，达到State-of-the-art，接口设计简单，文档齐全，拿来就可以用缺点: 现在mxnet官方社区主要在推gluon接口，接口稍有混乱，坑较多，入手门槛稍高 偏小众，经典网络和项目的开源实现相对于tensorflow和pytorch还是比较少，很多还是需要自己手动实现相关资源链接： 官方教程：http://mxnet.incubator.apache.org 提供有快速入门教程和详细文档说明 中文教程：http://zh.gluon.ai/ 官方的中文教程，此课程有对应的中文版视频，主要由李沐大神讲课 中文论坛：https://discuss.gluon.ai/ 官方发中文论坛，mxnet的主要作者都在这里，论坛比较活跃，可及时得到作者的回答 基于mxnet的开源项目实现：https://github.com/chinakook/Awesome-MXNet这里主要列举了mxnet在各个领域的项目的开源实现 CNTK PaddlePaddle 其他国内自主开发开源框架 15.7.3 哪些框架对于部署环境友好？ Tensorflow Serving ONNX 标准 TensorRT ONNPACK Clipper 15.7.4 移动平台的框架如何选择？ Tensorflow Lite Caffe2 15.8 其他15.8.1 多GPU环境的配置 Tensorflow PyTorch 15.8.2 是不是可以分布式训练？15.8.3 可以在SPARK环境里训练或者部署模型吗？15.8.4 怎么进一步优化性能？ TVM nGraph 15.8.5 TPU和GPU的区别？15.8.6 未来量子计算对于深度学习等AI技术的影响？ 15.1 GPU购买指南深度学习训练通常需要大量的计算资源。GPU目前是深度学习最常使用的计算加速硬件。相对于CPU来说，GPU更便宜且计算更加密集。一方面，相同计算能力的GPU的价格一般是CPU价格的十分之一。另一方面，一台服务器通常可以搭载8块或者16块GPU。因此，GPU数量可以看作是衡量一台服务器的深度学习计算能力的一个标准。 15.1.1 如何选择GPU15.1.2 GPU的主要性能指标在选择GPU时，首先要考虑的第一个GPU性能问题是什么呢：是否为cuda核心？时钟速度多大？内存大小多少？这些都不是，对于深度学习性能而言，最重要的特征是内存带宽（memory bandwidth）。简而言之：GPU针对内存带宽进行了优化，但同时牺牲了内存访问时间（延迟）。CPU的设计恰恰相反：如果涉及少量内存（例如几个数字相乘（3 6 9）），CPU可以快速计算，但是对于大量内存（如矩阵乘法（A B C）则很慢。由于内存带宽的限制，当涉及大量内存的问题时，GPU快速计算的优势往往会受到限制。当然，GPU和CPU之间还有更复杂的区别，关于为何GPU如此适用于处理深度学习问题，另做探讨。 所以如果你想购买一个快速的GPU，首先要关注的是GPU的带宽（bandwidth）。 15.1.3 整机配置通常，我们主要用GPU做深度学习训练。因此，不需要购买高端的CPU。至于整机配置，尽量参考网上推荐的中高档的配置就好。不过，考虑到GPU的功耗、散热和体积，我们在整机配置上也需要考虑以下三个额外因素。 机箱体积。GPU尺寸较大，通常考虑较大且自带风扇的机箱。 电源。购买GPU时需要查一下GPU的功耗，例如50W到300W不等。购买电源要确保功率足够，且不会过载机房的供电。 主板的PCIe卡槽。推荐使用PCIe 3.0 16x来保证充足的GPU到主内存的带宽。如果搭载多块GPU，要仔细阅读主板说明，以确保多块GPU一起使用时仍然是16x带宽。注意，有些主板搭载4块GPU时会降到8x甚至4x带宽。 15.1.4 小结 在预算范围之内，尽可能买较新的GPU。 整机配置需要考虑到GPU的功耗、散热和体积。 15.2 框架选型目前常用的框架有tensorflow,keras,pytorch,mxnet等等，各个框架的优缺点在此简单介绍： 15.2.1 常用框架简介1，tensorflow：tensorflow由于有google的强大背书，加上其优秀的分布式设计，丰富的教程资源和论坛，工业部署方便，基本很多人都是从tensorflow入门的优点：google的强大背书，分布式训练，教程资源丰富，常见问题基本都可以在互联网中找到解决办法，工业部署方便缺点: 接口混乱，官方文档不够简洁，清晰， 2，keras:keras是一种高层编程接口，其可以选择不同的后端，比如tensorflow，therao等等优点：接口简洁，上手快，文档好，资源多缺点: 封装的太好了导致不理解其技术细节 3,pytorch: 4,caffe2:caffe2是在caffe之后的第二代版本，同属于Facebook。。。优点：支持模型的全平台部署，。。。。缺点:使用人数相对较少，资源较少，和pytorch合并后应该会更受欢迎 5,mxnetmxnet是dmlc社区推出的深度学习框架，在2017年被亚马逊指定为官方框架优点：支持多种语言，代码设计优秀，省显存，华人团队开发，中文社区活跃，官方复现经典论文推出gluoncv和gluonNLP模块，非常方便，拿来就可以用。缺点:现在mxnet官方社区主要在推gluon接口，接口稍有混乱，坑较多，入手门槛稍高 6，caffe：目前很多做深度学习比较早的大厂基本都是在用caffe，因为在2013-2015年基本就是caffe的天下，并且caffe的代码设计很优秀，基本所有代码都被翻了很多遍了，被各种分析，大厂基本都是魔改caffe，基于caffe来进行二次开发，所在目前在很多大厂还是在使用caffe优点：资源丰富，代码容易理解，部署方便缺点：入门门槛高，文档较少 ###15.2.1 框架选型总结1，新手入门，首推pytorch，上手快，资源丰富,官方文档写的非常好(https://pytorch.org/tutorials/)2，目前工业部署，tensorflow是首选,资源丰富，并且在分布式训练这一块基本一家独大3，mxnet的gluon接口有比较丰富的中文资源（教程：zh.gluon.ai，论坛：discuss.gluon.ai）,gluoncv模块（https://gluon-cv.mxnet.io）,gluonNLP模块（https://gluon-nlp.mxnet.io） ##15.3 模型部署我们一般都是通过python或者其他语言来编码训练模型，然后基于后端来进行部署一般的框架都有自身的部署框架，比如tensorflow，pytorch，caffe2，mxnet等等有一些框架是专门做推理部署使用的，比如（1）tensorRT (2)TVM (3)ONNX]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式]]></title>
    <url>%2F2017%2F12%2F05%2F%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%EF%BC%88MLE%EF%BC%89%E3%80%81%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E4%BC%B0%E8%AE%A1%EF%BC%88MAP%EF%BC%89%EF%BC%8C%E4%BB%A5%E5%8F%8A%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式 第一部分Likelihood &amp; Maximum likelihood似然与概率在统计学中，似然函数（likelihood function，通常简写为likelihood，似然）是一个非常重要的内容，在非正式场合似然和概率（Probability）几乎是一对同义词，但是在统计学中似然和概率却是两个不同的概念。概率是在特定环境下某件事情发生的可能性，也就是结果没有产生之前依据环境所对应的参数来预测某件事情发生的可能性，比如抛硬币，抛之前我们不知道最后是哪一面朝上，但是根据硬币的性质我们可以推测任何一面朝上的可能性均为50%，这个概率只有在抛硬币之前才是有意义的，抛完硬币后的结果便是确定的；而似然刚好相反，是在确定的结果下去推测产生这个结果的可能环境（参数），还是抛硬币的例子，假设我们随机抛掷一枚硬币1,000次，结果500次人头朝上，500次数字朝上（实际情况一般不会这么理想，这里只是举个例子），我们很容易判断这是一枚标准的硬币，两面朝上的概率均为50%，这个过程就是我们运用出现的结果来判断这个事情本身的性质（参数），也就是似然。 结果和参数相互对应的时候，似然和概率在数值上是相等的，如果用 θ 表示环境对应的参数，x 表示结果，那么概率可以表示为：P(x|θ) p(x|θ) 是条件概率的表示方法，θ 是前置条件，理解为在 θ 的前提下，事件 x 发生的概率，相对应的似然可以表示为：L(θ|x) 可以理解为已知结果为 x ，参数为 θ (似然函数里 θ 是变量，这里说的参数和变量是相对与概率而言的)对应的概率，即：L(θ|x)=P(x|θ)需要说明的是两者在数值上相等，但是意义并不相同，L 是关于 θ 的函数，而 P 则是关于 x 的函数，两者从不同的角度描述一件事情。 第二部分最大似然估计（Maximum likelihood estimation, 简称MLE）和最大后验概率估计（Maximum a posteriori estimation, 简称MAP）是很常用的两种参数估计方法，如果不理解这两种方法的思路，很容易弄混它们。下文将详细说明MLE和MAP的思路与区别。 但别急，我们先从概率和统计的区别讲起。 概率和统计是一个东西吗？概率（probabilty）和统计（statistics）看似两个相近的概念，其实研究的问题刚好相反。 概率研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性（例如均值，方差，协方差等等）。 举个例子，我想研究怎么养猪（模型是猪），我选好了想养的品种、喂养方式、猪棚的设计等等（选择参数），我想知道我养出来的猪大概能有多肥，肉质怎么样（预测结果）。 统计研究的问题则相反。统计是，有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉（这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等），然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等（推测模型参数）。 一句话总结：概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。 显然，本文解释的MLE和MAP都是统计领域的问题。它们都是用来推测参数的方法。为什么会存在着两种不同方法呢？ 这需要理解贝叶斯思想。我们来看看贝叶斯公式。 贝叶斯公式到底在说什么？学习机器学习和模式识别的人一定都听过贝叶斯公式(Bayes’ Theorem)： 【式1】贝叶斯公式看起来很简单，无非是倒了倒条件概率和联合概率的公式。 把B展开，可以写成： 【式2】（∼A∼A表示”非A”） 这个式子就很有意思了。 想想这个情况。一辆汽车（或者电瓶车）的警报响了，你通常是什么反应？有小偷？撞车了？ 不。。 你通常什么反应都没有。因为汽车警报响一响实在是太正常了！每天都要发生好多次。本来，汽车警报设置的功能是，出现了异常情况，需要人关注。然而，由于虚警实在是太多，人们渐渐不相信警报的功能了。 贝叶斯公式就是在描述，你有多大把握能相信一件证据？（how much you can trust the evidence） 我们假设响警报的目的就是想说汽车被砸了。把A计作“汽车被砸了”，B计作“警报响了”，带进贝叶斯公式里看。我们想求等式左边发生A|B的概率，这是在说警报响了，汽车也确实被砸了。汽车被砸引起（trigger）警报响，即B|A。但是，也有可能是汽车被小孩子皮球踢了一下、被行人碰了一下等其他原因（统统计作∼A），其他原因引起汽车警报响了，即B|∼A。那么，现在突然听见警报响了，这时汽车已经被砸了的概率是多少呢（这即是说，警报响这个证据有了，多大把握能相信它确实是在报警说汽车被砸了）？想一想，应当这样来计算。用警报响起、汽车也被砸了这事件的数量，除以响警报事件的数量（这即【式1】）。进一步展开，即警报响起、汽车也被砸了的事件的数量，除以警报响起、汽车被砸了的事件数量加上警报响起、汽车没被砸的事件数量（这即【式2】）。 可能有点绕，请稍稍想一想。 再思考【式2】。想让P(A|B)=1，即警报响了，汽车一定被砸了，该怎么做呢？让P(B|∼A)P(∼A)=0即可。很容易想清楚，假若让P(∼A)=0，即杜绝了汽车被球踢、被行人碰到等等其他所有情况，那自然，警报响了，只剩下一种可能——汽车被砸了。这即是提高了响警报这个证据的说服力。 从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。 老板骂你，不一定是你把什么工作搞砸了，可能只是他今天出门前和太太吵了一架。 再思考【式2】。观察【式2】右边的分子，P(B|A)为汽车被砸后响警报的概率。姑且仍为这是1吧。但是，若P(A)很小，即汽车被砸的概率本身就很小，则P(B|A)P(A)仍然很小，即【式2】右边分子仍然很小，P(A|B) 还是大不起来。 这里，​P(A)即是常说的先验概率，如果A的先验概率很小，就算P(B|A)较大，可能A的后验概率P(A|B)还是不会大（假设P(B|∼A)P(∼A)不变的情况下）。 从这个角度思考贝叶斯公式：一个本来就难以发生的事情，就算出现某个证据和他强烈相关，也要谨慎。证据很可能来自别的虽然不是很相关，但发生概率较高的事情。 发现刚才写的代码编译报错，可是我今天状态特别好，这语言我也很熟悉，犯错的概率很低。因此觉得是编译器出错了。 ————别，还是先再检查下自己的代码吧。 好了好了，说了这么多，下面言归正传，说一说MLE。 ——————不行，还得先说似然函数（likelihood function） 似然函数似然（likelihood）这个词其实和概率（probability）是差不多的意思，Colins字典这么解释：The likelihood of something happening is how likely it is to happen. 你把likelihood换成probability，这解释也读得通。但是在统计里面，似然函数和概率函数却是两个不同的概念（其实也很相近就是了）。 对于这个函数： **P(x|θ)输入有两个：x表示某一个具体的数据；θ表示模型的参数。 如果θ是已知确定的，xx是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少。 如果x是已知确定的，θ是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现x这个样本点的概率是多少。** 这有点像“一菜两吃”的意思。其实这样的形式我们以前也不是没遇到过。例如，f(x,y)=x^y, 即x的y次方。如果xx是已知确定的(例如x=2)，这就是f(y)=2^y, 这是指数函数。 如果yy是已知确定的(例如y=2)，这就是f(x)=x^2，这是二次函数。同一个数学形式，从不同的变量角度观察，可以有不同的名字。 这么说应该清楚了吧？ 如果还没讲清楚，别急，下文会有具体例子。 现在真要先讲讲MLE了。。 最大似然估计（MLE）假设有一个造币厂生产某种硬币，现在我们拿到了一枚这种硬币，想试试这硬币是不是均匀的。即想知道抛这枚硬币，正反面出现的概率（记为θ）各是多少？ 这是一个统计问题，回想一下，解决统计问题需要什么？ 数据！ 于是我们拿这枚硬币抛了10次，得到的数据（x0）是：反正正正正反正正正反。我们想求的正面概率θθ是模型参数，而抛硬币模型我们可以假设是 二项分布。 那么，出现实验结果x0（即反正正正正反正正正反）的似然函数是多少呢？ f(x0,θ)=(1−θ)×θ×θ×θ×θ×(1−θ)×θ×θ×θ×(1−θ)=θ^7(1−θ)^3=f(θ)注意，这是个只关于θ的函数。而最大似然估计，顾名思义，就是要最大化这个函数。我们可以画出f(θ)的图像： 可以看出，在θ=0.7时，似然函数取得最大值。 这样，我们已经完成了对θ的最大似然估计。即，抛10次硬币，发现7次硬币正面向上，最大似然估计认为正面向上的概率是0.7。（ummm..这非常直观合理，对吧？） 且慢，一些人可能会说，硬币一般都是均匀的啊！ 就算你做实验发现结果是“反正正正正反正正正反”，我也不信θ=0.7。 这里就包含了贝叶斯学派的思想了——要考虑先验概率。 为此，引入了最大后验概率估计。 最大后验概率估计最大似然估计是求参数θθ, 使似然函数P(x0|θ)最大。最大后验概率估计则是想求θθ使P(x0|θ)P(θ)最大。求得的θ不单单让似然函数大，θ自己出现的先验概率也得大。 （这有点像正则化里加惩罚项的思想，不过正则化里是利用加法，而MAP里是利用乘法） MAP其实是在最大化P(θ|x0)=P(x0|θ)P(θ)P(x0)，不过因为x0是确定的（即投出的“反正正正正反正正正反”），P(x0)是一个已知值，所以去掉了分母P(x0)（假设“投10次硬币”是一次实验，实验做了1000次，“反正正正正反正正正反”出现了n次，则P(x0)=n/1000。总之，这是一个可以由数据集得到的值）。最大化P(θ|x0)的意义也很明确，x0已经出现了，要求θ取什么值使P(θ|x0)最大。顺带一提，P(θ|x0)即后验概率，这就是“最大后验概率估计”名字的由来。 对于投硬币的例子来看，我们认为（”先验地知道“）θ取0.5的概率很大，取其他值的概率小一些。我们用一个高斯分布来具体描述我们掌握的这个先验知识，例如假设P(θ)为均值0.5，方差0.1的高斯函数，如下图：则P(x0|θ)P(θ)的函数图像为： 注意，此时函数取最大值时，θ取值已向左偏移，不再是0.7。实际上，在θ=0.558时函数取得了最大值。即，用最大后验概率估计，得到θ=0.558最后，那要怎样才能说服一个贝叶斯派相信θ=0.7呢？你得多做点实验。。 如果做了1000次实验，其中700次都是正面向上，这时似然函数为:如果仍然假设P(θ)为均值0.5，方差0.1的高斯函数，P(x0|θ)P(θ)的函数图像为：在θ=0.696处，P(x0|θ)P(θ)取得最大值。 这样，就算一个考虑了先验概率的贝叶斯派，也不得不承认得把θ估计在0.7附近了。 PS. 要是遇上了顽固的贝叶斯派，认为P(θ=0.5)=1 ，那就没得玩了。。 无论怎么做实验，使用MAP估计出来都是θ=0.5。这也说明，一个合理的先验概率假设是很重要的。（通常，先验概率能从数据中直接分析得到） 最大似然估计和最大后验概率估计的区别相信读完上文，MLE和MAP的区别应该是很清楚的了。MAP就是多个作为因子的先验概率P(θ)。或者，也可以反过来，认为MLE是把先验概率P(θ)认为等于1，即认为θ是均匀分布。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习 超参数调整]]></title>
    <url>%2F2017%2F11%2F24%2F%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0_%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E6%95%B4%2F</url>
    <content type="text"><![CDATA[Markdown Revision 1;Editor: 乔成磊-同济大学，王超锋Contact: qchl0318@163.com，syusuke0516@163.comUpdater: sjsdfg，王超锋 14.1 写在前面 关于训练深度学习模型最难的事情之一是你要处理的参数的数量。无论是从网络本身的层宽（宽度）、层数（深度）、连接方式，还是损失函数的超参数设计和调试，亦或者是学习率、批样本数量、优化器参数等等。这些大量的参数都会有网络模型最终的有效容限直接或者间接的影响。面对如此众多的参数，如果我们要一一对其优化调整，所需的无论是时间、资源都是不切实际。结果证实一些超参数比其它的更为重要，因此认识各个超参数的作用和其可能会造成的影响是深度学习训练中必不可少的一项重要技能。 ​ 目前，超参数调整一般分为手动调整和自动优化超参数两种。本章节不会过多阐述所有超参数的详细原理，如果需要了解这部分，您可以翻阅前面的基础章节或者查阅相关文献资料。当然，下面会讲到的一些超参数优化的建议是根据笔者们的实践以及部分文献资料得到认知建议，并不是非常严格且一定有效的，很多研究者可能会很不同意某些的观点或有着不同的直觉，这都是可保留讨论的，因为这很依赖于数据本身情况。 14.2 超参数概述14.2.1 什么是超参数，参数和超参数的区别​ 区分两者最大的一点就是是否通过数据来进行调整，模型参数通常是有数据来驱动调整，超参数则不需要数据来驱动，而是在训练前或者训练中人为的进行调整的参数。例如卷积核的具体核参数就是指模型参数，这是有数据驱动的。而学习率则是人为来进行调整的超参数。这里需要注意的是，通常情况下卷积核数量、卷积核尺寸这些也是超参数，注意与卷积核的核参数区分。 14.2.2 神经网络中包含哪些超参数 通常可以将超参数分为三类：网络参数、优化参数、正则化参数。 ​ 网络参数：可指网络层与层之间的交互方式（相加、相乘或者串接等）、卷积核数量和卷积核尺寸、网络层数（也称深度）和激活函数等。 ​ 优化参数：一般指学习率（learning rate）、批样本数量（batch size）、不同优化器的参数以及部分损失函数的可调参数。 ​ 正则化：权重衰减系数，丢弃法比率（dropout） 14.2.3 模型优化寻找最优解和正则项之间的关系​ 网络模型优化调整的目的是为了寻找到全局最优解（或者相比更好的局部最优解），而正则项又希望模型尽量拟合到最优。两者通常情况下，存在一定的对立，但两者的目标是一致的，即最小化期望风险。模型优化希望最小化经验风险，而容易陷入过拟合，正则项用来约束模型复杂度。所以如何平衡两者之间的关系，得到最优或者较优的解就是超参数调整优化的目的。 14.2.4 超参数的重要性顺序 首先， 学习率，损失函数上的可调参数。在网络参数、优化参数、正则化参数中最重要的超参数可能就是学习率了。学习率直接控制着训练中网络梯度更新的量级，直接影响着模型的有效容限能力；损失函数上的可调参数，这些参数通常情况下需要结合实际的损失函数来调整，大部分情况下这些参数也能很直接的影响到模型的的有效容限能力。这些损失一般可分成三类，第一类辅助损失结合常见的损失函数，起到辅助优化特征表达的作用。例如度量学习中的Center loss，通常结合交叉熵损失伴随一个权重完成一些特定的任务。这种情况下一般建议辅助损失值不高于或者不低于交叉熵损失值的两个数量级；第二类，多任务模型的多个损失函数，每个损失函数之间或独立或相关，用于各自任务，这种情况取决于任务之间本身的相关性，目前笔者并没有一个普适的经验由于提供参考；第三类，独立损失函数，这类损失通常会在特定的任务有显著性的效果。例如RetinaNet中的focal loss，其中的参数γ，α，对最终的效果会产生较大的影响。这类损失通常论文中会给出特定的建议值。 其次，批样本数量，动量优化器（Gradient Descent with Momentum）的动量参数β。批样本决定了数量梯度下降的方向。过小的批数量，极端情况下，例如batch size为1，即每个样本都去修正一次梯度方向，样本之间的差异越大越难以收敛。若网络中存在批归一化（batchnorm），batch size过小则更难以收敛，甚至垮掉。这是因为数据样本越少，统计量越不具有代表性，噪声也相应的增加。而过大的batch size，会使得梯度方向基本稳定，容易陷入局部最优解，降低精度。一般参考范围会取在[1:1024]之间，当然这个不是绝对的，需要结合具体场景和样本情况；动量衰减参数β是计算梯度的指数加权平均数，并利用该值来更新参数，设置为 0.9 是一个常见且效果不错的选择； 最后，Adam优化器的超参数、权重衰减系数、丢弃法比率（dropout）和网络参数。在这里说明下，这些参数重要性放在最后并不等价于这些参数不重要。而是表示这些参数在大部分实践中不建议过多尝试，例如Adam优化器中的β1，β2，ϵ，常设为 0.9、0.999、10−8就会有不错的表现。权重衰减系数通常会有个建议值，例如0.0005 ，使用建议值即可，不必过多尝试。dropout通常会在全连接层之间使用防止过拟合，建议比率控制在[0.2,0.5]之间。使用dropout时需要特别注意两点：一、在RNN中，如果直接放在memory cell中,循环会放大噪声，扰乱学习。一般会建议放在输入和输出层；二、不建议dropout后直接跟上batchnorm，dropout很可能影响batchnorm计算统计量，导致方差偏移，这种情况下会使得推理阶段出现模型完全垮掉的极端情况；网络参数通常也属于超参数的范围内，通常情况下增加网络层数能增加模型的容限能力，但模型真正有效的容限能力还和样本数量和质量、层之间的关系等有关，所以一般情况下会选择先固定网络层数，调优到一定阶段或者有大量的硬件资源支持可以在网络深度上进行进一步调整。 14.2.5 部分超参数如何影响模型性能 超参数 如何影响模型容量 原因 注意事项 学习率 调至最优，提升有效容量 过高或者过低的学习率，都会由于优化失败而导致降低模型有效容限 学习率最优点，在训练的不同时间点都可能变化，所以需要一套有效的学习率衰减策略 损失函数部分超参数 调至最优，提升有效容量 损失函数超参数大部分情况都会可能影响优化，不合适的超参数会使即便是对目标优化非常合适的损失函数同样难以优化模型，降低模型有效容限。 对于部分损失函数超参数其变化会对结果十分敏感，而有些则并不会太影响。在调整时，建议参考论文的推荐值，并在该推荐值数量级上进行最大最小值调试该参数对结果的影响。 批样本数量 过大过小，容易降低有效容量 大部分情况下，选择适合自身硬件容量的批样本数量，并不会对模型容限造成。 在一些特殊的目标函数的设计中，如何选择样本是很可能影响到模型的有效容限的，例如度量学习（metric learning）中的N-pair loss。这类损失因为需要样本的多样性，可能会依赖于批样本数量。 丢弃法 比率降低会提升模型的容量 较少的丢弃参数意味着模型参数量的提升，参数间适应性提升，模型容量提升，但不一定能提升模型有效容限 权重衰减系数 调至最优，提升有效容量 权重衰减可以有效的起到限制参数变化的幅度，起到一定的正则作用 优化器动量 调至最优，可能提升有效容量 动量参数通常用来加快训练，同时更容易跳出极值点，避免陷入局部最优解。 模型深度 同条件下，深度增加，模型容量提升 同条件，下增加深度意味着模型具有更多的参数，更强的拟合能力。 同条件下，深度越深意味着参数越多，需要的时间和硬件资源也越高。 卷积核尺寸 尺寸增加，模型容量提升 增加卷积核尺寸意味着参数量的增加，同条件下，模型参数也相应的增加。 14.2.6 部分超参数合适的范围 超参数 建议范围 注意事项 初始学习率 SGD: [1e-2, 1e-1]momentum: [1e-3, 1e-2]Adagrad: [1e-3, 1e-2]Adadelta: [1e-2, 1e-1]RMSprop: [1e-3, 1e-2]Adam: [1e-3, 1e-2]Adamax: [1e-3, 1e-2]Nadam: [1e-3, 1e-2] 这些范围通常是指从头开始训练的情况。若是微调，初始学习率可在降低一到两个数量级。 损失函数部分超参数 多个损失函数之间，损失值之间尽量相近，不建议超过或者低于两个数量级 这是指多个损失组合的情况，不一定完全正确。单个损失超参数需结合实际情况。 批样本数量 [1:1024] 当批样本数量过大(大于6000)或者等于1时，需要注意学习策略或者BN的替代品。 丢弃法比率 [0, 0.5] 权重衰减系数 [0, 1e-4] 卷积核尺寸 [7x7],[5x5],[3x3],[1x1], [7x1,1x7] 14.3 网络训练中的超参调整策略14.3.1 如何调试模型？在讨论如何调试模型之前，我们先来纠正一个误区。通常理解如何调试模型的时候，我们想到一系列优秀的神经网络模型以及调试技巧。但这里需要指出的是数据才是模型的根本，如果有一批质量优秀的数据，或者说你能将数据质量处理的很好的时候，往往比挑选或者设计模型的收益来的更大。那在这之后才是模型的设计和挑选以及训练技巧上的事情。 1、探索和清洗数据。探索数据集是设计算法之前最为重要的一步，以图像分类为例，我们需要重点知道给定的数据集样本类别和各类别样本数量是否平衡，图像之间是否存在跨域问题（例如网上爬取的图像通常质量各异，存在噪声）。若是类别数远远超过类别样本数（比如类别10000，每个类别却只有10张图像），那通常的方法可能效果并不显著，这时候few-shot learning或者对数据集做进一步增强可能是你比较不错的选择。再如目标检测，待检测目标在数据集中的尺度范围是对检测器的性能有很大影响的部分。因此重点是检测大目标还是小目标、目标是否密集完全取决于数据集本身。所以，探索和进一步清洗数据集一直都是深度学习中最重要的一步。这是很多新手通常会忽略的一点。 2、探索模型结果。探索模型的结果，通常是需要对模型在验证集上的性能进行进一步的分析，这是如何进一步提升模型性能很重要的步骤。将模型在训练集和验证集都进行结果的验证和可视化，可直观的分析出模型是否存在较大偏差以及结果的正确性。以图像分类为例，若类别间样本数量很不平衡时，我们需要重点关注少样本类别在验证集的结果是否和训练集的出入较大，对出错类别可进一步进行模型数值分析以及可视化结果分析，进一步确认模型的行为。 3、监控训练和验证误差。首先很多情况下，我们忽略代码的规范性和算法撰写正确性验证，这点上容易产生致命的影响。在训练和验证都存在问题时，首先请确认自己的代码是否正确。其次，根据训练和验证误差进一步追踪模型的拟合状态。若训练数据集很小，此时监控误差则显得格外重要。确定了模型的拟合状态对进一步调整学习率的策略的选择或者其他有效超参数的选择则会更得心应手。 4、反向传播数值的计算，这种情况通常适合自己设计一个新操作的情况。目前大部分流行框架都已包含自动求导部分，但并不一定是完全符合你的要求的。验证求导是否正确的方式是比较自动求导的结果和有限差分计算结果是否一致。所谓有限差分即导数的定义，使用一个极小的值近似导数。 14.3.2 为什么要做学习率调整?​ 学习率可以说是模型训练最为重要的超参数。通常情况下，一个或者一组优秀的学习率既能加速模型的训练，又能得到一个较优甚至最优的精度。过大或者过小的学习率会直接影响到模型的收敛。我们知道，当模型训练到一定程度的时候，损失将不再减少，这时候模型的一阶梯度接近零，对应Hessian 矩阵通常是两种情况，一、正定，即所有特征值均为正，此时通常可以得到一个局部极小值，若这个局部极小值接近全局最小则模型已经能得到不错的性能了，但若差距很大，则模型性能还有待于提升，通常情况下后者在训练初最常见。二，特征值有正有负，此时模型很可能陷入了鞍点，若陷入鞍点，模型性能表现就很差。以上两种情况在训练初期以及中期，此时若仍然以固定的学习率，会使模型陷入左右来回的震荡或者鞍点，无法继续优化。所以，学习率衰减或者增大能帮助模型有效的减少震荡或者逃离鞍点。 14.3.3 学习率调整策略有哪些？通常情况下，大部分学习率调整策略都是衰减学习率，当然也有部分增大学习率的策略。这里结合TensorFlow的内置方法来举例。 1、exponential_decay和natural_exp_decay 12345exponential_decay(learning_rate, global_step, decay_steps, decay_rate, staircase=False, name=None)natural_exp_decay(learning_rate, global_step, decay_steps, decay_rate, staircase=False, name=None) 指数衰减是最常用的衰减方式，这种方式简单直接，在训练初期衰减较大利于收敛，在后期衰减较小利于精调。以上两种均为指数衰减，区别在于后者使用以自然指数下降。 2、piecewise_constant 1piecewise_constant(x, boundaries, values, name=None) 分段设置学习率法，跟指数型类似，区别在于每个阶段的衰减并不是按指数调整。可在不同阶段设置手动不同的学习率。这种学习率重点在有利于精调。 3、polynomial_decay 123polynomial_decay(learning_rate, global_step, decay_steps, end_learning_rate=0.0001, power=1.0, cycle=False, name=None) 多项式衰减，计算如下： global_step = min(global_step,decay_steps) decayed_learning_rate = (learning_rate-end_learning_rate)*(1-global_step/decay_steps)^ (power)+end_learning_rate 有别去上述两种，多项式衰减则是在每一步迭代上都会调整学习率。主要看Power参数，若Power为1，则是下图中的红色直线；若power小于1，则是开1/power次方，为蓝色线；绿色线为指数，power大于1。 此外，需要注意的是参数cycle，cycle对应的是一种周期循环调整的方式，主要的目的在后期防止在一个局部极小值震荡，若跳出该区域或许能得到更有的结果。这里说明cycle的方式不止可以在多项式中应用，可配合类似的周期函数进行衰减，如下图。 4、inverse_time_decay 12inverse_time_decay(learning_rate, global_step, decay_steps, decay_rate, staircase=False, name=None) 逆时衰减，这种方式和指数型类似。如图， 5、cosine_decay 12cosine_decay(learning_rate, global_step, decay_steps, alpha=0.0, name=None) 余弦衰减，即按余弦函数的方式衰减学习率，如图 6、cosine_decay_restarts 12cosine_decay_restarts(learning_rate, global_step, first_decay_steps, t_mul=2.0, m_mul=1.0, alpha=0.0, name=None) 余弦重启衰减，即余弦版本的cycle策略，作用与多项式衰减中的cycle相同。区别在于余弦重启衰减会重新回到初始学习率，拉长周期，而多项式版本则会逐周期衰减。 7、linear_cosine_decay 123linear_cosine_decay(learning_rate, global_step, decay_steps, num_periods=0.5, alpha=0.0, beta=0.001, name=None) 线性余弦衰减，主要应用于增强学习领域。 8、noisy_linear_cosine_decay 噪声线性余弦衰减，即在线性余弦衰减中加入随机噪声，增大寻优的随机性。 14.3.4 极端批样本数量下，如何训练网络？14.3.5 为什么卷积核设计尺寸都是奇数主要原因有两点： 保证像素点中心位置，避免位置信息偏移 填充边缘时能保证两边都能填充，原矩阵依然对称 14.3.6 权重共享的形式有哪些，为什么要权重共享权重共享的形式： 深度学习中，权重共享最具代表性的就是卷积网络的卷积操作。卷积相比于全连接神经网络参数大大减少； 多任务网络中，通常为了降低每个任务的计算量，会共享一个骨干网络。 一些相同尺度下的结构化递归网络 权重共享的好处： ​ 权重共享一定程度上能增强参数之间的联系，获得更好的共性特征。同时很大程度上降低了网络的参数，节省计算量和计算所需内存（当然，结构化递归并不节省计算量）。此外权重共享能起到很好正则的作用。正则化的目的是为了降低模型复杂度，防止过拟合，而权重共享则正好降低了模型的参数和复杂度。 ​ 因此一个设计优秀的权重共享方式，在降低计算量的同时，通常会较独享网络有更好的效果。 14.4 合理使用预训练网络14.4.1 什么是微调（fine-tune）​ 微调（fine-tune），顾名思义指稍微调整参数即可得到优秀的性能，是迁移学习的一种实现方式。微调和从头训练（train from scratch）的本质区别在于模型参数的初始化，train from scratch通常指对网络各类参数进行随机初始化（当然随机初始化也存在一定技巧），随机初始化模型通常不具有任何预测能力，通常需要大量的数据或者特定域的数据进行从零开始的训练，这样需要训练到优秀的模型通常是稍困难的。而微调的网络，网络各类参数已经在其他数据集（例如ImageNet数据集）完成较好调整的，具备了较优秀的表达能力。因此，我们只需要以较小的学习速率在自己所需的数据集领域进行学习即可得到较为优秀的模型。微调通常情况下，无须再重新设计网络结构，预训练模型提供了优秀的结构，只需稍微修改部分层即可。在小数据集上，通常微调的效果比从头训练要好很多，原因在于数据量较小的前提下，训练更多参数容易导致过度拟合。 14.4.2 微调有哪些不同方法？​ 以图像分类为例，通常情况下由于不同数据集需要的类别数不同，我们需要修改网络的输出顶层。这种情况下有两种微调方式： 不冻结网络模型的任何层，对最后的改动层使用较大的学习率，对未改动层以较小的学习率进行训练全模型训练，进行多轮训练即可。即一步完成训练。 冻结除了顶部改动层以外的所有层参数，即不对冻结部分的层进行参数训练更新，进行若干轮的微调训练后，放开顶部层以下的若干层或者全部放开所有层的参数，再次进行若干轮训练即可。即分多步训练。 以上两种都属于微调。目前由于存在大量优秀的预训练模型，如何确定哪个模型适合自己的任务并能得到最佳性能需要花大量的时间探索。此时，上述的前者是种不错训练方式，你无须进行过多分步的操作。而当探索到一个比较适合的模型时，你不妨可以再次重新尝试下以第二种方式进行训练，或许能得到相比于前者稍高些的性能，因为小数据集上调整过多的参数过拟合的机率也会增大，当然这并不是绝对的。 14.4.3 微调先冻结底层，训练顶层的原因？​ 14.12中第二种冻结多步训练的方式。首先冻结除了顶部改动层以外的所有层参数，对顶层进行训练，这个过程可以理解为顶层的域适应训练，主要用来训练适应模型的现有特征空间，防止顶层糟糕的初始化，对已经具备一定表达能力的层的干扰和破坏，影响最终的性能。之后，在很多深度学习框架教程中会使用放开顶层往下一半的层数，继续进行微调。这样的好处在于越底层的特征通常是越通用的特征，越往上其整体的高层次语义越完备，这通过感受野很容易理解。所以，若预训练模型的数据和微调训练的数据语义差异越大（例如ImageNet的预模型用于医学图像的训练），那越往顶层的特征语义差异就越大，因此通常也需要进行相应的调整。 14.4.4 不同的数据集特性下如何微调？ 数据集数据量少，数据和原数据集类似。这是通常做法只需修改最后的输出层，训练即可，训练过多参数容易过拟合。 数据集数据量少，数据和原数据集差异较大。由于数据差异较大，可以在完成输出顶层的微调后，微调顶层往下一半的层数，进行微调。 数据集数据量大，数据与原数据集差异较大。这种情况下，通常已经不需要用预训练模型进行微调，通常直接重新训练即可。 数据集数据量大，数据与原数据类似。这时预训练模型的参数是个很好的初始化，可利用预训练模型放开所有层以较小的学习率微调即可。 14.4.4 目标检测中使用预训练模型的优劣？​ 目标检测中无论是一阶段的YOLO、SSD或者RetinaNet 还是二阶段的Faster R-CNN、R-FCN 和 FPN都是基于ImageNet上预训练好的分类模型。 ​ 优势在于： ​ 1、正如大部分微调的情况一样，使用预训练网络已拥有优秀的语义特征，能有效的加快训练速度； ​ 2、其次，对于大部分二阶段的模型来说，并未实现严格意义上的完全端对端的训练，所以使用预训练模型能直接提取到语义特征，能使两个阶段的网络更容易实现模型的优化。 ​ 劣势在于，分类模型和检测模型之间仍然存在一定任务上的差异： ​ 1、检测模型能在多尺度上获取更高的收益； ​ 2、分类模型大部分训练于单目标数据，对同时进行多目标的捕捉能力稍弱； ​ 3、分类模型并不关注目标的位置，在一定程度上让模型损失部分空间信息，这对检测模型通常是不利的。 14.4.5 目标检测中如何从零开始训练？​ 参考14.15提到的使用预训练模型训练检测模型的优劣势，有两个方案在实际实现中可能会更有效。 ​ 方案一、通常二阶段检测模型并未实现真正完全端对端的训练，因此二阶段模型会更难以训练。所以一阶段检测模型相较起来更适合从零训练，参考DSOD，使用DenseNet使用更多层次的特征将更适应训练。 ​ 方案二、二阶段模型从零训练很难，而分类模型对于多目标、尺度并不敏感。因此仍然需要预训练模型的参数，这时借鉴DetNet训练一个专属于目标检测的模型网络，而参考分类模型的劣势，该专属网络应对多目标、尺度和位置拥有更强的适应性。 14.5 如何改善 GAN 的性能优化GAN性能通常需要在如下几个方面进行 设计或选择更适合目的代价函数。 添加额外的惩罚。 避免判别器过度自信和生成器过度拟合。 更好的优化模型的方法。 添加标签明确优化目标。 GAN常用训练技巧 输入规范化到（-1，1）之间，最后一层的激活函数使用tanh（BEGAN除外） 使用wassertein GAN的损失函数， 如果有标签数据的话，尽量使用标签，也有人提出使用反转标签效果很好，另外使用标签平滑，单边标签平滑或者双边标签平滑 使用mini-batch norm， 如果不用batch norm 可以使用instance norm 或者weight norm 避免使用RELU和pooling层，减少稀疏梯度的可能性，可以使用leakrelu激活函数 优化器尽量选择ADAM，学习率不要设置太大，初始1e-4可以参考，另外可以随着训练进行不断缩小学习率， 给D的网络层增加高斯噪声，相当于是一种正则 14.6 AutoML 14.6.1 什么是AutoML？​ 目前一个优秀的机器学习和深度学习模型，离不开这几个方面： ​ 一、优秀的数据预处理； ​ 二、合适的模型结构和功能； ​ 三、优秀的训练策略和超参数； ​ 四、合适的后处理操作； ​ 五、严格的结果分析。 ​ 这几方面都对最终的结果有着举足轻重的影响，这也是目前的数据工程师和学者们的主要工作。但由于这每一方面都十分繁琐，尤其是在构建模型和训练模型上。而大部分情况下，这些工作有无须过深专业知识就能使用起来。所以AutoML主要的作用就是来帮助实现高效的模型构建和超参数调整。例如深度学习网络的架构搜索、超参数的重要性分析等等。当然AutoML并不简单的进行暴力或者随机的搜索，其仍然需要机器学习方面的知识，例如贝叶斯优化、强化学习、元学习以及迁移学习等等。目前也有些不错的AutoML工具包，例如Alex Honchar的Hyperopt、微软的NNI、Autokeras等。 14.6.2 自动化超参数搜索方法有哪些？​ 目前自动化搜索主要包含网格搜索，随机搜索，基于模型的超参优化 ​ 网格搜索： ​ 通常当超参数量较少的时候，可以使用网格搜索法。即列出每个超参数的大致候选集合。利用这些集合 进行逐项组合优化。在条件允许的情况下，重复进行网格搜索会当优秀，当然每次重复需要根据上一步得到的最优参数组合，进行进一步的细粒度的调整。网格搜索最大的问题就在于计算时间会随着超参数的数量指数级的增长。 ​ 随机搜索： ​ 随机搜索，是一种用来替代网格搜索的搜索方式。随机搜索有别于网格搜索的一点在于，我们不需要设定一个离散的超参数集合，而是对每个超参数定义一个分布函数来生成随机超参数。随机搜索相比于网格搜索在一些不敏感超参上拥有明显优势。例如网格搜索对于批样本数量（batch size），在[16,32,64]这些范围内进行逐项调试，这样的调试显然收益更低下。当然随机搜索也可以进行细粒度范围内的重复的搜索优化。 ​ 基于模型的超参优化： ​ 有别于上述两种的搜索策略，基于模型的超参调优问题转化为了优化问题。直觉上会考虑是否进行一个可导建模，然后利用梯度下降进行优化。但不幸的是我们的超参数通常情况下是离散的，而且其计算代价依旧很高。 ​ 基于模型的搜索算法，最常见的就是贝叶斯超参优化。有别于的网格搜索和随机搜索独立于前几次搜索结果的搜索，贝叶斯则是利用历史的搜索结果进行优化搜索。其主要有四部分组成，1.目标函数，大部分情况下就是模型验证集上的损失。2、搜索空间，即各类待搜索的超参数。3、优化策略，建立的概率模型和选择超参数的方式。4、历史的搜索结果。首先对搜索空间进行一个先验性的假设猜想，即假设一种选择超参的方式，然后不断的优化更新概率模型，最终的目标是找到验证集上误差最小的一组超参数。 14.6.3 什么是神经网络架构搜索（NAS）2015至2017年间，是CNN网络设计最兴盛的阶段，大多都是由学者人工设计的网络结构。这个过程通常会很繁琐。其主要原因在于对不同模块组件的组成通常是个黑盒优化的问题，此外，在不同结构超参数以及训练超参数的选择优化上非凸优化问题，或者是个混合优化问题，既有离散空间又有连续空间。NAS（Neural Architecture Search）的出现就是为了解决如何通过机器策略和自动化的方式设计出优秀高效的网络。而这种策略通常不是统一的标准，不同的网络结合实际的需求通常会有不同的设计，比如移动端的模型会在效率和精度之间做平衡。目前的网络架构搜索通常会分为三个方面，搜索空间，搜索策略以及评价预估。链接 | https://www.paperweekly.site/papers/2249 搜索空间，定义了优化问题的变量，网络结构和超参数的变量定义有所不同，不同的变量规模对于算法的难度来说也不尽相同。早期很多工作都是用以遗传算法为代表的进化算法对神经网络的超参数和权重进行优化，因为当时的神经网络只有几层，每层十几个神经元，也不存在复杂的网络架构，参数很有限，可直接进行优化。而深度学习模型一方面有着复杂的网络结构，另一方面权重参数通常都以百万到亿来计，进化算法根本无法优化。但换个思路，假如我们找到了一组网络架构参数和对应的超参数，深度学习模型的性能其实是由这组参数来控制和决定的，所以只需要对复杂模型的架构参数和对应的超参数进行优化即可。 搜索策略， 搜索策略定义了使用怎样的算法可以快速、准确找到最优的网络结构参数配置。常见的搜索方法包括：随机搜索、贝叶斯优化、进化算法、强化学习、基于梯度的算法。其中，2017 年谷歌大脑的那篇强化学习搜索方法将这一研究带成了研究热点，后来 Uber、Sentient、OpenAI、Deepmind 等公司和研究机构用进化算法对这一问题进行了研究，这个 task 算是进化算法一大热点应用。 评价预估，类似于工程优化中的代理模型（surrogate model），因为深度学习模型的效果非常依赖于训练数据的规模，大规模数据上的模型训练会非常耗时，对优化结果的评价将会非常耗时，所以需要一些手段去做近似的评估。 一种思路是用一些低保真的训练集来训练模型，低保真在实际应用可以有多种表达，比如训练更少的次数，用原始训练数据的一部分，低分辨率的图片，每一层用更少的滤波器等。用这种低保真的训练集来测试优化算法会大大降低计算时间，但也存在一定的 bias，不过选择最优的架构并不需要绝对数值，只需要有相对值就可以进行排序选优了； 另一种主流思路是借鉴于工程优化中的代理模型，在很多工程优化问题中，每一次优化得到的结果需要经过实验或者高保真仿真（有限元分析）进行评价，实验和仿真的时间非常久，不可能无限制地进行评价尝试，学者们提出了一种叫做代理模型的回归模型，用观测到的点进行插值预测，这类方法中最重要的是在大搜索空间中如何选择尽量少的点预测出最优结果的位置； 第三种主流思路是参数级别的迁移，用之前已经训练好的模型权重参数对target问题进行赋值，从一个高起点的初值开始寻优将会大大地提高效率。在这类问题中，积累了大量的历史寻优数据，对新问题的寻优将会起到很大的帮助，用迁移学习进行求解，是一个很不错的思路；另一种比较有意思的思路叫做单次（One-Shot）架构搜索，这种方法将所有架构视作一个 one-shot 模型（超图）的子图，子图之间通过超图的边来共享权重。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习之优化算法]]></title>
    <url>%2F2017%2F11%2F02%2F%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0_%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[13.1 CPU 和 GPU 的区别?&emsp;&emsp;概念：&emsp;&emsp;CPU 全称是 central processing unit，CPU 是一块超大规模的集成电路，是一台计算机的运 算和控制核心，它的主要功能是解释计算机指令和处理计算机软件中的数据。 &emsp;&emsp;GPU 全称是 graphics processing unit，GPU 是将计算机系统，所需要的显示信息进行转换 的驱动，并向显示器提供扫描信号，控制显示器的正确显示，是连接显示器和个人电脑主板的 重要元件，是人机对话的重要设备之一。 &emsp;&emsp;缓存：&emsp;&emsp;CPU 有大量的缓存结构，目前主流的 CPU 芯片上都有四级缓存，这些缓存结构消耗了大 量的晶体管，在运行的时候需要大量的电力。反观 GPU 的缓存就很简单，目前主流的 GPU 芯 片最多有两层缓存。CPU 消耗在晶体管上的空间和能耗，GPU 都可以用来做成 ALU 单元，也 因此 GPU 比 CPU 的效率要高一些。 &emsp;&emsp;响应方式：&emsp;&emsp;对 CPU 来说，要求的是实时响应，对单任务的速度要求很高，所以就要用很多层缓存的 办法来保证单任务的速度。对 GPU 来说大家不关心第一个像素什么时候计算完成，而是都关 心最后一个像素什么时候计算出来，所以 GPU 就把所有的任务都排好，然后再批处理，这样 对缓存的要求就很低了。举个不恰当的例子，在点击 10 次鼠标的时候，CPU 要每一次点击都 要及时响应，而 GPU 会等第 10 次点击后，再一次性批处理响应。 &emsp;&emsp;浮点运算：&emsp;&emsp;CPU 除了负责浮点整形运算外，还有很多其他的指令集的负载，比如像多媒体解码，硬 件解码等，所以 CPU 是个多才多艺的东西，而 GPU 基本上就是只做浮点运算的，也正是因为 只做浮点运算，所以设计结构简单，也就可以做的更快。另外显卡的 GPU 和单纯为了跑浮点 高性能运算的 GPU 还是不太一样，显卡的 GPU 还要考虑配合图形输出显示等方面，而有些专 用 GPU 设备，就是一个 PCI 卡上面有一个性能很强的浮点运算 GPU，没有显示输出的，这样 的 GPU 就是为了加快某些程序的浮点计算能力。CPU 注重的是单线程的性能，也就是延迟， 对于 CPU 来说，要保证指令流不中断，所以 CPU 需要消耗更多的晶体管和能耗用在控制部分， 于是CPU分配在浮点计算的功耗就会变少。GPU注重的是吞吐量，单指令能驱动更多的计算， 所以相比较而言 GPU 消耗在控制部分的能耗就比较少，因此也就可以把电省下来的资源给浮 点计算使用。 &emsp;&emsp;应用方向：&emsp;&emsp;像操作系统这一类应用，需要快速响应实时信息，需要针对延迟优化，所以晶体管数量和能耗都需要用在分支预测，乱序执行上，低延迟缓存等控制部分，而这都是 CPU 的所擅长的。 对于像矩阵一类的运算，具有极高的可预测性和大量相似运算的，这种高延迟，高吞吐的架构 运算，就非常适合 GPU。 &emsp;&emsp;浅显解释：&emsp;&emsp;一块 CPU 相当于一个数学教授，一块 GPU 相当于 100 个小学生。&emsp;&emsp;第一回合，四则运算，一百个题。教授拿到卷子一道道计算。100 个小学生各拿一道题。 教授刚开始计算到第二题的时候，小学生就集体交卷了。&emsp;&emsp;第二回合，高等函数，一百个题。当教授搞定后。一百个小学生可能还不知道该做些什么。&emsp;&emsp;这两个回合就是 CPU 和 GPU 的区别了。 13.2 如何解决训练样本少的问题&emsp;&emsp;要训练一个好的 CNN 模型，通常需要很多训练数据，尤其是模型结构比较复杂的时候， 比如 ImageNet 数据集上训练的模型。虽然深度学习在 ImageNet 上取得了巨大成功，但是一个 现实的问题是，很多应用的训练集是较小的，如何在这种情况下应用深度学习呢?有三种方法 可供读者参考。 &emsp;&emsp;（1）可以将 ImageNet 上训练得到的模型做为起点，利用目标训练集和反向传播对其进 行继续训练，将模型适应到特定的应用。ImageNet 起到预训练的作用。&emsp;&emsp;（2）如果目标训练集不够大，也可以将低层的网络参数固定，沿用 ImageNet 上的训练集 结果，只对上层进行更新。这是因为底层的网络参数是最难更新的，而从 ImageNet 学习得到 的底层滤波器往往描述了各种不同的局部边缘和纹理信息，而这些滤波器对一般的图像有较好 的普适性。&emsp;&emsp;（3）直接采用 ImageNet 上训练得到的模型，把最高的隐含层的输出作为特征表达，代 替常用的手工设计的特征。 13.3 什么样的样本集不适合用深度学习?&emsp;&emsp;（1）数据集太小，数据样本不足时，深度学习相对其它机器学习算法，没有明显优势。&emsp;&emsp;（2）数据集没有局部相关特性，目前深度学习表现比较好的领域主要是图像/语音 /自然语言处理等领域，这些领域的一个共性是局部相关性。图像中像素组成物体，语音 信号中音位组合成单词，文本数据中单词组合成句子，这些特征元素的组合一旦被打乱， 表示的含义同时也被改变。对于没有这样的局部相关性的数据集，不适于使用深度学习算 法进行处理。举个例子:预测一个人的健康状况，相关的参数会有年龄、职业、收入、家 庭状况等各种元素，将这些元素打乱，并不会影响相关的结果。 13.4 有没有可能找到比已知算法更好的算法?&emsp;&emsp;没有免费的午餐定理: 图 13.4 没有免费的午餐（黑点：训练样本；白点：测试样本） &emsp;&emsp;对于训练样本（黑点），不同的算法 A/B 在不同的测试样本（白点）中有不同的表现，这表示:对于一个学习算法A，若它在某些问题上比学习算法B更好，则必然存在一些问题， 在那里B比A好。&emsp;&emsp;也就是说:对于所有问题，无论学习算法 A 多聪明，学习算法 B 多笨拙，它们的期望性 能相同。&emsp;&emsp;但是:没有免费午餐定力假设所有问题出现几率相同，实际应用中，不同的场景，会有不 同的问题分布，所以，在优化算法时，针对具体问题进行分析，是算法优化的核心所在。 13.5 何为共线性, 跟过拟合有啥关联?&emsp;&emsp;共线性:多变量线性回归中，变量之间由于存在高度相关关系而使回归估计不准确。&emsp;&emsp;产生问题:共线性会造成冗余，导致过拟合。&emsp;&emsp;解决方法:排除变量的相关性、加入权重正则。 13.6 广义线性模型是怎被应用在深度学习中?&emsp;&emsp;深度学习从统计学角度，可以看做递归的广义线性模型。&emsp;&emsp;广义线性模型相对于经典的线性模型$(y=wx+b)$，核心在于引入了连接函数 $g(\cdot)$，形式变为: $y=g-1(wx+b)$。&emsp;&emsp;深度学习时递归的广义线性模型，神经元的激活函数，即为广义线性模型的链接函数。逻 辑回归(广义线性模型的一种)的 Logistic 函数即为神经元激活函数中的 Sigmoid 函数，很多 类似的方法在统计学和神经网络中的名称不一样，容易引起困惑。 13.7 造成梯度消失的原因?&emsp;&emsp;神经网络的训练中，通过改变神经元的权重，使网络的输出值尽可能逼近标签以降低误差 值，训练普遍使用 BP 算法，核心思想是，计算出输出与标签间的损失函数值，然后计算其相 对于每个神经元的梯度，进行权值的迭代。&emsp;&emsp;梯度消失会造成权值更新缓慢，模型训练难度增加。造成梯度消失的一个原因是，许多激 活函数将输出值挤压在很小的区间内，在激活函数两端较大范围的定义域内梯度为 $0$。造成学 习停止。 图 13.7 sigmoid 函数的梯度消失 13.8 权值初始化方法有哪些？&emsp;&emsp;权值初始化的方法主要有:常量初始化(constant)、高斯分布初始化(gaussian)、 positive_unitball 初始化、均匀分布初始化(uniform)、xavier 初始化、msra 初始化、双线性初 始化(bilinear)。 &emsp;&emsp;1. 常量初始化(constant)&emsp;&emsp;把权值或者偏置初始化为一个常数，具体是什么常数，可以自己定义。 &emsp;&emsp;2. 高斯分布初始化(gaussian)&emsp;&emsp;需要给定高斯函数的均值与标准差。 &emsp;&emsp;3. positive_unitball 初始化&emsp;&emsp;让每一个神经元的输入的权值和为 $1$，例如:一个神经元有 $100$ 个输入，让这 $100$ 个输入的权值和为 $1$. 首先给这 $100$ 个权值赋值为在$(0,1)$之间的均匀分布，然后，每一个权值再 除以它们的和就可以啦。这么做，可以有助于防止权值初始化过大，从而防止激活函数(sigmoid 函数)进入饱和区。所以，它应该比较适合 simgmoid 形的激活函数。 &emsp;&emsp;4. 均匀分布初始化(uniform)&emsp;&emsp;将权值与偏置进行均匀分布的初始化，用 min 与 max 控制它们的的上下限，默认为$(0,1)$。 &emsp;&emsp;5. xavier 初始化&emsp;&emsp;对于权值的分布:均值为 $0$，方差为($1$ / 输入的个数)的均匀分布。如果我们更注重前向传播的话，我们可以选择 fan_in，即正向传播的输入个数;如果更注重后向传播的话，我们选择 fan_out, 因为在反向传播的时候，fan_out 就是神经元的输入个数;如果两者都考虑的话， 就选 average = (fan_in + fan_out) /$2$。对于 ReLU 激活函数来说，XavierFiller 初始化也是很适合。关于该初始化方法，具体可以参考文章1、文章2，该方法假定激活函数是线性的。 &emsp;&emsp;6. msra 初始化&emsp;&emsp;对于权值的分布:基于均值为 $0$，方差为( $2$/输入的个数)的高斯分布;它特别适合 ReLU 激活函数，该方法主要是基于 Relu 函数提出的，推导过程类似于 xavier。 &emsp;&emsp;7. 双线性初始化（bilinear）&emsp;&emsp;常用在反卷积神经网络里的权值初始化。 13.9 启发式优化算法中，如何避免陷入局部最优解?&emsp;&emsp;启发式算法中，局部最优值的陷入无法避免。启发式，本质上是一种贪心策略，这也在客 观上决定了不符合贪心规则的更好(或者最优)解会错过。&emsp;&emsp;简单来说，避免陷入局部最优就是两个字:随机。&emsp;&emsp;具体实现手段上，可以根据所采用的启发式框架来灵活地加入随机性。比如遗传里面，可 以在交叉变异时，可以在控制人口策略中，也可以在选择父本母本样本时;禁忌里面，可以在 禁忌表的长度上体现，也可以在解禁策略中使用，等等。这些都要结合具体问题特定的算例集， 需要反复尝试摸索才行。参数的敏感性是一个问题，建议不要超过 $3$ 个参数，参数越不敏感越好。不同算例集用不同种子运行多次($100$ 次左右才有统计意义)，统计平均性能即可。需注 意全局的随机重启通常来说不是一个好办法，因为等于主动放弃之前搜索结果，万不得已不要 用，或者就是不用。 &emsp;&emsp;三个原则应该把握:越随机越好;越不随机越好;二者平衡最好。 &emsp;&emsp;1. 越随机越好&emsp;&emsp;没有随机性，一定会陷入局部最优。为了获得更大的找到最优解的期望，算法中一定要有足够的随机性。具体体现为鲁棒性较好，搜索时多样性较好。算法的每一步选择都可以考虑加入随机性，但要控制好概率。比如，某个贪心策略下，是以概率 $1 $做某一动作，可以考虑将其 改为以概率 $0.999$ 做之前的操作，以剩余概率做其他操作。具体参数设置需调试。 &emsp;&emsp;2. 越不随机越好&emsp;&emsp;随机性往往是对问题内在规律的一种妥协。即没有找到其内在规律，又不知道如何是好， 为了获得更好的多样性，逼不得已加入随机。因此，对给定问题的深入研究才是根本:分辨出 哪些时候，某个动作就是客观上能严格保证最优的——这点至关重要，直接决定了算法性能。 最好的算法一定是和问题结构紧密相连的，范范地套用某个启发式的框架不会有出色的性能。 当然，如果不是追求性能至上，而是考虑到开发效率实现成本这些额外因素，则另当别论。 &emsp;&emsp;3. 二者平衡最好&emsp;&emsp;通常情况下，做好第一点，可以略微改善算法性能;做好第二点，有希望给算法带来质的提高。而二者调和后的平衡则会带来质的飞跃。 &emsp;&emsp;贪心是“自强不息”的精进，不放过任何改进算法的机会;多样性的随机是“厚德载物”的一分包 容，给那些目前看似不那么好的解一些机会。调和好二者，不偏颇任何一方才能使算法有出色 的性能。要把握这种平衡，非一朝一夕之功，只能在反复试验反思中去细细品味。&emsp;&emsp;要结合具体问题而言，范范空谈无太大用。 13.10 凸优化中如何改进 GD 方法以防止陷入局部最优解?&emsp;&emsp;在对函数进行凸优化时，如果使用导数的方法(如:梯度下降法/GD，牛顿法等)来寻找最优解，有可能陷入到局部最优解而非全局最优解。&emsp;&emsp;为了防止得到局部最优，可以对梯度下降法进行一些改进，防止陷入局部最优。&emsp;&emsp;但是请注意，这些方法只能保证以最大的可能找到全局最优，无法保证 $100\%$得到全局最优。 &emsp;&emsp;（1）incremental GD/stochastic GD&emsp;&emsp;在 GD 中，是需要遍历所有的点之后才计算 $w$ 的变化的;但是，在 stochastic GD 中，每输入一个点，就根据该点计算下一步的 $w$，这样，不仅可以从 batch training 变成 online training 方法，而且每次是按照单点的最优方向而不是整体的最优方向前进，从而相当于在朝目标前进的路上多拐了好多弯，有可能逃出局部最优。 &emsp;&emsp;（2）momentum 方法&emsp;&emsp;momentum 相当与记忆住上一次的更新。在每次的更新中，都要加一个 $k$ 倍的上一次更新 量。这样，也不再是按照标准路线前进，每次的步骤都容易受到上一次的影响，从而可能会逃 出局部最优。另外，也会加大步长，从而加快收敛。 13.11 常见的损失函数?&emsp;&emsp;机器学习通过对算法中的目标函数进行不断求解优化，得到最终想要的结果。分类和回归 问题中，通常使用损失函数或代价函数作为目标函数。&emsp;&emsp;损失函数用来评价预测值和真实值不一样的程度。通常损失函数越好，模型的性能也越好。&emsp;&emsp;损失函数可分为经验风险损失函数和结构风险损失函数。经验风险损失函数指预测结果和 实际结果的差别，结构风险损失函数是在经验风险损失函数上加上正则项。 &emsp;&emsp;下面介绍常用的损失函数: &emsp;&emsp;1）$0-1$ 损失函数&emsp;&emsp;如果预测值和目标值相等，值为 $0$，如果不相等，值为 $1$：$$L(Y,f(x))=\left{\begin{array}{}1\;\;\;,\;\;Y\ne f(x), \0\;\;\;,\;\;Y=f(x).\end{array}\right.$$ &emsp;&emsp;一般的在实际使用中，相等的条件过于严格，可适当放宽条件：$$L(Y,f(x))=\left{\begin{array}{}1\;\;\;,\;\;|Y - f(x)| \ge T, \0\;\;\;,\;\;|Y-f(x)| &lt; T.\end{array}\right.$$ &emsp;&emsp;2）绝对值损失函数&emsp;&emsp;和 $0-1$ 损失函数相似，绝对值损失函数表示为：$$L(Y,f(x))=|Y-f(x)|.$$ &emsp;&emsp;3）平方损失函数$$L(Y|f(x))=\sum_{N}(Y-f(x))^2.$$ &emsp;&emsp;这点可从最小二乘法和欧几里得距离角度理解。最小二乘法的原理是，最优拟合曲线应该 使所有点到回归直线的距离和最小。 &emsp;&emsp;4）$log$ 对数损失函数$$L(Y,P(Y|X))=-logP(Y|X).$$ &emsp;&emsp;常见的逻辑回归使用的就是对数损失函数，有很多人认为逻辑回归的损失函数式平方损失， 其实不然。逻辑回归它假设样本服从伯努利分布，进而求得满足该分布的似然函数，接着取对 数求极值等。逻辑回归推导出的经验风险函数是最小化负的似然函数，从损失函数的角度看， 就是 $log$ 损失函数。 &emsp;&emsp;5）指数损失函数&emsp;&emsp;指数损失函数的标准形式为：$$L(Y|f(x))=exp[-yf(x)].$$ &emsp;&emsp;例如 AdaBoost 就是以指数损失函数为损失函数。 &emsp;&emsp;6）Hinge 损失函数&emsp;&emsp;Hinge 损失函数的标准形式如下：$$L(y)=max(0, 1-ty).$$ &emsp;&emsp;其中 $y$ 是预测值，范围为$(-1,1)$, $t$ 为目标值，其为$-1$ 或 $1$。&emsp;&emsp;在线性支持向量机中，最优化问题可等价于：$$\underset{w,b}{min}\sum_{i=1}^{N}(1-y_i(wx_i+b))+\lambda \lVert w^2 \rVert$$ &emsp;&emsp;$$\frac{1}{m}\sum_{i=1}^{N}l(wx_i+by_i))+\lVert w^2 \rVert$$ &emsp;&emsp;其中$l(wx_i+by_i))$是Hinge损失函数，$\lVert w^2 \rVert$可看做为正则化项。 13.14 如何进行特征选择(feature selection)?13.14.1 如何考虑特征选择&emsp;&emsp;当数据预处理完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。通常来说，从两个方面考虑来选择特征: &emsp;&emsp;（1）特征是否发散:如果一个特征不发散，例如方差接近于 $0$，也就是说样本在这个特 征上基本上没有差异，这个特征对于样本的区分并没有什么用。&emsp;&emsp;（2）特征与目标的相关性:这点比较显见，与目标相关性高的特征，应当优选选择。除移除低方差法外，本文介绍的其他方法均从相关性考虑。 13.14.2 特征选择方法分类&emsp;&emsp;根据特征选择的形式又可以将特征选择方法分为 $3$ 种: &emsp;&emsp;（1）Filter:过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。&emsp;&emsp;（2）Wrapper:包装法，根据目标函数(通常是预测效果评分)，每次选择若干特征，或者排除若干特征。&emsp;&emsp;（3）Embedded:嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于 Filter 方法，但是是通过训练来确定特征的优劣。 13.14.3 特征选择目的&emsp;&emsp;（1）减少特征数量、降维，使模型泛化能力更强，减少过拟合;&emsp;&emsp;（2）增强对特征和特征值之间的理解。拿到数据集，一个特征选择方法，往往很难同时完成这两个目的。通常情况下，选择一种自己最熟悉或者最方便的特征选择方法(往往目的是降维，而忽略了对特征和数据理解的目的)。 本文将结合 Scikit-learn 提供的例子介绍几种常用的特征选择方法，它们各自的优缺点和问题。 13.15 梯度消失/梯度爆炸原因，以及解决方法13.15.1 为什么要使用梯度更新规则?&emsp;&emsp;在介绍梯度消失以及爆炸之前，先简单说一说梯度消失的根源—–深度神经网络和反向传 播。目前深度学习方法中，深度神经网络的发展造就了我们可以构建更深层的网络完成更复杂 的任务，深层网络比如深度卷积网络，LSTM 等等，而且最终结果表明，在处理复杂任务上， 深度网络比浅层的网络具有更好的效果。但是，目前优化神经网络的方法都是基于反向传播的 思想，即根据损失函数计算的误差通过梯度反向传播的方式，指导深度网络权值的更新优化。 这样做是有一定原因的，首先，深层网络由许多非线性层堆叠而来，每一层非线性层都可以视 为是一个非线性函数 $f(x)$（$f(x)$非线性来自于非线性激活函数），因此整个深度网络可以视为是一个复合的非线性多元函数：$$F(x)=f_n(\cdots f_3(f_2(f_1(x)\theta_1+b)\theta_2+b)\cdots)$$ &emsp;&emsp;我们最终的目的是希望这个多元函数可以很好的完成输入到输出之间的映射，假设不同的输入，输出的最优解是$g(x)$ ，那么，优化深度网络就是为了寻找到合适的权值，满足 $Loss=L(g(x),F(x))$取得极小值点，比如最简单的损失函数：$$Loss = \lVert g(x)-f(x) \rVert^2_2.$$ &emsp;&emsp;假设损失函数的数据空间是下图这样的，我们最优的权值就是为了寻找下图中的最小值点， 对于这种数学寻找最小值问题，采用梯度下降的方法再适合不过了。 图 13.15.1 13.15.2 梯度消失、爆炸原因?&emsp;&emsp;梯度消失与梯度爆炸其实是一种情况，看接下来的文章就知道了。两种情况下梯度消失经 常出现，一是在深层网络中，二是采用了不合适的损失函数，比如 sigmoid。梯度爆炸一般出 现在深层网络和权值初始化值太大的情况下，下面分别从这两个角度分析梯度消失和爆炸的原因。 &emsp;&emsp;（1）深层网络角度&emsp;&emsp;对激活函数进行求导，如果此部分大于 $1$，那么层数增多的时候，最终的求出的梯度更新 将以指数形式增加，即发生梯度爆炸，如果此部分小于 $1$，那么随着层数增多，求出的梯度更 新信息将会以指数形式衰减，即发生了梯度消失。&emsp;&emsp;从深层网络角度来讲，不同的层学习的速度差异很大，表现为网络中靠近输出的层学习的 情况很好，靠近输入的层学习的很慢，有时甚至训练了很久，前几层的权值和刚开始随机初始 化的值差不多。因此，梯度消失、爆炸，其根本原因在于反向传播训练法则，属于先天不足， 另外多说一句，Hinton 提出 capsule 的原因就是为了彻底抛弃反向传播，如果真能大范围普及， 那真是一个革命。 &emsp;&emsp;（2）激活函数角度&emsp;&emsp;计算权值更新信息的时候需要计算前层偏导信息，因此如果激活函数选择不合适，比如使用 sigmoid，梯度消失就会很明显了，原因看下图，左图是sigmoid的损失函数图，右边是其倒数的图像，如果使用 sigmoid 作为损失函数，其梯度是不可能超过 $0.25$ 的，这样经过链式求导之后，很容易发生梯度消失。 图 13.15.2 sigmod函数与其导数 13.15.3 梯度消失、爆炸的解决方案&emsp;&emsp;方案1-预训练加微调&emsp;&emsp;此方法来自Hinton在2006年发表的一篇论文，Hinton为了解决梯度的问题，提出采取无监督逐层训练方法，其基本思想是每次训练一层隐节点，训练时将上一层隐节点的输出作为输入，而本层隐节点的输出作为下一层隐节点的输入，此过程就是逐层“预训练”（pre-training）；在预训练完成后，再对整个网络进行“微调”（fine-tunning）。Hinton在训练深度信念网络（Deep Belief Networks中，使用了这个方法，在各层预训练完成后，再利用BP算法对整个网络进行训练。此思想相当于是先寻找局部最优，然后整合起来寻找全局最优，此方法有一定的好处，但是目前应用的不是很多了。 &emsp;&emsp;方案2-梯度剪切、正则&emsp;&emsp;梯度剪切这个方案主要是针对梯度爆炸提出的，其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。&emsp;&emsp;另外一种解决梯度爆炸的手段是采用权重正则化（weithts regularization）比较常见的是l1l1正则，和l2l2正则，在各个深度框架中都有相应的API可以使用正则化。 &emsp;&emsp;方案3-relu、leakrelu、elu等激活函数&emsp;&emsp;Relu&emsp;&emsp;思想也很简单，如果激活函数的导数为1，那么就不存在梯度消失爆炸的问题了，每层的网络都可以得到相同的更新速度，relu就这样应运而生。&emsp;&emsp;relu函数的导数在正数部分是恒等于1的，因此在深层网络中使用relu激活函数就不会导致梯度消失和爆炸的问题。relu的主要贡献在于：&emsp;&emsp;（1）解决了梯度消失、爆炸的问题&emsp;&emsp;（2）计算方便，计算速度快&emsp;&emsp;（3）加速了网络的训练 &emsp;&emsp;同时也存在一些缺点：&emsp;&emsp;（1）由于负数部分恒为0，会导致一些神经元无法激活（可通过设置小学习率部分解决）；&emsp;&emsp;（2）输出不是以0为中心的。 &emsp;&emsp;leakrelu&emsp;&emsp;leakrelu就是为了解决relu的0区间带来的影响，其数学表达为：leakrelu$=max(k*x,0)$其中$k$是leak系数，一般选择$0.01$或者$0.02$，或者通过学习而来。 &emsp;&emsp;方案4-batchnorm&emsp;&emsp;Batchnorm是深度学习发展以来提出的最重要的成果之一了，目前已经被广泛的应用到了各大网络中，具有加速网络收敛速度，提升训练稳定性的效果，Batchnorm本质上是解决反向传播过程中的梯度问题。Batchnorm全名是Batch Normalization，简称BN，即批规范化，通过规范化操作将输出信号$x$规范化到均值为$0$，方差为$1$保证网络的稳定性。 &emsp;&emsp;方案5-残差结构&emsp;&emsp;事实上，就是残差网络的出现导致了Imagenet比赛的终结，自从残差提出后，几乎所有的深度网络都离不开残差的身影，相比较之前的几层，几十层的深度网络，在残差网络面前都不值一提，残差可以很轻松的构建几百层，一千多层的网络而不用担心梯度消失过快的问题，原因就在于残差的捷径（shortcut）部分。 &emsp;&emsp;方案6-LSTM&emsp;&emsp;LSTM全称是长短期记忆网络（long-short term memory networks），是不那么容易发生梯度消失的，主要原因在于LSTM内部复杂的“门”(gates)。 13.16 深度学习为什么不用二阶优化 二阶优化方法可以用到深度学习网络中，比如DistBelief，《Large-scale L-BFGS using MapReduce》.采用了数据并行的方法解决了海量数据下L-BFGS算法的可用性问题。 二阶优化方法目前还不适用于深度学习训练中，主要存在问题是：（1）最重要的问题是二阶方法的计算量大，训练较慢。（2）求导不易，实现比SGD这类一阶方法复杂。（3）另外其优点在深度学习中无法展现出来，主要是二阶方法能够更快地求得更高精度的解，这在浅层模型是有益的，但是在神经网络这类深层模型中对参数的精度要求不高，相反 相对而言不高的精度对模型还有益处，能够提高模型的泛化能力。（4）稳定性。题主要明白的一点事，越简单的东西往往越robust，对于优化算法也是这样。梯度下降等一阶算法只要步长不选太大基本都不会出问题，但二阶方法遍地是坑，数值稳定性啊等等。 13.17 怎样优化你的深度学习系统？&emsp;&emsp;你可能有很多想法去改善你的系统，比如，你可能想我们去收集更多的训练数据吧。或者你会说，可能你的训练集的多样性还不够，你应该收集更多不同姿势的猫咪图片，或者更多样化的反例集。或者你想再用梯度下降训练算法，训练久一点。或者你想尝试用一个完全不同的优化算法，比如Adam优化算法。或者尝试使用规模更大或者更小的神经网络。或者你想试试dropout或者正则化。或者你想修改网络的架构，比如修改激活函数，改变隐藏单元的数目之类的方法。 &emsp;&emsp;当你尝试优化一个深度学习系统时，你通常可以有很多想法可以去试，问题在于，如果你做出了错误的选择，你完全有可能白费6个月的时间，往错误的方向前进，在6个月之后才意识到这方法根本不管用。比如，我见过一些团队花了6个月时间收集更多数据，却在6个月之后发现，这些数据几乎没有改善他们系统的性能。所以，假设你的项目没有6个月的时间可以浪费，如果有快速有效的方法能够判断哪些想法是靠谱的，或者甚至提出新的想法，判断哪些是值得一试的想法，哪些是可以放心舍弃的。 &emsp;&emsp;我希望在这门课程中，可以教给你们一些策略，一些分析机器学习问题的方法，可以指引你们朝着最有希望的方向前进。这门课中，我会和你们分享我在搭建和部署大量深度学习产品时学到的经验和教训，我想这些内容是这门课程独有的。比如说，很多大学深度学习课程很少提到这些策略。事实上，机器学习策略在深度学习的时代也在变化，因为现在对于深度学习算法来说能够做到的事情，比上一代机器学习算法大不一样。我希望这些策略能帮助你们提高效率，让你们的深度学习系统更快投入实用。 13.18 为什么要设置单一数字评估指标？&emsp;&emsp;无论你是调整超参数，或者是尝试不同的学习算法，或者在搭建机器学习系统时尝试不同手段，你会发现，如果你有一个单实数评估指标，你的进展会快得多，它可以快速告诉你，新尝试的手段比之前的手段好还是差。所以当团队开始进行机器学习项目时，我经常推荐他们为问题设置一个单实数评估指标。 &emsp;&emsp;我发现很多机器学习团队就是这样，有一个定义明确的开发集用来测量查准率和查全率，再加上这样一个单一数值评估指标，有时我叫单实数评估指标，能让你快速判断分类器或者分类器更好。所以有这样一个开发集，加上单实数评估指标，你的迭代速度肯定会很快，它可以加速改进您的机器学习算法的迭代过程。 图 13.8.1 13.19 满足和优化指标（Satisficing and optimizing metrics）&emsp;&emsp;要把你顾及到的所有事情组合成单实数评估指标有时并不容易，在那些情况里，我发现有时候设立满足和优化指标是很重要的，让我告诉你是什么意思吧。 图 13.9.1 &emsp;&emsp;假设你已经决定你很看重猫分类器的分类准确度，这可以是分数或者用其他衡量准确度的指标。但除了准确度之外，我们还需要考虑运行时间，就是需要多长时间来分类一张图。分类器需要$80$毫秒，需要$95$毫秒，C需要$1500$毫秒，就是说需要$1.5$秒来分类图像。 &emsp;&emsp;你可以这么做，将准确度和运行时间组合成一个整体评估指标。所以成本，比如说，总体成本是，这种组合方式可能太刻意，只用这样的公式来组合准确度和运行时间，两个数值的线性加权求和。 &emsp;&emsp;你还可以做其他事情，就是你可能选择一个分类器，能够最大限度提高准确度，但必须满足运行时间要求，就是对图像进行分类所需的时间必须小于等于$100$毫秒。所以在这种情况下，我们就说准确度是一个优化指标，因为你想要准确度最大化，你想做的尽可能准确，但是运行时间就是我们所说的满足指标，意思是它必须足够好，它只需要小于$100$毫秒，达到之后，你不在乎这指标有多好，或者至少你不会那么在乎。所以这是一个相当合理的权衡方式，或者说 将准确度和运行时间结合起来的方式。实际情况可能是，只要运行时间少于 100 毫秒，你的用 户就不会在乎运行时间是 100 毫秒还是 50 毫秒，甚至更快。 &emsp;&emsp;通过定义优化和满足指标，就可以给你提供一个明确的方式，去选择“最好的”分类器。在 这种情况下分类器 B 最好，因为在所有的运行时间都小于 100 毫秒的分类器中，它的准确度最好。 &emsp;&emsp;总结一下，如果你需要顾及多个指标，比如说，有一个优化指标，你想尽可能优化的，然 后还有一个或多个满足指标，需要满足的，需要达到一定的门槛。现在你就有一个全自动的方 法，在观察多个成本大小时，选出”最好的”那个。现在这些评估指标必须是在训练集或开发集 或测试集上计算或求出来的。所以你还需要做一件事，就是设立训练集、开发集，还有测试集。 在下一个视频里，我想和大家分享一些如何设置训练、开发和测试集的指导方针，我们下一个 视频继续。 13.20 怎样划分训练/开发/测试集&emsp;&emsp;设立训练集，开发集和测试集的方式大大影响了你或者你的团队在建立机器学习应用方面取得进展的速度。同样的团队，即使是大公司里的团队，在设立这些数据集的方式，真的会让团队的进展变慢而不是加快，我们看看应该如何设立这些数据集，让你的团队效率最大化。 &emsp;&emsp;我建议你们不要这样，而是让你的开发集和测试集来自同一分布。我的意思是这样，你们要记住，我想就是设立你的开发集加上一个单实数评估指标，这就是像是定下目标，然后告诉你的团队，那就是你要瞄准的靶心，因为你一旦建立了这样的开发集和指标，团队就可以快速迭代，尝试不同的想法，跑实验，可以很快地使用开发集和指标去评估不同分类器，然后尝试选出最好的那个。所以，机器学习团队一般都很擅长使用不同方法去逼近目标，然后不断迭代，不断逼近靶心。所以，针对开发集上的指标优化。 &emsp;&emsp;所以我建议你们在设立开发集和测试集时，要选择这样的开发集和测试集，能够反映你未来会得到的数据，认为很重要的数据，必须得到好结果的数据，特别是，这里的开发集和测试集可能来自同一个分布。所以不管你未来会得到什么样的数据，一旦你的算法效果不错，要尝试收集类似的数据，而且，不管那些数据是什么，都要随机分配到开发集和测试集上。因为这样，你才能将瞄准想要的目标，让你的团队高效迭代来逼近同一个目标，希望最好是同一个目标。 &emsp;&emsp;我们还没提到如何设立训练集，我们会在之后的视频里谈谈如何设立训练集，但这个视频的重点在于，设立开发集以及评估指标，真的就定义了你要瞄准的目标。我们希望通过在同一分布中设立开发集和测试集，你就可以瞄准你所希望的机器学习团队瞄准的目标。而设立训练集的方式则会影响你逼近那个目标有多快，但我们可以在另一个讲座里提到。我知道有一些机器学习团队，他们如果能遵循这个方针，就可以省下几个月的工作，所以我希望这些方针也能帮到你们。 &emsp;&emsp;接下来，实际上你的开发集和测试集的规模，如何选择它们的大小，在深度学习时代也在变化，我们会在下一个视频里提到这些内容。 13.21 如何划分开发/测试集大小&emsp;&emsp;你可能听说过一条经验法则，在机器学习中，把你取得的全部数据用$70/30$比例分成训练集和测试集。或者如果你必须设立训练集、开发集和测试集，你会这么分$60\%$训练集，$20\%$开发集，$20\%$测试集。在机器学习的早期，这样分是相当合理的，特别是以前的数据集大小要小得多。所以如果你总共有100个样本，这样$70/30$或者$60/20/20$分的经验法则是相当合理的。如果你有几千个样本或者有一万个样本，这些做法也还是合理的。 &emsp;&emsp;但在现代机器学习中，我们更习惯操作规模大得多的数据集，比如说你有$1$百万个训练样本，这样分可能更合理，$98\%$作为训练集，$1\%$开发集，$1\%$测试集，我们用和缩写来表示开发集和测试集。因为如果你有$1$百万个样本，那么$1\%$就是$10,000$个样本，这对于开发集和测试集来说可能已经够了。所以在现代深度学习时代，有时我们拥有大得多的数据集，所以使用小于$20\%$的比例或者小于$30\%$比例的数据作为开发集和测试集也是合理的。而且因为深度学习算法对数据的胃口很大，我们可以看到那些有海量数据集的问题，有更高比例的数据划分到训练集里，那么测试集呢？ &emsp;&emsp;总结一下，在大数据时代旧的经验规则，这个$70/30$不再适用了。现在流行的是把大量数据分到训练集，然后少量数据分到开发集和测试集，特别是当你有一个非常大的数据集时。以前的经验法则其实是为了确保开发集足够大，能够达到它的目的，就是帮你评估不同的想法，然后选出还是更好。测试集的目的是评估你最终的成本偏差，你只需要设立足够大的测试集，可以用来这么评估就行了，可能只需要远远小于总体数据量的$30\%$。 &emsp;&emsp;所以我希望本视频能给你们一点指导和建议，让你们知道如何在深度学习时代设立开发和测试集。接下来，有时候在研究机器学习的问题途中，你可能需要更改评估指标，或者改动你的开发集和测试集，我们会讲什么时候需要这样做。 13.22 什么时候该改变开发/测试集和指标？&emsp;&emsp;我们来看一个例子，假设你在构建一个猫分类器，试图找到很多猫的照片，向你的爱猫人士用户展示，你决定使用的指标是分类错误率。所以算法和分别有3％错误率和5％错误率，所以算法似乎做得更好。 &emsp;&emsp;但我们实际试一下这些算法，你观察一下这些算法，算法由于某些原因，把很多色情图像分类成猫了。如果你部署算法，那么用户就会看到更多猫图，因为它识别猫的错误率只有$3\%$，但它同时也会给用户推送一些色情图像，这是你的公司完全不能接受的，你的用户也完全不能接受。相比之下，算法有$5\%$的错误率，这样分类器就得到较少的图像，但它不会推送色情图像。所以从你们公司的角度来看，以及从用户接受的角度来看，算法实际上是一个更好的算法，因为它不让任何色情图像通过。 &emsp;&emsp;那么在这个例子中，发生的事情就是，算法A在评估指标上做得更好，它的错误率达到$3\%$，但实际上是个更糟糕的算法。在这种情况下，评估指标加上开发集它们都倾向于选择算法，因为它们会说，看算法A的错误率较低，这是你们自己定下来的指标评估出来的。但你和你的用户更倾向于使用算法，因为它不会将色情图像分类为猫。所以当这种情况发生时，当你的评估指标无法正确衡量算法之间的优劣排序时，在这种情况下，原来的指标错误地预测算法A是更好的算法这就发出了信号，你应该改变评估指标了，或者要改变开发集或测试集。在这种情况下，你用的分类错误率指标可以写成这样： &emsp;&emsp;但粗略的结论是，如果你的评估指标无法正确评估好算法的排名，那么就需要花时间定义一个新的评估指标。这是定义评估指标的其中一种可能方式（上述加权法）。评估指标的意义在于，准确告诉你已知两个分类器，哪一个更适合你的应用。就这个视频的内容而言，我们不需要太注重新错误率指标是怎么定义的，关键在于，如果你对旧的错误率指标不满意，那就不要一直沿用你不满意的错误率指标，而应该尝试定义一个新的指标，能够更加符合你的偏好，定义出实际更适合的算法。 &emsp;&emsp;所以方针是，如果你在指标上表现很好，在当前开发集或者开发集和测试集分布中表现很好，但你的实际应用程序，你真正关注的地方表现不好，那么就需要修改指标或者你的开发测试集。换句话说，如果你发现你的开发测试集都是这些高质量图像，但在开发测试集上做的评估无法预测你的应用实际的表现。因为你的应用处理的是低质量图像，那么就应该改变你的开发测试集，让你的数据更能反映你实际需要处理好的数据。 &emsp;&emsp;但总体方针就是，如果你当前的指标和当前用来评估的数据和你真正关心必须做好的事情关系不大，那就应该更改你的指标或者你的开发测试集，让它们能更够好地反映你的算法需要处理好的数据。 13.23 设置评估指标的意义？&emsp;&emsp;评估指标的意义在于，准确告诉你已知两个分类器，哪一个更适合你的应用。就这个视频的内容而言，我们不需要太注重新错误率指标是怎么定义的，关键在于，如果你对旧的错误率指标不满意，那就不要一直沿用你不满意的错误率指标，而应该尝试定义一个新的指标，能够更加符合你的偏好，定义出实际更适合的算法。 13.24 什么是可避免偏差？&emsp;&emsp;http://www.ai-start.com/dl2017/lesson3-week1.html &emsp;&emsp;所以要给这些概念命名一下，这不是广泛使用的术语，但我觉得这么说思考起来比较流畅。就是把这个差值，贝叶斯错误率或者对贝叶斯错误率的估计和训练错误率之间的差值称为可避免偏差，你可能希望一直提高训练集表现，直到你接近贝叶斯错误率，但实际上你也不希望做到比贝叶斯错误率更好，这理论上是不可能超过贝叶斯错误率的，除非过拟合。而这个训练错误率和开发错误率之前的差值，就大概说明你的算法在方差问题上还有多少改善空间。 &emsp;&emsp;可避免偏差这个词说明了有一些别的偏差，或者错误率有个无法超越的最低水平，那就是说如果贝叶斯错误率是$7.5\%$。你实际上并不想得到低于该级别的错误率，所以你不会说你的训练错误率是$8\%$，然后$8\%$就衡量了例子中的偏差大小。你应该说，可避免偏差可能在$0.5\%$左右，或者$0.5\%$是可避免偏差的指标。而这个$2\%$是方差的指标，所以要减少这个$2\%$比减少这个$0.5\%$空间要大得多。而在左边的例子中，这$7\%$衡量了可避免偏差大小，而$2\%$衡量了方差大小。所以在左边这个例子里，专注减少可避免偏差可能潜力更大。 13.25 什么是TOP5错误率？&emsp;&emsp;top1就是你预测的label取最后概率向量里面最大的那一个作为预测结果，你的预测结果中概率最大的那个类必须是正确类别才算预测正确。而top5就是最后概率向量最大的前五名中出现了正确概率即为预测正确。 &emsp;&emsp;ImageNet 项目是一个用于物体对象识别检索大型视觉数据库。截止$2016$年，ImageNet 已经对超过一千万个图像的url进行手动注释，标记图像的类别。在至少一百万张图像中还提供了边界框。自$2010$年以来，ImageNet 举办一年一度的软件竞赛，叫做 ImageNet 大尺度视觉识别挑战(ImageNet Large Scale Visual Recognition Challenge,ILSVRC)。主要内容是通过算法程序实现正确分类和探测识别物体与场景，评价标准就是Top-5 错误率。 &emsp;&emsp;Top-5 错误率&emsp;&emsp;ILSRVRC（ImageNet 图像分类大赛） 比赛设置如下：$1000$类图像分类问题，训练数据集$126$万张图像，验证集$5$万张，测试集$10$万张（标注未公布）。评价标准采用 top-5 错误率——即对一张图像预测$5$个类别，只要有一个和人工标注类别相同就算对，否则算错。 13.26 什么是人类水平错误率？&emsp;&emsp;人类水平错误率的定义，就是如果你想要替代或估计贝叶斯错误率，那么一队经验丰富的医生讨论和辩论之后，可以达到$0.5\%$的错误率。我们知道贝叶斯错误率小于等于$0.5\%$，因为有些系统，这些医生团队可以达到$0.5\%$的错误率。所以根据定义，最优错误率必须在$0.5\%$以下。我们不知道多少更好，也许有一个更大的团队，更有经验的医生能做得更好，所以也许比$0.5\%$好一点。但是我们知道最优错误率不能高于$0.5\%$，那么在这个背景下，我就可以用$0.5\%$估计贝叶斯错误率。所以我将人类水平定义为$0.5\%$，至少如果你希望使用人类水平错误来分析偏差和方差的时候，就像上个视频那样。 &emsp;&emsp;现在，为了发表研究论文或者部署系统，也许人类水平错误率的定义可以不一样，你可以使用1%，只要你超越了一个普通医生的表现，如果能达到这种水平，那系统已经达到实用了。也许超过一名放射科医生，一名医生的表现，意味着系统在一些情况下可以有部署价值了。 13.27 可避免偏差、几大错误率之间的关系？&emsp;&emsp;要了解为什么这个很重要，我们来看一个错误率分析的例子。比方说，在医学图像诊断例子中，你的训练错误率是$5\%$，你的开发错误率是$6\%$。而在上一张幻灯片的例子中，我们的人类水平表现，我将它看成是贝叶斯错误率的替代品，取决于你是否将它定义成普通单个医生的表现，还是有经验的医生或医生团队的表现，你可能会用$1\%$或$0.7\%$或$0.5\%$。同时也回想一下，前面视频中的定义，贝叶斯错误率或者说贝叶斯错误率的估计和训练错误率直接的差值就衡量了所谓的可避免偏差，这（训练误差与开发误差之间的差值）可以衡量或者估计你的学习算法的方差问题有多严重。 &emsp;&emsp;所以在这个第一个例子中，无论你做出哪些选择，可避免偏差大概是$4\%$，这个值我想介于……，如果你取$1\%$就是$4\%$，如果你取$0.5\%$就是$4.5\%$，而这个差距（训练误差与开发误差之间的差值）是$1\%$。所以在这个例子中，我得说，不管你怎么定义人类水平错误率，使用单个普通医生的错误率定义，还是单个经验丰富医生的错误率定义或经验丰富的医生团队的错误率定义，这是$4\%$还是$4.5\%$，这明显比都比方差问题更大。所以在这种情况下，你应该专注于减少偏差的技术，例如培训更大的网络。 13.28 怎样选取可避免偏差及贝叶斯错误率?&emsp;&emsp;就是比如你的训练错误率是0.7%，所以你现在已经做得很好了，你的开发错误率是$0.8\%$。在这种情况下，你用$0.5\%$来估计贝叶斯错误率关系就很大。因为在这种情况下，你测量到的可避免偏差是$0.2\%$，这是你测量到的方差问题$0.1\%$的两倍，这表明也许偏差和方差都存在问题。但是，可避免偏差问题更严重。在这个例子中，我们在上一张幻灯片中讨论的是$0.5\%$，就是对贝叶斯错误率的最佳估计，因为一群人类医生可以实现这一目标。如果你用$0.7$代替贝叶斯错误率，你测得的可避免偏差基本上是$0\%$，那你就可能忽略可避免偏差了。实际上你应该试试能不能在训练集上做得更好。 13.29 怎样减少方差？&emsp;&emsp;如果你的算法方差较高，可以尝试下面的技巧： &emsp;&emsp;（1）增加训练数据：只要你可以获得大量数据和足够的算力去处理数据，这就是一种解决高方差问题最简单，最可靠的方式。&emsp;&emsp;（2）正则化（L2, L1, dropout）：这种技巧减少方差的同时，增加了偏差。&emsp;&emsp;（3）提前停止（例如，根据开发集的错误率来提前停止梯度下降）：这种技巧减少方差的同时增加的偏差。提前停止技巧很像正则化方法，一些论文作者也叫他正则化技巧。&emsp;&emsp;（4）特征选择来减少输入特征的数量或类型：这种技巧可能会处理好方差问题，但是同时会增大偏差。稍微减少特征数量（比如从1000个特征减少到900个特征）不太可能对偏差产生大的影响。大量减少特征数量（比如从$1000$减少到$100-$减少$10$倍）可能产生较大偏差，因为去掉了很多有用的特征。（注：可能会欠拟合）。在现代的深度学习中，数据量很大，人们对待特征选择的态度出现了转变，现在我们更加倾向于使用全部的特征，让算法自己选择合适的特征。但是当训练集比较小时，特征选择非常有用。&emsp;&emsp;（5）缩小模型（例如减少网络层数和神经元数量）：谨慎使用。这种技巧可以减少方差，同时也可能增加偏差。然而，我并不推荐使用这种技巧来解决方差问题。添加正则化通常会获得更好的分类性能。缩小模型的优点在于减少计算成本，以更快的速度来训练模型。如果模型的训练速度非常重要，那么就想尽一切方法来缩小模型。但是如果目标是减少方差，不是那么在意计算成本，可以考虑添加正则化。 13.30 贝叶斯错误率的最佳估计&emsp;&emsp;对于这样的问题，更好的估计贝叶斯错误率很有必要，可以帮助你更好地估计可避免偏差和方差，这样你就能更好的做出决策，选择减少偏差的策略，还是减少方差的策略。 13.31 举机器学习超过单个人类表现几个例子？&emsp;&emsp;现在，机器学习有很多问题已经可以大大超越人类水平了。例如，我想网络广告，估计某个用户点击广告的可能性，可能学习算法做到的水平已经超越任何人类了。还有提出产品建议，向你推荐电影或书籍之类的任务。我想今天的网站做到的水平已经超越你最亲近的朋友了。还有物流预测，从到开车需要多久，或者预测快递车从开到需要多少时间。或者预测某人会不会偿还贷款，这样你就能判断是否批准这人的贷款。我想这些问题都是今天的机器学习远远超过了单个人类的表现。 &emsp;&emsp;除了这些问题，今天已经有语音识别系统超越人类水平了，还有一些计算机视觉任务，一些图像识别任务，计算机已经超越了人类水平。但是由于人类对这种自然感知任务非常擅长，我想计算机达到那种水平要难得多。还有一些医疗方面的任务，比如阅读ECG或诊断皮肤癌，或者某些特定领域的放射科读图任务，这些任务计算机做得非常好了，也许超越了单个人类的水平。 13.32如何改善你的模型？&emsp;&emsp;你们学过正交化，如何设立开发集和测试集，用人类水平错误率来估计贝叶斯错误率以及如何估计可避免偏差和方差。我们现在把它们全部组合起来写成一套指导方针，如何提高学习算法性能的指导方针。 &emsp;&emsp;首先，你的算法对训练集的拟合很好，这可以看成是你能做到可避免偏差很低。还有第二件事你可以做好的是，在训练集中做得很好，然后推广到开发集和测试集也很好，这就是说方差不是太大。 总结一下前几段视频我们见到的步骤，如果你想提升机器学习系统的性能，我建议你们看看训练错误率和贝叶斯错误率估计值之间的距离，让你知道可避免偏差有多大。换句话说，就是你觉得还能做多好，你对训练集的优化还有多少空间。 然后看看你的开发错误率和训练错误率之间的距离，就知道你的方差问题有多大。换句话说，你应该做多少努力让你的算法表现能够从训练集推广到开发集，算法是没有在开发集上训练的。 用尽一切办法减少可避免偏差 比如使用规模更大的模型，这样算法在训练集上的表现会更好，或者训练更久。 使用更好的优化算法，比如说加入momentum或者RMSprop，或者使用更好的算法，比如Adam。你还可以试试寻找更好的新神经网络架构，或者说更好的超参数。这些手段包罗万有，你可以改变激活函数，改变层数或者隐藏单位数，虽然你这么做可能会让模型规模变大。 或者试用其他模型，其他架构，如循环神经网络和卷积神经网络。 &emsp;&emsp;在之后的课程里我们会详细介绍的，新的神经网络架构能否更好地拟合你的训练集，有时也很难预先判断，但有时换架构可能会得到好得多的结果。 13.33 理解误差分析&emsp;&emsp;如果你希望让学习算法能够胜任人类能做的任务，但你的学习算法还没有达到人类的表现，那么人工检查一下你的算法犯的错误也许可以让你了解接下来应该做什么。这个过程称为错误分析，我们从一个例子开始讲吧。 &emsp;&emsp;假设你正在调试猫分类器，然后你取得了$90\%$准确率，相当于$10\%$错误，，在你的开发集上做到这样，这离你希望的目标还有很远。也许你的队员看了一下算法分类出错的例子，注意到算法将一些狗分类为猫，你看看这两只狗，它们看起来是有点像猫，至少乍一看是。所以也许你的队友给你一个建议，如何针对狗的图片优化算法。试想一下，你可以针对狗，收集更多的狗图，或者设计一些只处理狗的算法功能之类的，为了让你的猫分类器在狗图上做的更好，让算法不再将狗分类成猫。所以问题在于，你是不是应该去开始做一个项目专门处理狗？这项目可能需要花费几个月的时间才能让算法在狗图片上犯更少的错误，这样做值得吗？或者与其花几个月做这个项目，有可能最后发现这样一点用都没有。这里有个错误分析流程，可以让你很快知道这个方向是否值得努力。 &emsp;&emsp;那这个简单的人工统计步骤，错误分析，可以节省大量时间，可以迅速决定什么是最重要的，或者最有希望的方向。实际上，如果你观察$100$个错误标记的开发集样本，也许只需要$5$到$10$分钟的时间，亲自看看这$100$个样本，并亲自统计一下有多少是狗。根据结果，看看有没有占到$5\%$、$50\%$或者其他东西。这个在$5$到$10$分钟之内就能给你估计这个方向有多少价值，并且可以帮助你做出更好的决定，是不是把未来几个月的时间投入到解决错误标记的狗图这个问题。 &emsp;&emsp;所以总结一下，进行错误分析，你应该找一组错误样本，可能在你的开发集里或者测试集里，观察错误标记的样本，看看假阳性（false positives）和假阴性（false negatives），统计属于不同错误类型的错误数量。在这个过程中，你可能会得到启发，归纳出新的错误类型，就像我们看到的那样。如果你过了一遍错误样本，然后说，天，有这么多Instagram滤镜或Snapchat滤镜，这些滤镜干扰了我的分类器，你就可以在途中新建一个错误类型。总之，通过统计不同错误标记类型占总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你构思新优化方向的灵感。在做错误分析的时候，有时你会注意到开发集里有些样本被错误标记了，这时应该怎么做呢？我们下一个视频来讨论。 13.34 为什么值得花时间查看错误标记数据？&emsp;&emsp;最后我讲几个建议：&emsp;&emsp;首先，深度学习研究人员有时会喜欢这样说：“我只是把数据提供给算法，我训练过了，效果拔群”。这话说出了很多深度学习错误的真相，更多时候，我们把数据喂给算法，然后训练它，并减少人工干预，减少使用人类的见解。但我认为，在构造实际系统时，通常需要更多的人工错误分析，更多的人类见解来架构这些系统，尽管深度学习的研究人员不愿意承认这点。&emsp;&emsp;其次，不知道为什么，我看一些工程师和研究人员不愿意亲自去看这些样本，也许做这些事情很无聊，坐下来看100或几百个样本来统计错误数量，但我经常亲自这么做。当我带领一个机器学习团队时，我想知道它所犯的错误，我会亲自去看看这些数据，尝试和一部分错误作斗争。我想就因为花了这几分钟，或者几个小时去亲自统计数据，真的可以帮你找到需要优先处理的任务，我发现花时间亲自检查数据非常值得，所以我强烈建议你们这样做，如果你在搭建你的机器学习系统的话，然后你想确定应该优先尝试哪些想法，或者哪些方向。 13.35 快速搭建初始系统的意义？&emsp;&emsp;一般来说，对于几乎所有的机器学习程序可能会有$50$个不同的方向可以前进，并且每个方向都是相对合理的可以改善你的系统。但挑战在于，你如何选择一个方向集中精力处理。即使我已经在语音识别领域工作多年了，如果我要为一个新应用程序域构建新系统，我还是觉得很难不花时间去思考这个问题就直接选择方向。所以我建议你们，如果你想搭建全新的机器学习程序，就是快速搭好你的第一个系统，然后开始迭代。我的意思是我建议你快速设立开发集和测试集还有指标，这样就决定了你的目标所在，如果你的目标定错了，之后改也是可以的。但一定要设立某个目标，然后我建议你马上搭好一个机器学习系统原型，然后找到训练集，训练一下，看看效果，开始理解你的算法表现如何，在开发集测试集，你的评估指标上表现如何。当你建立第一个系统后，你就可以马上用到之前说的偏差方差分析，还有之前最后几个视频讨论的错误分析，来确定下一步优先做什么。特别是如果错误分析让你了解到大部分的错误的来源是说话人远离麦克风，这对语音识别构成特殊挑战，那么你就有很好的理由去集中精力研究这些技术，所谓远场语音识别的技术，这基本上就是处理说话人离麦克风很远的情况。 &emsp;&emsp;建立这个初始系统的所有意义在于，它可以是一个快速和粗糙的实现（quick and dirty implementation），你知道的，别想太多。初始系统的全部意义在于，有一个学习过的系统，有一个训练过的系统，让你确定偏差方差的范围，就可以知道下一步应该优先做什么，让你能够进行错误分析，可以观察一些错误，然后想出所有能走的方向，哪些是实际上最有希望的方向。 13.36 为什么要在不同的划分上训练及测试？&emsp;&emsp;深度学习算法对训练数据的胃口很大，当你收集到足够多带标签的数据构成训练集时，算法效果最好，这导致很多团队用尽一切办法收集数据，然后把它们堆到训练集里，让训练的数据量更大，即使有些数据，甚至是大部分数据都来自和开发集、测试集不同的分布。在深度学习时代，越来越多的团队都用来自和开发集、测试集分布不同的数据来训练，这里有一些微妙的地方，一些最佳做法来处理训练集和测试集存在差异的情况，我们来看看。 图 13.36 Cat app example &emsp;&emsp;假设你在开发一个手机应用，用户会上传他们用手机拍摄的照片，你想识别用户从应用中上传的图片是不是猫。现在你有两个数据来源，一个是你真正关心的数据分布，来自应用上传的数据，比如右边的应用，这些照片一般更业余，取景不太好，有些甚至很模糊，因为它们都是业余用户拍的。另一个数据来源就是你可以用爬虫程序挖掘网页直接下载，就这个样本而言，可以下载很多取景专业、高分辨率、拍摄专业的猫图片。如果你的应用用户数还不多，也许你只收集到$10,000$张用户上传的照片，但通过爬虫挖掘网页，你可以下载到海量猫图，也许你从互联网上下载了超过$20$万张猫图。而你真正关心的算法表现是你的最终系统处理来自应用程序的这个图片分布时效果好不好，因为最后你的用户会上传类似右边这些图片，你的分类器必须在这个任务中表现良好。现在你就陷入困境了，因为你有一个相对小的数据集，只有$10,000$个样本来自那个分布，而你还有一个大得多的数据集来自另一个分布，图片的外观和你真正想要处理的并不一样。但你又不想直接用这$10,000$张图片，因为这样你的训练集就太小了，使用这$20$万张图片似乎有帮助。但是，困境在于，这$20$万张图片并不完全来自你想要的分布，那么你可以怎么做呢？ &emsp;&emsp;这里有一种选择，你可以做的一件事是将两组数据合并在一起，这样你就有$21$万张照片，你可以把这$21$万张照片随机分配到训练、开发和测试集中。为了说明观点，我们假设你已经确定开发集和测试集各包含$2500$个样本，所以你的训练集有$205000$个样本。现在这么设立你的数据集有一些好处，也有坏处。好处在于，你的训练集、开发集和测试集都来自同一分布，这样更好管理。但坏处在于，这坏处还不小，就是如果你观察开发集，看看这$2500$个样本其中很多图片都来自网页下载的图片，那并不是你真正关心的数据分布，你真正要处理的是来自手机的图片。 &emsp;&emsp;我建议你走另外一条路，就是这样，训练集，比如说还是$205,000$张图片，我们的训练集是来自网页下载的$200,000$张图片，然后如果需要的话，再加上$5000$张来自手机上传的图片。然后对于开发集和测试集，这数据集的大小是按比例画的，你的开发集和测试集都是手机图。而训练集包含了来自网页的$20$万张图片，还有$5000$张来自应用的图片，开发集就是$2500$张来自应用的图片，测试集也是$2500$张来自应用的图片。这样将数据分成训练集、开发集和测试集的好处在于，现在你瞄准的目标就是你想要处理的目标，你告诉你的团队，我的开发集包含的数据全部来自手机上传，这是你真正关心的图片分布。我们试试搭建一个学习系统，让系统在处理手机上传图片分布时效果良好。缺点在于，当然了，现在你的训练集分布和你的开发集、测试集分布并不一样。但事实证明，这样把数据分成训练、开发和测试集，在长期能给你带来更好的系统性能。我们以后会讨论一些特殊的技巧，可以处理 训练集的分布和开发集和测试集分布不一样的情况。 13.37 如何解决数据不匹配问题？&emsp;&emsp;如果您的训练集来自和开发测试集不同的分布，如果错误分析显示你有一个数据不匹配的问题该怎么办？这个问题没有完全系统的解决方案，但我们可以看看一些可以尝试的事情。如果我发现有严重的数据不匹配问题，我通常会亲自做错误分析，尝试了解训练集和开发测试集的具体差异。技术上，为了避免对测试集过拟合，要做错误分析，你应该人工去看开发集而不是测试集。 &emsp;&emsp;但作为一个具体的例子，如果你正在开发一个语音激活的后视镜应用，你可能要看看……我想如果是语音的话，你可能要听一下来自开发集的样本，尝试弄清楚开发集和训练集到底有什么不同。所以，比如说你可能会发现很多开发集样本噪音很多，有很多汽车噪音，这是你的开发集和训练集差异之一。也许你还会发现其他错误，比如在你的车子里的语言激活后视镜，你发现它可能经常识别错误街道号码，因为那里有很多导航请求都有街道地址，所以得到正确的街道号码真的很重要。当你了解开发集误差的性质时，你就知道，开发集有可能跟训练集不同或者更难识别，那么你可以尝试把训练数据变得更像开发集一点，或者，你也可以收集更多类似你的开发集和测试集的数据。所以，比如说，如果你发现车辆背景噪音是主要的错误来源，那么你可以模拟车辆噪声数据，我会在下一张幻灯片里详细讨论这个问题。或者你发现很难识别街道号码，也许你可以有意识地收集更多人们说数字的音频数据，加到你的训练集里。 &emsp;&emsp;现在我知道这张幻灯片只给出了粗略的指南，列出一些你可以做的尝试，这不是一个系统化的过程，我想，这不能保证你一定能取得进展。但我发现这种人工见解，我们可以一起尝试收集更多和真正重要的场合相似的数据，这通常有助于解决很多问题。所以，如果你的目标是让训练数据更接近你的开发集，那么你可以怎么做呢？ &emsp;&emsp;你可以利用的其中一种技术是人工合成数据（artificial data synthesis），我们讨论一下。在解决汽车噪音问题的场合，所以要建立语音识别系统。也许实际上你没那么多实际在汽车背景噪音下录得的音频，或者在高速公路背景噪音下录得的音频。但我们发现，你可以合成。所以假设你录制了大量清晰的音频，不带车辆背景噪音的音频，“The quick brown fox jumps over the lazy dog”（音频播放），所以，这可能是你的训练集里的一段音频，顺便说一下，这个句子在AI测试中经常使用，因为这个短句包含了从a到z所有字母，所以你会经常见到这个句子。但是，有了这个“the quick brown fox jumps over the lazy dog”这段录音之后，你也可以收集一段这样的汽车噪音，（播放汽车噪音音频）这就是汽车内部的背景噪音，如果你一言不发开车的话，就是这种声音。如果你把两个音频片段放到一起，你就可以合成出”the quick brown fox jumps over the lazy dog”（带有汽车噪声），在汽车背景噪音中的效果，听起来像这样，所以这是一个相对简单的音频合成例子。在实践中，你可能会合成其他音频效果，比如混响，就是声音从汽车内壁上反弹叠加的效果。 &emsp;&emsp;但是通过人工数据合成，你可以快速制造更多的训练数据，就像真的在车里录的那样，那就不需要花时间实际出去收集数据，比如说在实际行驶中的车子，录下上万小时的音频。所以，如果错误分析显示你应该尝试让你的数据听起来更像在车里录的，那么人工合成那种音频，然后喂给你的机器学习算法，这样做是合理的。 &emsp;&emsp;现在我们要提醒一下，人工数据合成有一个潜在问题，比如说，你在安静的背景里录得$10,000$小时音频数据，然后，比如说，你只录了一小时车辆背景噪音，那么，你可以这么做，将这$1$小时汽车噪音回放$10,000$次，并叠加到在安静的背景下录得的$10,000$小时数据。如果你这么做了，人听起来这个音频没什么问题。但是有一个风险，有可能你的学习算法对这1小时汽车噪音过拟合。特别是，如果这组汽车里录的音频可能是你可以想象的所有汽车噪音背景的集合，如果你只录了一小时汽车噪音，那你可能只模拟了全部数据空间的一小部分，你可能只从汽车噪音的很小的子集来合成数据。 &emsp;&emsp;所以，总而言之，如果你认为存在数据不匹配问题，我建议你做错误分析，或者看看训练集，或者看看开发集，试图找出，试图了解这两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像开发集的数据作训练。 &emsp;&emsp;我们谈到其中一种办法是人工数据合成，人工数据合成确实有效。在语音识别中。我已经看到人工数据合成显著提升了已经非常好的语音识别系统的表现，所以这是可行的。但当你使用人工数据合成时，一定要谨慎，要记住你有可能从所有可能性的空间只选了很小一部分去模拟数据。 &emsp;&emsp;所以这就是如何处理数据不匹配问题，接下来，我想和你分享一些想法就是如何从多种类型的数据同时学习。 13.38 梯度检验注意事项？&emsp;&emsp;首先，不要在训练中使用梯度检验，它只用于调试。我的意思是，计算所有值的是一个非常漫长的计算过程，为了实施梯度下降，你必须使用和 backprop来计算，并使用backprop来计算导数，只要调试的时候，你才会计算它，来确认数值是否接近。完成后，你会关闭梯度检验，梯度检验的每一个迭代过程都不执行它，因为它太慢了。 &emsp;&emsp;第二点，如果算法的梯度检验失败，要检查所有项，检查每一项，并试着找出bug，也就是说，如果与$d\theta[i]$的值相差很大，我们要做的就是查找不同的$i$值，看看是哪个导致与的值相差这么多。举个例子，如果你发现，相对某些层或某层的或的值相差很大，但是的各项非常接近，注意的各项与和的各项都是一一对应的，这时，你可能会发现，在计算参数的导数的过程中存在bug。反过来也是一样，如果你发现它们的值相差很大，的值与的值相差很大，你会发现所有这些项目都来自于或某层的，可能帮你定位bug的位置，虽然未必能够帮你准确定位bug的位置，但它可以帮助你估测需要在哪些地方追踪bug。 &emsp;&emsp;第三点，在实施梯度检验时，如果使用正则化，请注意正则项。如果代价函数，这就是代价函数J的定义，等于与相关的函数的梯度，包括这个正则项，记住一定要包括这个正则项。 &emsp;&emsp;第四点，梯度检验不能与dropout同时使用，因为每次迭代过程中，dropout会随机消除隐藏层单元的不同子集，难以计算dropout在梯度下降上的代价函数J。因此dropout可作为优化代价函数的一种方法，但是代价函数J被定义为对所有指数极大的节点子集求和。而在任何迭代过程中，这些节点都有可能被消除，所以很难计算代价函数。你只是对成本函数做抽样，用dropout，每次随机消除不同的子集，所以很难用梯度检验来双重检验dropout的计算，所以我一般不同时使用梯度检验和dropout。如果你想这样做，可以把dropout中的keepprob设置为$1.0$，然后打开dropout，并寄希望于dropout的实施是正确的，你还可以做点别的，比如修改节点丢失模式确定梯度检验是正确的。实际上，我一般不这么做，我建议关闭dropout，用梯度检验进行双重检查，在没有dropout的情况下，你的算法至少是正确的，然后打开dropout。 &emsp;&emsp;最后一点，也是比较微妙的一点，现实中几乎不会出现这种情况。当和接近0时，梯度下降的实施是正确的，在随机初始化过程中$……$，但是在运行梯度下降时，和变得更大。可能只有在和接近$0$时，backprop的实施才是正确的。但是当和变大时，它会变得越来越不准确。你需要做一件事，我不经常这么做，就是在随机初始化过程中，运行梯度检验，然后再训练网络，和会有一段时间远离$0$，如果随机初始化值比较小，反复训练网络之后，再重新运行梯度检验。 &emsp;&emsp;这就是梯度检验，恭喜大家，这是本周最后一课了。回顾这一周，我们讲了如何配置训练集，验证集和测试集，如何分析偏差和方差，如何处理高偏差或高方差以及高偏差和高方差并存的问题，如何在神经网络中应用不同形式的正则化，如正则化和dropout，还有加快神经网络训练速度的技巧，最后是梯度检验。这一周我们学习了很多内容，你可以在本周编程作业中多多练习这些概念。祝你好运，期待下周再见。 13.39什么是随机梯度下降？&emsp;&emsp;随机梯度下降，简称SGD，是指梯度下降算法在训练集上，对每一个训练数据都计算误差并更新模型。对每一个数据都进行模型更新意味着随机梯度下降是一种在线机器学习算法。 &emsp;&emsp;优点: 频繁的更新可以给我们一个模型表现和效率提升的即时反馈。 这可能是最容易理解和实现的一种方式，尤其对于初学者。 较高的模型更新频率在一些问题上可以快速的学习。 这种伴有噪声的更新方式能让模型避免局部最优（比如过早收敛）。 &emsp;&emsp;缺点: 这种方式相比其他来说，计算消耗更大，在大数据集上花费的训练时间更多。 频繁的更新产生的噪声可能导致模型参数和模型误差来回跳动（更大的方差）。 这种伴有噪声的更新方式也能让算法难以稳定的收敛于一点。 13.40什么是批量梯度下降？&emsp;&emsp;批量梯度下降对训练集上每一个数据都计算误差，但只在所有训练数据计算完成后才更新模型。&emsp;&emsp;对训练集上的一次训练过程称为一代（epoch）。因此，批量梯度下降是在每一个训练epoch之后更新模型。 &emsp;&emsp;优点： 更少的模型更新意味着比SGD有更高的计算效率。 在一些问题上可以得到更稳定的误差梯度和更稳定的收敛点。 误差计算和模型更新过程的分离有利于并行算法的实现。 &emsp;&emsp;缺点： 更稳定的误差梯度可能导致模型过早收敛于一个不是最优解的参数集。 每一次epoch之后才更新会增加一个累加所有训练数据误差的复杂计算。 通常来说，批量梯度下降算法需要把所有的训练数据都存放在内存中。 在大数据集上，训练速度会非常慢。 13.41什么是小批量梯度下降？&emsp;&emsp;小批量梯度下降把训练集划分为很多批，对每一批（batch）计算误差并更新参数。&emsp;&emsp;可以选择对batch的梯度进行累加，或者取平均值。取平均值可以减少梯度的方差。&emsp;&emsp;小批量梯度下降在随机梯度下降的鲁棒性和批量梯度下降的效率之间取得平衡。是如今深度学习领域最常见的实现方式。 &emsp;&emsp;优点： 比批量梯度下降更快的更新频率有利于更鲁棒的收敛，避免局部最优。 相比随机梯度下降更具计算效率。 不需要把所有数据放入内存中。 &emsp;&emsp;缺点： 小批量梯度下降给算法增加了一个超参数batch size。 和批量梯度下降一样，每一个batch上的误差需要累加。 13.42怎么配置mini-batch梯度下降&emsp;&emsp;Mini-batch梯度下降对于深度学习大部分应用是最常用的方法。&emsp;&emsp;Mini-batch sizes，简称为 “batch sizes”，是算法设计中需要调节的参数。比如对应于不同GPU或CPU硬件$(32,64,128,256,\cdots)$的内存要求。&emsp;&emsp;batch size是学习过程中的“滑块”。 &emsp;&emsp;（1）较小的值让学习过程收敛更快，但是产生更多噪声。&emsp;&emsp;（2）较大的值让学习过程收敛较慢，但是准确的估计误差梯度。 &emsp;&emsp;建议1：batch size的默认值最好是$32$&emsp;&emsp;batch size通常从1到几百之间选择，比如$32$是一个很好的默认值，超过$10$的值可以充分利用矩阵$$矩阵相对于矩阵$$向量的加速优势。——Practical recommendations for gradient-based training of deep architectures, 2012 &emsp;&emsp;建议2：调节batch size时，最好观察模型在不同batch size下的训练时间和验证误差的学习曲线&emsp;&emsp;相比于其他超参数，它可以被单独优化。在其他超参数（除了学习率）确定之后，在对比训练曲线（训练误差和验证误差对应于训练时间）。 &emsp;&emsp;建议3：调整其他所有超参数之后再调整batch size和学习率&emsp;&emsp;batch size和学习率几乎不受其他超参数的影响，因此可以放到最后再优化。batch size确定之后，可以被视为固定值，从而去优化其他超参数（如果使用了动量超参数则例外）。 13.43 局部最优的问题&emsp;&emsp;在深度学习研究早期，人们总是担心优化算法会困在极差的局部最优，不过随着深度学习理论不断发展，我们对局部最优的理解也发生了改变。我向你展示一下现在我们怎么看待局部最优以及深度学习中的优化问题。 图 13.43.1 &emsp;&emsp;这是曾经人们在想到局部最优时脑海里会出现的图，也许你想优化一些参数，我们把它们称之为和，平面的高度就是损失函数。在图中似乎各处都分布着局部最优。梯度下降法或者某个算法可能困在一个局部最优中，而不会抵达全局最优。如果你要作图计算一个数字，比如说这两个维度，就容易出现有多个不同局部最优的图，而这些低维的图曾经影响了我们的理解，但是这些理解并不正确。事实上，如果你要创建一个神经网络，通常梯度为零的点并不是这个图中的局部最优点，实际上成本函数的零梯度点，通常是鞍点。 图 13.43.2 &emsp;&emsp;也就是在这个点，这里是和，高度即成本函数的值。 图 13.43.3 &emsp;&emsp;但是一个具有高维度空间的函数，如果梯度为$0$，那么在每个方向，它可能是凸函数，也可能是凹函数。如果你在$2$万维空间中，那么想要得到局部最优，所有的$2$万个方向都需要是这样，但发生的机率也许很小，也许是，你更有可能遇到有些方向的曲线会这样向上弯曲，另一些方向曲线向下弯，而不是所有的都向上弯曲，因此在高维度空间，你更可能碰到鞍点。 图 13.43.4 &emsp;&emsp;就像下面的这种： 图 13.43.5 &emsp;&emsp;而不会碰到局部最优。至于为什么会把一个曲面叫做鞍点，你想象一下，就像是放在马背上的马鞍一样，如果这是马，这是马的头，这就是马的眼睛，画得不好请多包涵，然后你就是骑马的人，要坐在马鞍上，因此这里的这个点，导数为$0$的点，这个点叫做鞍点。我想那确实是你坐在马鞍上的那个点，而这里导数为$0$。 图 13.43.6 &emsp;&emsp;所以我们从深度学习历史中学到的一课就是，我们对低维度空间的大部分直觉，比如你可以画出上面的图，并不能应用到高维度空间中。适用于其它算法，因为如果你有$2$万个参数，那么函数有$2$万个维度向量，你更可能遇到鞍点，而不是局部最优点。 &emsp;&emsp;如果局部最优不是问题，那么问题是什么？结果是平稳段会减缓学习，平稳段是一块区域，其中导数长时间接近于$0$，如果你在此处，梯度会从曲面从从上向下下降，因为梯度等于或接近$0$，曲面很平坦，你得花上很长时间慢慢抵达平稳段的这个点，因为左边或右边的随机扰动，我换个笔墨颜色，大家看得清楚一些，然后你的算法能够走出平稳段（红色笔）。 图 13.43.7 &emsp;&emsp;我们可以沿着这段长坡走，直到这里，然后走出平稳段。 图 13.43.8 &emsp;&emsp;所以此次视频的要点是，首先，你不太可能困在极差的局部最优中，条件是你在训练较大的神经网络，存在大量参数，并且成本函数被定义在较高的维度空间。 &emsp;&emsp;第二点，平稳段是一个问题，这样使得学习十分缓慢，这也是像Momentum或是RMSprop，Adam这样的算法，能够加速学习算法的地方。在这些情况下，更成熟的优化算法，如Adam算法，能够加快速度，让你尽早往下走出平稳段。 &emsp;&emsp;因为你的网络要解决优化问题，说实话，要面临如此之高的维度空间，我觉得没有人有那么好的直觉，知道这些空间长什么样，而且我们对它们的理解还在不断发展，不过我希望这一点能够让你更好地理解优化算法所面临的问题。 13.44 提升算法性能思路&emsp;&emsp;这个列表里提到的思路并完全，但是一个好的开始。&emsp;&emsp;我的目的是给出很多可以尝试的思路，希望其中的一或两个你之前没有想到。你经常只需要一个好的想法就能得到性能提升。&emsp;&emsp;如果你能从其中一个思路中得到结果，请在评论区告诉我。我很高兴能得知这些好消息。&emsp;&emsp;如果你有更多的想法，或者是所列思路的拓展，也请告诉我，我和其他读者都将受益！有时候仅仅是一个想法或许就能使他人得到突破。 通过数据提升性能 通过算法提升性能 通过算法调参提升性能 通过嵌套模型提升性能 &emsp;&emsp;通常来讲，随着列表自上而下，性能的提升也将变小。例如，对问题进行新的架构或者获取更多的数据，通常比调整最优算法的参数能带来更好的效果。虽然并不总是这样，但是通常来讲是的。 &emsp;&emsp;我已经把相应的链接加入了博客的教程中，相应网站的问题中，以及经典的Neural Net FAQ中。&emsp;&emsp;部分思路只适用于人工神经网络，但是大部分是通用的。通用到足够你用来配合其他技术来碰撞出提升模型性能的方法。OK，现在让我们开始吧。 通过数据提升性能 &emsp;&emsp;对你的训练数据和问题定义进行适当改变，你能得到很大的性能提升。或许是最大的性能提升。 &emsp;&emsp;以下是我将要提到的思路：&emsp;&emsp;获取更多数据、创造更多数据、重放缩你的数据、转换你的数据、特征选取、重架构你的问题 &emsp;&emsp;1）获取更多数据&emsp;&emsp;你能获取更多训练数据吗？&emsp;&emsp;你的模型的质量通常受到你的训练数据质量的限制。为了得到最好的模型，你首先应该想办法获得最好的数据。你也想尽可能多的获得那些最好的数据。&emsp;&emsp;有更多的数据，深度学习和其他现代的非线性机器学习技术有更全的学习源，能学得更好，深度学习尤为如此。这也是机器学习对大家充满吸引力的很大一个原因（世界到处都是数据）。 &emsp;&emsp;2） 创造更多数据&emsp;&emsp;上一小节说到了有了更多数据，深度学习算法通常会变的更好。有些时候你可能无法合理地获取更多数据，那你可以试试创造更多数据。&emsp;&emsp;如果你的数据是数值型向量，可以随机构造已有向量的修改版本。&emsp;&emsp;如果你的数据是图片，可以随机构造已有图片的修改版本(平移、截取、旋转等)。&emsp;&emsp;如果你的数据是文本，类似的操作……&emsp;&emsp;这通常被称作数据扩增（data augmentation）或者数据生成（data generation）。&emsp;&emsp;你可以利用一个生成模型。你也可以用一些简单的技巧。例如，针对图片数据，你可以通过随机地平移或旋转已有图片获取性能的提升。如果新数据中包含了这种转换，则提升了模型的泛化能力。&emsp;&emsp;这也与增加噪声是相关的，我们习惯称之为增加扰动。它起到了与正则化方法类似的作用，即抑制训练数据的过拟合。 &emsp;&emsp;3）重缩放(rescale)你的数据&emsp;&emsp;这是一个快速获得性能提升的方法。 当应用神经网络时，一个传统的经验法则是：重缩放(rescale)你的数据至激活函数的边界。&emsp;&emsp;如果你在使用sigmoid激活函数，重缩放你的数据到0和1的区间里。如果你在使用双曲正切（tanh）激活函数，重缩放数据到－1和1的区间里。&emsp;&emsp;这种方法可以被应用到输入数据（x）和输出数据（y）。例如，如果你在输出层使用sigmoid函数去预测二元分类的结果，应当标准化y值，使之成为二元的。如果你在使用softmax函数，你依旧可以通过标准化y值来获益。&emsp;&emsp;这依旧是一个好的经验法则，但是我想更深入一点。我建议你可以参考下述方法来创造一些训练数据的不同的版本：&emsp;&emsp;归一化到0和1的区间。&emsp;&emsp;重放缩到－1和1的区间&emsp;&emsp;标准化（译者注：标准化数据使之成为零均值，单位标准差）&emsp;&emsp;然后对每一种方法，评估你的模型的性能，选取最好的进行使用。如果你改变了你的激活函数，重复这一过程。&emsp;&emsp;在神经网络中，大的数值累积效应(叠加叠乘)并不是好事，除上述方法之外，还有其他的方法来控制你的神经网络中数据的数值大小，譬如归一化激活函数和权重，我们会在以后讨论这些技术。 &emsp;&emsp;4）数据变换&emsp;&emsp;这里的数据变换与上述的重缩放方法类似，但需要更多工作。你必须非常熟悉你的数据。通过可视化来考察离群点。&emsp;&emsp;猜测每一列数据的单变量分布。&emsp;&emsp;列数据看起来像偏斜的高斯分布吗？考虑用Box-Cox变换调整偏态。&emsp;&emsp;列数据看起来像指数分布吗？考虑用对数变换。&emsp;&emsp;列数据看起来有一些特征，但是它们被一些明显的东西遮盖了，尝试取平方或者开平方根来转换数据&emsp;&emsp;你能离散化一个特征或者以某种方式组合特征，来更好地突出一些特征吗？&emsp;&emsp;依靠你的直觉，尝试以下方法。&emsp;&emsp;你能利用类似PCA的投影方法来预处理数据吗？&emsp;&emsp;你能综合多维特征至一个单一数值(特征)吗？&emsp;&emsp;你能用一个新的布尔标签去发现问题中存在一些有趣的方面吗？&emsp;&emsp;你能用其他方法探索出目前场景下的其他特殊结构吗？&emsp;&emsp;神经网层擅长特征学习(feature engineering)。它(自己)可以做到这件事。但是如果你能更好的发现问题到网络中的结构，神经网层会学习地更快。你可以对你的数据就不同的转换方式进行抽样调查，或者尝试特定的性质，来看哪些有用，哪些没用。 &emsp;&emsp;5）特征选择&emsp;&emsp;一般说来，神经网络对不相关的特征是具有鲁棒的(校对注：即不相关的特征不会很大影响神经网络的训练和效果)。它们会用近似于0的权重来弱化那些没有预测能力的特征的贡献。 &emsp;&emsp;尽管如此，这些无关的数据特征，在训练周期依旧要耗费大量的资源。所以你能去除数据里的一些特征吗？&emsp;&emsp;有许多特征选择的方法和特征重要性的方法，这些方法能够给你提供思路，哪些特征该保留，哪些特征该剔除。最简单的方式就是对比所有特征和部分特征的效果。同样的，如果你有时间，我建议在同一个网络中尝试选择不同的视角来看待你的问题，评估它们，来看看分别有怎样的性能。&emsp;&emsp;或许你利用更少的特征就能达到同等甚至更好的性能。而且，这将使模型变得更快！&emsp;&emsp;或许所有的特征选择方法都剔除了同样的特征子集。很好，这些方法在没用的特征上达成了一致。&emsp;&emsp;或许筛选过后的特征子集，能带给特征工程的新思路。&emsp;&emsp; &emsp;&emsp;6）重新架构你的问题&emsp;&emsp;有时候要试试从你当前定义的问题中跳出来，想想你所收集到的观察值是定义你问题的唯一方式吗？或许存在其他方法。或许其他构建问题的方式能够更好地揭示待学习问题的结构。&emsp;&emsp;我真的很喜欢这个尝试，因为它迫使你打开自己的思路。这确实很难，尤其是当你已经对当前的方法投入了大量的时间和金钱时。&emsp;&emsp;但是咱们这么想想，即使你列出了3-5个可供替代的建构方案，而且最终还是放弃了它们，但这至少说明你对当前的方案更加自信了。&emsp;&emsp;看看能够在一个时间窗（时间周期）内对已有的特征/数据做一个合并。&emsp;&emsp;或许你的分类问题可以成为一个回归问题(有时候是回归到分类)。&emsp;&emsp;或许你的二元输出可以变成softmax输出？&emsp;&emsp;或许你可以转而对子问题进行建模。&emsp;&emsp;仔细思考你的问题，最好在你选定工具之前就考虑用不同方法构建你的问题，因为此时你对解决方案并没有花费太多的投入。除此之外，如果你在某个问题上卡住了，这样一个简单的尝试能释放更多新的想法。 通过算法提升性能 &emsp;&emsp;机器学习当然是用算法解决问题。&emsp;&emsp;所有的理论和数学都是描绘了应用不同的方法从数据中学习一个决策过程（如果我们这里只讨论预测模型）。&emsp;&emsp;你已经选择了深度学习来解释你的问题。但是这真的是最好的选择吗？在这一节中，我们会在深入到如何最大地发掘你所选择的深度学习方法之前，接触一些算法选择上的思路。 下面是一个简要列表： 对算法进行抽样调查 借鉴已有文献 重采样方法 下面我解释下上面提到的几个方法: &emsp;&emsp;1）对算法进行抽样调查&emsp;&emsp;其实你事先无法知道，针对你的问题哪个算法是最优的。如果你知道，你可能就不需要机器学习了。那有没有什么数据(办法)可以证明你选择的方法是正确的？ &emsp;&emsp;让我们来解决这个难题。当从所有可能的问题中平均来看各算法的性能时，没有哪个算法能够永远胜过其他算法。所有的算法都是平等的，下面是在no free lunch theorem中的一个总结。 &emsp;&emsp;或许你选择的算法不是针对你的问题最优的那个&emsp;&emsp;我们不是在尝试解决所有问题，算法世界中有很多新热的方法，可是它们可能并不是针对你数据集的最优算法。&emsp;&emsp;我的建议是收集(证据)数据指标。接受更好的算法或许存在这一观点，并且给予其他算法在解决你的问题上“公平竞争”的机会。&emsp;&emsp;抽样调查一系列可行的方法，来看看哪些还不错，哪些不理想。&emsp;&emsp;首先尝试评估一些线性方法，例如逻辑回归（logistic regression）和线性判别分析（linear discriminate analysis）。&emsp;&emsp;评估一些树类模型，例如CART， 随机森林（Random Forest）和Gradient Boosting。&emsp;&emsp;评估一些实例方法，例如支持向量机（SVM）和K-近邻（kNN）。&emsp;&emsp;评估一些其他的神经网络方法，例如LVQ, MLP, CNN, LSTM, hybrids等 &emsp;&emsp;选取性能最好的算法，然后通过进一步的调参和数据准备来提升。尤其注意对比一下深度学习和其他常规机器学习方法，对上述结果进行排名，比较他们的优劣。 &emsp;&emsp;很多时候你会发现在你的问题上可以不用深度学习，而是使用一些更简单，训练速度更快，甚至是更容易理解的算法。 &emsp;&emsp;2）借鉴已有文献&emsp;&emsp;方法选择的一个捷径是借鉴已有的文献资料。可能有人已经研究过与你的问题相关的问题，你可以看看他们用的什么方法。&emsp;&emsp;你可以阅读论文，书籍，博客，问答网站，教程，以及任何能在谷歌搜索到的东西。&emsp;&emsp;写下所有的想法，然后用你的方式把他们研究一遍。&emsp;&emsp;这不是复制别人的研究，而是启发你想出新的想法，一些你从没想到但是却有可能带来性能提升的想法。&emsp;&emsp;发表的研究通常都是非常赞的。世界上有非常多聪明的人，写了很多有趣的东西。你应当好好挖掘这个“图书馆”，找到你想要的东西。 &emsp;&emsp;3）重采样方法&emsp;&emsp;你必须知道你的模型效果如何。你对模型性能的估计可靠吗？&emsp;&emsp;深度学习模型在训练阶段非常缓慢。这通常意味着，我们无法用一些常用的方法，例如k层交叉验证，去估计模型的性能。 &emsp;&emsp;或许你在使用一个简单的训练集／测试集分割，这是常规套路。如果是这样，你需要确保这种分割针对你的问题具有代表性。单变量统计和可视化是一个好的开始。 &emsp;&emsp;或许你能利用硬件来加速估计的过程。例如，如果你有集群或者AWS云端服务（Amazon Web Services）账号，你可以并行地训练n个模型，然后获取结果的均值和标准差来得到更鲁棒的估计。 &emsp;&emsp;或许你可以利用hold-out验证方法来了解模型在训练后的性能（这在早停法（early stopping）中很有用，后面会讲到）。 &emsp;&emsp;或许你可以先隐藏一个完全没用过的验证集，等到你已经完成模型选择之后再使用它。&emsp;&emsp;而有时候另外的方式，或许你能够让数据集变得更小，以及使用更强的重采样方法。&emsp;&emsp;有些情况下你会发现在训练集的一部分样本上训练得到的模型的性能，和在整个数据集上训练得到的模型的性能有很强的相关性。也许你可以先在小数据集上完成模型选择和参数调优，然后再将最终的方法扩展到全部数据集上。 &emsp;&emsp;或许你可以用某些方式限制数据集，只取一部分样本，然后用它进行全部的建模过程。 通过算法调参提升性能 &emsp;&emsp;这通常是工作的关键所在。你经常可以通过抽样调查快速地发现一个或两个性能优秀的算法。但是如果想得到最优的算法可能需要几天，几周，甚至几个月。 为了获得更优的模型，以下是对神经网络算法进行参数调优的几点思路： 诊断（Diagnostics） 权重初始化（Weight Initialization） 学习速率（Learning Rate） 激活函数 网络拓扑（Network Topology） 批次和周期（Batches and Epochs） 正则化 优化和损失 早停法 &emsp;&emsp;你可能需要训练一个给定“参数配置”的神经网络模型很多次（3-10次甚至更多），才能得到一个估计性能不错的参数配置。这一点几乎适用于这一节中你能够调参的所有方面。 &emsp;&emsp;1）诊断&emsp;&emsp;如果你能知道为什么你的模型性能不再提高了，你就能获得拥有更好性能的模型。&emsp;&emsp;你的模型是过拟合还是欠拟合？永远牢记这个问题。永远。&emsp;&emsp;模型总是会遇到过拟合或者欠拟合，只是程度不同罢了。一个快速了解模型学习行为的方法是，在每个周期，评估模型在训练集和验证集上的表现，并作出图表。 &emsp;&emsp;如果训练集上的模型总是优于验证集上的模型，你可能遇到了过拟合，你可以使用诸如正则化的方法。 &emsp;&emsp;如果训练集和验证集上的模型都很差，你可能遇到了欠拟合，你可以提升网络的容量，以及训练更多或者更久。 &emsp;&emsp;如果有一个拐点存在，在那之后训练集上的模型开始优于验证集上的模型，你可能需要使用早停法。&emsp;&emsp;经常画一画这些图表，学习它们来了解不同的方法，你能够提升模型的性能。这些图表可能是你能创造的最有价值的（模型状态）诊断信息。&emsp;&emsp;另一个有用的诊断是网络模型判定对和判定错的观察值。&emsp;&emsp;对于难以训练的样本，或许你需要更多的数据。&emsp;&emsp;或许你应该剔除训练集中易于建模的多余的样本。&emsp;&emsp;也许可以尝试对训练集划分不同的区域，在特定区域中用更专长的模型。 &emsp;&emsp;2）权重初始化&emsp;&emsp;经验法则通常是：用小的随机数进行初始化。&emsp;&emsp;在实践中，这可能依旧效果不错，但是对于你的网络来说是最佳的吗？对于不同的激活函数也有一些启发式的初始化方法，但是在实践应用中并没有太多不同。&emsp;&emsp;固定你的网络，然后尝试多种初始化方式。&emsp;&emsp;记住，权重是你的模型真正的参数，你需要找到他们。有很多组权重都能有不错的性能表现，但我们要尽量找到最好的。 &emsp;&emsp;尝试所有不同的初始化方法，考察是否有一种方法在其他情况不变的情况下(效果)更优。 &emsp;&emsp;尝试用无监督的方法，例如自动编码（autoencoder），来进行预先学习。 &emsp;&emsp;尝试使用一个已经存在的模型，只是针对你的问题重新训练输入层和输出层（迁移学习（transfer learning））&emsp;&emsp;需要提醒的一点是，改变权重初始化方法和激活函数，甚至优化函数/损失函数紧密相关。 &emsp;&emsp;3）学习率&emsp;&emsp;调整学习率很多时候也是行之有效的时段。 以下是可供探索的一些想法： &emsp;&emsp;实验很大和很小的学习率 &emsp;&emsp;格点搜索文献里常见的学习速率值，考察你能学习多深的网络。 &emsp;&emsp;尝试随周期递减的学习率 &emsp;&emsp;尝试经过固定周期数后按比例减小的学习率。 &emsp;&emsp;尝试增加一个动量项（momentum term），然后对学习速率和动量同时进行格点搜索。 &emsp;&emsp;越大的网络需要越多的训练，反之亦然。如果你添加了太多的神经元和层数，适当提升你的学习速率。同时学习率需要和训练周期，batch size大小以及优化方法联系在一起考虑。 &emsp;&emsp;4）激活函数&emsp;&emsp;你或许应该使用修正激活函数（rectifier activation functions）。他们也许能提供更好的性能。&emsp;&emsp;在这之前，最早的激活函数是sigmoid和tanh，之后是softmax, 线性激活函数，或者输出层上的sigmoid函数。我不建议尝试更多的激活函数，除非你知道你自己在干什么。&emsp;&emsp;尝试全部三种激活函数，并且重缩放你的数据以满足激活函数的边界。&emsp;&emsp;显然，你想要为输出的形式选择正确的传递函数，但是可以考虑一下探索不同表示。例如，把在二元分类问题上使用的sigmoid函数切换到回归问题上使用的线性函数，然后后置处理你的输出。这可能需要改变损失函数使之更合适。详情参阅数据转换那一节。 &emsp;&emsp;5）网络拓扑&emsp;&emsp;网络结构的改变能带来好处。&emsp;&emsp;你需要多少层以及多少个神经元？抱歉没有人知道。不要问这种问题…&emsp;&emsp;那怎么找到适用你的问题的配置呢？去实验吧。 &emsp;&emsp;尝试一个隐藏层和许多神经元（广度模型）。 &emsp;&emsp;尝试一个深的网络，但是每层只有很少的神经元（深度模型）。 &emsp;&emsp;尝试上述两种方法的组合。 &emsp;&emsp;借鉴研究问题与你的类似的论文里面的结构。 &emsp;&emsp;尝试拓扑模式（扇出（fan out）然后扇入（fan in））和书籍论文里的经验法则（下有链接） &emsp;&emsp;选择总是很困难的。通常说来越大的网络有越强的代表能力，或许你需要它。越多的层数可以提供更强的从数据中学到的抽象特征的能力。或许需要它。&emsp;&emsp;深层的神经网络需要更多的训练，无论是训练周期还是学习率，都应该相应地进行调整。 &emsp;&emsp;6）Batches和周期&emsp;&emsp;batch size大小会决定最后的梯度，以及更新权重的频度。一个周期(epoch)指的是神经网络看一遍全部训练数据的过程。&emsp;&emsp;你是否已经试验了不同的批次batch size和周期数？ 之前，我们已经讨论了学习率，网络大小和周期之间的关系。&emsp;&emsp;在很深的网络结构里你会经常看到：小的batch size配以大的训练周期。&emsp;&emsp;下面这些或许能有助于你的问题，也或许不能。你要在自己的数据上尝试和观察。 &emsp;&emsp;尝试选取与训练数据同大小的batch size，但注意一下内存（批次学习（batch learning）） &emsp;&emsp;尝试选取1作为batch size（在线学习（online learning）） &emsp;&emsp;尝试用格点搜索不同的小的batch size（8，16，32，…） &emsp;&emsp;分别尝试训练少量周期和大量周期。 &emsp;&emsp;考虑一个接近无穷的周期值(持续训练)，去记录到目前为止能得到的最佳的模型。&emsp;&emsp;一些网络结构对batch size更敏感。我知道多层感知器（Multilayer Perceptrons）通常对batch size是鲁棒的，而LSTM和CNNs比较敏感，但是这只是一个说法（仅供参考）。 &emsp;&emsp;7）正则化正则化是一个避免模型在训练集上过拟合的好方法。&emsp;&emsp;神经网络里最新最热的正则化技术是dropout方法，你是否试过？dropout方法在训练阶段随机地跳过一些神经元，驱动这一层其他的神经元去捕捉松弛。简单而有效。你可以从dropout方法开始。 &emsp;&emsp;格点搜索不同的丢失比例。 &emsp;&emsp;分别在输入，隐藏层和输出层中试验dropout方法 &emsp;&emsp;dropout方法也有一些拓展，比如你也可以尝试drop connect方法。 &emsp;&emsp;也可以尝试其他更传统的神经网络正则化方法，例如： &emsp;&emsp;权重衰减（Weight decay）去惩罚大的权重 &emsp;&emsp;激活约束（Activation constraint）去惩罚大的激活值 &emsp;&emsp;你也可以试验惩罚不同的方面，或者使用不同种类的惩罚/正则化（L1, L2, 或者二者同时） &emsp;&emsp;8）优化和损失&emsp;&emsp;最常见是应用随机梯度下降法（stochastic gradient descent），但是现在有非常多的优化器。你试验过不同的优化(方法)过程吗？随机梯度下降法是默认的选择。先好好利用它，配以不同的学习率和动量。 &emsp;&emsp;许多更高级的优化方法有更多的参数，更复杂，也有更快的收敛速度。 好与坏，是不是需要用，取决于你的问题。 &emsp;&emsp;为了更好的利用好一个给定的(优化)方法，你真的需要弄明白每个参数的意义，然后针对你的问题通过格点搜索不同的的取值。困难，消耗时间，但是值得。 &emsp;&emsp;我发现了一些更新更流行的方法，它们可以收敛的更快，并且针对一个给定网络的容量提供了一个快速了解的方式，例如： ADAM RMSprop &emsp;&emsp;你还可以探索其他优化算法，例如，更传统的（Levenberg-Marquardt）和不那么传统的（genetic algorithms）。其他方法能够为随机梯度下降法和其他类似方法提供好的出发点去改进。 &emsp;&emsp;要被优化的损失函数与你要解决的问题高度相关。然而，你通常还是有一些余地（可以做一些微调，例如回归问题中的均方误（MSE）和平均绝对误差（MAE）等），有时候变换损失函数还有可能获得小的性能提升，这取决于你输出数据的规模和使用的激活函数。 &emsp;&emsp;9）Early Stopping/早停法&emsp;&emsp;一旦训练过程中出现(验证集)性能开始下降，你可以停止训练与学习。这可以节省很多时间，而且甚至可以让你使用更详尽的重采样方法来评估你的模型的性能。 &emsp;&emsp;早停法是一种用来避免模型在训练数据上的过拟合的正则化方式，它需要你监测模型在训练集以及验证集上每一轮的效果。一旦验证集上的模型性能开始下降，训练就可以停止。 &emsp;&emsp;如果某个条件满足（衡量准确率的损失），你还可以设置检查点(Checkpointing)来储存模型，使得模型能够继续学习。检查点使你能够早停而非真正的停止训练，因此在最后，你将有一些模型可供选择。 通过嵌套模型提升性能 &emsp;&emsp;你可以组合多个模型的预测能力。刚才提到了算法调参可以提高最后的性能，调参之后这是下一个可以提升的大领域。&emsp;&emsp;事实上，你可以经常通过组合多个“足够好的”模型来得到优秀的预测能力，而不是通过组合多个高度调参的（脆弱的）模型。 你可以考虑以下三个方面的嵌套方式： 组合模型 组合视角 堆叠（Stacking） &emsp;&emsp;1）组合模型&emsp;&emsp;有时候我们干脆不做模型选择，而是直接组合它们。&emsp;&emsp;如果你有多个不同的深度学习模型，在你的研究问题上每一个都表现的还不错，你可以通过取它们预测的平均值来进行组合。&emsp;&emsp;模型差异越大，最终效果越好。例如，你可以应用非常不同的网络拓扑或者不同的技术。&emsp;&emsp;如果每个模型都效果不错但是不同的方法/方式，嵌套后的预测能力将更加鲁棒。&emsp;&emsp;每一次你训练网络，你初始化不同的权重，然后它会收敛到不同的最终权重。你可以多次重复这一过程去得到很多网络，然后把这些网络的预测值组合在一起。&emsp;&emsp;它们的预测将会高度相关，但是在那些难以预测的特征上，它会给你一个意外的小提升。 &emsp;&emsp;2）组合视角&emsp;&emsp;同上述类似，但是从不同视角重构你的问题，训练你的模型。&emsp;&emsp;同样，目标得到的是效果不错但是不同的模型（例如，不相关的预测）。得到不同的模型的方法，你可以依赖我们在数据那一小节中罗列的那些非常不同的放缩和转换方法。&emsp;&emsp;你用来训练模型的转换方法越不同，你构建问题的方式越不同，你的结果被提升的程度就越高。&emsp;&emsp;简单使用预测的均值将会是一个好的开始。 &emsp;&emsp;3）stacking/堆叠&emsp;&emsp;你还可以学习如何最佳地组合多个模型的预测。这称作堆叠泛化（stacked generalization），或者简短来说就叫堆叠。&emsp;&emsp;通常上，你使用简单线性回归方法就可以得到比取预测平均更好的结果，像正则化的回归（regularized regression），就会学习如何给不同的预测模型赋权重。基线模型是通过取子模型的预测均值得到的，但是应用学习了权重的模型会提升性能。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习算法优缺点对比及选择-小结]]></title>
    <url>%2F2017%2F10%2F26%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%BC%98%E7%BC%BA%E7%82%B9%E5%AF%B9%E6%AF%94%E5%8F%8A%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[机器学习算法优缺点对比及选择 机器学习算法太多了，分类、回归、聚类、推荐、图像识别领域等等，要想找到一个合适算法真的不容易，所以在实际应用中，我们一般都是采用启发式学习方式来实验。通常最开始我们都会选择大家普遍认同的算法，诸如SVM，GBDT，Adaboost，现在深度学习很火热，神经网络也是一个不错的选择。 假如你在乎精度（accuracy）的话，最好的方法就是通过交叉验证（cross-validation）对各个算法一个个地进行测试，进行比较，然后调整参数确保每个算法达到最优解，最后选择最好的一个。但是如果你只是在寻找一个“足够好”的算法来解决你的问题，或者这里有些技巧可以参考，下面来分析下各个算法的优缺点，基于算法的优缺点，更易于我们去选择它。 1.概述在机器学习领域，一个基本的定理就是“没有免费的午餐”。换言之，就是没有算法能完美地解决所有问题，尤其是对监督学习而言（例如预测建模）。 举例来说，你不能去说神经网络任何情况下都能比决策树更有优势，反之亦然。它们要受很多因素的影响，比如你的数据集的规模或结构。 其结果是，在用给定的测试集来评估性能并挑选算法时，你应当根据具体的问题来采用不同的算法。 当然，所选的算法必须要适用于你自己的问题，这就要求选择正确的机器学习任务。作为类比，如果你需要打扫房子，你可能会用到吸尘器、扫帚或是拖把，但你绝对不该掏出铲子来挖地。 **2. 偏差&amp;方差在统计学中，一个模型好坏，是根据偏差和方差来衡量的，所以我们先来普及一下偏差(bias)和方差(variance)： 偏差：描述的是预测值（估计值）的期望E’与真实值Y之间的差距。偏差越大，越偏离真实数据。 方差：描述的是预测值P的变化范围，离散程度，是预测值的方差，也就是离其期望值E的距离。方差越大，数据的分布越分散。 模型的真实误差是两者之和，如公式： 通常情况下，如果是小训练集，高偏差/低方差的分类器（例如，朴素贝叶斯NB）要比低偏差/高方差大分类的优势大（例如，KNN），因为后者会发生过拟合（overfiting）。然而，随着你训练集的增长，模型对于原数据的预测能力就越好，偏差就会降低，此时低偏差/高方差的分类器就会渐渐的表现其优势（因为它们有较低的渐近误差），而高偏差分类器这时已经不足以提供准确的模型了。 为什么说朴素贝叶斯是高偏差低方差? 以下内容引自知乎： 首先，假设你知道训练集和测试集的关系。简单来讲是我们要在训练集上学习一个模型，然后拿到测试集去用，效果好不好要根据测试集的错误率来衡量。但很多时候，我们只能假设测试集和训练集的是符合同一个数据分布的，但却拿不到真正的测试数据。这时候怎么在只看到训练错误率的情况下，去衡量测试错误率呢？ 由于训练样本很少（至少不足够多），所以通过训练集得到的模型，总不是真正正确的。（就算在训练集上正确率100%，也不能说明它刻画了真实的数据分布，要知道刻画真实的数据分布才是我们的目的，而不是只刻画训练集的有限的数据点）。而且，实际中，训练样本往往还有一定的噪音误差，所以如果太追求在训练集上的完美而采用一个很复杂的模型，会使得模型把训练集里面的误差都当成了真实的数据分布特征，从而得到错误的数据分布估计。这样的话，到了真正的测试集上就错的一塌糊涂了（这种现象叫过拟合）。但是也不能用太简单的模型，否则在数据分布比较复杂的时候，模型就不足以刻画数据分布了（体现为连在训练集上的错误率都很高，这种现象较欠拟合）。过拟合表明采用的模型比真实的数据分布更复杂，而欠拟合表示采用的模型比真实的数据分布要简单。 在统计学习框架下，大家刻画模型复杂度的时候，有这么个观点，认为Error = Bias +Variance。这里的Error大概可以理解为模型的预测错误率，是有两部分组成的，一部分是由于模型太简单而带来的估计不准确的部分（Bias），另一部分是由于模型太复杂而带来的更大的变化空间和不确定性（Variance）。 所以，这样就容易分析朴素贝叶斯了。它简单的假设了各个数据之间是无关的，是一个被严重简化了的模型。所以，对于这样一个简单模型，大部分场合都会Bias部分大于Variance部分，也就是说高偏差而低方差。 在实际中，为了让Error尽量小，我们在选择模型的时候需要平衡Bias和Variance所占的比例，也就是平衡over-fitting和under-fitting。 当模型复杂度上升的时候，偏差会逐渐变小，而方差会逐渐变大。 **3. 常见算法优缺点3.1 朴素贝叶斯朴素贝叶斯属于生成式模型（关于生成模型和判别式模型，主要还是在于是否需要求联合分布），比较简单，你只需做一堆计数即可。如果注有条件独立性假设（一个比较严格的条件），朴素贝叶斯分类器的收敛速度将快于判别模型，比如逻辑回归，所以你只需要较少的训练数据即可。即使NB条件独立假设不成立，NB分类器在实践中仍然表现的很出色。它的主要缺点是它不能学习特征间的相互作用——(不能处理冗余特征)，用mRMR中R来讲，就是特征冗余。引用一个比较经典的例子，比如，虽然你喜欢BradPitt和Tom Cruise的电影，但是它不能学习出你不喜欢他们在一起演的电影。 优点： 朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以及稳定的分类效率。 对大数量训练和查询时具有较高的速度。即使使用超大规模的训练集，针对每个项目通常也只会有相对较少的特征数，并且对项目的训练和分类也仅仅是特征概率的数学运算而已； 对小规模的数据表现很好，能处理多分类任务，适合增量式训练（即可以实时的对新增的样本进行训练）； 对缺失数据不太敏感，算法也比较简单，常用于文本分类； 朴素贝叶斯对结果解释容易理解； 缺点： 需要计算先验概率； 分类决策存在错误率； 对输入数据的表达形式很敏感； 由于使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好； 朴素贝叶斯应用领域 欺诈检测中使用较多 一封电子邮件是否是垃圾邮件 一篇文章应该分到科技、政治，还是体育类 一段文字表达的是积极的情绪还是消极的情绪？ 人脸识别 **3.2 Logistic Regression（逻辑回归）逻辑回归属于判别式模型，同时伴有很多模型正则化的方法（L0，L1，L2，etc），而且你不必像在用朴素贝叶斯那样担心你的特征是否相关。与决策树、SVM相比，你还会得到一个不错的概率解释，你甚至可以轻松地利用新数据来更新模型（使用在线梯度下降算法-online gradient descent）。如果你需要一个概率架构（比如，简单地调节分类阈值，指明不确定性，或者是要获得置信区间），或者你希望以后将更多的训练数据快速整合到模型中去，那么使用它吧。 Sigmoid函数：表达式如下: 优点： 实现简单，广泛的应用于工业问题上； 分类时计算量非常小，速度很快，存储资源低； 便利的观测样本概率分数； 对逻辑回归而言，多重共线性并不是问题，它可以结合L2正则化来解决该问题； 计算代价不高，易于理解和实现； 缺点： 当特征空间很大时，逻辑回归的性能不是很好； 容易欠拟合，一般准确度不太高 不能很好地处理大量多类特征或变量； 只能处理两分类问题（在此基础上衍生出来的softmax可以用于多分类），且必须线性可分； 对于非线性特征，需要进行转换； logistic回归应用领域： 用于二分类领域，可以得出概率值，适用于根据分类概率排名的领域，如搜索排名等。 Logistic回归的扩展softmax可以应用于多分类领域，如手写字识别等。 信用评估 测量市场营销的成功度 预测某个产品的收益 特定的某天是否会发生地震 **3.3 线性回归线性回归是用于回归的，它不像Logistic回归那样用于分类，其基本思想是用梯度下降法对最小二乘法形式的误差函数进行优化，当然也可以用normal equation直接求得参数的解，结果为： 而在LWLR（局部加权线性回归）中，参数的计算表达式为: 由此可见LWLR与LR不同，LWLR是一个非参数模型，因为每次进行回归计算都要遍历训练样本至少一次。 优点： 实现简单，计算简单； 缺点： 不能拟合非线性数据. **3.4 最近邻算法——KNNKNN即最近邻算法，其主要过程为： 1.计算训练样本和测试样本中每个样本点的距离（常见的距离度量有欧式距离，马氏距离等）； 对上面所有的距离值进行排序(升序)； 选前k个最小距离的样本； 根据这k个样本的标签进行投票，得到最后的分类类别； 如何选择一个最佳的K值，这取决于数据。一般情况下，在分类时较大的K值能够减小噪声的影响，但会使类别之间的界限变得模糊。一个较好的K值可通过各种启发式技术来获取，比如，交叉验证。另外噪声和非相关性特征向量的存在会使K近邻算法的准确性减小。近邻算法具有较强的一致性结果，随着数据趋于无限，算法保证错误率不会超过贝叶斯算法错误率的两倍。对于一些好的K值，K近邻保证错误率不会超过贝叶斯理论误差率。 KNN算法的优点 理论成熟，思想简单，既可以用来做分类也可以用来做回归； 可用于非线性分类； 训练时间复杂度为O(n)； 对数据没有假设，准确度高，对outlier不敏感； KNN是一种在线技术，新数据可以直接加入数据集而不必进行重新训练； KNN理论简单，容易实现； 缺点 样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）效果差； 需要大量内存； 对于样本容量大的数据集计算量比较大（体现在距离计算上）； 样本不平衡时，预测偏差比较大。如：某一类的样本比较少，而其它类样本比较多； KNN每一次分类都会重新进行一次全局运算； k值大小的选择没有理论选择最优，往往是结合K-折交叉验证得到最优k值选择； KNN算法应用领域文本分类、模式识别、聚类分析，多分类领域 **3.5 决策树决策树的一大优势就是易于解释。它可以毫无压力地处理特征间的交互关系并且是非参数化的，因此你不必担心异常值或者数据是否线性可分（举个例子，决策树能轻松处理好类别A在某个特征维度x的末端，类别B在中间，然后类别A又出现在特征维度x前端的情况）。它的缺点之一就是不支持在线学习，于是在新样本到来后，决策树需要全部重建。另一个缺点就是容易出现过拟合，但这也就是诸如随机森林RF（或提升树boostedtree）之类的集成方法的切入点。另外，随机森林经常是很多分类问题的赢家（通常比支持向量机好上那么一丁点），它训练快速并且可调，同时你无须担心要像支持向量机那样调一大堆参数，所以在以前都一直很受欢迎。 决策树中很重要的一点就是选择一个属性进行分枝，因此要注意一下信息增益的计算公式，并深入理解它。 信息熵的计算公式如下: 其中的n代表有n个分类类别（比如假设是二类问题，那么n=2）。分别计算这2类样本在总样本中出现的概率 和 ，这样就可以计算出未选中属性分枝前的信息熵。 现在选中一个属性 用来进行分枝，此时分枝规则是：如果 的话，将样本分到树的一个分支；如果不相等则进入另一个分支。很显然，分支中的样本很有可能包括2个类别，分别计算这2个分支的熵 和 ,计算出分枝后的总信息熵 ，则此时的信息增益 。以信息增益为原则，把所有的属性都测试一边，选择一个使增益最大的属性作为本次分枝属性。 决策树自身的优点 决策树易于理解和解释，可以可视化分析，容易提取出规则； 可以同时处理标称型和数值型数据； 比较适合处理有缺失属性的样本； 能够处理不相关的特征； 测试数据集时，运行速度比较快； 在相对短的时间内能够对大型数据源做出可行且效果良好的结果。 缺点 容易发生过拟合（随机森林可以很大程度上减少过拟合）； 容易忽略数据集中属性的相互关联； 对于那些各类别样本数量不一致的数据，在决策树中，进行属性划分时，不同的判定准则会带来不同的属性选择倾向；信息增益准则对可取数目较多的属性有所偏好（典型代表ID3算法），而增益率准则（CART）则对可取数目较少的属性有所偏好，但CART进行属性划分时候不再简单地直接利用增益率尽心划分，而是采用一种启发式规则）（只要是使用了信息增益，都有这个缺点，如RF）。 ID3算法计算信息增益时结果偏向数值比较多的特征。 改进措施 对决策树进行剪枝。可以采用交叉验证法和加入正则化的方法。 使用基于决策树的combination算法，如bagging算法，randomforest算法，可以解决过拟合的问题； 应用领域企业管理实践，企业投资决策，由于决策树很好的分析能力，在决策过程应用较多。 **3.5.1 ID3、C4.5算法ID3算法是以信息论为基础，以信息熵和信息增益度为衡量标准，从而实现对数据的归纳分类。ID3算法计算每个属性的信息增益，并选取具有最高增益的属性作为给定的测试属性。C4.5算法核心思想是ID3算法，是ID3算法的改进，改进方面有： 用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足； 在树构造过程中进行剪枝； - 能处理非离散的数据； - 能处理不完整的数据。 优点 产生的分类规则易于理解，准确率较高。 缺点 在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效； C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。 **3.5.2 CART分类与回归树是一种决策树分类方法，采用基于最小距离的基尼指数估计函数，用来决定由该子数据集生成的决策树的拓展形。如果目标变量是标称的，称为分类树；如果目标变量是连续的，称为回归树。分类树是使用树结构算法将数据分成离散类的方法。 优点1）非常灵活，可以允许有部分错分成本，还可指定先验概率分布，可使用自动的成本复杂性剪枝来得到归纳性更强的树。2）在面对诸如存在缺失值、变量数多等问题时CART 显得非常稳健。 **3.6 AdaboostingAdaboost是一种加和模型，每个模型都是基于上一次模型的错误率来建立的，过分关注分错的样本，而对正确分类的样本减少关注度，逐次迭代之后，可以得到一个相对较好的模型。该算法是一种典型的boosting算法，其加和理论的优势可以使用Hoeffding不等式得以解释。有兴趣的同学可以阅读下自己之前写的这篇文章AdaBoost算法详述.下面总结下它的优缺点。 优点 Adaboost是一种有很高精度的分类器。 可以使用各种方法构建子分类器，Adaboost算法提供的是框架。 当使用简单分类器时，计算出的结果是可以理解的，并且弱分类器的构造极其简单。 简单，不用做特征筛选。 不易发生overfitting。 关于Adaboost, GBDT 及 XGBoost算法区别，参考这篇文章：Adaboost、GBDT与XGBoost的区别 缺点 对outlier比较敏感 **3.7 SVM支持向量机支持向量机，一个经久不衰的算法，高准确率，为避免过拟合提供了很好的理论保证，而且就算数据在原特征空间线性不可分，只要给个合适的核函数，它就能运行得很好。在动辄超高维的文本分类问题中特别受欢迎。可惜内存消耗大，难以解释，运行和调参也有些烦人，而随机森林却刚好避开了这些缺点，比较实用。 优点 可以解决高维问题，即大型特征空间； 解决小样本下机器学习问题； 能够处理非线性特征的相互作用； 无局部极小值问题；（相对于神经网络等算法） 无需依赖整个数据； 泛化能力比较强； 缺点 当观测样本很多时，效率并不是很高； 对非线性问题没有通用解决方案，有时候很难找到一个合适的核函数； 对于核函数的高维映射解释力不强，尤其是径向基函数； 常规SVM只支持二分类； 对缺失数据敏感； 对于核的选择也是有技巧的（libsvm中自带了四种核函数：线性核、多项式核、RBF以及sigmoid核）： 第一，如果样本数量小于特征数，那么就没必要选择非线性核，简单的使用线性核就可以了； 第二，如果样本数量大于特征数目，这时可以使用非线性核，将样本映射到更高维度，一般可以得到更好的结果； 第三，如果样本数目和特征数目相等，该情况可以使用非线性核，原理和第二种一样。 对于第一种情况，也可以先对数据进行降维，然后使用非线性核，这也是一种方法。 SVM应用领域文本分类、图像识别（主要二分类领域，毕竟常规SVM只能解决二分类问题） **3.8 人工神经网络的优缺点人工神经网络的优点： 分类的准确度高； 并行分布处理能力强,分布存储及学习能力强， 对噪声神经有较强的鲁棒性和容错能力； 具备联想记忆的功能，能充分逼近复杂的非线性关系； 人工神经网络的缺点： 神经网络需要大量的参数，如网络拓扑结构、权值和阈值的初始值； 黑盒过程，不能观察之间的学习过程，输出结果难以解释，会影响到结果的可信度和可接受程度； 学习时间过长，有可能陷入局部极小值，甚至可能达不到学习的目的。 人工神经网络应用领域： 目前深度神经网络已经应用与计算机视觉，自然语言处理，语音识别等领域并取得很好的效果。 **3.9 K-Means聚类是一个简单的聚类算法，把n的对象根据他们的属性分为k个分割，k\&lt; n。算法的核心就是要优化失真函数J,使其收敛到局部最小值但不是全局最小值。 关于K-Means聚类的文章，参见机器学习算法-K-means聚类。关于K-Means的推导，里面可是有大学问的，蕴含着强大的EM思想。 优点 算法简单，容易实现 ； 算法速度很快； 对处理大数据集，该算法是相对可伸缩的和高效率的，因为它的复杂度大约是O(nkt)，其中n是所有对象的数目，k是簇的数目,t是迭代的次数。通常k\&lt;\&lt;n。这个算法通常局部收敛。 算法尝试找出使平方误差函数值最小的k个划分。当簇是密集的、球状或团状的，且簇与簇之间区别明显时，聚类效果较好。 缺点 对数据类型要求较高，适合数值型数据； 可能收敛到局部最小值，在大规模数据上收敛较慢 分组的数目k是一个输入参数，不合适的k可能返回较差的结果。 对初值的簇心值敏感，对于不同的初始值，可能会导致不同的聚类结果； 不适合于发现非凸面形状的簇，或者大小差别很大的簇。 对于”噪声”和孤立点数据敏感，少量的该类数据能够对平均值产生极大影响。 **3.10 EM最大期望算法EM算法是基于模型的聚类方法，是在概率模型中寻找参数最大似然估计的算法，其中概率模型依赖于无法观测的隐藏变量。E步估计隐含变量，M步估计其他参数，交替将极值推向最大。 EM算法比K-means算法计算复杂，收敛也较慢，不适于大规模数据集和高维数据，但比K-means算法计算结果稳定、准确。EM经常用在机器学习和计算机视觉的数据集聚（DataClustering）领域。 **3.11 集成算法（AdaBoost算法）AdaBoost算法优点： 很好的利用了弱分类器进行级联； 可以将不同的分类算法作为弱分类器； AdaBoost具有很高的精度； 相对于bagging算法和Random Forest算法，AdaBoost充分考虑的每个分类器的权重； Adaboost算法缺点： AdaBoost迭代次数也就是弱分类器数目不太好设定，可以使用交叉验证来进行确定； 数据不平衡导致分类精度下降； 训练比较耗时，每次重新选择当前分类器最好切分点； AdaBoost应用领域：模式识别、计算机视觉领域，用于二分类和多分类场景 **3.12 排序算法（PageRank）PageRank是google的页面排序算法，是基于从许多优质的网页链接过来的网页，必定还是优质网页的回归关系，来判定所有网页的重要性。（也就是说，一个人有着越多牛X朋友的人，他是牛X的概率就越大。） PageRank优点 完全独立于查询，只依赖于网页链接结构，可以离线计算。 PageRank缺点 PageRank算法忽略了网页搜索的时效性。 旧网页排序很高，存在时间长，积累了大量的in-links，拥有最新资讯的新网页排名却很低，因为它们几乎没有in-links。 **3.13 关联规则算法（Apriori算法）Apriori算法是一种挖掘关联规则的算法，用于挖掘其内含的、未知的却又实际存在的数据关系，其核心是基于两阶段频集思想的递推算法。 Apriori算法分为两个阶段： 寻找频繁项集 由频繁项集找关联规则 算法缺点： 在每一步产生侯选项目集时循环产生的组合过多，没有排除不应该参与组合的元素； 每次计算项集的支持度时，都对数据库中的全部记录进行了一遍扫描比较，需要很大的I/O负载。 **4. 算法选择参考之前笔者翻译过一些国外的文章，其中有一篇文章中给出了一个简单的算法选择技巧： 首当其冲应该选择的就是逻辑回归，如果它的效果不怎么样，那么可以将它的结果作为基准来参考，在基础上与其他算法进行比较； 然后试试决策树（随机森林）看看是否可以大幅度提升你的模型性能。即便最后你并没有把它当做为最终模型，你也可以使用随机森林来移除噪声变量，做特征选择； 如果特征的数量和观测样本特别多，那么当资源和时间充足时（这个前提很重要），使用SVM不失为一种选择。 通常情况下：【GBDT>=SVM>=RF>=Adaboost>=Other…】，现在深度学习很热门，很多领域都用到，它是以神经网络为基础的，目前笔者自己也在学习，只是理论知识不扎实，理解的不够深入，这里就不做介绍了，希望以后可以写一片抛砖引玉的文章。 算法固然重要，但好的数据却要优于好的算法，设计优良特征是大有裨益的。假如你有一个超大数据集，那么无论你使用哪种算法可能对分类性能都没太大影响（此时就可以根据速度和易用性来进行抉择）。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络搭建及训练]]></title>
    <url>%2F2017%2F10%2F18%2F%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0_%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA%E5%8F%8A%E8%AE%AD%E7%BB%83%2F</url>
    <content type="text"><![CDATA[第十二章 网络搭建及训练目录常用框架介绍常用框架对比(表格展示) 16个最棒的深度学习框架 https://baijiahao.baidu.com/s?id=1599943447101946075&amp;wfr=spider&amp;for=pc基于tensorfolw网络搭建实例CNN训练注意事项训练技巧深度学习模型训练痛点及解决方法 https://blog.csdn.net/weixin_40581617/article/details/80537559深度学习模型训练流程 https://blog.csdn.net/Quincuntial/article/details/79242364深度学习模型训练技巧 https://blog.csdn.net/w7256037/article/details/52071345https://blog.csdn.net/u012033832/article/details/79017951https://blog.csdn.net/u012968002/article/details/72122965 深度学习几大难点 https://blog.csdn.net/m0_37867246/article/details/79766371 CNN训练注意事项http://www.cnblogs.com/softzrp/p/6724884.html1.用Mini-batch SGD对神经网络做训练的过程如下： 不断循环 ： ① 采样一个 batch 数据( ( 比如 32 张 ） ②前向计算得到损失 loss ③ 反向传播计算梯度( 一个 batch） ④ 用这部分梯度迭代更新权重参数 2.去均值 去均值一般有两种方式：第一种是在每个像素点都算出3个颜色通道上的平均值，然后对应减去，如AlexNet。 第二种是在整个样本上就只得到一组数，不分像素点了，如VGGNet。3.权重初始化4.Dropout 第十二章 TensorFlow、pytorch和caffe介绍12.1 TensorFlow12.1.1 TensorFlow是什么？&emsp;&emsp;TensorFlow支持各种异构平台，支持多CPU/GPU、服务器、移动设备，具有良好的跨平台的特性；TensorFlow架构灵活，能够支持各种网络模型，具有良好的通用性；此外，TensorFlow架构具有良好的可扩展性，对OP的扩展支持，Kernel特化方面表现出众。 &emsp;&emsp;TensorFlow最初由Google大脑的研究员和工程师开发出来，用于机器学习和神经网络方面的研究，于2015.10宣布开源，在众多深度学习框架中脱颖而出，在Github上获得了最多的Star量。 12.1.2 TensorFlow的设计理念是什么？TensorFlow的设计理念主要体现在两个方面： （1）将图定义和图运算完全分开。&emsp;&emsp;TensorFlow 被认为是一个“符号主义”的库。我们知道，编程模式通常分为命令式编程（imperative style programming）和符号式编程（symbolic style programming）。命令式编程就是编写我们理解的通常意义上的程序，很容易理解和调试，按照原有逻辑执行。符号式编程涉及很多的嵌入和优化，不容易理解和调试，但运行速度相对有所提升。现有的深度学习框架中，Torch 是典型的命令式的，Caffe、MXNet 采用了两种编程模式混合的方法，而 TensorFlow 完全采用符号式编程。 &emsp;&emsp;符号式计算一般是先定义各种变量，然后建立一个数据流图，在数据流图中规定各个变量间的计算关系，最后需要对据流图进行编译，但此时的数据流图还是一个空壳儿，里面没有任何实际数据，只有把需要运算的输入放进去后，才能在整个模型中形成数据流，从而形成输出值。 例如： 12t = 8 + 9print(t) &emsp;&emsp;在传统的程序操作中，定义了 t 的运算，在运行时就执行了，并输出 17。而在 TensorFlow中，数据流图中的节点，实际上对应的是 TensorFlow API 中的一个操作，并没有真正去运行： 12345import tensorflow as tft = tf.add(8,9)print(t)#输出 Tensor&#123;&quot;Add_1:0&quot;,shape=&#123;&#125;,dtype=int32&#125; &emsp;&emsp;（2）TensorFlow 中涉及的运算都要放在图中，而图的运行只发生在会话（session）中。开启会话后，就可以用数据去填充节点，进行运算；关闭会话后，就不能进行计算了。因此，会话提供了操作运行和 Tensor 求值的环境。 例如： 12345678910import tensorflow as tf#创建图a = tf.constant([4.0,5.0])b = tf.constant([6.0,7.0])c = a * b#创建会话sess = tf.Session()#计算cprint(sess.run(c)) #进行矩阵乘法，输出[24.,35.]sess.close() 12.1.3 TensorFlow特点有哪些？1.高度的灵活性&emsp;&emsp;TensorFlow 并不仅仅是一个深度学习库，只要可以把你的计算过程表示称一个数据流图的过程，我们就可以使用 TensorFlow 来进行计算。TensorFlow 允许我们用计算图的方式建立计算网络，同时又可以很方便的对网络进行操作。用户可以基于 TensorFlow 的基础上用 python 编写自己的上层结构和库，如果TensorFlow没有提供我们需要的API的，我们也可以自己编写底层的 C++ 代码，通过自定义操作将新编写的功能添加到 TensorFlow 中。 2.真正的可移植性&emsp;&emsp;TensorFlow 可以在 CPU 和 GPU 上运行，可以在台式机、服务器、移动设备上运行。你想在你的笔记本上跑一下深度学习的训练，或者又不想修改代码，想把你的模型在多个CPU上运行， 亦或想将训练好的模型放到移动设备上跑一下，这些TensorFlow都可以帮你做到。 3.多语言支持&emsp;&emsp;TensorFlow采用非常易用的python来构建和执行我们的计算图，同时也支持 C++ 的语言。我们可以直接写python和C++的程序来执行TensorFlow，也可以采用交互式的ipython来方便的尝试我们的想法。当然，这只是一个开始，后续会支持更多流行的语言，比如Lua，JavaScript 或者R语言。 4.丰富的算法库&emsp;&emsp;TensorFlow提供了所有开源的深度学习框架里，最全的算法库，并且在不断的添加新的算法库。这些算法库基本上已经满足了大部分的需求，对于普通的应用，基本上不用自己再去自定义实现基本的算法库了。 5.完善的文档&emsp;&emsp;TensorFlow的官方网站，提供了非常详细的文档介绍，内容包括各种API的使用介绍和各种基础应用的使用例子，也包括一部分深度学习的基础理论。 &emsp;&emsp;自从宣布开源以来，大量人员对TensorFlow做出贡献，其中包括Google员工，外部研究人员和独立程序员，全球各地的工程师对TensorFlow的完善，已经让TensorFlow社区变成了Github上最活跃的深度学习框架。 12.1.4 TensorFlow的系统架构是怎样的？&emsp;&emsp;整个系统从底层到上层可分为七层： &emsp;&emsp;设备层：硬件计算资源，支持CPU、GPU &emsp;&emsp;网络层：支持两种通信协议 &emsp;&emsp;数值计算层：提供最基础的计算，有线性计算、卷积计算 &emsp;&emsp;高维计算层：数据的计算都是以数组的形式参与计算 &emsp;&emsp;计算图层：用来设计神经网络的结构 &emsp;&emsp;工作流层：提供轻量级的框架调用 &emsp;&emsp;构造层：最后构造的深度学习网络可以通过TensorBoard服务端可视化 12.1.5 TensorFlow编程模型是怎样的？TensorFlow的编程模型：让向量数据在计算图里流动。那么在编程时至少有这几个过程：1.构建图，2.启动图，3.给图输入数据并获取结果。 1.构建图TensorFlow的图的类型是tf.Graph，它包含着计算节点和tensor的集合。 &emsp;&emsp;这里引用了两个新概念：tensor和计算节点。&emsp;&emsp;我们先介绍tensor，一开始我们就介绍了，我们需要把数据输入给启动的图才能获取计算结果。那么问题来了，在构建图时用什么表示中间计算结果？这个时候tensor的概念就需要引入了。&emsp;&emsp;类型是tf.Tensor，代表某个计算节点的输出，一定要看清楚是“代表”。它主要有两个作用： 1.构建不同计算节点之间的数据流 2.在启动图时，可以设置某些tensor的值，然后获取指定tensor的值。这样就完成了计算的输入输出功能。 如下代码所示： 12inImage = tf.placeholder(tf.float32,[32,32,3],&quot;inputImage&quot;)processedImage = tf.image.per_image_standardization(inImage,&quot;processedImage&quot;) &emsp;&emsp;这里inImage和processedImage都是tensor类型。它们代表着计算节点输出的数据，数据的值具体是多少在启动图的时候才知道。上面两个方法调用都传递了一个字符串，它是计算节点的名字，最好给节点命名，这样我们可以在图上调用get_tensor_by_name(name)获取对应的tensor对象，十分方便。（tensor名字为“&lt;计算节点名字&gt;:&lt;tensor索引&gt;”） &emsp;&emsp;创建tensor时，需要指定类型和shape。对不同tensor进行计算时要求类型相同，可以使用 tf.cast 进行类型转换。同时也要求 shape (向量维度)满足运算的条件，我们可以使用 tf.reshape 改变shape。 &emsp;&emsp;现在了解计算节点的概念，其功能是对tensor进行计算、创建tensor或进行其他操作，类型是tf.Operation。获取节点对象的方法为get_operation_by_name(name)。 构建图，如下代码： 123456789101112131415g=tf.Graph()with g.as_default(): input_data=tf.placeholder(tf.float32,[None,2],&quot;input_data&quot;) input_label=tf.placeholder(tf.float32,[None,2],&quot;input_label&quot;) W1=tf.Variable(tf.truncated_normal([2,2]),name=&quot;W1&quot;) B1=tf.Variable(tf.zeros([2]),name=&quot;B1&quot;) output=tf.add(tf.matmul(input_data,W1),B1,name=&quot;output&quot;) cross_entropy=tf.nn.softmax_cross_entropy_with_logits(logits=output,labels=input_label) train_step=tf.train.AdamOptimizer().minimize(cross_entropy,name=&quot;train_step&quot;) initer=tf.global_variables_initializer() &emsp;&emsp;上面的代码中我们创建了一个图，并在上面添加了很多节点。我们可以通过调用get_default_graph()获取默认的图。 &emsp;&emsp;Input_data，input_label，W1，B1，output，cross_entropy都是tensor类型，train_step，initer，是节点类型。 有几类tensor或节点比较重要，下面介绍一下： 1.placeholder&emsp;&emsp;Tensorflow，顾名思义， tensor代表张量数据，flow代表流，其最初的设计理念就是构建一张静态的数据流图。图是有各个计算节点连接而成，计算节点之间流动的便是中间的张量数据。要想让张量数据在我们构建的静态计算图中流动起来，就必须有最初的输入数据流。而placeholder，翻译过来叫做占位符，顾名思义，是给我们的输入数据提供一个接口，也就是说我们的一切输入数据，例如训练样本数据，超参数数据等都可以通过占位符接口输送到数据流图之中。使用实例如下代码： 12345678import tensorflow as tfx = tf.placeholder(dtype=tf.float32,shape=[],name=&apos;x&apos;)y = tf.placeholder(dtpe=tf.float32,shape=[],nmae=&apos;y&apos;)z = x*ywith tf.Session() as sess: prod = sess.run(z,feed_dict=&#123;x:1.,y:5.2&#125;) print(prod)[out]:5.2 2. variable&emsp;&emsp;无论是传统的机器学习算法，例如线性支持向量机（Support Vector Machine, SVM)，其数学模型为y = &lt;w,x&gt; + b，还是更先进的深度学习算法，例如卷积神经网络（Convolutional Neural Network， CNN）单个神经元输出的模型y = w*x + b。可以看到，w和b就是我们要求的模型，模型的求解是通过优化算法（对于SVM，使用SMO[1]算法，对于CNN，一般基于梯度下降法）来一步一步更新w和b的值直到满足停止条件。因此，大多数机器学习的模型中的w和b实际上是以变量的形式出现在代码中的，这就要求我们在代码中定义模型变量。 1234567import tensorflow as tfa = tf.Variable(2.)b = tf.Variable(3.)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) #变量初始化 print(sess.run(a*b))[out]:6. [1] Platt, John. “Sequential minimal optimization: A fast algorithm for training support vector machines.” (1998). 3. initializer&emsp;&emsp;由于tensorflow构建的是静态的计算流图，在开启会话之前，所有的操作都不会被执行。因此为了执行在计算图中所构建的赋值初始化计算节点，需要在开启会话之后，在会话环境下运行初始化。如果计算图中定义了变量，而会话环境下为执行初始化命令，则程序报错，代码如下： 1234567import tensorflow as tfa = tf.Variable(2.)b = tf.Variable(3.)with tf.Session() as sess: #sess.run(tf.global_variables_initializer()) #注释掉初始化命令 print(sess.run(a*b))[Error]: Attempting to use uninitialized value Variable 2.启动图&emsp;&emsp;先了解session的概念，然后才能更好的理解图的启动。&emsp;&emsp;图的每个运行实例都必须在一个session里，session为图的运行提供环境。Session的类型是tf.Session，在实例化session对象时我们需要给它传递一个图对象，如果不显示给出将使用默认的图。Session有一个graph属性，我们可以通过它获取session对应的图。 代码如下： 12345678910111213141516171819numOfBatch=5datas=np.zeros([numOfBatch,2],np.float32)labels=np.zeros([numOfBatch,2],np.float32)sess=tf.Session(graph=g)graph=sess.graphsess.run([graph.get_operation_by_name(&quot;initer&quot;)])dataHolder=graph.get_tensor_by_name(&quot;input_data:0&quot;)labelHolder=graph.get_tensor_by_name(&quot;input_label:0&quot;)train=graph.get_operation_by_name(&quot;train_step&quot;)out=graph.get_tensor_by_name(&quot;output:0&quot;)for i inrange(200): result=sess.run([out,train],feed_dict=&#123;dataHolder:datas,labelHolder:labels&#125;) if i%100==0: saver.save(sess,&quot;./moules&quot;)sess.close() 代码都比较简单，就不介绍了。不过要注意2点：1.别忘记运行初始化节点，2.别忘记close掉session对象以释放资源。 3.给图输入数据并获取结果代码： 12for i inrange(200): result=sess.run([out,train],feed_dict=&#123;dataHolder:datas,labelHolder:labels&#125;) &emsp;&emsp;这里主要用到了session对象的run方法，它用来运行某个节点或tensor并获取对应的值。我们一般会一次传递一小部分数据进行mini-batch梯度下降来优化模型。 &emsp;&emsp;我们需要把我们需要运行的节点或tensor放入一个列表，然后作为第一个参数(不考虑self)传递给run方法，run方法会返回一个计算结果的列表，与我们传递的参数一一对应。 &emsp;&emsp;如果我们运行的节点依赖某个placeholder，那我们必须给这个placeholder指定值，怎么指定代码里面很清楚，给关键字参数feed_dict传递一个字典即可，字典里的元素的key是placeholder对象，value是我们指定的值。值的数据的类型必须和placeholder一致，包括shape。值本身的类型是numpy数组。 这里再解释一个细节，在定义placeholder时代码如下： 12input_data=tf.placeholder(tf.float32,[None,2],&quot;input_data&quot;)input_label=tf.placeholder(tf.float32,[None,2],&quot;input_label&quot;) &emsp;&emsp;shape为[None,2]，说明数据第一个维度是不确定的，然后TensorFlow会根据我们传递的数据动态推断第一个维度，这样我们就可以在运行时改变batch的大小。比如一个数据是2维，一次传递10个数据对应的tensor的shape就是[10,2]。可不可以把多个维度指定为None？理论上不可以！ 12.1.6 如何基于tensorflow搭建VGG16​ 介绍完关于tensorflow的基础知识，是时候来一波网络搭建实战了。虽然网上有很多相关教程，但我想从最标准的tensorflow代码和语法出发（而不是调用更高级的API，失去了原来的味道），向大家展示如何搭建其标准的VGG16网络架构。话不多说，上代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import numpy as npimport tensorflow as tfdef get_weight_variable(shape): return tf.get_variable('weight', shape=shape, initializer=tf.truncated_normal_initializer(stddev=0.1))def get_bias_variable(shape): return tf.get_variable('bias', shape=shape, initializer=tf.constant_initializer(0))def conv2d(x, w, padding = 'SAME', s=1): x = tf.nn.conv2d(x, w, strides=[1, s, s, 1], padding = padding) return xdef maxPoolLayer(x): return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')def conv2d_layer(x,in_chs, out_chs, ksize, layer_name): with tf.variable_scope(layer_name): w = get_weight_variable([ksize, ksize, in_chs, out_chs]) b = get_bias_variable([out_chs]) y = tf.nn.relu(tf.bias_add(conv2d(x,w,padding = 'SAME', s=1), b)) return ydef fc_layer(x,in_kernels, out_kernels, layer_name): with tf.variable_scope(layer_name): w = get_weight_variable([in_kernels,out_kernels]) b = get_bias_variable([out_kernels]) y = tf.nn.relu(tf.bias_add(tf.matmul(x,w),b)) return y def VGG16(x): conv1_1 = conv2d_layer(x,tf.get_shape(x).as_list()[-1], 64, 3, 'conv1_1') conv1_2 = conv2d_layer(conv1_1,64, 64, 3, 'conv1_2') pool_1 = maxPoolLayer(conv1_2) conv2_1 = conv2d_layer(pool1,64, 128, 3, 'conv2_1') conv2_2 = conv2d_layer(conv2_1,128, 128, 3, 'conv2_2') pool2 = maxPoolLayer(conv2_2) conv3_1 = conv2d_layer(pool2,128, 256, 3, 'conv3_1') conv3_2 = conv2d_layer(conv3_1,256, 256, 3, 'conv3_2') conv3_3 = conv2d_layer(conv3_2,256, 256, 3, 'conv3_3') pool3 = maxPoolLayer(conv3_3) conv4_1 = conv2d_layer(pool3,256, 512, 3, 'conv4_1') conv4_2 = conv2d_layer(conv4_1,512, 512, 3, 'conv4_2') conv4_3 = conv2d_layer(conv4_2,512, 512, 3, 'conv4_3') pool4 = maxPoolLayer(conv4_3) conv5_1 = conv2d_layer(pool4,512, 512, 3, 'conv5_1') conv5_2 = conv2d_layer(conv5_1,512, 512, 3, 'conv5_2') conv5_3 = conv2d_layer(conv5_1,512, 512, 3, 'conv5_3') pool5 = maxPoolLayer(conv5_3) pool5_flatten_dims = int(np.prod(pool5.get_shape().as_list()[1:])) pool5_flatten = tf.reshape(pool5,[-1,pool5_flatten_dims]) fc_6 = fc_layer(pool5_flatten, pool5_flatten_dims, 4096, 'fc6') fc_7 = fc_layer(fc_6, 4096, 4096, 'fc7') fc_8 = fc_layer(fc_7, 4096, 10, 'fc8') return fc_8 12.2 Pytorch12.2.1 Pytorch是什么？&emsp;&emsp;Pytorch是torch的python版本，是由Facebook开源的神经网络框架，专门针对 GPU 加速的深度神经网络（DNN）编程。Torch 是一个经典的对多维矩阵数据进行操作的张量（tensor ）库，在机器学习和其他数学密集型应用有广泛应用。与Tensorflow的静态计算图不同，pytorch的计算图是动态的，可以根据计算需要实时改变计算图。但由于Torch语言采用 Lua，导致在国内一直很小众，并逐渐被支持 Python 的 Tensorflow 抢走用户。作为经典机器学习库 Torch 的端口，PyTorch 为 Python 语言使用者提供了舒适的写代码选择。 12.2.2 为什么选择 Pytorch？1.简洁：&emsp;&emsp;PyTorch的设计追求最少的封装，尽量避免重复造轮子。不像 TensorFlow 中充斥着session、graph、operation、name_scope、variable、tensor、layer等全新的概念，PyTorch 的设计遵循tensor→variable(autograd)→nn.Module 三个由低到高的抽象层次，分别代表高维数组（张量）、自动求导（变量）和神经网络（层/模块），而且这三个抽象之间联系紧密，可以同时进行修改和操作。简洁的设计带来的另外一个好处就是代码易于理解。PyTorch的源码只有TensorFlow的十分之一左右，更少的抽象、更直观的设计使得PyTorch的源码十分易于阅读。 2.速度：&emsp;&emsp;PyTorch 的灵活性不以速度为代价，在许多评测中，PyTorch 的速度表现胜过 TensorFlow和Keras 等框架。框架的运行速度和程序员的编码水平有极大关系，但同样的算法，使用PyTorch实现的那个更有可能快过用其他框架实现的。 3.易用：&emsp;&emsp;PyTorch 是所有的框架中面向对象设计的最优雅的一个。PyTorch的面向对象的接口设计来源于Torch，而Torch的接口设计以灵活易用而著称，Keras作者最初就是受Torch的启发才开发了Keras。PyTorch继承了Torch的衣钵，尤其是API的设计和模块的接口都与Torch高度一致。PyTorch的设计最符合人们的思维，它让用户尽可能地专注于实现自己的想法，即所思即所得，不需要考虑太多关于框架本身的束缚。 4.活跃的社区：&emsp;&emsp;PyTorch 提供了完整的文档，循序渐进的指南，作者亲自维护的论坛 供用户交流和求教问题。Facebook 人工智能研究院对 PyTorch 提供了强力支持，作为当今排名前三的深度学习研究机构，FAIR的支持足以确保PyTorch获得持续的开发更新，不至于像许多由个人开发的框架那样昙花一现。 12.2.3 PyTorch 的架构是怎样的？&emsp;&emsp;PyTorch(Caffe2) 通过混合前端，分布式训练以及工具和库生态系统实现快速，灵活的实验和高效生产。PyTorch 和 TensorFlow 具有不同计算图实现形式，TensorFlow 采用静态图机制(预定义后再使用)，PyTorch采用动态图机制(运行时动态定义)。PyTorch 具有以下高级特征： &emsp;&emsp;混合前端:新的混合前端在急切模式下提供易用性和灵活性，同时无缝转换到图形模式，以便在C ++运行时环境中实现速度，优化和功能。&emsp;&emsp;分布式训练:通过利用本地支持集合操作的异步执行和可从Python和C ++访问的对等通信，优化了性能。&emsp;&emsp;Python优先: PyTorch为了深入集成到Python中而构建的，因此它可以与流行的库和Cython和Numba等软件包一起使用。&emsp;&emsp;丰富的工具和库:活跃的研究人员和开发人员社区建立了丰富的工具和库生态系统，用于扩展PyTorch并支持从计算机视觉到强化学习等领域的开发。&emsp;&emsp;本机ONNX支持:以标准ONNX（开放式神经网络交换）格式导出模型，以便直接访问与ONNX兼容的平台，运行时，可视化工具等。&emsp;&emsp;C++前端：C++前端是PyTorch的纯C++接口，它遵循已建立的Python前端的设计和体系结构。它旨在实现高性能，低延迟和裸机C++应用程序的研究。使用GPU和CPU优化的深度学习张量库。 12.2.4 Pytorch 与 tensorflow 之间的差异在哪里？&emsp;&emsp;上面也将了PyTorch 最大优势是建立的神经网络是动态的, 对比静态的 Tensorflow, 它能更有效地处理一些问题, 比如说 RNN 变化时间长度的输出。各有各的优势和劣势。两者都是大公司发布的, Tensorflow（Google）宣称在分布式训练上下了很大的功夫, 那就默认 Tensorflow 在分布式训练上要超出 Pytorch（Facebook），还有tensorboard可视化工具, 但是 Tensorflow 的静态计算图使得在 RNN 上有一点点被动 (虽然它用其他途径解决了), 不过用 PyTorch 的时候, 会对这种动态的 RNN 有更好的理解。而且 Tensorflow 的高度工业化, 它的底层代码很难看懂， Pytorch 好那么一点点, 如果深入 PytorchAPI, 至少能比看 Tensorflow 多看懂一点点 Pytorch 的底层在干啥。 12.2.5 Pytorch有哪些常用工具包？&emsp;&emsp;torch ：类似 NumPy 的张量库，强 GPU 支持 ；&emsp;&emsp;torch.autograd ：基于 tape 的自动区别库，支持 torch 之中的所有可区分张量运行；&emsp;&emsp;torch.nn ：为最大化灵活性未涉及、与 autograd 深度整合的神经网络库；&emsp;&emsp;torch.optim：与 torch.nn 一起使用的优化包，包含 SGD、RMSProp、LBFGS、Adam 等标准优化方式；&emsp;&emsp;torch.multiprocessing： python 多进程并发，进程之间 torch Tensors 的内存共享；&emsp;&emsp;torch.utils：数据载入器。具有训练器和其他便利功能；&emsp;&emsp;torch.legacy(.nn/.optim) ：处于向后兼容性考虑，从 Torch 移植来的 legacy 代码； 12.3 Caffe12.3.1 什么是 Caffe？&emsp;&emsp;Caffe的全称应该是Convolutional Architecture for Fast Feature Embedding，它是一个清晰、高效的深度学习框架，它是开源的，核心语言是C++，它支持命令行、Python和Matlab接口，它既可以在CPU上运行也可以在GPU上运行。它的license是BSD 2-Clause。 12.3.2 Caffe的特点是什么？(1)、模块化：Caffe从一开始就设计得尽可能模块化，允许对新数据格式、网络层和损失函数进行扩展。 (2)、表示和实现分离：Caffe的模型(model)定义是用Protocol Buffer语言写进配置文件的。以任意有向无环图的形式，Caffe支持网络架构。Caffe会根据网络的需要来正确占用内存。通过一个函数调用，实现CPU和GPU之间的切换。 (3)、测试覆盖：在Caffe中，每一个单一的模块都对应一个测试。 (4)、python和Matlab接口：同时提供Python和Matlab接口。 (5)、预训练参考模型：针对视觉项目，Caffe提供了一些参考模型，这些模型仅应用在学术和非商业领域，它们的license不是BSD。 12.3.3 Caffe的设计思想是怎样的？&emsp;&emsp;基本上，Caffe 沿用了神经网络的一个简单假设—-所有的计算都是以layer的形式表示的，layer做的事情就是take一些数据，然后输出一些计算以后的结果，比如说卷积，就是输入一个图像，然后和这一层的参数（filter）做卷积，然后输出卷积的结果。每一个layer需要做两个计算：forward是从输入计算输出，然后backward是从上面给的gradient来计算相对于输入的gradient，只要这两个函数实现了以后，我们就可以把很多层连接成一个网络，这个网络做的事情就是输入我们的数据（图像或者语音或者whatever），然后来计算我们需要的输出（比如说识别的label），在training的时候，我们可以根据已有的label来计算loss和gradient，然后用gradient来update网络的参数，这个就是Caffe的一个基本流程。 &emsp;&emsp;基本上，最简单地用Caffe上手的方法就是先把数据写成Caffe的格式，然后设计一个网络，然后用Caffe提供的solver来做优化看效果如何，如果你的数据是图像的话，可以从现有的网络，比如说alexnet或者googlenet开始，然后做fine tuning，如果你的数据稍有不同，比如说是直接的float vector，你可能需要做一些custom的configuration，Caffe的logistic regression example兴许会很有帮助。 &emsp;&emsp;Fine tune方法：fine tuning的想法就是说，在imagenet那么大的数据集上train好一个很牛的网络了，那别的task上肯定也不错，所以我们可以把pretrain的网络拿过来，然后只重新train最后几层，重新train的意思是说，比如我以前需要classify imagenet的一千类，现在我只想识别是狗还是猫，或者是不是车牌，于是我就可以把最后一层softmax从一个40961000的分类器变成一个40962的分类器，这个strategy在应用中非常好使，所以我们经常会先在imagenet上pretrain一个网络，因为我们知道imagenet上training的大概过程会怎么样。 12.3.4 Caffe架构是怎样的？&emsp;&emsp;Caffe的架构与其它的深度学习框架稍微不同，它没有根据算法实现过程的方式来进行编码，而是以系统级的抽象作为整体架构，逐层的封装实现细节，使得上层的架构变得很清晰。Caffe的整体架构如下： 1. SyncedMem&emsp;&emsp;这个类的主要功能是封装CPU和GPU的数据交互操作。一般来说，数据的流动形式都是：硬盘-&gt;CPU内存-&gt;GPU内存-&gt;CPU内存-&gt;（硬盘），所以在写代码的过程中经常会写CPU/GPU之间数据传输的代码，同时还要维护CPU和GPU两个处理端的内存指针。这些事情处理起来不会很难，但是会很繁琐。因此SyncedMem的出现就是把CPU/GPU的数据传输操作封装起来，只需要调用简单的接口就可以获得两个处理端同步后的数据。 2. Blob&emsp;&emsp;Blob是用于存储数据的对象，在Caffe中各种数据(图像输入、模型参数)都是以Blob的形式在网络中传输的，Blob提供统一的存储操作接口，可用来保存训练数据、模型参数等，同时Blob还能在CPU和GPU之间进行同步以支持CPU/GPU的混合运算。&emsp;&emsp;这个类做了两个封装：一个是操作数据的封装，使用Blob可以操纵高维的数据，快速访问其中的数据，变换数据的维度等；另一个是对原始数据和更新量的封装，每一个Blob中都有data和diff两个数据指针，data用于存储原始数据，diff 用于存储反向传播（Backpropagation）的梯度更新值。Blob使用了SyncedMem，这样便于访问不同的处理端。Blob基本实现了整个Caffe数据结构部分的封装，在Net类中可以看到所有的前后向数据和参数都用Blob来表示就足够了。数据的抽象到这个就可以了，接下来作层级的抽象。神经网络的前后向计算可以做到层与层之间完全独立，只要每个层按照一定的接口规则实现，就可以确保整个网络的正确性。 3. Layer&emsp;&emsp;Layer是网络Net的基本单元，也是Caffe中能在外部进行调整的最小网络结构单元，每个Layer都有输入Blob和输出Blob。Layer（层）是Caffe中最庞大最繁杂的模块，它是神经网络的基本计算单元。由于Caffe强调模块化设计，因此只允许每个layer完成一类特定的计算，例如convolution操作、pooling、非线性变换、内积运算，以及数据加载、归一化和损失计算等。Caffe中layer的种类有很多，具体的种类及功能请看官方文档。在创建一个Caffe模型的时候，也是以Layer为基础进行的。Layer是一个父类，它的下面还有各种实现特定功能的子类，例如data_layer，conv_layer，loss_layer等。Layer是通过LayFactory来创建的。 4. Net&emsp;&emsp;Net是一个完整的深度网络，包含输入层、隐藏层、输出层，在Caffe中一般是一个卷积神经网络(Convolution Neural Networ，CNN)。通过定义不同类型的Layer，并用Blob将不同的Layer连接起来，就能产生一个Net。Net将数据Blob和层Layer组合起来做进一步的封装，对外提供了初始化和前后传播的接口，使得整体看上去和一个层的功能类似，但内部的组合可以是多种多样的。值得一提的是，每一层的输入输出数据统一保存在Net中，同时每个层内的参数指针也保存在Net中，不同的层可以通过WeightShare共享相同的参数，因此可以通过配置来实现多个神经网络层之间共享参数的功能。一个Net由多个Layer组成。一个典型的网络从data layer（从磁盘中载入数据）出发到loss layer结束。 5. Solver&emsp;&emsp;有了Net就可以进行神经网络的前后向传播计算了，但是还缺少神经网络的训练和预测功能，Solver类进一步封装了训练和预测相关的一些功能。它还提供了两个接口：一个是更新参数的接口，继承Solver可以实现不同的参数更新方法，如Momentum，Nesterov，Adagrad等，因此可以使用不同的优化算法。另一个接口是训练过程中每一轮特定状态下的可注入的一些回调函数，在代码中这个回调点的直接使用者就是多GPU训练算法。Solver定义了针对Net网络模型的求解方法，记录网络的训练过程，保存网络模型参数，中断并恢复网络的训练过程。自定义Solver能够实现不同的神经网络求解方式。阅读Solver的代码可以了解网络的求解优化过程。Solver是一个父类，它下面还有实现不同优化方法的子类，例如sgd_solver，adagrad_sovler等，Solver是通过SolverFactory来创建的。 6. Proto&emsp;&emsp;caffe.proto位于…/src/caffe/proto目录下，在这个文件夹下还有一个.pb.cc和一个.pb.h文件，这两个文件都是由caffe.proto编译而来的。 在caffe.proto中定义了很多结构化数据，包括：BlobProto、Datum、FillerParameter、NetParameter、SolverParameter、SolverState、LayerParameter、ConcatParameter、ConvolutionParameter、DataParameter、DropoutParameter、HDF5DataParameter、HDF5OutputParameter、ImageDataParameter、InfogainLossParameter、InnerProductParameter、LRNParameter、MemoryDataParameter、PoolingParameter、PowerParameter、WindowDataParameter、V0LayerParameter。 7. IO&emsp;&emsp;除了上面的东西之外，还需要输入数据和参数。DataReader和DataTransformer帮助准备输入数据，Filler对参数进行初始化，一些Snapshot方法可以对模型进行持久化。 12.3.5 Caffe的有哪些接口？&emsp;&emsp;Caffe深度学习框架支持多种编程接口，包括命令行、Python和Matlab,下面将介绍如何使用这些接口。 1. Caffe Python接口&emsp;&emsp;Caffe提供 Python 接口，即Pycaffe，具体实现在caffe、python文件夹内。在Python代码中import caffe，可以load models（导入模型）、forward and backward （前向、反向迭代）、handle IO（数据输入输出）、visualize networks（绘制net）和instrument model solving（自定义优化方法)。所有的模型数据、计算参数都是暴露在外、可供读写的。&emsp;&emsp;(1)caffe.Net 是主要接口，负责导入数据、校验数据、计算模型。&emsp;&emsp;(2)caffe.Classsifier 用于图像分类。&emsp;&emsp;(3)caffe.Detector 用于图像检测。&emsp;&emsp;(4)caffe.SGDSolver 是露在外的 solver 的接口。&emsp;&emsp;(5)caffe.io 处理输入输出，数据预处理。&emsp;&emsp;(6)caffe.draw 可视化 net 的结构。&emsp;&emsp;(7)caffe blobs 以 numpy ndarrys 的形式表示，方便而且高效。 2. Caffe MATLAB接口&emsp;&emsp;MATLAB接口（Matcaffe）在 caffe/matlab 目录的 caffe 软件包。在 matcaffe 的基础上，可将Caffe整合到MATLAB代码中。&emsp;&emsp;MATLAB接口包括：&emsp;&emsp;(1)MATLAB 中创建多个网络结构。&emsp;&emsp;(2)网络的前向传播（Forward）与反向传播（Backward）计算。&emsp;&emsp;(3)网络中的任意一层以及参数的存取。&emsp;&emsp;(4)网络参数保存至文件或从文件夹加载。&emsp;&emsp;(5)blob 和 network 形状调整。&emsp;&emsp;(6)网络参数编辑和调整。&emsp;&emsp;(7)创建多个 solvers 进行训练。&emsp;&emsp;(8)从solver 快照（Snapshots）恢复并继续训练。&emsp;&emsp;(9)访问训练网络（Train nets）和测试网络(Test nets)。&emsp;&emsp;(10)迭代后网络交由 MATLAB 控制。&emsp;&emsp;(11)MATLAB代码融合梯度算法。 3. Caffe 命令行接口&emsp;&emsp;命令行接口 Cmdcaffe 是 Caffe 中用来训练模型、计算得分以及方法判断的工具。Cmdcaffe 存放在 caffe/build/tools 目录下。 1. caffe train&emsp;&emsp;caffe train 命令用于模型学习，具体包括：&emsp;&emsp;(1)caffe train 带 solver.prototxt 参数完成配置。&emsp;&emsp;(2)caffe train 带 snapshot mode_iter_1000.solverstate 参数加载 solver snapshot。&emsp;&emsp;(3)caffe train 带 weights 参数 model.caffemodel 完成 Fine-tuning 模型初始化。 2. caffe test&emsp;&emsp;caffe test 命令用于测试运行模型的得分，并且用百分比表示网络输出的最终结果，比如 accuracyhuoloss 作为其结果。测试过程中，显示每个 batch 的得分，最后输出全部 batch 的平均得分值。 3. caffe time&emsp;&emsp;caffe time 命令用来检测系统性能和测量模型相对执行时间，此命令通过逐层计时与同步，执行模型检测。 参考文献：1.深度学习：Caffe之经典模型讲解与实战/ 乐毅，王斌 10.4 网络搭建有什么原则？10.4.1新手原则。刚入门的新手不建议直接上来就开始搭建网络模型。比较建议的学习顺序如下： 1.了解神经网络工作原理，熟悉基本概念及术语。 2.阅读经典网络模型论文+实现源码(深度学习框架视自己情况而定)。 3.找数据集动手跑一个网络，可以尝试更改已有的网络模型结构。 4.根据自己的项目需要设计网络。 10.4.2深度优先原则。通常增加网络深度可以提高准确率，但同时会牺牲一些速度和内存。但深度不是盲目堆起来的，一定要在浅层网络有一定效果的基础上，增加深度。深度增加是为了增加模型的准确率，如果浅层都学不到东西，深了也没效果。 10.4.3卷积核size一般为奇数。卷积核为奇数有以下好处： 1 保证锚点刚好在中间，方便以 central pixel为标准进行滑动卷积，避免了位置信息发生偏移 。 2 保证在填充（Padding）时，在图像之间添加额外的零层，图像的两边仍然对称。 10.4.4卷积核不是越大越好。AlexNet中用到了一些非常大的卷积核，比如11×11、5×5卷积核，之前人们的观念是，卷积核越大，感受野越大，看到的图片信息越多，因此获得的特征越好。但是大的卷积核会导致计算量的暴增，不利于模型深度的增加，计算性能也会降低。于是在VGG、Inception网络中，利用2个3×3卷积核的组合比1个5×5卷积核的效果更佳，同时参数量（3×3×2+1=19&lt;26=5×5×1+1）被降低，因此后来3×3卷积核被广泛应用在各种模型中。 10.5 有哪些经典的网络模型值得我们去学习的？提起经典的网络模型就不得不提起计算机视觉领域的经典比赛：ILSVRC .其全称是 ImageNet Large Scale Visual Recognition Challenge.正是因为ILSVRC 2012挑战赛上的AlexNet横空出世，使得全球范围内掀起了一波深度学习热潮。这一年也被称作“深度学习元年”。而在历年ILSVRC比赛中每次刷新比赛记录的那些神经网络也成为了人们心中的经典，成为学术界与工业届竞相学习与复现的对象，并在此基础上展开新的研究。 序号 年份 网络名称 获得荣誉 1 2012 AlexNet ILSVRC图像分类冠军 2 2014 VGGNet ILSVRC图像分类亚军 3 2014 GoogLeNet ILSVRC图像分类冠军 4 2015 ResNet ILSVRC图像分类冠军 5 2017 SeNet ILSVRC图像分类冠军 1 AlexNet论文:ImageNet Classification with Deep Convolutional Neural Networks代码实现:tensorflow主要特点： 1.第一次使用非线性激活函数ReLU。 2.增加防加过拟合方法：Droupout层,提升了模型鲁棒性。 3.首次使用数据增强。 4.首次使用GPU加速运算。 2 VGGNet论文:Very Deep Convolutional Networks for Large-Scale Image Recognition代码实现:tensorflow主要特点： 1.网络结构更深。 2.普遍使用小卷积核。 3 GoogLeNet论文:Going Deeper with Convolutions代码实现:tensorflow主要特点： 1.增强卷积模块功能。主要的创新在于他的Inception，这是一种网中网（Network In Network）的结构，即原来的结点也是一个网络。Inception一直在不断发展，目前已经V2、V3、V4。其中1*1卷积主要用来降维，用了Inception之后整个网络结构的宽度和深度都可扩大，能够带来2-3倍的性能提升。 2.连续小卷积代替大卷积，保证感受野不变的同时，减少了参数数目。 4 ResNet论文:Deep Residual Learning for Image Recognition代码实现:tensorflow主要特点: 解决了“退化”问题，即当模型的层次加深时，错误率却提高了。 5 SeNet论文:Squeeze-and-Excitation Networks代码实现:tensorflow主要特点: 提出了feature recalibration，通过引入 attention 重新加权，可以得到抑制无效特征，提升有效特征的权重，并很容易地和现有网络结合，提升现有网络性能，而计算量不会增加太多。 CV领域网络结构演进历程： ILSVRC挑战赛历年冠军: 此后，ILSVRC挑战赛的名次一直是衡量一个研究机构或企业技术水平的重要标尺。ILSVRC 2017 已是最后一届举办.2018年起，将由WebVision竞赛（Challenge on Visual Understanding by Learning from Web Data）来接棒。因此，即使ILSVRC挑战赛停办了，但其对深度学习的深远影响和巨大贡献，将永载史册。 10.6 网络训练有哪些技巧吗？10.6.1.合适的数据集。 1 没有明显脏数据(可以极大避免Loss输出为NaN)。 2 样本数据分布均匀。 10.6.2.合适的预处理方法。关于数据预处理，在Batch Normalization未出现之前预处理的主要做法是减去均值，然后除去方差。在Batch Normalization出现之后，减均值除方差的做法已经没有必要了。对应的预处理方法主要是数据筛查、数据增强等。 10.6.3.网络的初始化。网络初始化最粗暴的做法是参数赋值为全0，这是绝对不可取的。因为如果所有的参数都是0，那么所有神经元的输出都将是相同的，那在back propagation的时候同一层内所有神经元的行为也是相同的，这可能会直接导致模型失效，无法收敛。吴恩达视频中介绍的方法是将网络权重初始化均值为0、方差为1符合的正态分布的随机数据。 10.6.4.小规模数据试练。在正式开始训练之前，可以先用小规模数据进行试练。原因如下： 1 可以验证自己的训练流程对否。 2 可以观察收敛速度，帮助调整学习速率。 3 查看GPU显存占用情况，最大化batch_size(前提是进行了batch normalization，只要显卡不爆，尽量挑大的)。 10.6.5.设置合理Learning Rate。 1 太大。Loss爆炸、输出NaN等。 2 太小。收敛速度过慢，训练时长大大延长。 3 可变的学习速率。比如当输出准确率到达某个阈值后，可以让Learning Rate减半继续训练。 10.6.6.损失函数损失函数主要分为两大类:分类损失和回归损失 1.回归损失： 1 均方误差(MSE 二次损失 L2损失)它是我们的目标变量与预测值变量差值平方。 2 平均绝对误差(MAE L1损失)它是我们的目标变量与预测值变量差值绝对值。关于MSE与MAE的比较。MSE更容易解决问题，但是MAE对于异常值更加鲁棒。更多关于MAE和MSE的性能，可以参考L1vs.L2 Loss Function 2.分类损失： 1 交叉熵损失函数。是目前神经网络中最常用的分类目标损失函数。 2 合页损失函数合页损失函数广泛在支持向量机中使用，有时也会在损失函数中使用。缺点:合页损失函数是对错误越大的样本施以更严重的惩罚，但是这样会导致损失函数对噪声敏感。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[迁移学习]]></title>
    <url>%2F2017%2F10%2F01%2F%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0_%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[10.1 为什么需要迁移学习？（中科院计算所-王晋东） 大数据与少标注的矛盾：虽然有大量的数据，但往往都是没有标注的，无法训练机器学习模型。人工进行数据标定太耗时。 大数据与弱计算的矛盾：普通人无法拥有庞大的数据量与计算资源。因此需要借助于模型的迁移。 普适化模型与个性化需求的矛盾：即使是在同一个任务上，一个模型也往往难以满足每个人的个性化需求，比如特定的隐私设置。这就需要在不同人之间做模型的适配。 特定应用（如冷启动）的需求。 10.2 迁移学习的基本问题有哪些？（中科院计算所-王晋东）基本问题主要有3个： How to transfer： 如何进行迁移学习？（设计迁移方法） What to transfer： 给定一个目标领域，如何找到相对应的源领域，然后进行迁移？（源领域选择） When to transfer： 什么时候可以进行迁移，什么时候不可以？（避免负迁移） 10.3 迁移学习有哪些常用概念？（KeyFoece） 基本定义 域(Domain)：数据特征和特征分布组成，是学习的主体 源域 (Source domain)：已有知识的域 目标域 (Target domain)：要进行学习的域 任务 (Task)：由目标函数和学习结果组成，是学习的结果 按特征空间分类 同构迁移学习（Homogeneous TL）： 源域和目标域的特征空间相同，$D_s=D_t$ 异构迁移学习（Heterogeneous TL）：源域和目标域的特征空间不同，$D_s\ne D_t$ 按迁移情景分类 归纳式迁移学习（Inductive TL）：源域和目标域的学习任务不同 直推式迁移学习（Transductive TL)：源域和目标域不同，学习任务相同 无监督迁移学习（Unsupervised TL)：源域和目标域均没有标签 按迁移方法分类 基于实例的迁移 (Instance based TL)：通过权重重用源域和目标域的样例进行迁移 基于特征的迁移 (Feature based TL)：将源域和目标域的特征变换到相同空间 基于模型的迁移 (Parameter based TL)：利用源域和目标域的参数共享模型 基于关系的迁移 (Relation based TL)：利用源域中的逻辑网络关系进行迁移 10.4 迁移学习与传统机器学习有什么区别？（KeyFoece） 迁移学习 传统机器学习 数据分布 训练和测试数据不需要同分布 训练和测试数据同分布 数据标签 不需要足够的数据标注 足够的数据标注 建模 可以重用之前的模型 每个任务分别建模 10.5 迁移学习的基本思路？（中科院计算所-王晋东）迁移学习的总体思路可以概括为：开发算法来最大限度地利用有标注的领域的知识，来辅助目标领域的知识获取和学习。 迁移学习的核心是：找到源领域和目标领域之间的相似性，并加以合理利用。这种相似性非常普遍。比如，不同人的身体构造是相似的；自行车和摩托车的骑行方式是相似的；国际象棋和中国象棋是相似的；羽毛球和网球的打球方式是相似的。这种相似性也可以理解为不变量。以不变应万变，才能立于不败之地。 有了这种相似性后，下一步工作就是， 如何度量和利用这种相似性。度量工作的目标有两点：一是很好地度量两个领域的相似性，不仅定性地告诉我们它们是否相似，更定量地给出相似程度。二是以度量为准则，通过我们所要采用的学习手段，增大两个领域之间的相似性，从而完成迁移学习。 一句话总结： 相似性是核心，度量准则是重要手段。 10.6 迁移学习与其他概念的区别(Limber) 迁移学习与多任务学习关系： 多任务学习：多个相关任务一起协同学习； 迁移学习：强调信息复用，从一个领域(domain)迁移到另一个领域。 迁移学习与领域自适应：领域自适应：使两个特征分布不一致的domain一致。 迁移学习与协方差漂移：协方差漂移：数据的条件概率分布发生变化。 10.7 什么是多任务学习？在迁移学习中，从任务A里学习只是然后迁移到任务B。在多任务学习中，同时开始学习的，试图让单个神经网络同时做几件事情，然后希望这里每个任务都能帮到其他所有任务。 指多个相关任务一起协同学习 10.8 多任务学习有什么意义？ 第一，如果你训练的一组任务，可以共用低层次特征。对于无人驾驶的例子，同时识别交通灯、汽车和行人是有道理的，这些物体有相似的特征，也许能帮你识别停车标志，因为这些都是道路上的特征。 第二，这个准则没有那么绝对，所以不一定是对的。但我从很多成功的多任务学习案例中看到，如果每个任务的数据量很接近，你还记得迁移学习时，你从任务学到知识然后迁移到任务，所以如果任务有1百万个样本，任务只有1000个样本，那么你从这1百万个样本学到的知识，真的可以帮你增强对更小数据集任务的训练。那么多任务学习又怎么样呢？在多任务学习中，你通常有更多任务而不仅仅是两个，所以也许你有，以前我们有4个任务，但比如说你要完成100个任务，而你要做多任务学习，尝试同时识别100种不同类型的物体。你可能会发现，每个任务大概有1000个样本。所以如果你专注加强单个任务的性能，比如我们专注加强第100个任务的表现，我们用表示，如果你试图单独去做这个最后的任务，你只有1000个样本去训练这个任务，这是100项任务之一，而通过在其他99项任务的训练，这些加起来可以一共有99000个样本，这可能大幅提升算法性能，可以提供很多知识来增强这个任务的性能。不然对于任务，只有1000个样本的训练集，效果可能会很差。如果有对称性，这其他99个任务，也许能提供一些数据或提供一些知识来帮到这100个任务中的每一个任务。所以第二点不是绝对正确的准则，但我通常会看的是如果你专注于单项任务，如果想要从多任务学习得到很大性能提升，那么其他任务加起来必须要有比单个任务大得多的数据量。要满足这个条件，其中一种方法是，比如右边这个例子这样，或者如果每个任务中的数据量很相近，但关键在于， 如果对于单个任务你已经有1000个样本了，那么对于所有其他任务，你最好有超过1000个样 本，这样其他任务的知识才能帮你改善这个任务的性能。 最后多任务学习往往在以下场合更有意义，当你可以训练一个足够大的神经网络，同时做好所有的工作，所以多任务学习的替代方法是为每个任务训练一个单独的神经网络。所以不是训练单个神经网络同时处理行人、汽车、停车标志和交通灯检测。你可以训练一个用于行人检测的神经网络，一个用于汽车检测的神经网络，一个用于停车标志检测的神经网络和一个用于交通信号灯检测的神经网络。那么研究员 Rich Carona 几年前发现的是什么呢？多任务学习会降低性能的唯一情况，和训练单个神经网络相比性能更低的情况就是你的神经网络还不够大。 但如果你可以训练一个足够大的神经网络，那么多任务学习肯定不会或者很少会降低性能，我们都希望它可以提升性能，比单独训练神经网络来单独完成各个任务性能要更好。 所以这就是多任务学习，在实践中，多任务学习的使用频率要低于迁移学习。我看到很多迁移学习的应用，你需要解决一个问题，但你的训练数据很少，所以你需要找一个数据很多的相关问题来预先学习，并将知识迁移到这个新问题上。但多任务学习比较少见，就是你需要同时处理很多任务，都要做好，你可以同时训练所有这些任务，也许计算机视觉是一个例子。在物体检测中，我们看到更多使用多任务学习的应用，其中一个神经网络尝试检测一大堆物体，比分别训练不同的神经网络检测物体更好。但我说，平均来说，目前迁移学习使用频率更高，比多任务学习频率更高，但两者都可以成为你的强力工具。 总结一下，多任务学习能让你训练一个神经网络来执行许多任务，这可以给你更高的性能，比单独完成各个任务更高的性能。但要注意，实际上迁移学习比多任务学习使用频率更高。我看到很多任务都是，如果你想解决一个机器学习问题，但你的数据集相对较小，那么迁移学习真的能帮到你，就是如果你找到一个相关问题，其中数据量要大得多，你就能以它为基础训练你的神经网络，然后迁移到这个数据量很少的任务上来。 今天我们学到了很多和迁移学习有关的问题，还有一些迁移学习和多任务学习的应用。但多任务学习，我觉得使用频率比迁移学习要少得多，也许其中一个例外是计算机视觉，物体检测。在那些任务中，人们经常训练一个神经网络同时检测很多不同物体，这比训练单独的神经网络来检测视觉物体要更好。但平均而言，我认为即使迁移学习和多任务学习工作方式类似。 实际上，我看到用迁移学习比多任务学习要更多，我觉得这是因为你很难找到那么多相似且数据量对等的任务可以用单一神经网络训练。再次，在计算机视觉领域，物体检测这个例子是最显著的例外情况。 所以这就是多任务学习，多任务学习和迁移学习都是你的工具包中的重要工具。最后，我想继续讨论端到端深度学习，所以我们来看下一个视频来讨论端到端学习。 10.9 什么是端到端的深度学习？ 深度学习中最令人振奋的最新动态之一就是端到端深度学习的兴起，那么端到端学习到底是什么呢？简而言之，以前有一些数据处理系统或者学习系统，它们需要多个阶段的处理。那么端到端深度学习就是忽略所有这些不同的阶段，用单个神经网络代替它。 而端到端深度学习就只需要把训练集拿过来，直接学到了和之间的函数映射，直接绕过了其中很多步骤。对一些学科里的人来说，这点相当难以接受，他们无法接受这样构建AI系统，因为有些情况，端到端方法完全取代了旧系统，某些投入了多年研究的中间组件也许已经过时了。 10.10 端到端的深度学习举例？ 这张图上是一个研究员做的人脸识别门禁，是百度的林元庆研究员做的。这是一个相机，它会拍下接近门禁的人，如果它认出了那个人，门禁系统就自动打开，让他通过，所以你不需要刷一个RFID工卡就能进入这个设施。系统部署在越来越多的中国办公室，希望在其他国家也可以部署更多，你可以接近门禁，如果它认出你的脸，它就直接让你通过，你不需要带RFID工卡。 我们再来看几个例子，比如机器翻译。传统上，机器翻译系统也有一个很复杂的流水线，比如英语机翻得到文本，然后做文本分析，基本上要从文本中提取一些特征之类的，经过很多步骤，你最后会将英文文本翻译成法文。因为对于机器翻译来说的确有很多(英文,法文)的数据对，端到端深度学习在机器翻译领域非常好用，那是因为在今天可以收集对的大数据集，就是英文句子和对应的法语翻译。所以在这个例子中，端到端深度学习效果很好。 10.11 端到端的深度学习有什么挑战？ 事实证明，端到端深度学习的挑战之一是，你可能需要大量数据才能让系统表现良好，比如，你只有3000小时数据去训练你的语音识别系统，那么传统的流水线效果真的很好。但当你拥有非常大的数据集时，比如10,000小时数据或者100,000小时数据，这样端到端方法突然开始很厉害了。所以当你的数据集较小的时候，传统流水线方法其实效果也不错，通常做得更好。 你需要大数据集才能让端到端方法真正发出耀眼光芒。如果你的数据量适中，那么也可以用中间件方法，你可能输入还是音频，然后绕过特征提取，直接尝试从神经网络输出音位，然后也可以在其他阶段用，所以这是往端到端学习迈出的一小步，但还没有到那里。 10.13 端到端的深度学习优缺点？假设你正在搭建一个机器学习系统，你要决定是否使用端对端方法，我们来看看端到端深度学习的一些优缺点，这样你就可以根据一些准则，判断你的应用程序是否有希望使用端到端方法。 这里是应用端到端学习的一些优点： 首先端到端学习真的只是让数据说话。所以如果你有足够多的数据，那么不管从 x 到 y 最适合的函数映射是什么，如果你训练一个足够大的神经网 络，希望这个神经网络能自己搞清楚，而使用纯机器学习方法，直接从到输入去训练的神经网 络，可能更能够捕获数据中的任何统计信息，而不是被迫引入人类的成见。例如，在语音识别领域，早期的识别系统有这个音位概念，就是基本的声音单元，如 cat 单词的“cat”的 Cu-、Ah-和 Tu-，我觉得这个音位是人类语言学家生造出来的，我实际上认为音位其实是语音学家的幻想，用音位描述语言也还算合理。但是不要强迫你的学习算法以音位为单位思考，这点有时没那么明显。如果你让你的学习算法学习它想学习的任意表示方式，而不是强迫你的学习算法使用音位作为表示方式，那么其整体表现可能会更好。 端到端深度学习的第二个好处就是这样，所需手工设计的组件更少，所以这也许能够简化你的设计工作流程，你不需要花太多时间去手工设计功能，手工设计这些中间表示方式。 这里是应用端到端学习的一些缺点： 首先，它可能需要大量的数据。要直接学到这个到的映射，你可能需要大量数据。我们在以前的视频里看过一个例子，其中你可以收集大量子任务数据。比如人脸识别，我们可以收集很多数据用来分辨图像中的人脸，当你找到一张脸后，也可以找得到很多人脸识别数据。但是对于整个端到端任务，可能只有更少的数据可用。所以这是端到端学习的输入端，是输出端，所以你需要很多这样的数据，在输入端和输出端都有数据，这样可以训练这些系统。这就是为什么我们称之为端到端学习，因为你直接学习出从系统的一端到 系统的另一端。 另一个缺点是，它排除了可能有用的手工设计组件。机器学习研究人员一般都很鄙视手工设计的东西，但如果你没有很多数据，你的学习算法就没办法从很小的训练集数据中获得洞察力。所以手工设计组件在这种情况，可能是把人类知识直接注入算法的途径，这总不是一件坏事。我觉得学习算法有两个主要的知识来源，一个是数据，另一个是你手工设计的任何东西，可能是组件，功能，或者其他东西。所以当你有大量数据时，手工设计的东西就不太重要了，但是当你没有太多的数据时，构造一个精心设计的系统，实际上可以将人类对这个问题的很多 认识直接注入到问题里，进入算法里应该挺有帮助的。 总结： 所以端到端深度学习的弊端之一是它把可能有用的人工设计的组件排除在外了，精心设计的人工组件可能非常有用，但它们也有可能真的伤害到你的算法表现。例如，强制你的算法以音位为单位思考，也许让算法自己找到更好的表示方法更好。所以这是一把双刃剑，可能有坏处，可能有好处，但往往好处更多，手工设计的组件往往在训练集更小的时候帮助更大。 10.14 什么是负迁移？产生负迁移的原因有哪些？（中科院计算所-王晋东）负迁移(Negative Transfer)指的是，在源域上学习到的知识，对于目标域上的学习产生负面作用。 产生负迁移的原因主要有： 数据问题：源域和目标域压根不相似，谈何迁移？ 方法问题：源域和目标域是相似的，但是，迁移学习方法不够好，没找到可迁移的成分。 负迁移给迁移学习的研究和应用带来了负面影响。在实际应用中，找到合理的相似性，并且选择或开发合理的迁移学习方法，能够避免负迁移现象。 10.15 什么是迁移学习？ 找到目标问题的相似性，迁移学习任务就是从相似性出发，将旧领域(domain)学习过的模型应用在新领域上。 迁移学习，是指利用数据、任务、或模型之间的相似性，将在旧领域学习过的模型，应用于新领域的一种学习过程。 迁移学习最有用的场合是，如果你尝试优化任务B的性能，通常这个任务数据相对较少。例如，在放射科中你知道很难收集很多射线扫描图来搭建一个性能良好的放射科诊断系统，所以在这种情况下，你可能会找一个相关但不同的任务，如图像识别，其中你可能用 1 百万张图片训练过了，并从中学到很多低层次特征，所以那也许能帮助网络在任务在放射科任务上做得更好，尽管任务没有这么多数据。 迁移学习什么时候是有意义的？它确实可以显著提高你的学习任务的性能，但我有时候也见过有些场合使用迁移学习时，任务实际上数据量比任务要少， 这种情况下增益可能不多。 什么情况下可以使用迁移学习？ 假如两个领域之间的区别特别的大，不可以直接采用迁移学习，因为在这种情况下效果不是很好。在这种情况下，推荐使用[3]的工作，在两个相似度很低的domain之间一步步迁移过去（踩着石头过河）。 迁移学习主要解决方案有哪些？ 除直接看infer的结果的Accurancy以外，如何衡量迁移学习学习效果？ 对抗网络是如何进行迁移的？ Reference： 王晋东，迁移学习简明手册 Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., &amp; Vaughan, J. W. (2010). A theory of learning from different domains. Machine learning, 79(1-2), 151-175. Tan, B., Song, Y., Zhong, E. and Yang, Q., 2015, August. Transitive transfer learning. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 1155-1164). ACM.]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强化学习]]></title>
    <url>%2F2017%2F09%2F20%2F%E7%AC%AC%E5%8D%81%E7%AB%A0_%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/ 第十章 强化学习10.1 强化学习的主要特点？其他许多机器学习算法中学习器都是学得怎样做，而RL是在尝试的过程中学习到在特定的情境下选择哪种行动可以得到最大的回报。在很多场景中，当前的行动不仅会影响当前的rewards，还会影响之后的状态和一系列的rewards。RL最重要的3个特定在于：(1) 基本是以一种闭环的形式；(2) 不会直接指示选择哪种行动（actions）；(3) 一系列的actions和奖励信号（reward signals）都会影响之后较长的时间。 10.1.1 定义强化学习是机器学习的一个重要分支，是多学科多领域交叉的一个产物，它的本质是解决 decision making 问题，即自动进行决策，并且可以做连续决策。它主要包含四个元素，agent，环境状态，行动，奖励, 强化学习的目标就是获得最多的累计奖励。我们列举几个形象的例子：小孩想要走路，但在这之前，他需要先站起来，站起来之后还要保持平衡，接下来还要先迈出一条腿，是左腿还是右腿，迈出一步后还要迈出下一步。小孩就是 agent，他试图通过采取行动（即行走）来操纵环境（行走的表面），并且从一个状态转变到另一个状态（即他走的每一步），当他完成任务的子任务（即走了几步）时，孩子得到奖励（给巧克力吃），并且当他不能走路时，就不会给巧克力。 上图中agent代表自身，如果是自动驾驶，agent就是车；如果你玩游戏它就是你当前控制的游戏角色，如马里奥，马里奥往前走时环境就一直在发生变化，有小怪物或者障碍物出现，它需要通过跳跃来进行躲避，就是要做action（如向前走和跳起的动作）；无人驾驶的action就是车左转、右转或刹车等等，它无时无刻都在与环境产生交互，action会反馈给环境，进而改变环境，如果自动驾驶的车行驶目标是100米，它向前开了10米，那环境就发生了变化，所以每次产生action都会导致环境改变，环境的改变会反馈给自身（agent），就是这样的一个循环；反馈又两种方式：1、做的好（reward）即正反馈，2、做得不好（punishment惩罚）即负反馈。Agent可能做得好，也可能做的不好，环境始终都会给它反馈，agent会尽量去做对自身有利的决策，通过反反复复这样的一个循环，agent会越来越做的好，就像孩子在成长过程中会逐渐明辨是非，这就是强化学习。 10.2 强化学习应用实例（1）Manufacturing 例如一家日本公司 Fanuc，工厂机器人在拿起一个物体时，会捕捉这个过程的视频，记住它每次操作的行动，操作成功还是失败了，积累经验，下一次可以更快更准地采取行动。 （2）Inventory Management 在库存管理中，因为库存量大，库存需求波动较大，库存补货速度缓慢等阻碍使得管理是个比较难的问题，可以通过建立强化学习算法来减少库存周转时间，提高空间利用率。 （3）Dynamic pricing 强化学习中的 Q-learning 可以用来处理动态定价问题。 （4）Customer Delivery 制造商在向各个客户运输时，想要在满足客户的所有需求的同时降低车队总成本。通过 multi-agents 系统和 Q-learning，可以降低时间，减少车辆数量。 （5）ECommerce Personalization 在电商中，也可以用强化学习算法来学习和分析顾客行为，定制产品和服务以满足客户的个性化需求。 （6）Ad Serving 例如算法 LinUCB （属于强化学习算法 bandit 的一种算法），会尝试投放更广范围的广告，尽管过去还没有被浏览很多，能够更好地估计真实的点击率。再如双 11 推荐场景中，阿里巴巴使用了深度强化学习与自适应在线学习，通过持续机器学习和模型优化建立决策引擎，对海量用户行为以及百亿级商品特征进行实时分析，帮助每一个用户迅速发现宝贝，提高人和商品的配对效率。还有，利用强化学习将手机用户点击率提升了 10-20%。 （7）Financial Investment Decisions 例如这家公司 Pit.ai，应用强化学习来评价交易策略，可以帮助用户建立交易策略，并帮助他们实现其投资目标。 （8）Medical Industry 动态治疗方案（DTR）是医学研究的一个主题，是为了给患者找到有效的治疗方法。 例如癌症这种需要长期施药的治疗，强化学习算法可以将患者的各种临床指标作为输入 来制定治疗策略。 10.3 强化学习和监督式学习、非监督式学习的区别在机器学习中，我们比较熟知的是监督式学习，非监督学习，此外还有一个大类就是强化学习：当前的机器学习算法可以分为3种：有监督的学习（Supervised Learning）、无监督的学习（Unsupervised Learning）和强化学习（Reinforcement Learning），结构图如下所示： 10.3.1 强化学习和监督式学习的区别：监督式学习就好比你在学习的时候，有一个导师在旁边指点，他知道怎么是对的怎么是错的，但在很多实际问题中，例如 chess，go，这种有成千上万种组合方式的情况，不可能有一个导师知道所有可能的结果。 而这时，强化学习会在没有任何标签的情况下，通过先尝试做出一些行为得到一个结果，通过这个结果是对还是错的反馈，调整之前的行为，就这样不断的调整，算法能够学习到在什么样的情况下选择什么样的行为可以得到最好的结果。 就好比你有一只还没有训练好的小狗，每当它把屋子弄乱后，就减少美味食物的数量（惩罚），每次表现不错时，就加倍美味食物的数量（奖励），那么小狗最终会学到一个知识，就是把客厅弄乱是不好的行为。 两种学习方式都会学习出输入到输出的一个映射，监督式学习出的是之间的关系，可以告诉算法什么样的输入对应着什么样的输出，强化学习出的是给机器的反馈 reward function，即用来判断这个行为是好是坏。另外强化学习的结果反馈有延时，有时候可能需要走了很多步以后才知道以前的某一步的选择是好还是坏，而监督学习做了比较坏的选择会立刻反馈给算法。 而且强化学习面对的输入总是在变化，每当算法做出一个行为，它影响下一次决策的输入，而监督学习的输入是独立同分布的。 通过强化学习，一个 agent 可以在探索和开发（exploration and exploitation）之间做权衡，并且选择一个最大的回报。 exploration 会尝试很多不同的事情，看它们是否比以前尝试过的更好。 exploitation 会尝试过去经验中最有效的行为。 一般的监督学习算法不考虑这种平衡，就只是是 exploitative。 10.3.2 强化学习和非监督式学习的区别：非监督式不是学习输入到输出的映射，而是模式。例如在向用户推荐新闻文章的任务中，非监督式会找到用户先前已经阅读过类似的文章并向他们推荐其一，而强化学习将通过向用户先推荐少量的新闻，并不断获得来自用户的反馈，最后构建用户可能会喜欢的文章的“知识图”。 对非监督学习来说，它通过对没有概念标记的训练例进行学习，以发现训练例中隐藏的结构性知识。这里的训练例的概念标记是不知道的，因此训练样本的歧义性最高。对强化学习来说，它通过对没有概念标记、但与一个延迟奖赏或效用（可视为延迟的概念标记）相关联的训练例进行学习，以获得某种从状态到行动的映射。这里本来没有概念标记的概念，但延迟奖赏可被视为一种延迟概念标记，因此其训练样本的歧义性介于监督学习和非监督学习之间。 需要注意的是，监督学习和非监督学习从一开始就是相对的，而强化学习在提出时并没有从训练样本歧义性的角度考虑其与监督学习和非监督学习的区别，因此，一些早期的研究中把强化学习视为一种特殊的非监督学习。事实上，对强化学习的定位到目前仍然是有争议的，有的学者甚至认为它是与“从例子中学习”同一级别的概念。 从训练样本歧义性角度进行的分类体系，在近几年可望有一些扩展，例如多示例学习（multi-instancelearning）等从训练样本歧义性方面来看很特殊的新的学习框架有可能会进入该体系。但到目前为止，没有任何新的框架得到了公认的地位。另外，半监督学习（semi-supervisedlearning）也有一定希望，它的障碍是半监督学习中的歧义性并不是与生俱来的，而是人为的，即用户期望用未标记的样本来辅助对已标记样本的学习。这与监督学习、非监督学习、强化学习等天生的歧义性完全不同。半监督学习中人为的歧义性在解决工程问题上是需要的、有用的（对大量样本进行标记的代价可能是极为昂贵的），但可能不太会导致方法学或对学习问题视点的大的改变。 强化学习和前二者的本质区别:没有前两者具有的明确数据概念，它不知道结果，只有目标。数据概念就是大量的数据，有监督学习、无监督学习需要大量数据去训练优化你建立的模型，就像猫狗识别，用n多张猫狗图片去训练模型，经过训练优化后，你用一张崭新的猫狗图片让模型作出判断，这个模型就知道是猫还是狗。 10.4 强化学习主要有哪些算法？强化学习不需要监督信号,可以在模型未知的环境中平衡探索和利用, 其主要算法有蒙特卡罗强化学习, 时间差分(temporal difference: TD)学习, 策略梯度等。典型的深度强化学习算法特点及性能比较如下图所示： 除了上述深度强化学习算法，还有深度迁移强化学习、分层深度强化学习、深度记忆强化学习以及多智能体强化学习等算法。 10.5 深度迁移强化学习算法传统深度强化学习算法每次只能解决一种游戏任务, 无法在一次训练中完成多种任务. 迁移学习和强化学习的结合也是深度强化学习的一种主要思路。 Parisotto等提出了一种基于行为模拟的深度迁移强化学习算法. 该算法通过监督信号的指导, 使得单一的策略网络学习各自的策略, 并将知识迁移到新任务中. Rusa等提出策略蒸馏(policy distillation)深度迁移强化学习算法. 策略蒸馏算法中分为学习网络和指导网络, 通过这两个网络Q值的偏差来确定目标函数,引导学习网络逼近指导网络的值函数空间. 此后,Rusa等又提出了一种基于渐进神经网络(progressive neural networks, PNN)的深度迁移强化学习算法.PNN是一种把神经网络和神经网络连起来的算法. 它在一系列序列任务中, 通过渐进的方式来存储知识和提取特征, 完成了对知识的迁移. PNN最终实现多个独立任务的训练, 通过迁移加速学习过程, 避免灾难性遗忘. Fernando 等提出了路径网络(PathNet)[45].PathNet可以说是PNN的进阶版. PathNet把网络中每一层都看作一个模块, 把构建一个网络看成搭积木,也就是复用积木. 它跟PNN非常类似, 只是这里不再有列, 而是不同的路径. PathNet将智能体嵌入到神经网络中, 其中智能体的任务是为新任务发现网络中可以复用的部分. 智能体是网络之中的路径, 其决定了反向传播过程中被使用和更新的参数范围. 在一系列的Atari强化学习任务上, PathNet都实现了正迁移, 这表明PathNet在训练神经网络上具有通用性应用能力.PathNet也可以显著提高A3C算法超参数选择的鲁棒性. Schaul等提出了一种通用值函数逼近器(universalvalue function approximators, UVFAs)来泛化状态和目标空间．UVFAs可以将学习到的知识迁移到环境动态特性相同但目标不同的新任务中. 10.6 分层深度强化学习算法分层强化学习可以将最终目标分解为多个子任务来学习层次化的策略, 并通过组合多个子任务的策略形成有效的全局策略. Kulkarni等提出了分层DQN(hierarchical deep Q-network, h–DQN) 算法. h–DQN基于时空抽象和内在激励分层, 通过在不同的时空尺度上设置子目标对值函数进行层次化处理. 顶层的值函数用于确定宏观决策, 底层的值函数用于确定具体行动．Krishnamurthy等在h–DQN的基础上提出了基于内部选择的分层深度强化学习算法. 该模型结合时空抽象和深度神经网络, 自动地完成子目标的学习, 避免了特定的内在激励和人工设定中间目标,加速了智能体的学习进程, 同时也增强了模型的泛化能力. Kulkarni等基于后续状态表示法提出了深度后续强化学习(deep successor reinforcement learning,DSRL)．DSRL通过阶段性地分解子目标和学习子目标策略, 增强了对未知状态空间的探索, 使得智能体更加适应那些存在延迟反馈的任务．Vezhnevets等受封建(feudal)强化学习算法的启发, 提出一种分层深度强化学习的架构FeUdal网络(FuNs)[49]. FuNs框架使用一个管理员模块和一个工人模块. 管理员模块在较低的时间分辨率下工作, 设置抽象目标并传递给工人模块去执行. FuNs框架创造了一个稳定的自然层次结构, 并且允许两个模块以互补的方式学习. 实验证明, FuNs有助于处理长期信用分配和记忆任务,在Atari视频游戏和迷宫游戏中都取得了不错的效果。 10.7 深度记忆强化学习算法传统的深度强化学习模型不具备记忆、认知、推理等高层次的能力, 尤其是在面对状态部分可观察和延迟奖赏的情形时. Junhyuk等通过在传统的深度强化学习模型中加入外部的记忆网络部件和反馈控制机制, 提出反馈递归记忆Q网络(feedback recurrent memory Q-network, FRMQN)). FRMQN模型具备了一定的记忆与推理功能, 通过反馈控制机制,FRMQN整合过去存储的有价值的记忆和当前时刻的上下文状态, 评估动作值函数并做出决策. FRMQN初步模拟了人类的主动认知与推理能力, 并完成了一些高层次的认知任务. 在一些未经过训练的任务中,FRMQN模型表现出了很强的泛化能力．Blundell等设计出一种模型无关的情节控制算法(model-free episode control, MFEC). MFEC可以快速存储和回放状态转移序列, 并将回放的序列整合到结构化知识系统中, 使得智能体在面对一些复杂的决策任务时, 能快速达到人类玩家的水平．MFEC通过反向经验回放, 使智能体拥有初步的情节记忆. 实验表明, 基于MFEC算法的深度强化学习不仅可以在Atari游戏中学习到有效策略, 还可以处理一些三维场景的复杂任务. Pritzel等在MFEC的基础上进一步提出了神经情节控制(neural episodic control, NEC),有效提高了深度强化学习智能体的记忆能力和学习效率[53]. NEC能快速吸收新经验并依据新经验来采取行动. 价值函数包括价值函数渐变状态表示和价值函数快速更新估计两部分. 大量场景下的研究表明,NEC的学习速度明显快于目前最先进的通用深度强化学习智能体. 10.8 多智能体深度强化学习算法在一些复杂场景中, 涉及到多智能体的感知决策问题, 这时需要将单一模型扩展为多个智能体之间相互合作、通信及竞争的多智能体深度强化学习系统.Foerster等提出了一种称为分布式深度递归Q网络(deep distributed recurrent Q-networks, DDRQN) 的模型, 解决了状态部分可观测状态下的多智能体通信与合作的挑战性难题[54]. 实验表明, 经过训练的DDRQN模型最终在多智能体之间达成了一致的通信协1536 控制理论与应用第34 卷议, 成功解决了经典的红蓝帽子问题.让智能体学会合作与竞争一直以来都是人工智能领域内的一项重要研究课题, 也是实现通用人工智能的必要条件. Lowe等提出了一种用于合作–竞争混合环境的多智能体actor-critic 算法(multi-agent deepdeterministic policy gradient, MADDPG)[55]. MADDPG对DDPG强化学习算法进行了延伸, 可实现多智能体的集中式学习和分布式执行, 让智能体学习彼此合作和竞争. 在多项测试任务中, MADDPG的表现都优于DDPG. 10.9 强化学习开源框架谷歌TensorFlow Agents —TensorFlow的加强版,它提供许多工具，通过强化学习可以实现各类智能应用程序的构建与训练。这个框架能够将OpoenAI Gym接口扩展至多个并行环境，并允许各代理立足TensorFlow之内实现以执行批量计算。其面向OpoenAI Gy环境的批量化接口可与TensorFlow实现全面集成，从而高效执行各类算法。该框架还结合有BatchPPO，一套经过优化的近端策略优化算法实现方案。其核心组件包括一个环境打包器，用于在外部过程中构建OpenAI Gym环境; 一套批量集成，用于实现TensorFlow图步并以强化学习运算的方式重置函数; 外加用于将TensorFlow图形批处理流程与强化学习算法纳入训练特内单一却步的组件。 Roboschool：Roboschool 提供开源软件以通过强化学习构建并训练机器人模拟。其有助于在同一环境当中对多个代理进行强化学习训练。通过多方训练机制，您可以训练同一代理分别作为两方玩家（因此能够自我对抗）、使用相同算法训练两套代理，或者设置两种算法进行彼此对抗。Roboschool由OpenAI开发完成，这一非营利性组织的背后赞助者包括Elon Musk、Sam Altman、Reid Hoffman以及Peter Thiel。其与OpenAI Gym相集成，后者是一套用于开发及评估强化学习算法的开源工具集。OpenAI Gym与TensorFlow、Theano以及其它多种深度学习库相兼容。OpenAI Gym当中包含用于数值计算、游戏以及物理引擎的相关代码。Roboschool基于Bullet物理引擎，这是一套开源许可物理库，并被其它多种仿真软件——例如Gazebo与Virtual Robot Experimentation Platform（简称V-REP）所广泛使用。其中包含多种强化学习算法，具体以怨报德 异步深度强化学习方法、Actor-Critic with Experience Replay、Actor- Critic using Kronecker-Factored Trust Region、深度确定性策略梯度、近端策略优化以及信任域策略优化等等。 Coach：英特尔公司的开源强化学习框架，可以对游戏、机器人以及其它基于代理的智能应用进行智能代理的建模、训练与评估。Coach 提供一套模块化沙箱、可复用组件以及用于组合新强化学习算法并在多种应用领域内训练新智能应用的Python API。该框架利用OpenAI Gym作为主工具，负责与不同强化学习环境进行交换。其还支持其它外部扩展，具体包括Roboschool、gym-extensions、PyBullet以及ViZDoom。Coach的环境打包器允许用户向其中添加自定义强化学习环境，从而解决其它学习问题。该框架能够在桌面计算机上高效训练强化学习代理，并利用多核CPU处理相关任务。其能够为一部分强化学习算法提供单线程与多线程实现能力，包括异步优势Actor-Critic、深度确定性策略梯度、近端策略优化、直接未来预测以及规范化优势函数。所有算法皆利用面向英特尔系统作出优化的TensorFLow完成，其中部分算法亦适用于英特尔的Neon深度学习框架。Coach 当中包含多种强化学习代理实现方案，具体包括从单线程实现到多线程实现的转换。其能够开发出支持单与多工作程序（同步或异步）强化学习实现方法的新代理。此外，其还支持连续与离散操作空间，以及视觉观察空间或仅包含原始测量指标的观察空间。 10.10 深度强化学习算法小结基于值函数概念的DQN及其相应的扩展算法在离散状态、离散动作的控制任务中已经表现了卓越的性能, 但是受限于值函数离散型输出的影响, 在连续型控制任务上显得捉襟见肘. 基于策略梯度概念的,以DDPG, TRPO等为代表的策略型深度强化学习算法则更适用于处理基于连续状态空间的连续动作的控制输出任务, 并且算法在稳定性和可靠性上具有一定的理论保证, 理论完备性较强. 采用actor-critic架构的A3C算法及其扩展算法, 相比于传统DQN算法, 这类算法的数据利用效率更高, 学习速率更快, 通用性、可扩展应用性更强, 达到的表现性能更优, 但算法的稳定性无法得到保证. 而其他的如深度迁移强化学习、分层深度强化学习、深度记忆强化学习和多智能体深度强化学习等算法都是现在的研究热点, 通过这些算法能应对更为复杂的场景问题、系统环境及控制任务, 是目前深度强化学习算法研究的前沿领域. 展望未来，人工智能开发者们需要尽可能掌握上述框架以及其中所使用的各类强化学习算法。此外，还需要强化自身对于多代理强化学习架构的理解，因为其中多种框架都大量利用前沿博弈论研究成果。最后，还需要熟悉深度强化学习知识。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像分割]]></title>
    <url>%2F2017%2F08%2F20%2F%E7%AC%AC%E4%B9%9D%E7%AB%A0_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%2F</url>
    <content type="text"><![CDATA[9.1 传统的基于CNN的分割方法缺点？&emsp;&emsp;传统的基于CNN的分割方法：为了对一个像素分类，使用该像素周围的一个图像块作为CNN的输入，用于训练与预测，这种方法主要有几个缺点：&emsp;&emsp;1）存储开销大，例如，对每个像素使用15 * 15的图像块，然后不断滑动窗口，将图像块输入到CNN中进行类别判断，因此，需要的存储空间随滑动窗口的次数和大小急剧上升；&emsp;&emsp;2）效率低下，相邻像素块基本上是重复的，针对每个像素块逐个计算卷积，这种计算有很大程度上的重复；&emsp;&emsp;3）像素块的大小限制了感受区域的大小，通常像素块的大小比整幅图像的大小小很多，只能提取一些局部特征，从而导致分类性能受到限制。&emsp;&emsp;而全卷积网络(FCN)则是从抽象的特征中恢复出每个像素所属的类别。即从图像级别的分类进一步延伸到像素级别的分类。 9.2 FCN9.2.1 FCN改变了什么?&emsp;&emsp;对于一般的分类CNN网络，如VGG和Resnet，都会在网络的最后加入一些全连接层，经过softmax后就可以获得类别概率信息。但是这个概率信息是1维的，即只能标识整个图片的类别，不能标识每个像素点的类别，所以这种全连接方法不适用于图像分割。 &emsp;&emsp;而FCN提出可以把后面几个全连接都换成卷积，这样就可以获得一张2维的feature map，后接softmax获得每个像素点的分类信息，从而解决了分割问题，如图4。 图 4 9.2.2 FCN网络结构？&emsp;&emsp;FCN对图像进行像素级的分类，从而解决了语义级别的图像分割（semantic segmentation）问题。与经典的CNN在卷积层之后使用全连接层得到固定长度的特征向量进行分类（全联接层＋softmax输出）不同，FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的feature map进行上采样, 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素分类。下图是语义分割所采用的全卷积网络(FCN)的结构示意图： 9.2.3 全卷积网络举例？&emsp;&emsp;通常CNN网络在卷积层之后会接上若干个全连接层, 将卷积层产生的特征图(feature map)映射成一个固定长度的特征向量。以AlexNet为代表的经典CNN结构适合于图像级的分类和回归任务，因为它们最后都得到整个输入图像的一个概率向量，比如AlexNet的ImageNet模型输出一个1000维的向量表示输入图像属于每一类的概率(softmax归一化)。 &emsp;&emsp;如图所示：&emsp;&emsp;（1）在CNN中, 猫的图片输入到AlexNet, 得到一个长为1000的输出向量, 表示输入图像属于每一类的概率, 其中在“tabby cat”这一类统计概率最高, 用来做分类任务。&emsp;&emsp;（2）FCN与CNN的区别在于把CNN最后的全连接层转换成卷积层，输出的是一张已经Label好的图片, 而这个图片就可以做语义分割。&emsp;&emsp;（3）CNN的强大之处在于它的多层结构能自动学习特征，并且可以学习到多个层次的特征: 较浅的卷积层感知域较小，学习到一些局部区域的特征；较深的卷积层具有较大的感知域，能够学习到更加抽象一些的特征。高层的抽象特征对物体的大小、位置和方向等敏感性更低，从而有助于识别性能的提高, 所以我们常常可以将卷积层看作是特征提取器。 9.2.4 全连接层和卷积层如何相互转化？&emsp;&emsp;两者相互转换的可能性：&emsp;&emsp;全连接层和卷积层之间唯一的不同就是卷积层中的神经元只与输入数据中的一个局部区域连接，并且在卷积列中的神经元共享参数。然而在两类层中，神经元都是计算点积，所以它们的函数形式是一样的。因此，将此两者相互转化是可能的：&emsp;&emsp;（1）对于任一个卷积层，都存在一个能实现和它一样的前向传播函数的全连接层。权重矩阵是一个巨大的矩阵，除了某些特定块，其余部分都是零。而在其中大部分块中，元素都是相等的。&emsp;&emsp;（2）任何全连接层都可以被转化为卷积层。比如VGG16中第一个全连接层是25088 4096的数据尺寸，将它转化为512 7 7 4096的数据尺寸，即一个K=4096的全连接层，输入数据体的尺寸是7 7 512，这个全连接层可以被等效地看做一个F=7, P=0, S=1, K=4096 的卷积层。换句话说，就是将滤波器的尺寸设置为和输入数据体的尺寸一致7 7, 这样输出就变为1 1 * 4096, 本质上和全连接层的输出是一样的。&emsp;&emsp;输出激活数据体深度是由卷积核的数目决定的(K=4096)。&emsp;&emsp;在两种变换中，将全连接层转化为卷积层在实际运用中更加有用。假设一个卷积神经网络的输入是227x227x3的图像，一系列的卷积层和下采样层将图像数据变为尺寸为7x7x512的激活数据体, AlexNet的处理方式为使用了两个尺寸为4096的全连接层，最后一个有1000个神经元的全连接层用于计算分类评分。我们可以将这3个全连接层中的任意一个转化为卷积层：&emsp;&emsp;（1）第一个连接区域是[7x7x512]的全连接层，令其滤波器尺寸为F=7,K=4096，这样输出数据体就为[1x1x4096]。&emsp;&emsp;（2）第二个全连接层，令其滤波器尺寸为F=1,K=4096，这样输出数据体为[1x1x4096]。&emsp;&emsp;（3）最后一个全连接层也做类似的，令其F=1,K=1000，最终输出为[1x1x1000]。 9.2.5 为什么传统CNN的输入图片是固定大小？&emsp;&emsp;对于CNN，一幅输入图片在经过卷积和pooling层时，这些层是不关心图片大小的。比如对于一个卷积层，outputsize = (inputsize - kernelsize) / stride + 1，它并不关心inputsize多大，对于一个inputsize大小的输入feature map，滑窗卷积，输出outputsize大小的feature map即可。pooling层同理。但是在进入全连接层时，feature map（假设大小为n×n）要拉成一条向量，而向量中每个元素（共n×n个）作为一个结点都要与下一个层的所有结点（假设4096个）全连接，这里的权值个数是4096×n×n，而我们知道神经网络结构一旦确定，它的权值个数都是固定的，所以这个n不能变化，n是conv5的outputsize，所以层层向回看，每个outputsize都要固定，那每个inputsize都要固定，因此输入图片大小要固定。 9.2.6 把全连接层的权重W重塑成卷积层的滤波器有什么好处？&emsp;&emsp;这样的转化可以在单个向前传播的过程中, 使得卷积网络在一张更大的输入图片上滑动，从而得到多个输出(可以理解为一个label map)。&emsp;&emsp;比如: 我们想让224×224尺寸的浮窗，以步长为32在384×384的图片上滑动，把每个经停的位置都带入卷积网络，最后得到6×6个位置的类别得分, 那么通过将全连接层转化为卷积层之后的运算过程为:&emsp;&emsp;如果224×224的输入图片经过卷积层和下采样层之后得到了[7x7x512]的数组，那么，384×384的大图片直接经过同样的卷积层和下采样层之后会得到[12x12x512]的数组, 然后再经过上面由3个全连接层转化得到的3个卷积层，最终得到[6x6x1000]的输出((12 – 7)/1 + 1 = 6), 这个结果正是浮窗在原图经停的6×6个位置的得分。&emsp;&emsp;一个确定的CNN网络结构之所以要固定输入图片大小，是因为全连接层权值数固定，而该权值数和feature map大小有关, 但是FCN在CNN的基础上把1000个结点的全连接层改为含有1000个1×1卷积核的卷积层，经过这一层，还是得到二维的feature map，同样我们也不关心这个feature map大小, 所以对于输入图片的size并没有限制。&emsp;&emsp;如下图所示，FCN将传统CNN中的全连接层转化成卷积层，对应CNN网络FCN把最后三层全连接层转换成为三层卷积层: 一个分类网络变为全卷积网络End-to-end, pixels-to pixels网络（1）全连接层转化为全卷积层 : 在传统的CNN结构中，前5层是卷积层，第6层和第7层分别是一个长度为4096的一维向量，第8层是长度为1000的一维向量，分别对应1000个不同类别的概率。FCN将这3层表示为卷积层，卷积核的大小 (通道数，宽，高) 分别为 (4096,1,1)、(4096,1,1)、(1000,1,1)。看上去数字上并没有什么差别，但是卷积跟全连接是不一样的概念和计算过程，使用的是之前CNN已经训练好的权值和偏置，但是不一样的在于权值和偏置是有自己的范围，属于自己的一个卷积核。&emsp;&emsp;（2）CNN中输入的图像大小是统一固定成227x227大小的图像，第一层pooling后为55x55，第二层pooling后图像大小为27x27，第五层pooling后的图像大小为13x13, 而FCN输入的图像是H W大小，第一层pooling后变为原图大小的1/2，第二层变为原图大小的1/4，第五层变为原图大小的1/8，第八层变为原图大小的1/16。&emsp;&emsp;（3）经过多次卷积和pooling以后，得到的图像越来越小，分辨率越来越低。其中图像到H/32 W/32的时候图片是最小的一层时，所产生图叫做heatmap热图，热图就是我们最重要的高维特征图，得到高维特征的heatmap之后就是最重要的一步也是最后的一步对原图像进行upsampling，把图像进行放大几次到原图像的大小。&emsp;&emsp;相较于使用被转化前的原始卷积神经网络对所有36个位置进行迭代计算优化模型，然后再对36个位置做预测，使用转化后的卷积神经网络进行一次前向传播计算要高效得多，因为36次计算都在共享计算资源。这一技巧在实践中经常使用，通常将一张图像尺寸变得更大，然后使用变换后的卷积神经网络来对空间上很多不同位置进行评价得到分类评分，然后在求这些分值的平均值。### 9.2.7 反卷积层理解&emsp;&emsp;Upsampling的操作可以看成是反卷积(deconvolutional)，卷积运算的参数和CNN的参数一样是在训练FCN模型的过程中通过bp算法学习得到。反卷积层也是卷积层，不关心input大小，滑窗卷积后输出output。deconv并不是真正的deconvolution（卷积的逆变换），最近比较公认的叫法应该是transposed convolution，deconv的前向传播就是conv的反向传播。&emsp;&emsp;反卷积参数: 利用卷积过程filter的转置（实际上就是水平和竖直方向上翻转filter）作为计算卷积前的特征图。&emsp;&emsp;反卷积的运算如下所示:&emsp;&emsp;蓝色是反卷积层的input，绿色是反卷积层的outputFull padding, transposed Full padding, transposed。上图中的反卷积，input是2×2, output是4×4。 Zero padding, non-unit strides, transposed。上图中的反卷积，input feature map是3×3, 转化后是5×5, output是5×5 9.2.8 跳级(skip)结构&emsp;&emsp;对CNN的结果做处理，得到了dense prediction，而作者在试验中发现，得到的分割结果比较粗糙，所以考虑加入更多前层的细节信息，也就是把倒数第几层的输出和最后的输出做一个fusion，实际上也就是加和： &emsp;&emsp;实验表明，这样的分割结果更细致更准确。在逐层fusion的过程中，做到第三行再往下，结果又会变差，所以作者做到这里就停了。 9.2.9 模型训练&emsp;&emsp;（1）用AlexNet，VGG16或者GoogleNet训练好的模型做初始化，在这个基础上做fine-tuning，全部都fine-tuning，只需在末尾加上upsampling，参数的学习还是利用CNN本身的反向传播原理。&emsp;&emsp;（2）采用whole image做训练，不进行patchwise sampling。实验证明直接用全图已经很effective and efficient。&emsp;&emsp;（3）对class score的卷积层做全零初始化。随机初始化在性能和收敛上没有优势。举例：&emsp;&emsp;FCN例子: 输入可为任意尺寸图像彩色图像；输出与输入尺寸相同，深度为：20类目标+背景=21，模型基于AlexNet。&emsp;&emsp;蓝色：卷积层。&emsp;&emsp;绿色：Max Pooling层。&emsp;&emsp;黄色: 求和运算, 使用逐数据相加，把三个不同深度的预测结果进行融合：较浅的结果更为精细，较深的结果更为鲁棒。&emsp;&emsp;灰色: 裁剪, 在融合之前，使用裁剪层统一两者大小, 最后裁剪成和输入相同尺寸输出。&emsp;&emsp;对于不同尺寸的输入图像，各层数据的尺寸（height，width）相应变化，深度（channel）不变。 &emsp;&emsp;（1）全卷积层部分进行特征提取, 提取卷积层（3个蓝色层）的输出来作为预测21个类别的特征。 &emsp;&emsp;（2）图中虚线内是反卷积层的运算, 反卷积层（3个橙色层）可以把输入数据尺寸放大。和卷积层一样，升采样的具体参数经过训练确定。 &emsp;&emsp;&emsp;&emsp;1) 以经典的AlexNet分类网络为初始化。最后两级是全连接（红色），参数弃去不用。 &emsp;&emsp;&emsp;&emsp;2) 从特征小图（）预测分割小图（），之后直接升采样为大图。 反卷积（橙色）的步长为32，这个网络称为FCN-32s&emsp;&emsp;&emsp;&emsp;3) 升采样分为两次完成（橙色×2）, 在第二次升采样前，把第4个pooling层（绿色）的预测结果（蓝色）融合进来。使用跳级结构提升精确性。第二次反卷积步长为16，这个网络称为FCN-16s&emsp;&emsp;&emsp;&emsp;4) 升采样分为三次完成（橙色×3）, 进一步融合了第3个pooling层的预测结果。第三次反卷积步长为8，记为FCN-8s 其他参数:&emsp;&emsp;minibatch：20张图片。&emsp;&emsp;learning rate：0.001。&emsp;&emsp;初始化：分类网络之外的卷积层参数初始化为0。&emsp;&emsp;反卷积参数初始化为bilinear插值。&emsp;&emsp;最后一层反卷积固定位bilinear插值不做学习。 9.2.10 FCN缺点&emsp;&emsp;（1）得到的结果还是不够精细。进行8倍上采样虽然比32倍的效果好了很多，但是上采样的结果还是比较模糊和平滑，对图像中的细节不敏感。&emsp;&emsp;（2）对各个像素进行分类，没有充分考虑像素与像素之间的关系。忽略了在通常的基于像素分类的分割方法中使用的空间规整（spatial regularization）步骤，缺乏空间一致性。 9.3 U-Net&emsp;&emsp;卷积网络被大规模应用在分类任务中，输出的结果是整个图像的类标签。然而，在许多视觉任务，尤其是生物医学图像处理领域，目标输出应该包括目标类别的位置，并且每个像素都应该有类标签。另外，在生物医学图像往往缺少训练图片。所以，Ciresan等人训练了一个卷积神经网络，用滑动窗口提供像素的周围区域（patch）作为输入来预测每个像素的类标签。这个网络有两个优点：第一，输出结果可以定位出目标类别的位置；第二，由于输入的训练数据是patches，这样就相当于进行了数据增广，解决了生物医学图像数量少的问题。&emsp;&emsp;但是，这个方法也有两个很明显缺点。&emsp;&emsp;第一，它很慢，因为这个网络必须训练每个patch，并且因为patch间的重叠有很多的冗余(冗余会造成什么影响呢？卷积核里面的W，就是提取特征的权重，两个块如果重叠的部分太多，这个权重会被同一些特征训练两次，造成资源的浪费，减慢训练时间和效率，虽然说会有一些冗余，训练集大了，准确率不就高了吗？可是你这个是相同的图片啊，重叠的东西都是相同的，举个例子，我用一张相同的图片训练20次，按照这个意思也是增大了训练集啊，可是会出现什么结果呢，很显然，会导致过拟合，也就是对你这个图片识别很准，别的图片就不一定了)。&emsp;&emsp;第二，定位准确性和获取上下文信息不可兼得。大的patches需要更多的max-pooling层这样减小了定位准确性(为什么？因为你是对以这个像素为中心的点进行分类，如果patch太大，最后经过全连接层的前一层大小肯定是不变的，如果你patch大就需要更多的pooling达到这个大小，而pooling层越多，丢失信息的信息也越多；小的patches只能看到很小的局部信息，包含的背景信息不够。&emsp;&emsp;这篇论文建立了一个更好全卷积方法。我们定义和扩展了这个方法它使用更少的训练图片但产生更精确的分割。 &emsp;&emsp;(1) 使用全卷积神经网络。(全卷积神经网络就是卷积取代了全连接层，全连接层必须固定图像大小而卷积不用，所以这个策略使得，你可以输入任意尺寸的图片，而且输出也是图片，所以这是一个端到端的网络。)&emsp;&emsp;(2) 左边的网络是收缩路径：使用卷积和maxpooling。&emsp;&emsp;(3) 右边的网络是扩张路径:使用上采样产生的特征图与左侧收缩路径对应层产生的特征图进行concatenate操作。（pooling层会丢失图像信息和降低图像分辨率且是不可逆的操作，对图像分割任务有一些影响，对图像分类任务的影响不大，为什么要做上采样？因为上采样可以补足一些图片的信息，但是信息补充的肯定不完全，所以还需要与左边的分辨率比较高的图片相连接起来（直接复制过来再裁剪到与上采样图片一样大小），这就相当于在高分辨率和更抽象特征当中做一个折衷，因为随着卷积次数增多，提取的特征也更加有效，更加抽象，上采样的图片是经历多次卷积后的图片，肯定是比较高效和抽象的图片，然后把它与左边不怎么抽象但更高分辨率的特征图片进行连接）。&emsp;&emsp;(4) 最后再经过两次反卷积操作，生成特征图，再用两个1X1的卷积做分类得到最后的两张heatmap,例如第一张表示的是第一类的得分，第二张表示第二类的得分heatmap,然后作为softmax函数的输入，算出概率比较大的softmax类，选择它作为输入给交叉熵进行反向传播训练。 下面是U-Net模型的代码实现：（贡献者：黄钦建－华南理工大学） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667def get_unet(): inputs = Input((img_rows, img_cols, 1)) conv1 = Conv2D(32, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(inputs) conv1 = Conv2D(32, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(conv1) pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) # pool1 = Dropout(0.25)(pool1) # pool1 = BatchNormalization()(pool1) conv2 = Conv2D(64, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(pool1) conv2 = Conv2D(64, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(conv2) pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) # pool2 = Dropout(0.5)(pool2) # pool2 = BatchNormalization()(pool2) conv3 = Conv2D(128, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(pool2) conv3 = Conv2D(128, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(conv3) pool3 = MaxPooling2D(pool_size=(2, 2))(conv3) # pool3 = Dropout(0.5)(pool3) # pool3 = BatchNormalization()(pool3) conv4 = Conv2D(256, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(pool3) conv4 = Conv2D(256, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(conv4) pool4 = MaxPooling2D(pool_size=(2, 2))(conv4) # pool4 = Dropout(0.5)(pool4) # pool4 = BatchNormalization()(pool4) conv5 = Conv2D(512, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(pool4) conv5 = Conv2D(512, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(conv5) up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=( 2, 2), padding=&apos;same&apos;)(conv5), conv4], axis=3) # up6 = Dropout(0.5)(up6) # up6 = BatchNormalization()(up6) conv6 = Conv2D(256, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(up6) conv6 = Conv2D(256, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(conv6) up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=( 2, 2), padding=&apos;same&apos;)(conv6), conv3], axis=3) # up7 = Dropout(0.5)(up7) # up7 = BatchNormalization()(up7) conv7 = Conv2D(128, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(up7) conv7 = Conv2D(128, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(conv7) up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=( 2, 2), padding=&apos;same&apos;)(conv7), conv2], axis=3) # up8 = Dropout(0.5)(up8) # up8 = BatchNormalization()(up8) conv8 = Conv2D(64, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(up8) conv8 = Conv2D(64, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(conv8) up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=( 2, 2), padding=&apos;same&apos;)(conv8), conv1], axis=3) # up9 = Dropout(0.5)(up9) # up9 = BatchNormalization()(up9) conv9 = Conv2D(32, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(up9) conv9 = Conv2D(32, (3, 3), activation=&apos;relu&apos;, padding=&apos;same&apos;)(conv9) # conv9 = Dropout(0.5)(conv9) conv10 = Conv2D(1, (1, 1), activation=&apos;sigmoid&apos;)(conv9) model = Model(inputs=[inputs], outputs=[conv10]) model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef]) return model 9.4 SegNet&emsp;&emsp;可训练的图像分割引擎，包含一个encoder网络，一个对应的decoder网络，衔接像素级分类层，解码网络与VGG16的13层卷积层相同。解码网络是将低分辨率的编码特征图映射到全分辨率的特征图。解码网络使用最大池化层的池化索引进行非线性上采样，上采样过程就不需要学习。上采样得到的稀疏图与可训练的滤波器卷积得到致密的特征图。&emsp;&emsp;使用池化层索引进行上采样的优势：&emsp;&emsp;1）提升边缘刻画度；&emsp;&emsp;2）减少训练的参数；&emsp;&emsp;3）这种上采样模式可以包含到任何编码-解码网络中。&emsp;&emsp;SegNet网络的结构如下图所示： &emsp;&emsp;SegNet网络结构如图1所示，Input为输入图片，Output为输出分割的图像，不同颜色代表不同的分类。语义分割的重要性就在于不仅告诉你图片中某个东西是什么，而且告知你他在图片的位置。我们可以看到是一个对称网络，由中间绿色pooling层与红色upsampling层作为分割，左边是卷积提取高维特征，并通过pooling使图片变小，SegNet作者称为Encoder，右边是反卷积（在这里反卷积与卷积没有区别）与upsampling，通过反卷积使得图像分类后特征得以重现，upsampling使图像变大，SegNet作者称为Decoder，最后通过Softmax，输出不同分类的最大值。这就是大致的SegNet过程，下面对这个过程里面使用到的方法进行介绍。&emsp;&emsp;编码网络与滤波器族卷积得到特征图，进行BN，ReLU，最大池化。最大池化是为了获得空间小位移的平移不变。最大池化和下采样损失了边缘细节，因此，在编码过程中保存边缘信息很重要。考虑到内存原因，只保存最大池化索引，如最大特征值的位置。&emsp;&emsp;SegNet解码技术如下图所示： &emsp;&emsp;解码网络使用保存的最大池化索引上采样，得到稀疏的特征图，将特征图与可训练的解码滤波器族卷积得到致密的特征图。之后进行BN。高维的特征图输入soft-max层，对每个像素进行分类，得到每个像素属于K类的概率。 图3中右边是FCN的解码技术，FCN对编码的特征图进行降维，降维后输入到解码网络，解码网络中，上采样使用反卷积实现，上采样的特征图与降维的编码图进行element-wise add得到最终的解码特征图。FCN解码模型需要存储编码特征图，在嵌入式设备中内存紧张。&emsp;&emsp;SegNet的Encoder过程中，卷积的作用是提取特征，SegNet使用的卷积为same卷积（详见卷积神经网络CNN（1）)，即卷积后不改变图片大小；在Decoder过程中，同样使用same卷积，不过卷积的作用是为upsampling变大的图像丰富信息，使得在Pooling过程丢失的信息可以通过学习在Decoder得到。SegNet中的卷积与传统CNN的卷积并没有区别。 9.5 空洞卷积(Dilated Convolutions)&emsp;&emsp;在图像分割领域，图像输入到CNN（典型的网络比如FCN[3]）中，FCN先像传统的CNN那样对图像做卷积再pooling，降低图像尺寸的同时增大感受野，但是由于图像分割预测是pixel-wise的输出，所以要将pooling后较小的图像尺寸upsampling到原始的图像尺寸进行预测（upsampling一般采用deconv反卷积操作，deconv可参见知乎答案如何理解深度学习中的deconvolution networks？），之前的pooling操作使得每个pixel预测都能看到较大感受野信息。因此图像分割FCN中有两个关键，一个是pooling减小图像尺寸增大感受野，另一个是upsampling扩大图像尺寸。在先减小再增大尺寸的过程中，肯定有一些信息损失掉了，那么能不能设计一种新的操作，不通过pooling也能有较大的感受野看到更多的信息呢？答案就是dilated conv。&emsp;&emsp;以前的CNN主要问题总结：&emsp;&emsp;（1）Up-sampling / pooling layer&emsp;&emsp;（2）内部数据结构丢失；空间层级化信息丢失。&emsp;&emsp;（3）小物体信息无法重建 (假设有四个pooling layer 则 任何小于 2^4 = 16 pixel 的物体信息将理论上无法重建。)&emsp;&emsp;举例如下： Dilated Convolution with a 3 x 3 kernel and dilation rate 2&emsp;&emsp;下面看一下dilated conv原始论文[4]中的示意图 &emsp;&emsp;(a) 图对应3x3的1-dilated conv，和普通的卷积操作一样，(b)图对应3x3的2-dilated conv，实际的卷积kernel size还是3x3，但是空洞为1，也就是对于一个7x7的图像patch，只有9个红色的点和3x3的kernel发生卷积操作，其余的点略过。也可以理解为kernel的size为7x7，但是只有图中的9个点的权重不为0，其余都为0。 可以看到虽然kernel size只有3x3，但是这个卷积的感受野已经增大到了7x7（如果考虑到这个2-dilated conv的前一层是一个1-dilated conv的话，那么每个红点就是1-dilated的卷积输出，所以感受野为3x3，所以1-dilated和2-dilated合起来就能达到7x7的conv）,(c)图是4-dilated conv操作，同理跟在两个1-dilated和2-dilated conv的后面，能达到15x15的感受野。对比传统的conv操作，3层3x3的卷积加起来，stride为1的话，只能达到(kernel-1) * layer+1=7的感受野，也就是和层数layer成线性关系，而dilated conv的感受野是指数级的增长。&emsp;&emsp;dilated的好处是不做pooling损失信息的情况下，加大了感受野，让每个卷积输出都包含较大范围的信息。在图像需要全局信息或者语音文本需要较长的sequence信息依赖的问题中，都能很好的应用dilated conv，比如图像分割、语音合成WaveNet、机器翻译ByteNet中。 9.6 RefineNet&emsp;&emsp;网络结构：&emsp;&emsp;RefineNet block的作用就是把不同resolution level的feature map进行融合。网络结构如下： &emsp;&emsp;最左边一栏就是FCN的encoder部分(文中是用的ResNet)，先把pretrained ResNet按feature map的分辨率分成四个ResNet blocks，然后向右把四个blocks分别作为4个path通过RefineNet block进行融合refine，最后得到一个refined feature map(接softmax再双线性插值输出)。注意除了RefineNet-4，所有的RefineNet block都是二输入的，用于融合不同level做refine，而单输入的RefineNet-4可以看作是先对ResNet的一个task adaptation。 &emsp;&emsp;RefineNet Block&emsp;&emsp;接下来仔细看一下RefineNet block，可以看到主要组成部分是Residual convolution unit, Multi-resolution fusion, Chained residual pooling, Output convolutions. 切记这个block作用是融合多个level的feature map输出单个level的feature map，但具体的实现应该是和输入个数、shape无关的。 &emsp;&emsp;Residual convolution unit就是普通的去除了BN的residual unit； &emsp;&emsp;Multi-resolution fusion是先对多输入的feature map都用一个卷积层进行adaptation(都化到最小的feature map的shape)，再上采样再做element-wise的相加。注意如果是像RefineNet-4那样的单输入block这一部分就直接pass了； &emsp;&emsp;Chained residual pooling中的ReLU对接下来池化的有效性很重要，还可以使模型对学习率的变化没这么敏感。这个链式结构能从很大范围区域上获取背景context。另外，这个结构中大量使用了identity mapping这样的连接，无论长距离或者短距离的，这样的结构允许梯度从一个block直接向其他任一block传播。 &emsp;&emsp;Output convolutions就是输出前再加一个RCU。 9.7 PSPNet&emsp;&emsp;场景解析对于无限制的开放词汇和不同场景来说是具有挑战性的.本文使用文中的pyramid pooling module实现基于不同区域的上下文集成，提出了PSPNet，实现利用上下文信息的能力进行场景解析。&emsp;&emsp;作者认为，FCN存在的主要问题是没有采取合适的策略来用全局的信息，本文的做法就是借鉴SPPNet来设计了PSPNet解决这个问题。&emsp;&emsp;很多State-of-the-art的场景解析框架都是基于FCN的.基于CNN的方法能够增强动态物体的理解，但是在无限制词汇和不同场景中仍然面临挑战.举个例子，如下图. &emsp;&emsp;FCN认为右侧框中是汽车，但是实际上是船，如果参考上下文的先验知识，就会发现左边是一个船屋，进而推断是框中是船.FCN存在的主要问题就是不能利用好全局的场景线索。 &emsp;&emsp;对于尤其复杂的场景理解，之前都是采用空间金字塔池化来做的，和之前方法不同（为什么不同，需要参考一下经典的金字塔算法），本文提出了pyramid scene parsing network(PSPNet)。&emsp;&emsp;本文的主要贡献如下:&emsp;&emsp;(1) 提出了PSPNet在基于FCN的框架中集成困难的上下文特征&emsp;&emsp;(2) 通过基于深度监督误差开发了针对ResNet的高效优化策略&emsp;&emsp;(3) 构建了一个用于state-of-the-art的场景解析和语义分割的实践系统（具体是什么？）&emsp;&emsp;通过观察FCN的结果，发现了如下问题：&emsp;&emsp;(1) 关系不匹配（Mismatched Relationship）&emsp;&emsp;(2) 易混淆的类别（Confusion Categories）&emsp;&emsp;(3) 不显眼的类别（Inconspicuous Classes）&emsp;&emsp;总结以上结果发现，以上问题部分或者全部与上下文关系和全局信息有关系，因此本文提出了PSPNet.框架如下: &emsp;&emsp;并且加入额外的深度监督 Loss 9.8 DeepLab系列9.8.1 DeepLabv1&emsp;&emsp;DeepLab 是结合了深度卷积神经网络（DCNNs）和概率图模型（DenseCRFs）的方法。&emsp;&emsp;在实验中发现 DCNNs 做语义分割时精准度不够的问题，根本原因是 DCNNs 的高级特征的平移不变性，即高层次特征映射，根源于重复的池化和下采样。&emsp;&emsp;针对信号下采样或池化降低分辨率，DeepLab 是采用的 atrous（带孔）算法扩展感受野，获取更多的上下文信息。&emsp;&emsp;分类器获取以对象中心的决策是需要空间变换的不变性，这天然地限制了 DCNN 的定位精度，DeepLab 采用完全连接的条件随机场（CRF）提高模型捕获细节的能力。&emsp;&emsp;除空洞卷积和 CRFs 之外，论文使用的 tricks 还有 Multi-Scale features。其实就是 U-Net 和 FPN 的思想，在输入图像和前四个最大池化层的输出上附加了两层的 MLP，第一层是 128 个 3×3 卷积，第二层是 128 个 1×1 卷积。最终输出的特征与主干网的最后一层特征图融合，特征图增加 5×128=640 个通道。&emsp;&emsp;实验表示多尺度有助于提升预测结果，但是效果不如 CRF 明显。&emsp;&emsp;论文模型基于 VGG16，在 Titan GPU 上运行速度达到了 8FPS，全连接 CRF 平均推断需要 0.5s ，在 PASCAL VOC-2012 达到 71.6% IOU accuracy。 9.8.2 DeepLabv2&emsp;&emsp;DeepLabv2 是相对于 DeepLabv1 基础上的优化。DeepLabv1 在三个方向努力解决，但是问题依然存在：特征分辨率的降低、物体存在多尺度，DCNN 的平移不变性。&emsp;&emsp;因 DCNN 连续池化和下采样造成分辨率降低，DeepLabv2 在最后几个最大池化层中去除下采样，取而代之的是使用空洞卷积，以更高的采样密度计算特征映射。&emsp;&emsp;物体存在多尺度的问题，DeepLabv1 中是用多个 MLP 结合多尺度特征解决，虽然可以提供系统的性能，但是增加特征计算量和存储空间。&emsp;&emsp;论文受到 Spatial Pyramid Pooling (SPP) 的启发，提出了一个类似的结构，在给定的输入上以不同采样率的空洞卷积并行采样，相当于以多个比例捕捉图像的上下文，称为 ASPP (atrous spatial pyramid pooling) 模块。&emsp;&emsp;DCNN 的分类不变形影响空间精度。DeepLabv2 是采样全连接的 CRF 在增强模型捕捉细节的能力。&emsp;&emsp;论文模型基于 ResNet，在 NVidia Titan X GPU 上运行速度达到了 8FPS，全连接 CRF 平均推断需要 0.5s ，在耗时方面和 DeepLabv1 无差异，但在 PASCAL VOC-2012 达到 79.7 mIOU。 9.8.3 DeepLabv3&emsp;&emsp;好的论文不止说明怎么做，还告诉为什么。DeepLab 延续到 DeepLabv3 系列，依然是在空洞卷积做文章，但是探讨不同结构的方向。&emsp;&emsp;DeepLabv3 论文比较了多种捕获多尺度信息的方式： &emsp;&emsp;1.Image Pyramid：将输入图片放缩成不同比例，分别应用在 DCNN 上，将预测结果融合得到最终输出。&emsp;&emsp;2.Encoder-Decoder：利用 Encoder 阶段的多尺度特征，运用到 Decoder 阶段上恢复空间分辨率，代表工作有 FCN、SegNet、PSPNet 等工。&emsp;&emsp;3.Deeper w. Atrous Convolution：在原始模型的顶端增加额外的模块，例如 DenseCRF，捕捉像素间长距离信息。&emsp;&emsp;4.Spatial Pyramid Pooling：空间金字塔池化具有不同采样率和多种视野的卷积核，能够以多尺度捕捉对象。&emsp;&emsp;DeepLabv1-v2 都是使用带孔卷积提取密集特征来进行语义分割。但是为了解决分割对象的多尺度问题，DeepLabv3 设计采用多比例的带孔卷积级联或并行来捕获多尺度背景。&emsp;&emsp;此外，DeepLabv3 将修改之前提出的带孔空间金字塔池化模块，该模块用于探索多尺度卷积特征，将全局背景基于图像层次进行编码获得特征，取得 state-of-art 性能，在 PASCAL VOC-2012 达到 86.9 mIOU。 9.8.4 DeepLabv3+&emsp;&emsp;语义分割关注的问题:&emsp;&emsp;1、 实例对象多尺度问题。&emsp;&emsp;2、 因为深度网络存在stride=2的层，会导致feature分辨率下降，从而导致预测精度降低，而造成的边界信息丢失问题。&emsp;&emsp;deeplab V3新设计的aspp结构解决了问题1，deeplab v3+主要目的在于解决问题2。&emsp;&emsp;问题2 可以使用空洞卷积替代更多的pooling层来获取分辨率更高的feature。但是feature分辨率更高会极大增加运算量。以deeplab v3使用的resnet101为例，stride=16将造成后面9层feature变大，后面9层的计算量变为原来的2*2=4倍大。stride=8则更为恐怖，后面78层的计算量都会变大很多。&emsp;&emsp;解决方案：1、编解码器结构；2 Modified Aligned Xception &emsp;&emsp;在deeplabv3基础上加入解码器。A是aspp结构，其中8x的上采样可以看做是一个解码器。B是编解码结构，它集合了高层和底层的特征。C就是本文采取的结构。&emsp;&emsp;方法：&emsp;&emsp;（1）Encoder-Decoder with Atrous Convolution &emsp;&emsp;编码器采用deeplabv3。&emsp;&emsp;解码器部分：先从低层级选一个feature，将低层级的feature用1 1的卷积进行通道压缩（原本为256通道，或者512通道），目的在于减少低层级的比重。作者认为编码器得到的feature具有更丰富的信息，所以编码器的feature应该有更高的比重。 这样做有利于训练。&emsp;&emsp;再将编码器的输出上采样，使其分辨率与低层级feature一致。举个例子，如果采用resnet conv2 输出的feature，则这里要 4上采样。将两种feature连接后，再进行一次3 * 3的卷积（细化作用），然后再次上采样就得到了像素级的预测。后面的实验结果表明这种结构在 stride=16 时既有很高的精度速度又很快。stride=8相对来说只获得了一点点精度的提升，但增加了很多的计算量。&emsp;&emsp;（2）Modified Aligned Xception&emsp;&emsp;Xception主要采用了deepwish seperable convolution来替换原来的卷积层。简单的说就是这种结构能在更少参数更少计算量的情况下学到同样的信息。这边则是考虑将原来的resnet-101骨架网换成xception。 &emsp;&emsp;红色部分为修改&emsp;&emsp;更多层：重复8次改为16次（基于MSRA目标检测的工作）。&emsp;&emsp;将原来简单的pool层改成了stride为2的deepwish seperable convolution。&emsp;&emsp;额外的RELU层和归一化操作添加在每个 3 × 3 depthwise convolution之后（原来只在1 * 1卷积之后） 9.9 Mask-R-CNN9.9.1 Mask-RCNN 的网络结构示意图 &emsp;&emsp;其中黑色部分为原来的Faster-RCNN，红色部分为在Faster网络上的修改：&emsp;&emsp;1）将ROI Pooling层替换成了ROIAlign；&emsp;&emsp;2）添加并列的FCN层（Mask层）；&emsp;&emsp;先来概述一下Mask-RCNN的几个特点（来自于PaperMask R-CNN的Abstract）：&emsp;&emsp;1）在边框识别的基础上添加分支网络，用于语义Mask识别；&emsp;&emsp;2）训练简单，相对于Faster仅增加一个小的Overhead，可以跑到5FPS；&emsp;&emsp;3）可以方便的扩展到其他任务，比如人的姿态估计等；&emsp;&emsp;4）不借助Trick，在每个任务上，效果优于目前所有的 single-model entries；包括 COCO 2016 的Winners。 9.9.2 RCNN行人检测框架&emsp;&emsp;来看下后面两种RCNN方法与Mask结合的示意图: &emsp;&emsp;图中灰色部分是原来的RCNN结合ResNet or FPN的网络，下面黑色部分为新添加的并联Mask层，这个图本身与上面的图也没有什么区别，旨在说明作者所提出的Mask RCNN方法的泛化适应能力：可以和多种RCNN框架结合，表现都不错。 9.9.3 Mask-RCNN 技术要点&emsp;&emsp;1.技术要点1 - 强化的基础网络&emsp;&emsp;通过ResNeXt-101+FPN用作特征提取网络，达到state-of-the-art的效果。&emsp;&emsp;2.技术要点2 - ROIAlign&emsp;&emsp;采用ROIAlign替代RoiPooling（改进池化操作）。引入了一个插值过程，先通过双线性插值到1414，再pooling到77，很大程度上解决了仅通过Pooling直接采样带来的Misalignment对齐问题。&emsp;&emsp;PS： 虽然 Misalignment 在分类问题上影响并不大，但在 Pixel 级别的 Mask 上会存在较大误差。&emsp;&emsp;后面我们把结果对比贴出来（Table2 c &amp; d），能够看到 ROIAlign 带来较大的改进，可以看到，Stride 越大改进越明显。&emsp;&emsp;3.技术要点3 - Loss Function&emsp;&emsp;每个ROIAlign对应K m^2维度的输出。K对应类别个数，即输出K个mask，m对应池化分辨率（7 7）。Loss函数定义：$$Lmask(Cls_k)=Sigmoid(Cls_k)$$&emsp;&emsp;$Lmask(Cls_k) = Sigmoid (Cls_k)$，平均二值交叉熵 （average binary cross-entropy）Loss，通过逐像素的 Sigmoid 计算得到。&emsp;&emsp;Why K个mask？通过对每个 Class 对应一个Mask可以有效避免类间竞争（其他Class不贡献Loss）。 &emsp;&emsp;通过结果对比来看（Table2 b），也就是作者所说的 Decouple 解耦，要比多分类的Softmax效果好很多。&emsp;&emsp;另外，作者给出了很多实验分割效果，就不都列了，只贴一张和FCIS的对比图（FCIS出现了Overlap的问题） 9.10 CNN在基于弱监督学习的图像分割中的应用&emsp;&emsp;答案来源：CNN在基于弱监督学习的图像分割中的应用 &emsp;&emsp;最近基于深度学习的图像分割技术一般依赖于卷积神经网络CNN的训练，训练过程中需要非常大量的标记图像，即一般要求训练图像中都要有精确的分割结果。&emsp;&emsp;对于图像分割而言，要得到大量的完整标记过的图像非常困难，比如在ImageNet数据集上，有1400万张图有类别标记，有50万张图给出了bounding box,但是只有4460张图像有像素级别的分割结果。对训练图像中的每个像素做标记非常耗时，特别是对医学图像而言，完成对一个三维的CT或者MRI图像中各组织的标记过程需要数小时。&emsp;&emsp;如果学习算法能通过对一些初略标记过的数据集的学习就能完成好的分割结果，那么对训练数据的标记过程就很简单，这可以大大降低花在训练数据标记上的时间。这些初略标记可以是：&emsp;&emsp;1、只给出一张图像里面包含哪些物体，&emsp;&emsp;2、给出某个物体的边界框，&emsp;&emsp;3、对图像中的物体区域做部分像素的标记，例如画一些线条、涂鸦等（scribbles)。 9.10.1 Scribble标记&emsp;&emsp;论文地址：ScribbleSup: Scribble-Supervised Convolutional Networks for Semantic Segmentation (CVPR 2016)&emsp;&emsp;香港中文大学的Di Lin提出了一个基于Scribble标记的弱监督学习方法。Scribble是一个很方便使用的标记方法，因此被用得比较广泛。如下图，只需要画五条线就能完成对一副图像的标记工作。 &emsp;&emsp;ScribbleSup分为两步，第一步将像素的类别信息从scribbles传播到其他未标记的像素，自动完成所有的训练图像的标记工作； 第二步使用这些标记图像训练CNN。在第一步中，该方法先生成super-pxels, 然后基于graph cut的方法对所有的super-pixel进行标记。 &emsp;&emsp;Graph Cut的能量函数为： $$\sum_{i}\psi _i\left(y_i|X,S\right)+\sum_{i,j}\psi_{ij}\left(y_i,y_j,X\right)$$ &emsp;&emsp;在这个graph中，每个super-pixel是graph中的一个节点，相接壤的super-pixel之间有一条连接的边。这个能量函数中的一元项包括两种情况，一个是来自于scribble的，一个是来自CNN对该super-pixel预测的概率。整个最优化过程实际上是求graph cut能量函数和CNN参数联合最优值的过程： $$\sum_{i}\psi _i^{scr}\left(y_i|X,S\right)+\sum _i-logP\left(y_i| X,\theta\right)+\sum_{i,j}\psi _{ij}\left(y_i,y_j|X\right)$$ &emsp;&emsp;上式的最优化是通过交替求 $Y$ 和 $\theta$ 的最优值来实现的。文章中发现通过三次迭代就能得到比较好的结果。 9.10.2 图像级别标记&emsp;&emsp;论文地址：Constrained Convolutional Neural Networks for Weakly Supervised Segmentation （ICCV 2015）&emsp;&emsp;UC Berkeley的Deepak Pathak使用了一个具有图像级别标记的训练数据来做弱监督学习。训练数据中只给出图像中包含某种物体，但是没有其位置信息和所包含的像素信息。该文章的方法将image tags转化为对CNN输出的label分布的限制条件，因此称为 Constrained convolutional neural network (CCNN). &emsp;&emsp; 该方法把训练过程看作是有线性限制条件的最优化过程： $$\underset{\theta ,P}{minimize}\qquad D(P(X)||Q(X|\theta ))\subject\to\qquad A\overrightarrow{P} \geqslant \overrightarrow{b},\sum_{X}^{ }P(X)=1$$&emsp;&emsp; 其中的线性限制条件来自于训练数据上的标记，例如一幅图像中前景类别像素个数期望值的上界或者下界（物体大小）、某个类别的像素个数在某图像中为0，或者至少为1等。该目标函数可以转化为为一个loss function，然后通过SGD进行训练。 &emsp;&emsp;实验中发现单纯使用Image tags作为限制条件得到的分割结果还比较差，在PASCAL VOC 2012 test数据集上得到的mIoU为35.6%，加上物体大小的限制条件后能达到45.1%，如果再使用bounding box做限制，可以达到54%。FCN-8s可以达到62.2%，可见弱监督学习要取得好的结果还是比较难。 9.10.3 DeepLab+bounding box+image-level labels**&emsp;&emsp;论文地址：Weakly-and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation&emsp;&emsp;Google的George Papandreou 和UCLA的Liang-Chieh Chen等在DeepLab的基础上进一步研究了使用bounding box和image-level labels作为标记的训练数据。使用了期望值最大化算法（EM）来估计未标记的像素的类别和CNN的参数。 &emsp;&emsp;对于image-level标记的数据，我们可以观测到图像的像素值和图像级别的标记 ,但是不知道每个像素的标号,因此把$y$当做隐变量。使用如下的概率图模式：$$P\left ( x,y,z;\theta \right ) = P\left ( x \right )\left (\prod_{m=1}^{M} P\left ( y_m|x;\theta \right )\right )P\left ( z|y \right )$$&emsp;&emsp;这篇论文是通过EM算法来学习模型的参数$\theta$，具体推导过程可参考原论文。 &emsp;&emsp;对于给出bounding box标记的训练图像，该方法先使用CRF对该训练图像做自动分割，然后在分割的基础上做全监督学习。通过实验发现，单纯使用图像级别的标记得到的分割效果较差，但是使用bounding box的训练数据可以得到较好的结果，在VOC2012 test数据集上得到mIoU 62.2%。另外如果使用少量的全标记图像和大量的弱标记图像进行结合，可以得到与全监督学习(70.3%)接近的分割结果(69.0%)。 9.10.4 统一的框架&emsp;&emsp;论文地址：Learning to Segment Under Various Forms of Weak Supervision (CVPR 2015) &emsp;&emsp;Wisconsin-Madison大学的Jia Xu提出了一个统一的框架来处理各种不同类型的弱标记：图像级别的标记、bounding box和部分像素标记如scribbles。该方法把所有的训练图像分成共计$n$个super-pixel，对每个super-pixel提取一个$d$维特征向量。因为不知道每个super-pixel所属的类别，相当于无监督学习，因此该方法对所有的super-pixel做聚类，使用的是最大间隔聚类方法(max-margin clustering, MMC),该过程的最优化目标函数是： $$\underset{W,H}{min} \qquad \frac{1}{2}tr\left ( W^TW \right ) + \lambda\sum_{p=1}^{n}\sum_{c=1}^{C}\xi \left ( w_c;x_p;h_p^c \right)$$ &emsp;&emsp;在这个目标函数的基础上，根据不同的弱标记方式，可以给出不同的限制条件，因此该方法就是在相应的限制条件下求最大间隔聚类。 &emsp;&emsp;该方法在Siftflow数据集上得到了比较好的结果，比state-of-the-art的结果提高了10%以上。 &emsp;&emsp;小结：在弱标记的数据集上训练图像分割算法可以减少对大量全标记数据的依赖，在大多数应用中会更加贴合实际情况。弱标记可以是图像级别的标记、边框和部分像素的标记等。训练的方法一般看做是限制条件下的最优化方法。另外EM算法可以用于CNN参数和像素类别的联合求优。 9.11 DenseNet（贡献者：黄钦建－华南理工大学）&emsp;&emsp;这篇论文是CVPR2017年的最佳论文。 &emsp;&emsp;卷积神经网络结构的设计主要朝着两个方向发展，一个是更宽的网络（代表：GoogleNet、VGG），一个是更深的网络（代表：ResNet）。但是随着层数的加深会出现一个问题——梯度消失，这将会导致网络停止训练。到目前为止解决这个问题的思路基本都是在前后层之间加一个identity connections(short path)。 &emsp;&emsp;由上图中可知Resnet是做值的相加（也就是add操作），通道数是不变的。而DenseNet是做通道的合并（也就是Concatenation操作），就像Inception那样。从这两个公式就可以看出这两个网络的本质不同。此外DensetNet的前面一层输出也是后面所有层的输入，这也不同于ResNet残差网络。 &emsp;&emsp;DenseNet的Block结构如上图所示。 &emsp;&emsp;1*1卷积核的目的：减少输入的特征图数量，这样既能降维减少计算量，又能融合各个通道的特征。我们将使用BottleNeck Layers的DenseNet表示为DenseNet-B。(在论文的实验里，将1×1×n小卷积里的n设置为4k，k为每个H产生的特征图数量) &emsp;&emsp;上图是DenseNet网络的整体网络结构示意图。其中1*1卷积核的目的是进一步压缩参数，并且在Transition Layer层有个参数Reduction（范围是0到1），表示将这些输出缩小到原来的多少倍，默认是0.5，这样传给下一个Dense Block的时候channel数量就会减少一半。当Reduction的值小于1的时候，我们就把带有这种层的网络称为DenseNet-C。 &emsp;&emsp;DenseNet网络的优点包括： 减轻了梯度消失 加强了feature的传递 更有效地利用了feature 一定程度上较少了参数数量 一定程度上减轻了过拟合]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目标检测]]></title>
    <url>%2F2017%2F07%2F20%2F%E7%AC%AC%E5%85%AB%E7%AB%A0_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[目录 8.1 基本概念 8.1.1 什么是目标检测？ 8.1.2 目标检测要解决的核心问题 8.1.2 目标检测算法 8.2 Two Stage目标检测算法 8.2.1 R-CNN 8.2.2 Fast R-CNN 8.2.3 Faster R-CNN 8.2.4 R-FCN 8.2.5 FPN 8.2.6 Mask R-CNN 8.2.7 RefineDet 8.2.8 Cascade R-CNN 8.3 One Stage目标检测算法 8.3.1 SSD 8.3.2 DSSD 8.3.3 FSSD 8.3.4 YOLOv1 8.3.5 YOLOv2 8.3.6 YOLO9000 8.3.7 YOLOv3 8.3.8 RetinaNet 8.3.9 RFBNet 8.3.10 M2Det Reference 8.1 基本概念8.1.1 什么是目标检测？目标检测（Object Detection）的任务是找出图像中所有感兴趣的目标（物体），确定它们的类别和位置，是计算机视觉领域的核心问题之一。由于各类物体有不同的外观，形状，姿态，加上成像时光照，遮挡等因素的干扰，目标检测一直是计算机视觉领域最具有挑战性的问题。 计算机视觉中关于图像识别有四大类任务： 分类-Classification：解决“是什么？”的问题，即给定一张图片或一段视频判断里面包含什么类别的目标。 定位-Location：解决“在哪里？”的问题，即定位出这个目标的的位置。 检测-Detection：解决“是什么？在哪里？”的问题，即定位出这个目标的的位置并且知道目标物是什么。 分割-Segmentation：分为实例的分割（Instance-level）和场景分割（Scene-level），解决“每一个像素属于哪个目标物或场景”的问题。 8.1.2 目标检测要解决的核心问题？除了图像分类之外，目标检测要解决的核心问题是： 1.目标可能出现在图像的任何位置。 2.目标有各种不同的大小。 3.目标可能有各种不同的形状。 如果用矩形框来定义目标，则矩形有不同的宽高比。由于目标的宽高比不同，因此采用经典的滑动窗口+图像缩放的方案解决通用目标检测问题的成本太高。 8.1.2 目标检测算法分类？基于深度学习的目标检测算法主要分为两类： 1.Two stage目标检测算法 先进行区域生成（region proposal，RP）（一个有可能包含待检物体的预选框），再通过卷积神经网络进行样本分类。 任务：特征提取—&gt;生成RP—&gt;分类/定位回归。 常见的two stage目标检测算法有：R-CNN、SPP-Net、Fast R-CNN、Faster R-CNN和R-FCN等。 2.One stage目标检测算法 不用RP，直接在网络中提取特征来预测物体分类和位置。 任务：特征提取—&gt;分类/定位回归。 常见的one stage目标检测算法有：OverFeat、YOLOv1、YOLOv2、YOLOv3、SSD和RetinaNet等。 8.2 Two Stage目标检测算法8.2.1 R-CNN标题：《Rich feature hierarchies for accurate object detection and semantic segmentation》 时间：2014 出版源：CVPR 2014 主要链接： arXiv：http://arxiv.org/abs/1311.2524 github(caffe)：https://github.com/rbgirshick/rcnn R-CNN 创新点 使用CNN（ConvNet）对 region proposals 计算 feature vectors。从经验驱动特征（SIFT、HOG）到数据驱动特征（CNN feature map），提高特征对样本的表示能力。 采用大样本下（ILSVRC）有监督预训练和小样本（PASCAL）微调（fine-tuning）的方法解决小样本难以训练甚至过拟合等问题。 注：ILSVRC其实就是众所周知的ImageNet的挑战赛，数据量极大；PASCAL数据集（包含目标检测和图像分割等），相对较小。 R-CNN 介绍 R-CNN作为R-CNN系列的第一代算法，其实没有过多的使用“深度学习”思想，而是将“深度学习”和传统的“计算机视觉”的知识相结合。比如R-CNN pipeline中的第二步和第四步其实就属于传统的“计算机视觉”技术。使用selective search提取region proposals，使用SVM实现分类。 原论文中R-CNN pipeline只有4个步骤，光看上图无法深刻理解R-CNN处理机制，下面结合图示补充相应文字 预训练模型。选择一个预训练 （pre-trained）神经网络（如AlexNet、VGG）。 重新训练全连接层。使用需要检测的目标重新训练（re-train）最后全连接层（connected layer）。 提取 proposals并计算CNN 特征。利用选择性搜索（Selective Search）算法提取所有proposals（大约2000幅images），调整（resize/warp）它们成固定大小，以满足 CNN输入要求（因为全连接层的限制），然后将feature map 保存到本地磁盘。 训练SVM。利用feature map 训练SVM来对目标和背景进行分类（每个类一个二进制SVM） 边界框回归（Bounding boxes Regression）。训练将输出一些校正因子的线性回归分类器 R-CNN 实验结果 R-CNN在VOC 2007测试集上mAP达到58.5%，打败当时所有的目标检测算法。 参考 Amusi-R-CNN论文笔记 8.2.2 Fast R-CNN标题：《Fast R-CNN》 时间：2015 出版源：ICCV 2015 主要链接： arXiv：https://arxiv.org/abs/1504.08083 github(Official)：https://github.com/rbgirshick/fast-rcnn Fast R-CNN 创新点 只对整幅图像进行一次特征提取，避免R-CNN中的冗余特征提取 用RoI pooling层替换最后一层的max pooling层，同时引入建议框数据，提取相应建议框特征 Fast R-CNN网络末尾采用并行的不同的全连接层，可同时输出分类结果和窗口回归结果，实现了end-to-end的多任务训练【建议框提取除外】，也不需要额外的特征存储空间【R-CNN中的特征需要保持到本地，来供SVM和Bounding-box regression进行训练】 采用SVD对Fast R-CNN网络末尾并行的全连接层进行分解，减少计算复杂度，加快检测速度。 Fast R-CNN 介绍 Fast R-CNN是基于R-CNN和SPPnets进行的改进。SPPnets，其创新点在于计算整幅图像的the shared feature map，然后根据object proposal在shared feature map上映射到对应的feature vector（就是不用重复计算feature map了）。当然，SPPnets也有缺点：和R-CNN一样，训练是多阶段（multiple-stage pipeline）的，速度还是不够”快”，特征还要保存到本地磁盘中。 将候选区域直接应用于特征图，并使用ROI池化将其转化为固定大小的特征图块。以下是Fast R-CNN的流程图 RoI Pooling层详解 因为Fast R-CNN使用全连接层，所以应用RoI Pooling将不同大小的ROI转换为固定大小。 RoI Pooling 是Pooling层的一种，而且是针对RoI的Pooling，其特点是输入特征图尺寸不固定，但是输出特征图尺寸固定（如7x7）。 什么是RoI呢？ RoI是Region of Interest的简写，一般是指图像上的区域框，但这里指的是由Selective Search提取的候选框。 往往经过rpn后输出的不止一个矩形框，所以这里我们是对多个RoI进行Pooling。 RoI Pooling的输入 输入有两部分组成： 特征图（feature map）：指的是上面所示的特征图，在Fast RCNN中，它位于RoI Pooling之前，在Faster RCNN中，它是与RPN共享那个特征图，通常我们常常称之为“share_conv”； RoIs，其表示所有RoI的N*5的矩阵。其中N表示RoI的数量，第一列表示图像index，其余四列表示其余的左上角和右下角坐标。 在Fast RCNN中，指的是Selective Search的输出；在Faster RCNN中指的是RPN的输出，一堆矩形候选框，形状为1x5x1x1（4个坐标+索引index），其中值得注意的是：坐标的参考系不是针对feature map这张图的，而是针对原图的（神经网络最开始的输入）。其实关于ROI的坐标理解一直很混乱，到底是根据谁的坐标来。其实很好理解，我们已知原图的大小和由Selective Search算法提取的候选框坐标，那么根据”映射关系”可以得出特征图（featurwe map）的大小和候选框在feature map上的映射坐标。至于如何计算，其实就是比值问题，下面会介绍。所以这里把ROI理解为原图上各个候选框（region proposals），也是可以的。 注：说句题外话，由Selective Search算法提取的一系列可能含有object的boudning box，这些通常称为region proposals或者region of interest（ROI）。 RoI的具体操作 根据输入image，将ROI映射到feature map对应位置 注：映射规则比较简单，就是把各个坐标除以“输入图片与feature map的大小的比值”，得到了feature map上的box坐标 将映射后的区域划分为相同大小的sections（sections数量与输出的维度相同） 对每个sections进行max pooling操作 这样我们就可以从不同大小的方框得到固定大小的相应 的feature maps。值得一提的是，输出的feature maps的大小不取决于ROI和卷积feature maps大小。ROI pooling 最大的好处就在于极大地提高了处理速度。 RoI Pooling的输出 输出是batch个vector，其中batch的值等于RoI的个数，vector的大小为channel w h；RoI Pooling的过程就是将一个个大小不同的box矩形框，都映射成大小固定（w * h）的矩形框。 RoI Pooling示例 参考 Amusi-Fast R-CNN论文笔记 8.2.3 Faster R-CNN标题：《Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks》 时间：2015 出版源：NIPS 2015 主要链接： arXiv：http://arxiv.org/abs/1506.01497 github(official, Matlab)：https://github.com/ShaoqingRen/faster_rcnn github(official, Caffe)：https://github.com/rbgirshick/py-faster-rcnn Fast R-CNN依赖于外部候选区域方法，如选择性搜索。但这些算法在CPU上运行且速度很慢。在测试中，Fast R-CNN需要2.3秒来进行预测，其中2秒用于生成2000个ROI。Faster R-CNN采用与Fast R-CNN相同的设计，只是它用内部深层网络代替了候选区域方法。新的候选区域网络（RPN）在生成ROI时效率更高，并且以每幅图像10毫秒的速度运行。 图8.1.13 Faster R-CNN的流程图 Faster R-CNN的流程图与Fast R-CNN相同，采用外部候选区域方法代替了内部深层网络。 图8.1.14 候选区域网络 候选区域网络（RPN）将第一个卷积网络的输出特征图作为输入。它在特征图上滑动一个3×3的卷积核，以使用卷积网络（如下所示的ZF网络）构建与类别无关的候选区域。其他深度网络（如VGG或ResNet）可用于更全面的特征提取，但这需要以速度为代价。ZF网络最后会输出256个值，它们将馈送到两个独立的全连接层，以预测边界框和两个objectness分数，这两个objectness分数度量了边界框是否包含目标。我们其实可以使用回归器计算单个objectness分数，但为简洁起见，Faster R-CNN使用只有两个类别的分类器：即带有目标的类别和不带有目标的类别。 图8.1.15 对于特征图中的每一个位置，RPN会做k次预测。因此，RPN将输出4×k个坐标和每个位置上2×k个得分。下图展示了8×8的特征图，且有一个3×3的卷积核执行运算，它最后输出8×8×3个ROI（其中k=3）。下图（右）展示了单个位置的3个候选区域。 图8.1.16 假设最好涵盖不同的形状和大小。因此，Faster R-CNN不会创建随机边界框。相反，它会预测一些与左上角名为锚点的参考框相关的偏移量（如x, y）。我们限制这些偏移量的值，因此我们的猜想仍然类似于锚点。 图8.1.17 要对每个位置进行k个预测，我们需要以每个位置为中心的k个锚点。每个预测与特定锚点相关联，但不同位置共享相同形状的锚点。 图8.1.18 这些锚点是精心挑选的，因此它们是多样的，且覆盖具有不同比例和宽高比的现实目标。这使得我们可以用更好的猜想来指导初始训练，并允许每个预测专门用于特定的形状。该策略使早期训练更加稳定和简便。 图8.1.19 Faster R-CNN使用更多的锚点。它部署9个锚点框：3个不同宽高比的3个不同大小的锚点框。每一个位置使用9个锚点，每个位置会生成2×9个objectness分数和4×9个坐标。 8.2.4 R-FCN标题：《R-FCN: Object Detection via Region-based Fully Convolutional Networks》 时间：2016 出版源：NIPS 2016 主要链接： arXiv：https://arxiv.org/abs/1605.06409 github(Official)：https://github.com/daijifeng001/r-fcn R-FCN 创新点 R-FCN 仍属于two-stage 目标检测算法：RPN+R-FCN Fully convolutional 位置敏感得分图（position-sentive score maps） our region-based detector is fully convolutional with almost all computation shared on the entire image. To achieve this goal, we propose position-sensitive score maps to address a dilemma between translation-invariance in image classification and translation-variance in object detection. R-FCN backbone：ResNet ResNet-101+R-FCN：83.6% in PASCAL VOC 2007 test datasets 既提高了mAP，又加快了检测速度 假设我们只有一个特征图用来检测右眼。那么我们可以使用它定位人脸吗？应该可以。因为右眼应该在人脸图像的左上角，所以我们可以利用这一点定位整个人脸。如果我们还有其他用来检测左眼、鼻子或嘴巴的特征图，那么我们可以将检测结果结合起来，更好地定位人脸。现在我们回顾一下所有问题。在Faster R-CNN中，检测器使用了多个全连接层进行预测。如果有2000个ROI，那么成本非常高。R-FCN通过减少每个ROI所需的工作量实现加速。上面基于区域的特征图与ROI是独立的，可以在每个ROI之外单独计算。剩下的工作就比较简单了，因此R-FCN的速度比Faster R-CNN快。 图8.2.1 人脸检测 现在我们来看一下5×5的特征图M，内部包含一个蓝色方块。我们将方块平均分成3×3个区域。现在，我们在M中创建了一个新的特征图，来检测方块的左上角（TL）。这个新的特征图如下图（右）所示。只有黄色的网格单元[2,2]处于激活状态。在左侧创建一个新的特征图，用于检测目标的左上角。 图8.2.2 检测示例 我们将方块分成9个部分，由此创建了9个特征图，每个用来检测对应的目标区域。这些特征图叫做位置敏感得分图（position-sensitive score map），因为每个图检测目标的子区域（计算其得分）。 图8.2.3生成9个得分图 下图中红色虚线矩形是建议的ROI。我们将其分割成3×3个区域，并询问每个区域包含目标对应部分的概率是多少。例如，左上角ROI区域包含左眼的概率。我们将结果存储成3×3 vote数组，如下图（右）所示。例如，vote_array[0][0]包含左上角区域是否包含目标对应部分的得分。 图8.2.4 将ROI应用到特征图上，输出一个3x3数组。将得分图和ROI映射到vote数组的过程叫做位置敏感ROI池化（position-sensitive ROI-pool）。该过程与前面讨论过的ROI池化非常接近。 图8.2.5 将ROI的一部分叠加到对应的得分图上，计算V[i][j]。在计算出位置敏感ROI池化的所有值后，类别得分是其所有元素得分的平均值。 图8.2.6 ROI池化 假如我们有C个类别要检测。我们将其扩展为C+1个类别，这样就为背景（非目标）增加了一个新的类别。每个类别有3×3个得分图，因此一共有(C+1)×3×3个得分图。使用每个类别的得分图可以预测出该类别的类别得分。然后我们对这些得分应用 softmax 函数，计算出每个类别的概率。以下是数据流图，在本案例中，k=3。 图8.2.7 8.2.5 FPN标题：《Feature Pyramid Networks for Object Detection》 时间：2016 出版源：CVPR 2017 主要链接： arXiv：https://arxiv.org/abs/1612.03144 [ ] TODO 8.2.6 Mask R-CNN标题：《Mask R-CNN》 时间：2017 出版源：ICCV 2017 主要链接： arXiv：https://arxiv.org/abs/1703.06870 github(Official)：https://github.com/facebookresearch/Detectron TODO 8.2.7 RefineDet标题：《Single-Shot Refinement Neural Network for Object Detection》 时间：2017 出版源：CVPR 2018 主要链接： arXiv：https://arxiv.org/abs/1711.06897 github(Official)：https://github.com/sfzhang15/RefineDet TODO 8.2.8 Cascade R-CNN标题：《Cascade R-CNN: Delving into High Quality Object Detection》 时间：2017 出版源：CVPR 2018 主要链接： arXiv：https://arxiv.org/abs/1712.00726 github(Official)：https://github.com/zhaoweicai/cascade-rcnn TODO 8.3 One Stage目标检测算法我们将对单次目标检测器（包括SSD、YOLO、YOLOv2、YOLOv3）进行综述。我们将分析FPN以理解多尺度特征图如何提高准确率，特别是小目标的检测，其在单次检测器中的检测效果通常很差。然后我们将分析Focal loss和RetinaNet，看看它们是如何解决训练过程中的类别不平衡问题的。 8.3.1 SSD标题：《SSD: Single Shot MultiBox Detector》 时间：2015 出版源：ECCV 2016 主要链接： arXiv：https://arxiv.org/abs/1512.02325 github(Official)：https://github.com/weiliu89/caffe/tree/ssd 不同于前面的RCNN系列，SSD属于one-stage方法。SSD使用 VGG16 网络作为特征提取器（和 Faster R-CNN 中使用的 CNN 一样）,将后面的全连接层替换成卷积层，并在之后添加自定义卷积层，并在最后直接采用卷积进行检测。在多个特征图上设置不同缩放比例和不同宽高比的default boxes（先验框）以融合多尺度特征图进行检测，靠前的大尺度特征图可以捕捉到小物体的信息，而靠后的小尺度特征图能捕捉到大物体的信息，从而提高检测的准确性和定位的准确性。如下图是SSD的网络结构图。 1. 怎样设置default boxes？SSD中default box的概念有点类似于Faster R-CNN中的anchor。不同于Faster R-CNN只在最后一个特征层取anchor, SSD在多个特征层上取default box，可以得到不同尺度的default box。在特征图的每个单元上取不同宽高比的default box,一般宽高比在{1,2,3,1/2,1/3}中选取，有时还会额外增加一个宽高比为1但具有特殊尺度的box。如下图所示，在8x8的feature map和4x4的feature map上的每个单元取4个不同的default box。原文对于300x300的输入，分别在conv4_3, conv7,conv8_2,conv9_2,conv10_2,conv11_2的特征图上的每个单元取4,6,6,6,4,4个default box. 由于以上特征图的大小分别是38x38,19x19,10x10,5x5,3x3,1x1，所以一共得到38x38x4+19x19x6+10x10x6+5x5x6+3x3x4+1x1x4=8732个default box.对一张300x300的图片输入网络将会针对这8732个default box预测8732个边界框。 2. 怎样对先验框进行匹配？SSD在训练的时候只需要输入图像和图像中每个目标对应的ground truth. 先验框与ground truth 的匹配遵循两个原则： （1）对图片中的每个ground truth, 在先验框中找到与其IOU最大的先验框，则该先验框对应的预测边界框与ground truth 匹配。 （2）对于（1）中每个剩下的没有与任何ground truth匹配到的先验框，找到与其IOU最大的ground truth，若其与该ground truth的IOU值大于某个阈值（一般设为0.5），则该先验框对应的预测边界框与该ground truth匹配。 按照这两个原则进行匹配，匹配到ground truth的先验框对应的预测边界框作为正样本，没有匹配到ground truth的先验框对应的预测边界框作为负样本。尽管一个ground truth可以与多个先验框匹配，但是ground truth的数量相对先验框还是很少，按照上面的原则进行匹配还是会造成负样本远多于正样本的情况。为了使正负样本尽量均衡（一般保证正负样本比例约为1：3），SSD采用hard negative mining, 即对负样本按照其预测背景类的置信度进行降序排列，选取置信度较小的top-k作为训练的负样本。 3. 怎样得到预测的检测结果？ 最后分别在所选的特征层上使用3x3卷积核预测不同default boxes所属的类别分数及其预测的边界框location。由于对于每个box需要预测该box属于每个类别的置信度（假设有c类，包括背景）和该box对应的预测边界框的location(包含4个值，即该box的中心坐标和宽高)，则每个box需要预测c+4个值。所以对于某个所选的特征层，该层的卷积核个数为（c+4）x该层的default box个数.最后将每个层得到的卷积结果进行拼接。对于得到的每个预测框，取其类别置信度的最大值，若该最大值大于置信度阈值，则最大值所对应的类别即为该预测框的类别，否则过滤掉此框。对于保留的预测框根据它对应的先验框进行解码得到其真实的位置参数（这里还需注意要防止预测框位置超出图片），然后根据所属类别置信度进行降序排列，取top-k个预测框，最后进行NMS，过滤掉重叠度较大的预测框，最后得到检测结果。 SSD优势是速度比较快，整个过程只需要一步，首先在图片不同位置按照不同尺度和宽高比进行密集抽样，然后利用CNN提取特征后直接进行分类与回归，所以速度比较快，但均匀密集采样会造成正负样本不均衡的情况使得训练比较困难，导致模型准确度有所降低。另外，SSD对小目标的检测没有大目标好，因为随着网络的加深，在高层特征图中小目标的信息丢失掉了，适当增大输入图片的尺寸可以提升小目标的检测效果。 8.3.2 DSSD标题：《DSSD : Deconvolutional Single Shot Detector》 时间：2017 出版源：CVPR 2017 主要链接： arXiv：https://arxiv.org/abs/1701.06659 github(Official)：https://github.com/chengyangfu/caffe/tree/dssd TODO 8.3.3 FSSD标题：《FSSD: Feature Fusion Single Shot Multibox Detector》 时间：2017 出版源：None 主要链接： arXiv：https://arxiv.org/abs/1712.00960 TODO 8.3.4 YOLOv1标题：《You Only Look Once: Unified, Real-Time Object Detection》 时间：2015 出版源：CVPR 2016 主要链接： arXiv：http://arxiv.org/abs/1506.02640 github(Official)：https://github.com/pjreddie/darknet YOLOv1介绍 YOLO（You Only Look Once: Unified, Real-Time Object Detection）是one-stage detection的开山之作。之前的物体检测方法首先需要产生大量可能包含待检测物体的先验框, 然后用分类器判断每个先验框对应的边界框里是否包含待检测物体，以及物体所属类别的概率或者置信度，同时需要后处理修正边界框，最后基于一些准则过滤掉置信度不高和重叠度较高的边界框，进而得到检测结果。这种基于先产生候选区再检测的方法虽然有相对较高的检测准确率，但运行速度较慢。 YOLO创造性的将物体检测任务直接当作回归问题（regression problem）来处理，将候选区和检测两个阶段合二为一。只需一眼就能知道每张图像中有哪些物体以及物体的位置。下图展示了各物体检测系统的流程图。 事实上，YOLO也并没有真正的去掉候选区，而是直接将输入图片划分成7x7=49个网格，每个网格预测两个边界框，一共预测49x2=98个边界框。可以近似理解为在输入图片上粗略的选取98个候选区，这98个候选区覆盖了图片的整个区域，进而用回归预测这98个候选框对应的边界框。 下面以问答的形式展示YOLO中的一些实现细节： 1. 网络结构是怎样的？ YOLO网络借鉴了GoogleNet分类网络结构，不同的是YOLO使用1x1卷积层和3x3卷积层替代inception module。如下图所示，整个检测网络包括24个卷积层和2个全连接层。其中，卷积层用来提取图像特征，全连接层用来预测图像位置和类别概率值。 2. YOLO的输入、输出、损失函数分别是什么？ 前面说到YOLO将输入图像分成7x7的网格，最后输出是7x7xk的张量。YOLO网络最后接了两个全连接层，全连接层要求输入是固定大小的，所以YOLO要求输入图像有固定大小，论文中作者设计的输入尺寸是448x448。 YOLO将输入图像分成7x7的网格，每个网格预测2个边界框。若某物体的ground truth的中心落在该网格，则该网格中与这个ground truth IOU最大的边界框负责预测该物体。对每个边界框会预测5个值，分别是边界框的中心x,y（相对于所属网格的边界），边界框的宽高w,h（相对于原始输入图像的宽高的比例），以及这些边界框的confidencescores（边界框与ground truth box的IOU值）。同时每个网格还需要预测c个类条件概率 （是一个c维向量，表示某个物体object在这个网格中，且该object分别属于各个类别的概率，这里的c类物体不包含背景）。论文中的c=20，则每个网格需要预测2x5+20=30个值，这些值被映射到一个30维的向量。为了让边界框坐标损失、分类损失达到很好的平衡，损失函数设计如下图所示。 如上图所示，损失函数分为坐标预测（蓝色框）、含有物体的边界框的confidence预测（红色框）、不含有物体的边界框的confidence预测（黄色框）、分类预测（紫色框）四个部分。 由于不同大小的边界框对预测偏差的敏感度不同，小的边界框对预测偏差的敏感度更大。为了均衡不同尺寸边界框对预测偏差的敏感度的差异。作者巧妙的对边界框的w,h取均值再求L2 loss. YOLO中更重视坐标预测，赋予坐标损失更大的权重，记为 coord，在pascal voc训练中coodd=5 ，classification error部分的权重取1。 某边界框的置信度定义为：某边界框的confidence = 该边界框存在某类对象的概率pr(object)*该边界框与该对象的ground truth的IOU值 ，若该边界框存在某个对象pr(object)=1 ，否则pr(object)=0 。由于一幅图中大部分网格中是没有物体的，这些网格中的边界框的confidence置为0，相比于有物体的网格，这些不包含物体的网格更多，对梯度更新的贡献更大，会导致网络不稳定。为了平衡上述问题，YOLO损失函数中对没有物体的边界框的confidence error赋予较小的权重，记为 noobj，对有物体的边界框的confidence error赋予较大的权重。在pascal VOC训练中noobj=0.5 ，有物体的边界框的confidence error的权重设为1. 3. YOLO怎样预测？ YOLO最后采用非极大值抑制（NMS）算法从输出结果中提取最有可能的对象和其对应的边界框。 输入一张图片到YOLO网络将输出一个7730的张量表示图片中每个网格对应的可能的两个边界框以及每个边界框的置信度和包含的对象属于各个类别的概率。由此可以计算某对象i属于类别 同时在第j个边界框中的得分： 每个网格有20个类条件概率，2个边界框置信度，相当于每个网格有40个得分，7x7个网格有1960个得分，每类对象有1960/20=98个得分，即98个候选框。 NMS步骤如下： 1.设置一个Score的阈值，一个IOU的阈值； 2.对于每类对象，遍历属于该类的所有候选框， ①过滤掉Score低于Score阈值的候选框； ②找到剩下的候选框中最大Score对应的候选框，添加到输出列表； ③进一步计算剩下的候选框与②中输出列表中每个候选框的IOU，若该IOU大于设置的IOU阈值，将该候选框过滤掉，否则加入输出列表中； ④最后输出列表中的候选框即为图片中该类对象预测的所有边界框 3.返回步骤2继续处理下一类对象。 YOLO将识别与定位合二为一，结构简便，检测速度快，更快的Fast YOLO可以达到155FPS。相对于RNN系列, YOLO的整个流程中都能看到整张图像的信息，因此它在检测物体时能很好的利用上下文信息，从而不容易在背景上预测出错误的物体信息。同时YOLO可以学习到高度泛化的特征，能将一个域上学到的特征迁移到不同但相关的域上，如在自然图像上做训练的YOLO，在艺术图片上可以得到较好的测试结果。 由于YOLO网格设置比较稀疏，且每个网格只预测2个边界框，其总体预测精度不高，略低于Fast RCNN。其对小物体的检测效果较差，尤其是对密集的小物体表现比较差。 8.3.5 YOLOv2标题：《YOLO9000: Better, Faster, Stronger》 时间：2016 出版源：None 主要链接： arXiv：https://arxiv.org/abs/1612.08242 github(Official)：https://pjreddie.com/darknet/yolov2/ YOLOv1虽然检测速度快，但在定位方面不够准确，并且召回率较低。为了提升定位准确度，改善召回率，YOLOv2在YOLOv1的基础上提出了几种改进策略，如下图所示，可以看到，一些改进方法能有效提高模型的mAP. YOLOv2 介绍 （1）Batch Normalization YOLOv2中在每个卷积层后加Batch Normalization(BN)层，去掉dropout. BN层可以起到一定的正则化效果，能提升模型收敛速度，防止模型过拟合。YOLOv2通过使用BN层使得mAP提高了2%。（2）High Resolution Classifier 目前的大部分检测模型都会使用主流分类网络（如vgg、resnet）在ImageNet上的预训练模型作为特征提取器,而这些分类网络大部分都是以小于256x256的图片作为输入进行训练的，低分辨率会影响模型检测能力。YOLOv2将输入图片的分辨率提升至448x448，为了使网络适应新的分辨率，YOLOv2先在ImageNet上以448x448的分辨率对网络进行10个epoch的微调，让网络适应高分辨率的输入。通过使用高分辨率的输入，YOLOv2的mAP提升了约4%。 （3）Convolutional With Anchor Boxes YOLOv1利用全连接层直接对边界框进行预测，导致丢失较多空间信息，定位不准。YOLOv2去掉了YOLOv1中的全连接层，使用Anchor Boxes预测边界框，同时为了得到更高分辨率的特征图，YOLOv2还去掉了一个池化层。由于图片中的物体都倾向于出现在图片的中心位置，若特征图恰好有一个中心位置，利用这个中心位置预测中心点落入该位置的物体，对这些物体的检测会更容易。所以总希望得到的特征图的宽高都为奇数。YOLOv2通过缩减网络，使用416x416的输入，模型下采样的总步长为32，最后得到13x13的特征图，然后对13x13的特征图的每个cell预测5个anchor boxes，对每个anchor box预测边界框的位置信息、置信度和一套分类概率值。使用anchorboxes之后，YOLOv2可以预测13x13x5=845个边界框，模型的召回率由原来的81%提升到88%，mAP由原来的69.5%降低到69.2%.召回率提升了7%，准确率下降了0.3%。 （4）Dimension Clusters 在Faster R-CNN和SSD中，先验框都是手动设定的，带有一定的主观性。YOLOv2采用k-means聚类算法对训练集中的边界框做了聚类分析，选用boxes之间的IOU值作为聚类指标。综合考虑模型复杂度和召回率，最终选择5个聚类中心，得到5个先验框，发现其中中扁长的框较少，而瘦高的框更多，更符合行人特征。通过对比实验，发现用聚类分析得到的先验框比手动选择的先验框有更高的平均IOU值，这使得模型更容易训练学习。 （5）New Network：Darknet-19 YOLOv2采用Darknet-19，其网络结构如下图所示，包括19个卷积层和5个max pooling层，主要采用3x3卷积和1x1卷积，这里1x1卷积可以压缩特征图通道数以降低模型计算量和参数，每个卷积层后使用BN层以加快模型收敛同时防止过拟合。最终采用global avg pool 做预测。采用YOLOv2，模型的mAP值没有显著提升，但计算量减少了。 （6）Direct location prediction Faster R-CNN使用anchor boxes预测边界框相对先验框的偏移量，由于没有对偏移量进行约束，每个位置预测的边界框可以落在图片任何位置，会导致模型不稳定，加长训练时间。YOLOv2沿用YOLOv1的方法，根据所在网格单元的位置来预测坐标,则Ground Truth的值介于0到1之间。网络中将得到的网络预测结果再输入sigmoid函数中，让输出结果介于0到1之间。设一个网格相对于图片左上角的偏移量是cx，cy。先验框的宽度和高度分别是pw和ph，则预测的边界框相对于特征图的中心坐标(bx，by)和宽高bw、bh的计算公式如下图所示。 YOLOv2结合Dimention Clusters, 通过对边界框的位置预测进行约束，使模型更容易稳定训练，这种方式使得模型的mAP值提升了约5%。 （7）Fine-Grained Features YOLOv2借鉴SSD使用多尺度的特征图做检测，提出pass through层将高分辨率的特征图与低分辨率的特征图联系在一起，从而实现多尺度检测。YOLOv2提取Darknet-19最后一个max pool层的输入，得到26x26x512的特征图。经过1x1x64的卷积以降低特征图的维度，得到26x26x64的特征图，然后经过pass through层的处理变成13x13x256的特征图（抽取原特征图每个2x2的局部区域组成新的channel，即原特征图大小降低4倍，channel增加4倍），再与13x13x1024大小的特征图连接，变成13x13x1280的特征图，最后在这些特征图上做预测。使用Fine-Grained Features，YOLOv2的性能提升了1%. （8）Multi-Scale Training YOLOv2中使用的Darknet-19网络结构中只有卷积层和池化层，所以其对输入图片的大小没有限制。YOLOv2采用多尺度输入的方式训练，在训练过程中每隔10个batches,重新随机选择输入图片的尺寸，由于Darknet-19下采样总步长为32，输入图片的尺寸一般选择32的倍数{320,352,…,608}。采用Multi-Scale Training, 可以适应不同大小的图片输入，当采用低分辨率的图片输入时，mAP值略有下降，但速度更快，当采用高分辨率的图片输入时，能得到较高mAP值，但速度有所下降。 YOLOv2借鉴了很多其它目标检测方法的一些技巧，如Faster R-CNN的anchor boxes, SSD中的多尺度检测。除此之外，YOLOv2在网络设计上做了很多tricks,使它能在保证速度的同时提高检测准确率，Multi-Scale Training更使得同一个模型适应不同大小的输入，从而可以在速度和精度上进行自由权衡。 YOLOv2的训练 YOLOv2的训练主要包括三个阶段。第一阶段：先在ImageNet分类数据集上预训练Darknet-19，此时模型输入为224224,共训练160个epochs。第二阶段：将网络的输入调整为448448,继续在ImageNet数据集上finetune分类模型，训练10个epochs，此时分类模型的top-1准确度为76.5%，而top-5准确度为93.3%。第三个阶段：修改Darknet-19分类模型为检测模型，并在检测数据集上继续finetune网络。网络修改包括（网路结构可视化）：移除最后一个卷积层、global avgpooling层以及softmax层，并且新增了三个332014卷积层，同时增加了一个passthrough层，最后使用1*1卷积层输出预测结果。 8.3.6 YOLO9000github：http://pjreddie.com/yolo9000/ YOLO9000是在YOLOv2的基础上提出的一种联合训练方法，可以检测超过9000个类别的模型。YOLOv2混合目标检测数据集和分类数据集，用目标检测数据集及其类别标记信息和位置标注信息训练模型学习预测目标定位和分类，用分类数据集及其类别标记信息进一步扩充模型所能识别的物体类别同时能增强模型鲁棒性。 1. YOLO9000是怎么组织数据的？ YOLO9000根据各个类别之间的从属关系建立一种树结WordTree, 将COCO数据集和ImageNet数据集组织起来。 WordTree的生成方式如下： ①首先遍历ImageNet中的类别名词。 ②对每个名词，在WordNet(一种结构化概念及概念之间关系的语言数据库)上找到从它所在位置到根节点（设根节点为实体对象physical object）的最短路径，由于在WordNet中大多数同义词只有一个路径，所以先把将该路径上的词全都加到树中。 ③迭代地检查剩下的名词，取它到根节点的最短路径，将该最短路径上的还没出现在层次树中的词加入到树中。混合后的数据集形成一个有9418类的WordTree.生成的WordTree模型如下图所示。另外考虑到COCO数据集相对于ImageNet数据集数据量太少了，为了平衡两个数据集，作者进一步对COCO数据集过采样，使COCO数据集与ImageNet数据集的数据量比例接近1：4。 对于物体的标签，采用one-hot编码的形式，数据集中的每个物体的类别标签被组织成1个长度为9418的向量，向量中除在WordTree中从该物体对应的名词到根节点的路径上出现的词对应的类别标号处为1，其余位置为0。 2. YOLO9000是怎么进行联合训练的？ YOLO9000采用YOLOv2的结构，anchorbox由原来的5调整到3，对每个anchorbox预测其对应的边界框的位置信息x,y,w,h和置信度以及所包含的物体分别属于9418类的概率，所以每个anchorbox需要预测4+1+9418=9423个值。每个网格需要预测3x9423=28269个值。在训练的过程中，当网络遇到来自检测数据集的图片时，用完整的YOLOv2loss进行反向传播计算，当网络遇到来自分类数据集的图片时，只用分类部分的loss进行反向传播。 3. YOLO9000是怎么预测的？ WordTree中每个节点的子节点都属于同一个子类，分层次的对每个子类中的节点进行一次softmax处理，以得到同义词集合中的每个词的下义词的概率。当需要预测属于某个类别的概率时，需要预测该类别节点的条件概率。即在WordTree上找到该类别名词到根节点的路径，计算路径上每个节点的概率之积。预测时，YOLOv2得到置信度，同时会给出边界框位置以及一个树状概率图，沿着根节点向下，沿着置信度最高的分支向下，直到达到某个阈值，最后到达的节点类别即为预测物体的类别。 YOLO9000使用WordTree混合目标检测数据集和分类数据集，并在其上进行联合训练，使之能实时检测出超过9000个类别的物体，其强大令人赞叹不已。YOLO9000尤其对动物的识别效果很好，但是对衣服或者设备等类别的识别效果不是很好，可能的原因是与目标检测数据集中的数据偏向有关。 8.3.7 YOLOv3标题：《YOLOv3: An Incremental Improvement》 时间：2018 出版源：None 主要链接： arXiv：https://arxiv.org/abs/1804.02767 github(Official)：https://github.com/pjreddie/darknet YOLOv3总结了自己在YOLOv2的基础上做的一些尝试性改进，有的尝试取得了成功，而有的尝试并没有提升模型性能。其中有两个值得一提的亮点，一个是使用残差模型，进一步加深了网络结构；另一个是使用FPN架构实现多尺度检测。 1. YOLOv3对网络结构做了哪些改进？ YOLOv3在之前Darknet-19的基础上引入了残差块，并进一步加深了网络，改进后的网络有53个卷积层，取名为Darknet-53，网络结构如下图所示（以256*256的输入为例）。 为了比较Darknet-53与其它网络结构的性能，作者在TitanX上，采用相同的实验设置，将256x256的图片分别输入以Darknet-19，ResNet-101，ResNet-152和Darknet-53为基础网络的分类模型中，实验得到的结果如下图所示。可以看到Darknet-53比ResNet-101的性能更好，而且速度是其1.5倍，Darknet-53与ResNet-152性能相似但速度几乎是其2倍。注意到，Darknet-53相比于其它网络结构实现了每秒最高的浮点计算量，说明其网络结构能更好的利用GPU。 2.YOLOv3中怎样实现多尺度检测？ YOLOv3借鉴了FPN的思想，从不同尺度提取特征。相比YOLOv2，YOLOv3提取最后3层特征图，不仅在每个特征图上分别独立做预测，同时通过将小特征图上采样到与大的特征图相同大小，然后与大的特征图拼接做进一步预测。用维度聚类的思想聚类出9种尺度的anchor box，将9种尺度的anchor box均匀的分配给3种尺度的特征图.如下图是在网络结构图的基础上加上多尺度特征提取部分的示意图（以在COCO数据集(80类)上256x256的输入为例）： 从YOLOv1到YOLOv2再到YOLO9000、YOLOv3, YOLO经历三代变革，在保持速度优势的同时，不断改进网络结构，同时汲取其它优秀的目标检测算法的各种trick，先后引入anchor box机制、引入FPN实现多尺度检测等。 8.3.8 RetinaNet标题：《Focal Loss for Dense Object Detection》 时间：2017 出版源：ICCV 2017（Best Student Paper Award） 主要链接： arXiv：https://arxiv.org/abs/1708.02002 github(Official)：https://github.com/facebookresearch/Detectron 研究背景 Two-Stage检测器（如Faster R-CNN、FPN）效果好，但速度相对慢 One-Stage检测器（如YOLO、SSD）速度快，但效果一般 作者对one-stage检测器准确率不高的问题进行探究，发现主要问题在于正负类别不均衡（简单-难分类别不均衡）。 We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. 作者建议通过重新设计标准的交叉熵损失（cross entropy loss）来解决这种类别不平衡（class inbalance）问题，即提出Focal Loss。 We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. 结合Focal Loss的one-stage检测器称为RetinaNet，该检测器在COCO上mAP可以和特征金字塔网络（feature pyramid network，FPN）或者Mask R-CNN接近， 问：什么是类别不均衡（class imbalance）？ 答：负样本的数量极大于正样本的数量，比如包含物体的区域（正样本）很少，而不包含物体的区域（负样本）很多。比如检测算法在早期会生成一大波的bbox。而一幅常规的图片中，顶多就那么几个object。这意味着，绝大多数的bbox属于background。 问：样本的类别不均衡会带来什么问题？ 答：由于大多数都是简单易分的负样本（属于背景的样本），使得训练过程不能充分学习到属于那些有类别样本的信息；其次简单易分的负样本太多，可能掩盖了其他有类别样本的作用（这些简单易分的负样本仍产生一定幅度的loss，见下图蓝色曲线，数量多会对loss起主要贡献作用，因此就主导了梯度的更新方向，掩盖了重要的信息） This imbalance causes two problems: (1) training is inefficient as most locations are easy negatives that contribute no useful learning signal; (2) en masse, the easy negatives can overwhelm training and lead to degenerate models. 简单来说，因为bbox数量爆炸。 正是因为bbox中属于background的bbox太多了，所以如果分类器无脑地把所有bbox统一归类为background，accuracy也可以刷得很高。于是乎，分类器的训练就失败了。分类器训练失败，检测精度自然就低了。 问：为什么在two-stage检测器中，没有出现类别不均衡（class imbalamce）问题呢？ 答：因为通过RPN阶段可以减少候选目标区域，而在分类阶段，可以固定前景与背景比值（foreground-to-background ratio）为1:3，或者使用OHEM（online hard example mining）使得前景和背景的数量达到均衡。 RetinaNet 创新点 概述： New loss：提出Focal Loss函数解决class imbalance $$FL(p_t) = -(1-p_t)^\gamma \log(p_t)FL(pt)=−(1−pt)γlog(pt)$$ New detector：RetinaNet = ResNet + FPN + Two sub-networks + Focal Loss Focal Loss更加聚焦在困难样本（hard examples）上的训练。 将Focal Loss与ResNet-101-FPN backbone结合提出RetinaNet（one-stage检测器），RetinaNet在COCO test-dev上达到39.1mAP，速度为5FPS。 RetinaNet检测器与当时最佳的其它检测器进行比较，无论是速度上还是准确率上都是最佳： 详解： 作者提出一种新的损失函数，思路是希望那些hard examples对损失的贡献变大，使网络更倾向于从这些样本上学习。 作者以二分类为例进行说明： 交叉熵函数CE 首先是我们常使用的交叉熵损失函数： 上式中，y=+1或者y=-1。p∈[0,1]是y=+1的估计概率。作者定义pt为： 注：对交叉熵函数不了解的，可以参考理解交叉熵作为损失函数在神经网络中的作用 均衡交叉熵函数 要对类别不均衡问题对loss的贡献进行一个控制，即加上一个控制权重即可，最初作者的想法即如下这样，对于属于少数类别的样本，增大α即可 但这样有一个问题，它仅仅解决了正负样本之间的平衡问题，并没有区分易分/难分样本，按作者的话说： While α balances the importance of positive/negative examples, it does not differentiate between easy/hard examples. Instead, we propose to reshape the loss function to down-weight easy examples and thus focus training on hard negatives. 问：为什么公式(3)只解决正负样本不均衡问题？ 答：增加了一个系数αt，跟pt的定义类似，当label=1的时候，αt=a；当label=-1的时候，αt=1-a，a的范围也是0到1。因此可以通过设定a的值（一般而言假如1这个类的样本数比-1这个类的样本数多很多，那么a会取0到0.5来增加-1这个类的样本的权重）来控制正负样本对总的loss的共享权重。 Focal Loss 作者一开始给交叉熵损失函数添加modulating factor：$$(1-pt)^γ(1−pt)γ$$ 显然，样本越易分，pt就越大（pt—&gt;1），modulating factor趋近于0，则贡献的loss就越小，同样地，样本越难分，其pt就越小，modulating factor接近于1，则贡献的loss不受影响。 问：为什么pt越大，FL值越小？ 答：根据公式（4）可知，FL与log(pt)中的pt成反比，与1-pt成正比，因此FL与pt的关系成反比。这是交叉熵函数的基本性质。当pt很大时（接近于1），FL值很小；而当pt很小时（接近于0），FL值会很大。 注：这里有个超参数—focusing parameter γ。 γ 放大了modulating factor的作用。 举原文中的一个例子，当pt=0.9时，带有modulating factor的focal loss是CE loss的100分之一，即进一步减小了正确分类的损失。 For instance, with γ = 2, an example classified with pt = 0.9 would have 100× lower loss compared with CE and with pt ≈ 0.968 it would have 1000× lower loss. This in turn increases the importance of correcting misclassified examples (whose loss is scaled down by at most 4× for pt ≤ .5 and γ = 2). 在实际中，作者采用如下公式，即综合了公式(3)和公式(4)的形式，这样机能调整正负样本的权重，又能控制难易分类样本的权重： 这里的两个参数 α和γ 来控制，在实验中a的选择范围也很广，一般而言当γ增加的时候，a需要减小一点，本文作者采用α=0.25，γ=2效果最好。 RetinaNet Detector RetinaNet是由backbone网络和两个特殊任务的子网络（subnet）组成（属于one-stage检测器）。Backbone用来计算feature map；第一个子网络用来object classification，第二个子网络用来bounding box regression。 Feature Pyramid Network Backbone Anchor Classification Subnet Box Regression Subnet RetinaNet结构注意内容： 训练时FPN每一级的所有example都被用于计算Focal Loss，loss值加到一起用来训练； 测试时FPN每一级只选取score最大的1000个example来做nms； 整个结构不同层的head部分(上图中的c和d部分)共享参数，但分类和回归分支间的参数不共享； 分类分支的最后一级卷积的bias初始化成前面提到的-log((1-π)/π); 作者：张磊_0503 链接：https://www.jianshu.com/p/204d9ad9507f 來源：简书 简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。 实验结果 Table1是关于RetinaNet和Focal Loss的一些实验结果。（a）是在交叉熵的基础上加上参数a，a=0.5就表示传统的交叉熵，可以看出当a=0.75的时候效果最好，AP值提升了0.9。（b）是对比不同的参数γ和a的实验结果，可以看出随着γ的增加，AP提升比较明显。（d）通过和OHEM的对比可以看出最好的Focal Loss比最好的OHEM提高了3.2AP。这里OHEM1:3表示在通过OHEM得到的minibatch上强制positive和negative样本的比例为1:3，通过对比可以看出这种强制的操作并没有提升AP。（e）加入了运算时间的对比，可以和前面的Figure2结合起来看，速度方面也有优势！注意这里RetinaNet-101-800的AP是37.8，当把训练时间扩大1.5倍同时采用scale jitter，AP可以提高到39.1，这就是全文和table2中的最高的39.1AP的由来。 8.3.9 RFBNet标题：《Receptive Field Block Net for Accurate and Fast Object Detection》 时间：2017 出版源：ECCV 2018 主要链接： arXiv：https://arxiv.org/pdf/1711.07767.pdf github(Official)：https://github.com/ruinmessi/RFBNet TODO 8.3.10 M2Det标题：《M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network》 时间：2018 出版源：AAAI 2019 主要链接： arXiv：https://arxiv.org/abs/1811.04533 github(Official)：https://github.com/qijiezhao/M2Det 8.4 人脸检测在目标检测领域可以划分为了人脸检测与通用目标检测，往往人脸这方面会有专门的算法（包括人脸检测、人脸识别、人脸其他属性的识别等等），并且和通用目标检测（识别）会有一定的差别，着主要来源于人脸的特殊性（有时候目标比较小、人脸之间特征不明显、遮挡问题等），下面将从人脸检测和通用目标检测两个方面来讲解目标检测。 8.4.1 目前主要有人脸检测方法分类？目前人脸检测方法主要包含两个区域：传统人脸检测算法和基于深度学习的人脸检测算法。传统人脸检测算法主要可以分为4类： （1）基于知识的人脸检测方法； （2）基于模型的人脸检测方法； （3）基于特征的人脸检测方法； （4）基于外观的人脸检测方法。 由于本书着重关注深度学习，下面会着重介绍基于深度学习的人脸检测方法。 2006年Hinton首次提出深度学习（Deep Learning）的概念，它是通过组合低层的特征形成更高层的抽象特征。随后研究者将深度学习应用在人脸检测领域，主要集中在基于卷积神经网络（CNN）的人脸检测研究，如基于级联卷积神经网络的人脸检测（cascade cnn）、 基于多任务卷积神经网络的人脸检测（MTCNN）、Facebox等，很大程度上提高了人脸检测的鲁棒性。当然通用目标检测算法像Faster-rcnn、yolo、ssd等也有用在人脸检测领域，也可以实现比较不错的结果，但是和专门人脸检测算法比还是有差别。下面部分主要介绍基于深度学习的的人脸检测算法，基于深度学习的通用目标检测算法将在第二大节介绍。 8.4.2 如何检测图片中不同大小的人脸？传统人脸检测算法中针对不同大小人脸主要有两个策略： （1）缩放图片的大小（图像金字塔如图8.4.1所示）； （2）缩放滑动窗的大小（如图8.4.2所示）。 图 8.1 图像金字塔 ​ 图 8.2 缩放滑动窗口 ​ 基于深度学习的人脸检测算法中针对不同大小人脸主要也有两个策略，但和传统人脸检测算法有点区别，主要包括: （1）缩放图片大小。（不过也可以通过缩放滑动窗的方式，基于深度学习的滑动窗人脸检测方式效率会很慢存在多次重复卷积，所以要采用全卷积神经网络（FCN），用FCN将不能用滑动窗的方法。） （2）通过anchor box的方法（如图8.3所示，不要和图8.2混淆，这里是通过特征图预测原图的anchorbox区域，具体在facebox中有描述）。 图 8.3 anchor box 8.4.3 如何设定算法检测最小人脸尺寸?主要是看滑动窗的最小窗口和anchorbox的最小窗口。 （1）滑动窗的方法 假设通过12×12的滑动窗，不对原图做缩放的话，就可以检测原图中12×12的最小人脸。但是往往通常给定最小人脸a=40、或者a=80，以这么大的输入训练CNN进行人脸检测不太现实，速度会很慢，并且下一次需求最小人脸a=30*30又要去重新训练，通常还会是12×12的输入，为满足最小人脸框a，只需要在检测的时候对原图进行缩放即可：w=w×12/a。 （2）anchorbox的方法 原理类似，这里主要看anchorbox的最小box，通过可以通过缩放输入图片实现最小人脸的设定。 8.4.4 如何定位人脸的位置（1）滑动窗的方式： 滑动窗的方式是基于分类器识别为人脸的框的位置确定最终的人脸， 图 8.4 滑动窗 （2）FCN的方式： ​ FCN的方式通过特征图映射到原图的方式确定最终识别为人脸的位置，特征图映射到原图人脸框是要看特征图相比较于原图有多少次缩放（缩放主要查看卷积的步长和池化层），假设特征图上(2,3)的点，可粗略计算缩放比例为8倍，原图中的点应该是(16,24)；如果训练的FCN为12*12的输入，对于原图框位置应该是(16,24,12,12),当然这只是估计位置，具体的再构建网络时要加入回归框的预测，主要是相对于原图框的一个平移与缩放。 （3）通过anchor box的方式： ​ 通过特征图映射到图的窗口，通过特征图映射到原图到多个框的方式确定最终识别为人脸的位置。 8.1.5 如何通过一个人脸的多个框确定最终人脸框位置？ 图 8.5 通过NMS得到最终的人脸位置 NMS改进版本有很多，最原始的NMS就是判断两个框的交集，如果交集大于设定的阈值，将删除其中一个框，那么两个框应该怎么选择删除哪一个呢？ 因为模型输出有概率值，一般会优选选择概率小的框删除。 8.1.6 基于级联卷积神经网络的人脸检测（Cascade CNN） cascade cnn的框架结构是什么？ 级联结构中有6个CNN，3个CNN用于人脸非人脸二分类，另外3个CNN用于人脸区域的边框校正。给定一幅图像，12-net密集扫描整幅图片，拒绝90%以上的窗口。剩余的窗口输入到12-calibration-net中调整大小和位置，以接近真实目标。接着输入到NMS中，消除高度重叠窗口。下面网络与上面类似。 cascade cnn人脸校验模块原理是什么？ 该网络用于窗口校正，使用三个偏移变量：Xn:水平平移量，Yn:垂直平移量，Sn:宽高比缩放。候选框口(x,y,w,h)中，(x,y)表示左上点坐标，(w,h)表示宽和高。 我们要将窗口的控制坐标调整为：$$（x-{x_nw}/{s_n},y-{y_nh}/{s_n},{w}/{s_n},{h}/{s_n}）$$这项工作中，我们有$N=5×3×3=45$种模式。偏移向量三个参数包括以下值：$$Sn：(0.83,0.91,1.0,1.10,1.21)$$ $$Xn：(-0.17,0,0.17)$$ $$Yn：(-0.17,0,0.17)$$ 同时对偏移向量三个参数进行校正。 3、训练样本应该如何准备？ 人脸样本： 非人脸样本： 级联的好处 级联的工作原理和好处： 最初阶段的网络可以比较简单，判别阈值可以设得宽松一点，这样就可以在保持较高召回率的同时排除掉大量的非人脸窗口； 最后阶段网络为了保证足够的性能，因此一般设计的比较复杂，但由于只需要处理前面剩下的窗口，因此可以保证足够的效率； 级联的思想可以帮助我们去组合利用性能较差的分类器，同时又可以获得一定的效率保证。 8.4.7 基于多任务卷积神经网络的人脸检测（MTCNN） 1.MTCNN模型有三个子网络。分别是P-Net,R-Net,O-Net.我想问一下，1.模型中的三个input size是指的是同一张图resize到不同尺度下喂给不同模型，还是同一张图，依次经过三个模型，然后是不同的输入尺寸？（这部分能给我讲一下吗）2.每个模型它都有对应三个结果（face classification;bounding box;facial landmark）这三个在网络上是如何对应的呢？ 为了检测不同大小的人脸，开始需要构建图像金字塔，先经过pNet模型，输出人脸类别和边界框（边界框的预测为了对特征图映射到原图的框平移和缩放得到更准确的框），将识别为人脸的框映射到原图框位置可以获取patch，之后每一个patch通过resize的方式输入到rNet，识别为人脸的框并且预测更准确的人脸框，最后rNet识别为人脸的的每一个patch通过resize的方式输入到oNet，跟rNet类似，关键点是为了在训练集有限情况下使模型更鲁棒。 还要注意一点构建图像金字塔的的缩放比例要保留，为了将边界框映射到最开始原图上的 还要注意一点：如何从featureMap映射回原图 8.4.8 Facebox （1）Rapidly Digested Convolutional Layers(RDCL) 在网络前期，使用RDCL快速的缩小feature map的大小。 主要设计原则如下： Conv1, Pool1, Conv2 和 Pool2 的stride分别是4, 2, 2 和 2。这样整个RDCL的stride就是32，可以很快把feature map的尺寸变小。 卷积(或pooling)核太大速度就慢，太小覆盖信息又不足。文章权衡之后，将Conv1, Pool1, Conv2 和 Pool2 的核大小分别设为7x7,3x3,5x5,3x3 使用CReLU来保证输出维度不变的情况下，减少卷积核数量。 （2）Multiple Scale Convolutional Layers(MSCL) 在网络后期，使用MSCL更好地检测不同尺度的人脸。 主要设计原则有： 类似于SSD，在网络的不同层进行检测； 采用Inception模块。由于Inception包含多个不同的卷积分支，因此可以进一步使得感受野多样化。 （3）Anchor densification strategy 为了anchor密度均衡，可以对密度不足的anchor以中心进行偏移加倍，如下图所示： Referencehttps://github.com/amusi/awesome-object-detection https://github.com/hoya012/deep_learning_object_detection https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[循环神经网络(RNN)]]></title>
    <url>%2F2017%2F06%2F20%2F%E7%AC%AC%E5%85%AD%E7%AB%A0_%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN%2F</url>
    <content type="text"><![CDATA[新增 https://blog.csdn.net/zhaojc1995/article/details/80572098RNN发展简述?为什么需要RNN?RNN的结构及变体标准RNN的前向输出流程?RNN的训练方法——BPTT?什么是长期依赖（Long-Term Dependencies）问题?LSTM 网络是什么?LSTM 的核心思想?如何逐步理解LSTM?常见的RNNs扩展和改进模型RNN种类?讲解CNN+RNN的各种组合方式 http://www.elecfans.com/d/775895.htmlRNN学习和实践过程中常常碰到的疑问 CNN和RNN的对比 http://www.elecfans.com/d/775895.html1、CNN卷积神经网络与RNN递归神经网络直观图2、相同点：2.1. 传统神经网络的扩展。2.2. 前向计算产生结果，反向计算模型更新。2.3. 每层神经网络横向可以多个神经元共存,纵向可以有多层神经网络连接。3、不同点3.1. CNN空间扩展，神经元与特征卷积；RNN时间扩展，神经元与多个时间输出计算3.2. RNN可以用于描述时间上连续状态的输出，有记忆功能，CNN用于静态输出3.3. CNN高级100+深度，RNN深度有限 http://blog.csdn.net/heyongluoyao8/article/details/48636251 6.1 为什么需要RNN？http://ai.51cto.com/art/201711/559441.htm神经网络可以当做是能够拟合任意函数的黑盒子，只要训练数据足够，给定特定的x，就能得到希望的y，结构图如下：将神经网络模型训练好之后，在输入层给定一个x，通过网络之后就能够在输出层得到特定的y，那么既然有了这么强大的模型，为什么还需要RNN（循环神经网络）呢？他们都只能单独的取处理一个个的输入，前一个输入和后一个输入是完全没有关系的。但是，某些任务需要能够更好的处理序列的信息，即前面的输入和后面的输入是有关系的。 比如，当我们在理解一句话意思时，孤立的理解这句话的每个词是不够的，我们需要处理这些词连接起来的整个序列； 当我们处理视频的时候，我们也不能只单独的去分析每一帧，而要分析这些帧连接起来的整个序列。 以nlp的一个最简单词性标注任务来说，将我 吃 苹果 三个单词标注词性为 我/nn 吃/v 苹果/nn。 那么这个任务的输入就是： 我 吃 苹果 （已经分词好的句子） 这个任务的输出是： 我/nn 吃/v 苹果/nn(词性标注好的句子) 对于这个任务来说，我们当然可以直接用普通的神经网络来做，给网络的训练数据格式了就是我-&gt; 我/nn 这样的多个单独的单词-&gt;词性标注好的单词。 但是很明显，一个句子中，前一个单词其实对于当前单词的词性预测是有很大影响的，比如预测苹果的时候，由于前面的吃是一个动词，那么很显然苹果作为名词的概率就会远大于动词的概率，因为动词后面接名词很常见，而动词后面接动词很少见。 所以为了解决一些这样类似的问题，能够更好的处理序列的信息，RNN就诞生了。 6.1 RNN种类？https://www.cnblogs.com/rucwxb/p/8047401.html sequence-to-sequence：输入输出都是一个序列。例如股票预测中的RNN，输入是前N天价格，输出明天的股市价格。 sequence-to-vector：输入是一个序列，输出单一向量。 vector-to-sequence：输入单一向量，输出一个序列。 4.Encoder-Decoder：输入sequence-to-vector，称作encoder，输出vector-to-sequence，称作decoder。 这是一个delay模型，经过一段延迟，即把所有输入都读取后，在decoder中获取输入并输出一个序列。这个模型在机器翻译中使用较广泛，源语言输在入放入encoder，浓缩在状态信息中，生成目标语言时，可以生成一个不长度的目标语言序列。 RNN train的时候，Loss波动很大https://www.jianshu.com/p/30b253561337由于RNN特有的memory会影响后期其他的RNN的特点，梯度时大时小，learning rate没法个性化的调整，导致RNN在train的过程中，Loss是震荡起伏的……为了解决RNN的这个问题，在train的时候，可以有个clipping的方式，当梯度大于某个临界值，直接截断，用这个临界值作为梯度的大小，防止飞出去…（居然还能这么操作，66666） 6.1 RNNs和FNNs有什么区别？ 不同于传统的前馈神经网络(FNNs)，RNNs引入了定向循环，能够处理输入之间前后关联问题。 RNNs可以记忆之前步骤的训练信息。定向循环结构如下图所示： 6.2 RNNs典型特点？ RNNs主要用于处理序列数据。对于传统神经网络模型，从输入层到隐含层再到输出层，层与层之间一般为全连接，每层之间神经元是无连接的。但是传统神经网络无法处理数据间的前后关联问题。例如，为了预测句子的下一个单词，一般需要该词之前的语义信息。这是因为一个句子中前后单词是存在语义联系的。 RNNs中当前单元的输出与之前步骤输出也有关，因此称之为循环神经网络。具体的表现形式为当前单元（cell）会对之前步骤信息进行储存并应用于当前输出的计算中。隐藏层之间的节点连接起来，隐藏层当前输出由当前时刻输入向量和之前时刻隐藏层状态共同决定。 理论上，RNNs能够对任何长度序列数据进行处理。但是在实践中，为了降低复杂度往往假设当前的状态只与之前某几个时刻状态相关，下图便是一个典型的RNNs： 输入单元(Input units)：输入集$\bigr{x_0,x_1,…,x_t,x_{t+1},…\bigr}$， 输出单元(Output units)：输出集$\bigr{y_0,y_1,…,y_t,y_{y+1},…\bigr}$， 隐藏单元(Hidden units)：输出集$\bigr{s_0,s_1,…,s_t,s_{t+1},…\bigr}$。 图中信息传递特点： 一条单向流动的信息流是从输入单元到隐藏单元。 一条单向流动的信息流从隐藏单元到输出单元。 在某些情况下，RNNs会打破后者的限制，引导信息从输出单元返回隐藏单元，这些被称为“Back Projections”。 在某些情况下，隐藏层的输入还包括上一时刻隐藏层的状态，即隐藏层内的节点可以自连也可以互连。 当前单元（cell）输出是由当前时刻输入和上一时刻隐藏层状态共同决定。 6.3 RNNs能干什么？RNNs在自然语言处理领域取得了巨大成功，如词向量表达、语句合法性检查、词性标注等。在RNNs及其变型中，目前使用最广泛最成功的模型是LSTMs(Long Short-Term Memory，长短时记忆模型)模型，该模型相比于RNNs，能够更好地对长短时依赖进行描述。 6.4 RNNs在NLP中典型应用？（1）语言模型与文本生成(Language Modeling and Generating Text) 给定一组单词序列，需要根据前面单词预测每个单词出现的可能性。语言模型能够评估某个语句正确的可能性，可能性越大，语句越正确。另一种应用便是使用生成模型预测下一个单词的出现概率，从而利用输出概率的采样生成新的文本。 （2）机器翻译(Machine Translation) 机器翻译是将一种源语言语句变成意思相同的另一种源语言语句，如将英语语句变成同样意思的中文语句。与语言模型关键的区别在于，需要将源语言语句序列输入后，才进行输出，即输出第一个单词时，便需要从完整的输入序列中进行获取。 （3）语音识别(Speech Recognition) 语音识别是指给定一段声波的声音信号，预测该声波对应的某种指定源语言语句以及计算该语句的概率值。 （4）图像描述生成 (Generating Image Descriptions) 同卷积神经网络(convolutional Neural Networks, CNNs)一样，RNNs已经在对无标图像描述自动生成中得到应用。CNNs与RNNs结合也被应用于图像描述自动生成。 6.5 RNNs训练和传统ANN训练异同点？相同点： RNNs与传统ANN都使用BP（Back Propagation）误差反向传播算法。 不同点： RNNs网络参数W,U,V是共享的，而传统神经网络各层参数间没有直接联系。 对于RNNs，在使用梯度下降算法中，每一步的输出不仅依赖当前步的网络，还依赖于之前若干步的网络状态。 6.6 常见的RNNs扩展和改进模型6.6.1 Simple RNNs(SRNs) SRNs是RNNs的一种特例，它是一个三层网络，其在隐藏层增加了上下文单元。下图中的y是隐藏层，u是上下文单元。上下文单元节点与隐藏层中节点的连接是固定的，并且权值也是固定的。上下文节点与隐藏层节点一一对应，并且值是确定的。 在每一步中，使用标准的前向反馈进行传播，然后使用学习算法进行学习。上下文每一个节点保存其连接隐藏层节点上一步输出，即保存上文，并作用于当前步对应的隐藏层节点状态，即隐藏层的输入由输入层的输出与上一步的自身状态所决定。因此SRNs能够解决标准多层感知机(MLP)无法解决的对序列数据进行预测的问题。SRNs网络结构如下图所示： 6.6.2 Bidirectional RNNsBidirectional RNNs(双向网络)将两层RNNs叠加在一起，当前时刻输出(第t步的输出)不仅仅与之前序列有关，还与之后序列有关。例如：为了预测一个语句中的缺失词语，就需要该词汇的上下文信息。Bidirectional RNNs是一个相对较简单的RNNs，是由两个RNNs上下叠加在一起组成的。输出由前向RNNs和后向RNNs共同决定。如下图所示： 6.6.3 Deep RNNsDeep RNNs与Bidirectional RNNs相似，其也是又多层RNNs叠加，因此每一步的输入有了多层网络。该网络具有更强大的表达与学习能力，但是复杂性也随之提高，同时需要更多的训练数据。Deep RNNs的结构如下图所示： 6.6.4 Echo State Networks（ESNs）ESNs(回声状态网络)虽然也是一种RNNs，但它与传统的RNNs相差较大。 ESNs具有三个特点： 它的核心结构为一个随机生成、且保持不变的储备池(Reservoir)。储备池是大规模随机生成稀疏连接(SD通常保持1%～5%，SD表示储备池中互相连接的神经元占总神经元个数N的比例)的循环结构； 从储备池到输出层的权值矩阵是唯一需要调整的部分； 简单的线性回归便能够完成网络训练； 从结构上讲，ESNs是一种特殊类型的循环神经网络，其基本思想是：使用大规模随机连接的循环网络取代经典神经网络中的中间层，从而简化网络的训练过程。因此ESNs的关键是储备池。网络中的参数包括：（1）W - 储备池中节点间连接权值矩阵；（2）Win - 输入层到储备池之间连接权值矩阵，表明储备池中的神经元之间是相互连接；（3）Wback - 输出层到储备池之间的反馈连接权值矩阵，表明储备池会有输出层来的反馈；（4）Wout - 输入层、储备池、输出层到输出层的连接权值矩阵，表明输出层不仅与储备池连接，还与输入层和自己连接。Woutbias - 输出层的偏置项。对于ESNs，关键是储备池的四个参数，如储备池内部连接权谱半径SR(SR=λmax=max{|W的特征指|}，只有SR &lt;1时，ESNs才能具有回声状态属性)、储备池规模N(即储备池中神经元的个数)、储备池输入单元尺度IS(IS为储备池的输入信号连接到储备池内部神经元之前需要相乘的一个尺度因子)、储备池稀疏程度SD(即为储备池中互相连接的神经元个数占储备池神经元总个数的比例)。对于IS，待处理任务的非线性越强，输入单元尺度越大。该原则本质就是通过输入单元尺度IS，将输入变换到神经元激活函数相应的范围(神经元激活函数的不同输入范围，其非线性程度不同)。ESNs的结构如下图所示： 6.6.5 Gated Recurrent Unit Recurrent Neural NetworksGRUs是一般的RNNs的变型版本，其主要是从以下两个方面进行改进。 序列中不同单词处（以语句为例）的数据对当前隐藏层状态的影响不同，越前面的影响越小，即每个之前状态对当前的影响进行了距离加权，距离越远，权值越小。 在产生误差error时，其可能是由之前某一个或者几个单词共同造成，所以应当对对应的单词weight进行更新。GRUs的结构如下图所示。GRUs首先根据当前输入单词向量word vector以及前一个隐藏层状态hidden state计算出update gate和reset gate。再根据reset gate、当前word vector以及前一个hidden state计算新的记忆单元内容(new memory content)。当reset gate为1的时候，new memory content忽略之前所有memory content，最终的memory是由之前的hidden state与new memory content一起决定。 6.6.6 LSTM Netwoorks LSTMs是当前一种非常流行的深度学习模型。为了解决RNNs存在的长时记忆问题，LSTMs利用了之前更多步的训练信息。 LSTMs与一般的RNNs结构本质上并没有太大区别，只是使用了不同函数控制隐藏层的状态。 在LSTMs中，基本结构被称为cell，可以把cell看作是黑盒用以保存当前输入之前Xt的隐藏层状态ht−1。 LSTMs有三种类型的门：遗忘门（forget gate）, 输入门（input gate）以及输出门（output gate）。遗忘门（forget gate）是用来决定 哪个cells的状态将被丢弃掉。输入门（input gate）决定哪些cells会被更新. 输出门（output gate）控制了结果输出. 因此当前输出依赖于cells状态以及门的过滤条件。实践证明，LSTMs可以有效地解决长序列依赖问题。LSTMs的网络结构如下图所示。 LSTMs与GRUs的区别如图所示： 从上图可以看出，二者结构十分相似，不同在于： new memory都是根据之前state及input进行计算，但是GRUs中有一个reset gate控制之前state的进入量，而在LSTMs里没有类似gate； 产生新的state的方式不同，LSTMs有两个不同的gate，分别是forget gate (f gate)和input gate(i gate)，而GRUs只有一种update gate(z gate)； LSTMs对新产生的state可以通过output gate(o gate)进行调节，而GRUs对输出无任何调节。 6.6.7 Bidirectional LSTMs 与bidirectional RNNs 类似，bidirectional LSTMs有两层LSTMs。一层处理过去的训练信息，另一层处理将来的训练信息。 在bidirectional LSTMs中，通过前向LSTMs获得前向隐藏状态，后向LSTMs获得后向隐藏状态，当前隐藏状态是前向隐藏状态与后向隐藏状态的组合。 6.6.8 Stacked LSTMs 与deep rnns 类似，stacked LSTMs 通过将多层LSTMs叠加起来得到一个更加复杂的模型。 不同于bidirectional LSTMs，stacked LSTMs只利用之前步骤的训练信息。 6.6.9 Clockwork RNNs(CW-RNNs)CW-RNNs是较新的一种RNNs模型，该模型首次发表于2014年Beijing ICML。CW-RNNs是RNNs的改良版本，其使用时钟频率来驱动。它将隐藏层分为几个块(组，Group/Module)，每一组按照自己规定的时钟频率对输入进行处理。为了降低RNNs的复杂度，CW-RNNs减少了参数数量，并且提高了网络性能，加速网络训练。CW-RNNs通过不同隐藏层模块在不同时钟频率下工作来解决长时依赖问题。将时钟时间进行离散化，不同的隐藏层组将在不同时刻进行工作。因此，所有的隐藏层组在每一步不会全部同时工作，这样便会加快网络的训练。并且，时钟周期小组的神经元不会连接到时钟周期大组的神经元，只允许周期大的神经元连接到周期小的(组与组之间的连接以及信息传递是有向的)。周期大的速度慢，周期小的速度快，因此是速度慢的神经元连速度快的神经元，反之则不成立。 CW-RNNs与SRNs网络结构类似，也包括输入层(Input)、隐藏层(Hidden)、输出层(Output)，它们之间存在前向连接，输入层到隐藏层连接，隐藏层到输出层连接。但是与SRN不同的是，隐藏层中的神经元会被划分为若干个组，设为$g$，每一组中的神经元个数相同，设为$k$，并为每一个组分配一个时钟周期$T_i\epsilon{T_1,T_2,…,T_g}$，每一组中的所有神经元都是全连接，但是组$j$到组$i$的循环连接则需要满足$T_j$大于$T_i$。如下图所示，将这些组按照时钟周期递增从左到右进行排序，即$T_1&lt;T_2&lt;…&lt;T_g$，那么连接便是从右到左。例如：隐藏层共有256个节点，分为四组，周期分别是[1,2,4,8]，那么每个隐藏层组256/4=64个节点，第一组隐藏层与隐藏层的连接矩阵为64$\times$64的矩阵，第二层的矩阵则为64$\times$128矩阵，第三组为64$\times$(3$\times$64)=64$\times$192矩阵，第四组为64$\times$(4$\times$64)=64$\times$256矩阵。这就解释了上一段中速度慢的组连接到速度快的组，反之则不成立。 CW-RNNs的网络结构如下图所示： 6.6.10 CNN-LSTMs 为了同时利用CNN以及LSTMs的优点，CNN-LSTMs被提出。在该模型中，CNN用于提取对象特征，LSTMs用于预测。CNN由于卷积特性，其能够快速而且准确地捕捉对象特征。LSTMs的优点在于能够捕捉数据间的长时依赖性。 6.7 常见疑问 从学习RNN伊始，常常说RNN结构可以解决不定长的数据，不像CNN中一般输入数据是图片，是一般是在建网络结构开始把图片resize到固定宽高，而RNN能解决不定长，这里指的是，time_steps可以不固定，而每次time，input的维度这是固定的。比如，语音特征数据或时间序列数据，一个完整的数据，时间帧数上可以不固定，但每帧的数据维度是固定的。 time_steps的不固定，在构建计算图中，就相当于是构建是动态神经网络图，因为每个数据的时间维度是不固定的，这在编程过程中，Tensorflow其实是以静态图著称，但TensorFlow中提供了tf.nn.dynamic_rnn()，达到动态图机制，，但是还是建议大家用PyTorch去搭建RNN模型，因为Pytorch原生就是动态图著称，理解上更容易。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卷积神经网络（CNN）]]></title>
    <url>%2F2017%2F04%2F25%2F%E7%AC%AC%E4%BA%94%E7%AB%A0%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%2F</url>
    <content type="text"><![CDATA[5.1 卷积神经网络的组成层在卷积神经网络中，一般包含5种类型的层： 输入层 卷积运算层 激活函数层 池化层 全连接层 输入层主要包含对原始图像进行预处理，包括白化、归一化、去均值等等。 卷积运算层主要使用滤波器，通过设定步长、深度等参数，对输入进行不同层次的特征提取。滤波器中的参数可以通过反向传播算法进行学习。 激活函数层主要是将卷积层的输出做一个非线性映射。常见的激活函数包括sigmoid,tanh,Relu等。 池化层主要是用于参数量压缩。可以减轻过拟合情况。常见的有平均池化和最大值池化，不包含需要学习的参数。 全连接层主要是指两层网络，所有神经元之间都有权重连接。常见用于网络的最后一层，用于计算类别得分。 5.2 卷积如何检测边缘信息？卷积运算是卷积神经网络最基本的组成部分。在神经网络中，以物体识别为例，特征的检测情况可大致做一下划分。前几层检测到的是一些边缘特征，中间几层检测到的是物体的局部区域，靠后的几层检测到的是完整物体。每个阶段特征的形成都是由多组滤波器来完成的。而其中的边缘检测部分是由滤波器来完成的。在传统的图像处理方法里面，有许多边缘检测算子，如canny算子。使用固定的模板来进行边缘检测。 先介绍一个概念，过滤器： 这是一个3*3的过滤器，是一个矩阵，数值如上所示。 假设我们有一个6*6的灰度图像： 把这个图像与过滤器进行卷积运算，卷积运算在此处用“*”表示。 如图深蓝色区域所示，过滤器在图像左上方3*3的范围内，逐一加权相加，得到-5。 同理，将过滤器右移进行相同操作，再下移，直到过滤器对准图像右下角最后一格。依次运算得到一个4*4的矩阵。 在了解了过滤器以及卷积运算后，让我们看看为何过滤器能检测物体边缘： 举一个最简单的例子： 这张图片如上所示，左半边全是白的，右半边全是灰的，我们仍然使用之前的过滤器，对该图片进行卷积处理： 可以看到，最终得到的结果中间是一段白色，两边为灰色，于是垂直边缘被找到了。为什么呢？因为在6*6图像中红框标出来的部分，也就是图像中的分界线所在部分，与过滤器进行卷积，结果是30。而在不是分界线的所有部分进行卷积，结果都为0. 在这个图中，白色的分界线很粗，那是因为6*6的图像尺寸过小，对于1000*1000的图像，我们会发现在最终结果中，分界线较细但很明显。 这就是检测物体垂直边缘的例子，水平边缘的话只需将过滤器旋转90度。 5.3 卷积层中的几个基本参数？在卷积层中，有一些我们常用的参数，定义如下 5.3.1 卷积核大小英文名是Kernel Size:卷积核的大小定义了卷积的感受野。二维卷积的核大小选择通常是3，即3×3。 5.3.2 卷积核的步长英文名是Stride: Stride定义了卷积核在卷积过程中的步长。虽然它的默认值通常为1，但我们可以将步长设置为2，可以实现类似于pooling的下采样功能。 5.3.3 边缘填充英文名是Padding: Padding用于填充输入图像的边界。一个(半)填充的卷积将使空间输出维度与输入相等，而如果卷积核大于1，则对于未被填充的图像，卷积后将会使图像一些边界消失。 5.3.4 输入和输出通道英文名是 Input/Output Channels 一个卷积层接受一定数量的输入通道I，并计算一个特定数量的输出通道O，这一层所需的参数可以由IOK计算，K等于卷积核中参数的数量。 5.4 卷积的网络类型分类？5.4.1 普通卷积普通卷积即如下图所示，使用一个固定大小的滤波器，对图像进行加权提特征。 5.4.2 扩张卷积扩张卷积，又称为带孔（atrous）卷积或者空洞（dilated）卷积。在使用扩张卷积时，会引入一个称作扩张率（dilation rate）的参数。该参数定义了卷积核内参数间的行（列）间隔数。例如下图所示，一个3×3的卷积核，扩张率为2，它的感受野与5×5卷积核相同，而仅使用9个参数。这样做的好处是，在参数量不变的情况下，可以获得更大的感受野。扩张卷积在实时分割领域应用非常广泛。 5.4.3 转置卷积转置卷积也就是反卷积（deconvolution）。虽然有些人经常直接叫它反卷积，但严格意义上讲是不合适的，因为它不符合一个反卷积的概念。反卷积确实存在，但它们在深度学习领域并不常见。一个实际的反卷积会恢复卷积的过程。想象一下，将一个图像放入一个卷积层中。现在把输出传递到一个黑盒子里，然后你的原始图像会再次出来。这个黑盒子就完成了一个反卷积。这是一个卷积层的数学逆过程。 一个转置的卷积在某种程度上是相似的，因为它产生的空间分辨率是跟反卷积后产生的分辨率相同。不同之处是在卷积核值上执行的实际数学操作。转置卷积层使用的是常规的卷积，但是它能够恢复其空间变换。 在这一点上，让我们来看一个具体的例子：将5×5的图像送到一个卷积层。步长设置为2，无边界填充，而卷积核是3×3。结果得到了2×2的图像。如果我们想要逆向该过程，则需要数学上的逆运算，以便从输入的每个像素值中生成9个值。然后，我们将步长设置为2来遍历输出图像。这就是一个反卷积过程。转置卷积的实现过程则不同。为了保证输出将是一个5×5的图像，在使用卷积运算时，我们需要在输入上执行一些特别的填充。而这一过程并不是逆转了卷积运算，它仅仅是重新构造了之前的空间分辨率并进行了卷积运算。这样的做法并不是数学上的逆过程，但是很适用于编码-解码器（Encoder-Decoder）架构。我们就可以把图像的上采样（upscaling）和卷积操作结合起来，而不是做两个分离的过程。 5.4.4 可分离卷积在一个可分离卷积中，我们可以将内核操作拆分成多个步骤。我们用y = conv（x，k）表示卷积，其中y是输出图像，x是输入图像，k是核大小。这一步很简单。接下来，我们假设k可以由下面这个等式计算得出：k = k1.dot（k2）。这将使它成为一个可分离的卷积，因为我们可以通过对k1和k2做2个一维卷积来取得相同的结果，而不是用k做二维卷积。 以图像处理中的Sobel算子为例。你可以通过乘以向量[1，0，-1]和[1,2,1] .T获得相同的核大小。在执行相同的操作时，你只需要6个参数，而不是9个。上面的示例显示了所谓的空间可分离卷积。即将一个二维的卷积分离成两个一维卷积的操作。在神经网络中，为了减少网络参数，加速网络运算速度。我们通常使用的是一种叫深度可分离卷积的神经网络。 5.5 图解12种不同类型的2D卷积？http://www.sohu.com/a/159591827_390227 5.6 2D卷积与3D卷积有什么区别？5.6.1 2D卷积二维卷积操作如图所示，为了更直观的说明，分别展示了单通道和多通道的操作。假定只使用了1个滤波器，即输出图像只有一个channel。其中，针对单通道，输入图像的channel为1，卷积核尺寸为 (k_h, k_w, 1)，卷积核在输入图像的空间维度上进行滑窗操作，每次滑窗和 (k_h, k_w)窗口内的值进行卷积操作，得到输出图像中的一个值。针对多通道，假定输入图像的channel为3，卷积核尺寸则为 (k_h, k_w, 3)，则每次滑窗与3个channels上的 (k_h, k_w)窗口内的所有值进行卷积操作，得到输出图像中的一个值。 5.6.2 3D卷积3D卷积操作如图所示，同样分为单通道和多通道，且假定只使用1个滤波器，即输出图像仅有一个channel。其中，针对单通道，与2D卷积不同之处在于，输入图像多了一个length维度，卷积核也多了一个k_l维度，因此3D卷积核的尺寸为（k_h, k_w, k_l)，每次滑窗与 (k_h, k_w, k_l)窗口内的值进行相关操作，得到输出3D图像中的一个值.针对多通道，则与2D卷积的操作一样，每次滑窗与3个channels上的 (k_h, k_w, k_l) 窗口内的所有值进行相关操作，得到输出3D图像中的一个值。 5.7 有哪些池化方法？在构建卷积神经网络时，经常会使用池化操作，而池化层往往在卷积层后面，通过池化操作来降低卷积层输出的特征维度，同时可以防止过拟合现象。池化操作可以降低图像维度的原因，本质上是因为图像具有一种“静态性”的属性，这个意思是说在一个图像区域有用的特征极有可能在另一个区域同样有用。因此，为了描述一个大的图像，很直观的想法就是对不同位置的特征进行聚合统计。例如，可以计算图像在固定区域上特征的平均值 (或最大值)来代表这个区域的特征。[1] 5.7.1 一般池化（General Pooling）池化操作与卷积操作不同，过程如下图。 池化操作过程如图所示，对固定区域的特征，使用某一个值来表示。最常见的池化操作有两种，分为平均池化mean pooling和最大池化max pooling 1、平均池化：计算图像区域的平均值作为该区域池化后的值。 2、最大池化：选图像区域的最大值作为该区域池化后的值。 上述的池化过程，相邻的池化窗口间没有重叠部分。 5.7.2 重叠池化（General Pooling）重叠池化即是一种相邻池化窗口之间会有重叠区域的池化技术。论文中[2]中，作者使用了重叠池化，其他的设置都不变的情况下，top-1和top-5 的错误率分别减少了0.4% 和0.3%。 5.7.3 空金字塔池化（Spatial Pyramid Pooling）空间金字塔池化可以将任意尺度的图像卷积特征转化为相同维度，这不仅可以让CNN处理任意尺度的图像，还能避免cropping和warping操作，导致一些信息的丢失。一般的卷积神经网络都需要固定输入图像大小，这是因为全连接层的输入需要固定输入维度，但在卷积操作时并没有对图像大小有限制，所以作者提出了空间金字塔池化方法，先让图像进行卷积操作，然后使用SPP方法转化成维度相同的特征，最后输入到全连接层。 根据论文作者所述，空间金字塔池化的思想来自于Spatial Pyramid Model,它是将一个pooling过程变成了多个尺度的pooling。用不同大小的池化窗口作用于卷积特征，这样就可以得到1X1,2X2,4X4的池化结果，由于conv5中共有256个滤波器，所以得到1个256维的特征，4个256个特征，以及16个256维的特征，然后把这21个256维特征链接起来输入全连接层，通过这种方式把不同大小的图像转化成相同维度的特征。 对于不同的图像，如果想要得到相同大小的pooling结果，就需要根据图像大小动态的计算池化窗口大小和步长。假设conv5输出的大小为aa，需要得到nn大小的池化结果，可以让窗口大小sizeX为[a/n]，步长为[a/n]。下图展示了以conv5输出大小是13*13为例，spp算法的各层参数。 总结来说，SPP方法其实就是一种使用多个尺度的池化方法，可以获取图像中的多尺度信息。在卷积神经网络中加入SPP后，可以让CNN处理任意大小的输入，这让模型变得更加的灵活。 5.8 1x1卷积作用？1×1的卷积主要有以下两个方面的作用： 实现信息的跨通道交互和整合。 对卷积核通道数进行降维和升维，减小参数量。 下面详细解释一下：第一点 实现信息的跨通道交互和整合对1×1卷积层的探讨最初是出现在NIN的结构，论文作者的动机是利用MLP代替传统的线性卷积核，从而提高网络的表达能力。文中从跨通道池化的角度进行解释，认为文中提出的MLP其实等价于在传统卷积核后面接cccp层，从而实现多个feature map的线性组合，实现跨通道的信息整合。而查看代码实现，cccp层即等价于1×1卷积层。第二点 对卷积核通道数进行降维和升维，减小参数量1x1卷积层能带来降维和升维的效果，在一系列的GoogLeNet中体现的最明显。对于每一个Inception模块（如下图），左图是原始模块，右图是加入1×1卷积进行降维的模块。虽然左图的卷积核都比较小，但是当输入和输出的通道数很大时，卷积核的参数量也会变的很大，而右图加入1×1卷积后可以降低输入的通道数，因此卷积核参数、运算复杂度也就大幅度下降。以GoogLeNet的3a模块为例，输入的feature map是28×28×192，3a模块中1×1卷积通道为64，3×3卷积通道为128,5×5卷积通道为32，如果是左图结构，那么卷积核参数为1×1×192×64+3×3×192×128+5×5×192×32，而右图对3×3和5×5卷积层前分别加入了通道数为96和16的1×1卷积层，这样卷积核参数就变成了1×1×192×64+（1×1×192×96+3×3×96×128）+（1×1×192×16+5×5×16×32），参数大约减少到原来的三分之一。同时在并行pooling层后面加入1×1卷积层后也可以降低输出的feature map数量，左图pooling后feature map是不变的，再加卷积层得到的feature map，会使输出的feature map扩大到416，如果每个模块都这样，网络的输出会越来越大。而右图在pooling后面加了通道数为32的1×1卷积，使得输出的feature map数降到了256。GoogLeNet利用1×1的卷积降维后，得到了更为紧凑的网络结构，虽然总共有22层，但是参数数量却只是8层AlexNet的十二分之一，当然其中也有丢掉全连接层的原因。 而非常经典的ResNet结构，同样也使用了1×1卷积，并且是在3×3卷积层的前后都使用了，不仅进行了降维，还进行了升维，使得卷积层的输入和输出的通道数都减小，参数数量进一步减少，如下图结构所示。 5.9 卷积层和池化层有什么区别？首先可以从结构上可以看出，卷积之后输出层的维度减小，深度变深。但池化层深度不变。同时池化可以把很多数据用最大值或者平均值代替。目的是降低数据量。降低训练的参数。对于输入层，当其中像素在邻域发生微小位移时，池化层的输出是不变的，从而能提升鲁棒性。而卷积则是把数据通过一个卷积核变化成特征，便于后面的分离。 1:卷积 当从一个大尺寸图像中随机选取一小块，比如说 8x8 作为样本，并且从这个小块样本中学习到了一些特征，这时我们可以把从这个 8x8 样本中学习到的特征作为探测器，应用到这个图像的任意地方中去。特别是，我们可以用从 8x8 样本中所学习到的特征跟原本的大尺寸图像作卷积，从而对这个大尺寸图像上的任一位置获得一个不同特征的激活值。 下面给出一个具体的例子：假设你已经从一个 96x96 的图像中学习到了它的一个 8x8 的样本所具有的特征，假设这是由有 100 个隐含单元的自编码完成的。为了得到卷积特征，需要对 96x96 的图像的每个 8x8 的小块图像区域都进行卷积运算。也就是说，抽取 8x8 的小块区域，并且从起始坐标开始依次标记为（1，1），（1，2），…，一直到（89，89），然后对抽取的区域逐个运行训练过的稀疏自编码来得到特征的激活值。在这个例子里，显然可以得到 100 个集合，每个集合含有 89x89 个卷积特征。 2：说下池化，其实池化很容易理解，先看图： 转自： http://blog.csdn.net/silence1214/article/details/11809947 比如上方左侧矩阵A是2020的矩阵要进行大小为1010的池化，那么左侧图中的红色就是10*10的大小，对应到右侧的矩阵，右侧每个元素的值，是左侧红色矩阵每个元素的值得和再处于红色矩阵的元素个数，也就是平均值形式的池化。 3：上面说了下卷积和池化，再说下计算中需要注意到的。在代码中使用的是彩色图，彩色图有3个通道，那么对于每一个通道来说要单独进行卷积和池化，有一个地方尤其是进行卷积的时候要注意到，隐藏层的每一个值是对应到一幅图的3个通道穿起来的，所以分3个通道进行卷积之后要加起来，正好才能对应到一个隐藏层的神经元上，也就是一个feature上去。 5.10 卷积核是否一定越大越好？首先，给出答案。不是。在AlexNet网络结构中，用到了一些非常大的卷积核，比如11×11、5×5卷积核。之前研究者的想法是，卷积核越大，receptive field（感受野）越大，因此获得的特征越好。虽说如此，但是大的卷积核会导致计算量大幅增加，不利于训练更深层的模型，而相应的计算性能也会降低。于是在VGG、Inception网络中，实验发现利用2个3×3卷积核的组合比1个5×5卷积核的效果更佳，同时参数量（3×3×2+1 VS 5×5×1+1）会更少，因此后来3×3卷积核被广泛应用在各种模型中。 多个小卷积核的叠加使用远比一个大卷积核单独使用效果要好的多，在连通性不变的情况下，大大降低了参数量和计算复杂度。当然，卷积核也不是越小越好，对于特别稀疏的数据，当使用比较小的卷积核的时候可能无法表示其特征，如果采用较大的卷积核则会导致复杂度极大的增加。 总而言之，我们多倾向于选择多个相对小的卷积核来进行卷积。 5.11 每层卷积是否只能用一种尺寸的卷积核？经典的神经网络，都属于层叠式网络，并且每层仅用一个尺寸的卷积核，例如VGG结构中使用了大量的3×3卷积层。事实上，同一层feature map可以分别使用多个不同尺寸的卷积核，以获得不同尺度的特征，再把这些特征结合起来，得到的特征往往比使用单一卷积核的要好，例如GoogLeNet、Inception系列的网络，均是每层使用了多个卷积核结构。如下图所示，输入的feature map在同一层，分别经过1×1、3×3、5×5三种不同尺寸的卷积核，再将分别得到的特征进行组合。 5.12 怎样才能减少卷积层参数量？发明GoogleNet的团队发现，如果仅仅引入多个尺寸的卷积核，会带来大量的额外的参数，受到Network In Network中1×1卷积核的启发，为了解决这个问题，他们往Inception结构中加入了一些1×1的卷积核，如图所示： 加入1×1卷积核的Inception结构 根据上图，我们来做个对比计算，假设输入feature map的维度为256维，要求输出维度也是256维。有以下两种操作： （1）256维的输入直接经过一个3×3×256的卷积层，输出一个256维的feature map，那么参数量为：256×3×3×256 = 589,824 （2）256维的输入先经过一个1×1×64的卷积层，再经过一个3×3×64的卷积层，最后经过一个1×1×256的卷积层，输出256维，参数量为：256×1×1×64 + 64×3×3×64 + 64×1×1×256 = 69,632。足足把第一种操作的参数量降低到九分之一！ 1×1卷积核也被认为是影响深远的操作，往后大型的网络为了降低参数量都会应用上1×1卷积核。 5.13 在进行卷积操作时，必须同时考虑通道和区域吗？标准的卷积过程可以看上图，一个2×2的卷积核在卷积时，对应图像区域中的所有通道均被同时考虑，那么问题来了，为什么一定要同时考虑图像区域和通道呢？能不能将通道和空间区域分开考虑？Xception网络由此诞生。我们首先对每一个通道进行各自的卷积操作，有多少个通道就有多少个过滤器。得到新的通道feature maps之后，这时再对这批新的通道feature maps进行标准的1×1跨通道卷积操作。这种操作被称为 “DepthWise convolution”，称为深度可分离卷积。在imagenet 1000类分类任务中取得了非常鲁棒的效果，同时也减少了大量的参数。我们可以通过一个例子来算一算，使用深度可分离卷积，能d假设输入通道数为3，要求输出通道数为256。 使用标准的卷积操作，使用3×3×256的卷积核，参数量为：3×3×3×256 = 6,912 使用深度可分离的结构，分两步完成。参数量为：3×3×3 + 3×1×1×256 = 795。参数量仅为标准卷积的九分之一！ 因此，使用depthwise操作比标准的卷积操作，在降低不少参数量的同时，得到了更好的分类效果。 5.14 采用宽卷积的好处有什么？5.14.1 窄卷积和宽卷积对于窄卷积来说，是从第一个点开始做卷积，每次窗口滑动固定步幅。比如下图左部分为窄卷积。那么注意到越在边缘的位置被卷积的次数越少。于是有了宽卷积的方法，可以看作在卷积之前在边缘用0补充，常见有两种情况，一个是全补充，入下图右部分，这样输出大于输入的维度。另一种常用的方法是补充一部0值，使得输出和输入的维度一致。这里文中给了一个公式 。这里npadding在全补充里是filter-1，在输入输出相等时，就要主要奇偶性了，注意到卷积核常为奇数。 5.14.2 为什么采用宽卷积？ 通过将输入边角的值纳入到滑窗中心进行计算，以便损失更少的信息。 5.15 在卷积操作后，输出特征图（图像）大小如何计算？在进行卷积操作时，往往根据需要，我们需设定一些参数。常见的参数有卷积核大小k, 窗口滑动的步长s, 进行填充的像素p, 假设输入特征图大小为Iw*Iw。则由以下公式可计算出输出特征图的大小Ow。 O_w = \frac{(I_w - k + 2p))}{s} + 1 5.16 如何得到卷积层输出的深度？参数共享：在卷积层中使用参数共享是用来控制参数的数量。假设在第一个卷积层就有55x55x96=290,400个神经元，每个有11x11x3=364个参数和1个偏差。将这些合起来就是290400x364=105,705,600个参数。单单第一层就有这么多参数，显然这个数目是非常大的。 作一个合理的假设：如果一个特征在计算某个空间位置(x,y)的时候有用，那么它在计算另一个不同位置(x2,y2)的时候也有用。基于这个假设，可以显著地减少参数数量。换言之，就是将深度维度上一个单独的2维切片看做深度切片（depth slice），比如一个数据体尺寸为[55x55x96]的就有96个深度切片，每个尺寸为[55x55]。在每个深度切片上的神经元都使用同样的权重和偏差。在这样的参数共享下，例子中的第一个卷积层就只有96个不同的权重集了，一个权重集对应一个深度切片，共有96x11x11x3=34,848个不同的权重，或34,944个参数（+96个偏差）。 w_conv1=weight_variable([5,5,1,32]) 可以看出，上面的32表示的是卷积层输出的深度，因为大家都明白width和height都可以通过公式计算得到，但是很多文献都没有告诉深度是如何得到的，下面是我的认识： 因为这个深度是没有公式可以计算出来的，因为深度是一个经验值，如上面代码的32 ，其实是一个经验值，是通过调整参数发现32是一个最合适的值，可以得到最好的准确率，但是不同的图像的深度是不一样的。 这个深度表示用了多少个卷积核，下面这个图可以说明一下： 上图就可以很有效的说明 ：卷积层输出的深度==卷积核的个数。 5.17 激活函数通常放在卷积神经网络的哪个操作之后？ 通常放在卷积层之后。 5.18 如何理解最大池化层有几分缩小？池化层：对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特征压缩，提取主要特征。 池化操作一般有两种，一种是Avy Pooling,一种是max Pooling。 同样地采用一个2*2的filter,max pooling是在每一个区域中寻找最大值，这里的stride=2,最终在原特征图中提取主要特征得到右图。 注1：（Avy pooling现在不怎么用了，方法是对每一个22的区域元素求和，再除以4，得到主要特征），而一般的filter取22,最大取3*3,stride取2，压缩为原来的1/4.注2：这里的pooling操作是特征图缩小，有可能影响网络的准确度，因此可以通过增加特征图的深度来弥补。 5.19 理解图像卷积与反卷积5.19.1 图像卷积首先给出一个输入输出结果 那他是怎样计算的呢？ 卷积的时候需要对卷积核进行180的旋转，同时卷积核中心与需计算的图像像素对齐，输出结构为中心对齐像素的一个新的像素值，计算例子如下： 这样计算出左上角(即第一行第一列)像素的卷积后像素值。 给出一个更直观的例子，从左到右看，原像素经过卷积由1变成-8。 通过滑动卷积核，就可以得到整张图片的卷积结果 5.19.2 图像反卷积这里提到的反卷积跟1维信号处理的反卷积计算是很不一样的，FCN作者称为backwards convolution，有人称Deconvolution layer is a very unfortunate name and should rather be called a transposed convolutional layer. 我们可以知道，在CNN中有con layer与pool layer，con layer进行对图像卷积提取特征，pool layer 对图像缩小一半筛选重要特征，对于经典的图像识别CNN网络，如IMAGENET，最后输出结果是1X1X1000，1000是类别种类，1x1得到的是。FCN作者，或者后来对end to end研究的人员，就是对最终1x1的结果使用反卷积（事实上FCN作者最后的输出不是1X1，是图片大小的32分之一，但不影响反卷积的使用）。 这里图像的反卷积与full卷积原理是一样的，使用了这一种反卷积手段使得图像可以变大，FCN作者使用的方法是这里所说反卷积的一种变体，这样就可以获得相应的像素值，图像可以实现end to end。 这里说另外一种反卷积做法，假设原图是33，首先使用上采样让图像变成77，可以看到图像多了很多空白的像素点。使用一个33的卷积核对图像进行滑动步长为1的valid卷积，得到一个55的图像，我们知道的是使用上采样扩大图片，使用反卷积填充图像内容，使得图像内容变得丰富，这也是CNN输出end to end结果的一种方法。韩国作者Hyeonwoo Noh使用VGG16层CNN网络后面加上对称的16层反卷积与上采样网络实现end to end 输出，其不同层上采样与反卷积变化效果如下： 经过上面的解释与推导，对卷积有基本的了解，但是在图像上的deconvolution究竟是怎么一回事，可能还是不能够很好的理解，因此这里再对这个过程解释一下。 目前使用得最多的deconvolution有2种，上文都已经介绍。 方法1：full卷积， 完整的卷积可以使得原来的定义域变大。 方法2：记录pooling index，然后扩大空间，再用卷积填充。 图像的deconvolution过程如下： 输入：2x2， 卷积核：4x4， 滑动步长：3， 输出：7x7 即输入为2x2的图片经过4x4的卷积核进行步长为3的反卷积的过程 输入图片每个像素进行一次full卷积，根据full卷积大小计算可以知道每个像素的卷积后大小为 1+4-1=4， 即4x4大小的特征图，输入有4个像素所以4个4x4的特征图 将4个特征图进行步长为3的fusion（即相加）； 例如红色的特征图仍然是在原来输入位置（左上角），绿色还是在原来的位置（右上角），步长为3是指每隔3个像素进行fusion，重叠部分进行相加，即输出的第1行第4列是由红色特阵图的第一行第四列与绿色特征图的第一行第一列相加得到，其他如此类推。 可以看出翻卷积的大小是由卷积核大小与滑动步长决定， in是输入大小， k是卷积核大小， s是滑动步长， out是输出大小 得到 out = (in - 1) s + k 上图过程就是， (2 - 1) 3 + 4 = 7 5.20 不同卷积后图像大小计算？5.20.1 类型划分2维卷积的计算分为了3类：1.full 2.same 3. valid 1、full 蓝色为原图像，白色为对应卷积所增加的padding，通常全部为0，绿色是卷积后图片。图6的卷积的滑动是从卷积核右下角与图片左上角重叠开始进行卷积，滑动步长为1，卷积核的中心元素对应卷积后图像的像素点。可以看到卷积后的图像是4X4，比原图2X2大了，我们还记1维卷积大小是n1+n2-1，这里原图是2X2，卷积核3X3，卷积后结果是4X4，与一维完全对应起来了。其实这才是完整的卷积计算，其他比它小的卷积结果都是省去了部分像素的卷积 2、same 3、valid 5.20.2 计算公式这里，我们可以总结出full，same，valid三种卷积后图像大小的计算公式： full: 滑动步长为1，图片大小为N1xN1，卷积核大小为N2xN2，卷积后图像大小：N1+N2-1 x N1+N2-1。 same: 滑动步长为1，图片大小为N1xN1，卷积核大小为N2xN2，卷积后图像大小：N1xN1。 valid:滑动步长为S，图片大小为N1xN1，卷积核大小为N2xN2，卷积后图像大小：(N1-N2)/S+1 x (N1-N2)/S+1。 5.21 步长、填充大小与输入输出关系总结？在设计深度学习网络的时候，需要计算输入尺寸和输出尺寸，那么就要设计卷积层的的各种参数。这里有一些设计时候的计算公式，方便得到各层的参数。 这里简化下，约定： 5.21.1 没有0填充，单位步长 5.21.2 零填充，单位步长 半填充 全填充 参考图如下图所示 5.21.3 不填充，非单位步长 5.21.4 零填充，非单位步长 http://blog.csdn.net/u011692048/article/details/77572024https://arxiv.org/pdf/1603.07285.pdf 5.22 理解反卷积和棋盘效应5.22.1 为什么出现棋盘现象？图像生成网络的上采样部分通常用反卷积网络，不合理的卷积核大小和步长会使反卷积操作产生棋盘效应 (checkerboard artifacts)。 重叠图案也在二维中形成。两个轴上的不均匀重叠相乘，产生不同亮度的棋盘状图案。 事实上，不均匀重叠往往在二维上更极端！因为两个模式相乘，所以它的不均匀性是原来的平方。例如，在一个维度中，一个步长为2，大小为3的反卷积的输出是其输入的两倍，但在二维中，输出是输入的4倍。 现在，生成图像时，神经网络通常使用多层反卷积，从一系列较低分辨率的描述中迭代建立更大的图像。虽然这些堆栈的反卷积可以消除棋盘效应，但它们经常混合，在更多尺度上产生棋盘效应。 直观地看，假设生成的图像中包含1只黑猫。黑猫身体部分的像素颜色应平滑过渡，或极端地说，该部分应全为黑色。实际生成的图像中该部分却有深深浅浅的近黑方块组成，很像棋盘的网格，即棋盘效应。 https://distill.pub/2016/deconv-checkerboard/http://blog.csdn.net/shadow_guo/article/details/52862161 5.22.2 有哪些方法可以避免棋盘效应？（1）第一种方法是用到的反卷积核的大小可被步长整除，从而避免重叠效应。与最近成功用于图像超分辨率的技术“子像素卷积”（sub-pixel convolution）等价。 （2）另一种方法是从卷积操作中分离出对卷积后更高分辨率的特征图上采样来计算特征。例如，可以先缩放图像（最近邻插值或双线性插值），再卷积。 反卷积与不同缩放卷积方法都是线性操作，并可用矩阵去解释。对于每个输出窗口，反卷积操作的输入唯一，缩放卷积会以阻碍高频棋盘效应的方式来隐式地集中权重（weight-tying）。 缩放卷积缩放卷积为线性操作：假设原图像为A，经过插值后的图像为A+B；用卷积核C对插值缩放后的图像卷积，得到最终的图像 ，其中*为卷积操作。则可将缩放卷积分解为原图像卷积和插值增量图像卷积，或卷积的原图像和卷积的插值增量图像。 C为卷积操作的卷积核。此时为上采样，理解为反卷积操作中的卷积核。 （1）最近邻缩放卷积 发现，插值增量图像表示的矩阵为原图像表示的矩阵下移1行。可将原图像矩阵看成环形队列（队列最后1行的输出送入队列的第1行）。 （2）双线性缩放卷积 发现，插值增量图像可细分为原图像表示的矩阵下移1行后乘以1/2与原图像表示的矩阵上移1行后乘以1/2。 5.23 CNN主要的计算瓶颈CNN的训练主要是在卷积层和子采样层的交互上，其主要的计算瓶颈是： 1）前向传播过程：下采样每个卷积层的maps； 2）反向传播过程：上采样高层子采样层的灵敏度map，以匹配底层的卷积层输出maps的大小； 3）sigmoid的运用和求导。 举例： 对于第一和第二个问题，我们考虑的是如何用Matlab内置的图像处理函数去实现上采样和下采样的操作。对于上采样，imresize函数可以搞定，但需要很大的开销。一个比较快速的版本是使用Kronecker乘积函数kron。通过一个全一矩阵ones来和我们需要上采样的矩阵进行Kronecker乘积，就可以实现上采样的效果。对于前向传播过程中的下采样，imresize并没有提供在缩小图像的过程中还计算nxn块内像素的和的功能，所以没法用。一个比较好和快速的方法是用一个全一的卷积核来卷积图像，然后简单的通过标准的索引方法来采样最后卷积结果。例如，如果下采样的域是2x2的，那么我们可以用2x2的元素全是1的卷积核来卷积图像。然后再卷积后的图像中，我们每个2个点采集一次数据，y=x(1:2:end,1:2:end)，这样就可以得到了两倍下采样，同时执行求和的效果。 对于第三个问题，实际上有些人以为Matlab中对sigmoid函数进行inline的定义会更快，其实不然，Matlab与C/C++等等语言不一样，Matlab的inline反而比普通的函数定义更费时间。所以，我们可以直接在代码中使用计算sigmoid函数及其导数的真实代码。 5.24 卷积神经网络的经验参数设置对于卷积神经网络的参数设置，没有很明确的指导原则，以下仅是一些经验集合。 1、learning-rate 学习率：学习率越小，模型收敛花费的时间就越长，但是可以逐步稳健的提高模型精确度。一般初始设置为0.1，然后每次除以0.2或者0.5来改进，得到最终值； 2、batch-size 样本批次容量：影响模型的优化程度和收敛速度，需要参考你的数据集大小来设置，具体问题具体分析，一般使用32或64，在计算资源允许的情况下，可以使用大batch进行训练。有论文提出，大batch可以加速训练速度，并取得更鲁棒的结果； 3、weight-decay 权重衰减：用来在反向传播中更新权重和偏置，一般设置为0.005或0.001； 4、epoch-number 训练次数：包括所有训练样本的一个正向传递和一个反向传递，训练至模型收敛即可；（注：和迭代次数iteration不一样）总之，不是训练的次数越多，测试精度就会越高。会有各种原因导致过拟合，比如一种可能是预训练的模型太复杂，而使用的数据集样本数量太少，种类太单一。 5.25 提高泛化能力的方法总结（代码示例）本节主要以代码示例来说明可以提高网络泛化能力的方法。代码实验是基于mnist数据集，mnist是一个从0到9的手写数字集合，共有60000张训练图片，10000张测试图片。每张图片大小是28*28大小。目的就是通过各种手段，来构建一个高精度的分类神经网络。 5.25.1 手段一般来说，提高泛化能力的方法主要有以下几个： 使用正则化技术 增加神经网络层数 使用恰当的代价函数 使用权重初始化技术 人为增广训练集 使用dropout技术 5.25.2 主要方法下面我们通过实验结果来判断每种手段的效果。 （1）普通的全连接神经网络网络结构使用一个隐藏层，其中包含100个隐藏神经元，输入层是784，输出层是one-hot编码的形式，最后一层是Softmax层。损失函数采用对数似然代价函数，60次迭代，学习速率η=0.1，随机梯度下降的小批量数据（mini-SGD）大小为10，没使用正则化。在测试集上得到的结果是97.8%，代码如下：12345678&gt;&gt;&gt; import network3 &gt;&gt;&gt; from network3 import Network &gt;&gt;&gt; from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer &gt;&gt;&gt; training_data, validation_data, test_data = network3.load_data_shared() &gt;&gt;&gt; mini_batch_size = 10 &gt;&gt;&gt; net = Network([FullyConnectedLayer(n_in=784, n_out=100), SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size) &gt;&gt;&gt; net.SGD(training_data, 60, mini_batch_size, 0.1, validation_data, test_data) （2）使用卷积神经网络 — 仅一个卷积层输入层是卷积层，卷积核大小是55，一共20个特征映射。最大池化层的大小为22。后面接一层100个隐藏神经元的全连接层。结构如图所示在这个结构中，我们把卷积层和池化层看做是训练图像的特征提取，而后的全连接层则是一个更抽象层次的特征提取，整合全局信息。同样设定是60次迭代，批量数据大小是10，学习率是0.1.代码如下，12345678&gt;&gt;&gt; net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), filter_shape=(20, 1, 5, 5), poolsize=(2, 2)), FullyConnectedLayer(n_in=20*12*12, n_out=100), SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)&gt;&gt;&gt; net.SGD(training_data, 60, mini_batch_size, 0.1, validation_data, test_data) 经过三次运行取平均后，准确率是98.78%，提高得较多。错误率降低了1/3。 （3）使用卷积神经网络 — 两个卷积层我们接着插入第二个卷积层，把它插入在之前结构的池化层和全连接层之间，同样是使用55的局部感受野，22的池化层。12345678910&gt;&gt;&gt; net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), filter_shape=(20, 1, 5, 5), poolsize=(2, 2)), ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), filter_shape=(40, 20, 5, 5), poolsize=(2, 2)), FullyConnectedLayer(n_in=40*4*4, n_out=100), SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)&gt;&gt;&gt; net.SGD(training_data, 60, mini_batch_size, 0.1, validation_data, test_data) 这一次，准确率达到了99.06%。 （4）使用卷积神经网络 — 两个卷积层+线性修正单元(ReLU)+正则化上面的网络结构，我们使用的是Sigmod激活函数，现在我们换成线性修正激活函数ReLU ，同样设定参数为60次迭代，学习速率η=0.03，使用L2正则化，正则化参数λ=0.1，代码如下：1234567891011121314&gt;&gt;&gt; from network3 import ReLU&gt;&gt;&gt; net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), filter_shape=(20, 1, 5, 5), poolsize=(2, 2), activation_fn=ReLU), ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), filter_shape=(40, 20, 5, 5), poolsize=(2, 2), activation_fn=ReLU), FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU), SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)&gt;&gt;&gt; net.SGD(training_data, 60, mini_batch_size, 0.03, validation_data, test_data, lmbda=0.1) 这一次，准确率达到了99.23%，超过了使用sigmoid激活函数的99.06%. ReLU的优势是当取最大极限时，梯度不会饱和。 （5）卷积神经网络 —两个卷基层+线性修正单元(ReLU)+正则化+拓展数据集拓展训练集数据的一个简单方法是将每个训练图像由一个像素来代替，无论是上一个像素，下一个像素，或者左右的像素。其他的方法也有改变亮度，改变分辨率，图片旋转，扭曲，位移等。我们把50000幅图像人为拓展到250000幅图像。使用与第四小节一样的网络，因为我们训练时使用了5倍的数据，所以减少了过拟合的风险。123456789101112131415&gt;&gt;&gt; expanded_training_data, _, _ = network3.load_data_shared( "../data/mnist_expanded.pkl.gz")&gt;&gt;&gt; net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), filter_shape=(20, 1, 5, 5), poolsize=(2, 2), activation_fn=ReLU), ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), filter_shape=(40, 20, 5, 5), poolsize=(2, 2), activation_fn=ReLU), FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU), SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)&gt;&gt;&gt; net.SGD(expanded_training_data, 60, mini_batch_size, 0.03, validation_data, test_data, lmbda=0.1) 这次得到了99.37的训练正确率。 （6）卷积神经网络 — 两个卷基层+线性修正单元(ReLU)+正则化+拓展数据集+继续插入额外的全连接层继续上面的网络，我们拓展全连接层的规模，使用300个隐藏神经元和1000个神经元的额精度分别是99.46%和99.43%.1234567891011121314&gt;&gt;&gt; net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), filter_shape=(20, 1, 5, 5), poolsize=(2, 2), activation_fn=ReLU), ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), filter_shape=(40, 20, 5, 5), poolsize=(2, 2), activation_fn=ReLU), FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU), FullyConnectedLayer(n_in=100, n_out=100, activation_fn=ReLU), SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)&gt;&gt;&gt; net.SGD(expanded_training_data, 60, mini_batch_size, 0.03, validation_data, test_data, lmbda=0.1) 这次取得了99.43%的精度。拓展后的网络并没有帮助太多。 （7）卷积神经网络 — 两个卷基层+线性修正单元(ReLU)+拓展数据集+继续插入额外的全连接层+dropout技术dropout的基本思想就是在训练网络时随机的移除单独的激活值，使得模型更稀疏，不太依赖于训练数据的特质。我们尝试应用dropout到最终的全连接层(而不是在卷积层)。由于训练时间，将迭代次数设置为40，全连接层使用1000个隐藏神经元，因为dropout会丢弃一些神经元。Dropout是一种非常有效且能提高泛化能力，降低过拟合的方法！1234567891011121314151617&gt;&gt;&gt; net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), filter_shape=(20, 1, 5, 5), poolsize=(2, 2), activation_fn=ReLU), ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), filter_shape=(40, 20, 5, 5), poolsize=(2, 2), activation_fn=ReLU), FullyConnectedLayer( n_in=40*4*4, n_out=1000, activation_fn=ReLU, p_dropout=0.5), FullyConnectedLayer( n_in=1000, n_out=1000, activation_fn=ReLU, p_dropout=0.5), SoftmaxLayer(n_in=1000, n_out=10, p_dropout=0.5)], mini_batch_size)&gt;&gt;&gt; net.SGD(expanded_training_data, 40, mini_batch_size, 0.03, validation_data, test_data) 使用dropout，得到了99.60%的准确率。 （8）卷积神经网络 — 两个卷基层+线性修正单元(ReLU)+正则化+拓展数据集+继续插入额外的全连接层+弃权技术+组合网络组合网络类似于随机森林或者adaboost的集成方法，创建几个神经网络，让他们投票来决定最好的分类。我们训练了5个不同的神经网络，每个都大到了99.60%的准去率，用这5个网络来进行投票表决一个图像的分类。采用这种集成方法，精度又得到了微小的提升，达到了99.67%。 5.26 CNN在CV与NLP领域运用的联系与区别？5.26.1 联系自然语言处理是对一维信号（词序列）做操作。计算机视觉是对二维（图像）或三维（视频流）信号做操作。 5.26.2 区别自然语言处理的输入数据通常是离散取值（例如表示一个单词或字母通常表示为词典中的one hot向量），计算机视觉则是连续取值（比如归一化到0，1之间的灰度值）。CNN有两个主要特点，区域不变性(location invariance)和组合性(Compositionality)。 区域不变性：滤波器在每层的输入向量(图像)上滑动，检测的是局部信息，然后通过pooling取最大值或均值。pooling这步综合了局部特征，失去了每个特征的位置信息。这很适合基于图像的任务，比如要判断一幅图里有没有猫这种生物，你可能不会去关心这只猫出现在图像的哪个区域。但是在NLP里，词语在句子或是段落里出现的位置，顺序，都是很重要的信息。 局部组合性：CNN中，每个滤波器都把较低层的局部特征组合生成较高层的更全局化的特征。这在CV里很好理解，像素组合成边缘，边缘生成形状，最后把各种形状组合起来得到复杂的物体表达。在语言里，当然也有类似的组合关系，但是远不如图像来的直接。而且在图像里，相邻像素必须是相关的，相邻的词语却未必相关。 5.27 卷积神经网络凸显共性的方法？5.27.1 局部连接我们首先了解一个概念，感受野，即每个神经元仅与输入神经元相连接的一块区域。在图像卷积操作中，神经元在空间维度上是局部连接，但在深度上是全连接。局部连接的思想，是受启发于生物学里的视觉系统结构，视觉皮层的神经元就是仅用局部接受信息。对于二维图像，局部像素关联性较强。这种局部连接保证了训练后的滤波器能够对局部特征有最强的响应，使神经网络可以提取数据的局部特征；下图是一个很经典的图示，左边是全连接，右边是局部连接。 对于一个1000 × 1000的输入图像而言，如果下一个隐藏层的神经元数目为10^6个，采用全连接则有1000 × 1000 × 10^6 = 10^12个权值参数，如此巨大的参数量几乎难以训练；而采用局部连接，隐藏层的每个神经元仅与图像中10 × 10的局部图像相连接，那么此时的权值参数数量为10 × 10 × 10^6 = 10^8，将直接减少4个数量级。 5.27.2 权值共享权值共享，即计算同一深度的神经元时采用的卷积核参数是共享的。权值共享在一定程度上讲是有意义的，是由于在神经网络中，提取的底层边缘特征与其在图中的位置无关。但是在另一些场景中是无意的，如在人脸识别任务，我们期望在不同的位置学到不同的特征。需要注意的是，权重只是对于同一深度切片的神经元是共享的。在卷积层中，通常采用多组卷积核提取不同的特征，即对应的是不同深度切片的特征，而不同深度切片的神经元权重是不共享。相反，偏置这一权值对于同一深度切片的所有神经元都是共享的。权值共享带来的好处是大大降低了网络的训练难度。如下图，假设在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6个神经元的权值参数相同，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 10 × 10个权值参数（也就是卷积核的大小）。 这里就体现了卷积神经网络的奇妙之处，使用少量的参数，却依然能有非常出色的性能。上述仅仅是提取图像一种特征的过程。如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像不同尺度下的特征，称之为特征图（feature map）。 5.27.3 池化操作池化操作与多层次结构一起，实现了数据的降维，将低层次的局部特征组合成为较高层次的特征，从而对整个图片进行表示。如下图： 5.28 全卷积与Local-Conv的异同点如果每一个点的处理使用相同的Filter，则为全卷积，如果使用不同的Filter，则为Local-Conv。 5.29 举例理解Local-Conv的作用并不是所有的卷积都会进行权重共享，在某些特定任务中，会使用不权重共享的卷积。下面通过人脸这一任务来进行讲解。在读人脸方向的一些paper时，会发现很多都会在最后加入一个Local Connected Conv，也就是不进行权重共享的卷积层。总的来说，这一步的作用就是使用3D模型来将人脸对齐，从而使CNN发挥最大的效果。 截取论文中的一部分图，经过3D对齐以后，形成的图像均是152×152，输入到上述的网络结构中。该结构的参数如下： Conv：32个11×11×3的卷积核 max-pooling: 3×3，stride=2， Conv: 16个9×9的卷积核， Local-Conv: 16个9×9的卷积核， Local-Conv: 16个7×7的卷积核， Local-Conv: 16个5×5的卷积核， Fully-connected: 4096维 Softmax: 4030维。 前三层的目的在于提取低层次的特征，比如简单的边和纹理。其中Max-pooling层使得卷积的输出对微小的偏移情况更加鲁棒。但不能使用更多的Max-pooling层，因为太多的Max-pooling层会使得网络损失图像信息。全连接层将上一层的每个单元和本层的所有单元相连，用来捕捉人脸图像不同位置特征之间的相关性。最后使用softmax层用于人脸分类。中间三层都是使用参数不共享的卷积核，之所以使用参数不共享，有如下原因： （1）对齐的人脸图片中，不同的区域会有不同的统计特征，因此并不存在特征的局部稳定性，所以使用相同的卷积核会导致信息的丢失。 （2）不共享的卷积核并不增加inference时特征的计算量，仅会增加训练时的计算量。使用不共享的卷积核，由于需要训练的参数量大大增加，因此往往需要通过其他方法增加数据量。 5.30 简述卷积神经网络进化史主要讨论CNN的发展，并且引用刘昕博士的思路，对CNN的发展作一个更加详细的介绍，将按下图的CNN发展史进行描述 ![image](第五章 卷积神经网络CNN/img/ch5/img67） 列表项http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;mid=2650324619&amp;idx=1&amp;sn=ca1aed9e42d8f020d0971e62148e13be&amp;scene=1&amp;srcid=0503De6zpYN01gagUvn0Ht8D#wechat_redirectCNN的演化路径可以总结为以下几个方向： 进化之路一：网络结构加深 进化之路二：加强卷积功能 进化之路三：从分类到检测 进化之路四：新增功能模块]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习经典网络汇总]]></title>
    <url>%2F2017%2F04%2F20%2F%E7%AC%AC%E5%9B%9B%E7%AB%A0_%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[4.1 LeNet5一种典型的用来识别数字的卷积网络是LeNet-5。 4.1.1 模型结构 4.1.2 模型结构LeNet-5共有7层（不包含输入层），每层都包含可训练参数；每个层有多个Feature Map，每个FeatureMap通过一种卷积滤波器提取输入的一种特征，然后每个FeatureMap有多个神经元。 C1层是一个卷积层输入图片：32 * 32卷积核大小：5 * 5卷积核种类：6输出featuremap大小：28 * 28 （32-5+1）神经元数量：28 * 28 * 6可训练参数：（5 * 5+1） * 6（每个滤波器5 * 5=25个unit参数和一个bias参数，一共6个滤波器）连接数：（5 * 5+1） * 6 * 28 * 28 S2层是一个下采样层输入：28 * 28采样区域：2 * 2采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid采样种类：6输出featureMap大小：14 * 14（28/2）神经元数量：14 * 14 * 6可训练参数：2 * 6（和的权+偏置）连接数：（2 * 2+1） * 6 * 14 * 14S2中每个特征图的大小是C1中特征图大小的1/4 C3层也是一个卷积层输入：S2中所有6个或者几个特征map组合卷积核大小：5 * 5卷积核种类：16输出featureMap大小：10 * 10C3中的每个特征map是连接到S2中的所有6个或者几个特征map的，表示本层的特征map是上一层提取到的特征map的不同组合存在的一个方式是：C3的前6个特征图以S2中3个相邻的特征图子集为输入。接下来6个特征图以S2中4个相邻特征图子集为输入。然后的3个以不相邻的4个特征图子集为输入。最后一个将S2中所有特征图为输入。 则：可训练参数：6 * （3 * 25+1）+6 * （4 * 25+1）+3 * （4 * 25+1）+（25 * 6+1）=1516连接数：10 * 10 * 1516=151600 S4层是一个下采样层输入：10 * 10采样区域：2 * 2采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid采样种类：16输出featureMap大小：5 * 5（10/2）神经元数量：5 * 5 * 16=400可训练参数：2 * 16=32（和的权+偏置）连接数：16 * （2 * 2+1） * 5 * 5=2000S4中每个特征图的大小是C3中特征图大小的1/4 C5层是一个卷积层输入：S4层的全部16个单元特征map（与s4全相连）卷积核大小：5 * 5卷积核种类：120输出featureMap大小：1 * 1（5-5+1）可训练参数/连接：120 * （16 * 5 * 5+1）=48120 F6层全连接层输入：c5 120维向量计算方式：计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过sigmoid函数可训练参数:84 * (120+1)=10164 4.1.3 模型特性 卷积网络使用一个3层的序列：卷积、池化、非线性——这可能是自这篇论文以来面向图像的深度学习的关键特性！ 使用卷积提取空间特征 使用映射的空间均值进行降采样 tanh或sigmoids非线性 多层神经网络（MLP）作为最终的分类器 层间的稀疏连接矩阵以避免巨大的计算开销 4.2 AlexNet4.2.1 模型介绍​ AlexNet在2012年ILSVRC竞赛中赢得了第一名，其Top5错误率为15.3%。AlexNet模型证明了CNN在复杂模型下的有效性，并且在可接受时间范围内，部署GPU得到了有效结果。 4.2.2 模型结构 4.2.3 模型解读AlexNet共8层，前五层为卷积层，后三层为全连接层。 conv1阶段： &nbsp;&nbsp; 输入图片：227 * 227 * 3 卷积核大小：11 11 3 卷积核数量：96 滤波器stride：4 输出featuremap大小：(227-11)/4+1=55 (227个像素减去11，然后除以4，生成54个像素，再加上被减去的11也对应生成一个像素) 输出featuremap大小：55 * 55 共有96个卷积核，会生成55 * 55 * 96个卷积后的像素层。96个卷积核分成2组，每组48个卷积核。对应生成2组55 * 55 * 48的卷积后的像素层数据。 这些像素层经过relu1单元的处理，生成激活像素层，尺寸仍为2组55 * 55 * 48的像素层数据。 这些像素层经过pool运算的处理，池化运算尺度为3 * 3，运算的步长为2，则池化后图像的尺寸为(55-3)/2+1=27。 即池化后像素的规模为27 * 27 * 96； 然后经过归一化处理，归一化运算的尺度为5 * 5；第一卷积层运算结束后形成的像素层的规模为27 * 27 * 96。分别对应96个卷积核所运算形成。这96层像素层分为2组，每组48个像素层，每组在一个独立的GPU上进行运算。 反向传播时，每个卷积核对应一个偏差值。即第一层的96个卷积核对应上层输入的96个偏差值。 conv2阶段： &nbsp;&nbsp;&nbsp;&nbsp; 输入图片：27 * 27 * 96（第一层输出） 为便于后续处理，每幅像素层的左右两边和上下两边都要填充2个像素 27 * 27 * 96的像素数据分成27 * 27 * 48的两组像素数据，两组数据分别再两个不同的GPU中进行运算。 卷积核大小：5 * 5 * 48 滤波器stride：1 输出featuremap大小：卷积核在移动的过程中会生成(27-5+2 * 2)/1+1=27个像素。(27个像素减去5，正好是22，在加上上下、左右各填充的2个像素，即生成26个像素，再加上被减去的5也对应生成一个像素)，行和列的27 * 27个像素形成对原始图像卷积之后的像素层。共有256个5 * 5 * 48卷积核；这256个卷积核分成两组，每组针对一个GPU中的27 * 27 * 48的像素进行卷积运算。会生成两组27 * 27 * 128个卷积后的像素层。 这些像素层经过relu2单元的处理，生成激活像素层，尺寸仍为两组27 * 27 * 128的像素层。 这些像素层经过pool运算(池化运算)的处理，池化运算的尺度为3 * 3，运算的步长为2，则池化后图像的尺寸为(57-3)/2+1=13。 即池化后像素的规模为2组13 * 13 * 128的像素层； 然后经过归一化处理，归一化运算的尺度为5 * 5； 第二卷积层运算结束后形成的像素层的规模为2组13 * 13 * 128的像素层。分别对应2组128个卷积核所运算形成。每组在一个GPU上进行运算。即共256个卷积核，共2个GPU进行运算。 反向传播时，每个卷积核对应一个偏差值。即第一层的96个卷积核对应上层输入的256个偏差值。 conv3阶段： 第三层输入数据为第二层输出的2组13 * 13 * 128的像素层； 为便于后续处理，每幅像素层的左右两边和上下两边都要填充1个像素； 2组像素层数据都被送至2个不同的GPU中进行运算。每个GPU中都有192个卷积核，每个卷积核的尺寸是3 * 3 * 256。因此，每个GPU中的卷积核都能对2组13 * 13 * 128的像素层的所有数据进行卷积运算。 移动的步长是1个像素。 运算后的卷积核的尺寸为(13-3+1 * 2)/1+1=13（13个像素减去3，正好是10，在加上上下、左右各填充的1个像素，即生成12个像素，再加上被减去的3也对应生成一个像素），每个GPU中共13 * 13 * 192个卷积核。2个GPU中共13 * 13 * 384个卷积后的像素层。这些像素层经过relu3单元的处理，生成激活像素层，尺寸仍为2组13 * 13 * 192像素层，共13 * 13 * 384个像素层。 conv4阶段DFD： &nbsp;&nbsp;&nbsp;&nbsp; 第四层输入数据为第三层输出的2组13 * 13 * 192的像素层； 为便于后续处理，每幅像素层的左右两边和上下两边都要填充1个像素； 2组像素层数据都被送至2个不同的GPU中进行运算。每个GPU中都有192个卷积核，每个卷积核的尺寸是3 * 3 * 192。因此，每个GPU中的卷积核能对1组13 * 13 * 192的像素层的数据进行卷积运算。 移动的步长是1个像素。 运算后的卷积核的尺寸为(13-3+1 * 2)/1+1=13（13个像素减去3，正好是10，在加上上下、左右各填充的1个像素，即生成12个像素，再加上被减去的3也对应生成一个像素），每个GPU中共13 * 13 * 192个卷积核。2个GPU中共13 * 13 * 384个卷积后的像素层。 这些像素层经过relu4单元的处理，生成激活像素层，尺寸仍为2组13 * 13 * 192像素层，共13 * 13 * 384个像素层。 conv5阶段： &nbsp;&nbsp;&nbsp;&nbsp; 第五层输入数据为第四层输出的2组13 * 13 * 192的像素层； 为便于后续处理，每幅像素层的左右两边和上下两边都要填充1个像素； 2组像素层数据都被送至2个不同的GPU中进行运算。每个GPU中都有128个卷积核，每个卷积核的尺寸是3 * 3 * 192。因此，每个GPU中的卷积核能对1组13 * 13 * 192的像素层的数据进行卷积运算。 移动的步长是1个像素。 因此，运算后的卷积核的尺寸为(13-3+1 * 2)/1+1=13（13个像素减去3，正好是10，在加上上下、左右各填充的1个像素，即生成12个像素，再加上被减去的3也对应生成一个像素），每个GPU中共13 * 13 * 128个卷积核。2个GPU中共13 * 13 * 256个卷积后的像素层。 这些像素层经过relu5单元的处理，生成激活像素层，尺寸仍为2组13 * 13 * 128像素层，共13 * 13 * 256个像素层。 2组13 * 13 * 128像素层分别在2个不同GPU中进行池化(pool)运算处理。池化运算的尺度为3 * 3，运算的步长为2，则池化后图像的尺寸为(13-3)/2+1=6。 即池化后像素的规模为两组6 * 6 * 128的像素层数据，共6 * 6 * 256规模的像素层数据。 fc6阶段： &nbsp;&nbsp;&nbsp;&nbsp; 第六层输入数据的尺寸是6 * 6 * 256 采用6 * 6 * 256尺寸的滤波器对第六层的输入数据进行卷积运算 共有4096个6 * 6 * 256尺寸的滤波器对输入数据进行卷积运算，通过4096个神经元输出运算结果； 这4096个运算结果通过relu激活函数生成4096个值； 通过drop运算后输出4096个本层的输出结果值。 由于第六层的运算过程中，采用的滤波器的尺寸(6 * 6 * 256)与待处理的feature map的尺寸(6 * 6 * 256)相同，即滤波器中的每个系数只与feature map中的一个像素值相乘；而其它卷积层中，每个滤波器的系数都会与多个feature map中像素值相乘；因此，将第六层称为全连接层。 第五层输出的6 * 6 * 256规模的像素层数据与第六层的4096个神经元进行全连接，然后经由relu6进行处理后生成4096个数据，再经过dropout6处理后输出4096个数据。 fc7阶段： 第六层输出的4096个数据与第七层的4096个神经元进行全连接 然后经由relu7进行处理后生成4096个数据，再经过dropout7处理后输出4096个数据。 fc8阶段： &nbsp;&nbsp;&nbsp;&nbsp; 第七层输出的4096个数据与第八层的1000个神经元进行全连接，经过训练后输出被训练的数值。 4.2.4 模型特性 使用ReLU作为非线性 使用dropout技术选择性地忽略训练中的单个神经元，避免模型的过拟合 重叠最大池化（overlapping max pooling），避免平均池化（average pooling）的平均效应 使用NVIDIA GTX 580 GPU减少训练时间 当时，GPU比CPU提供了更多的核心，可以将训练速度提升10倍，从而允许使用更大的数据集和更大的图像。 4.3 可视化ZFNet-转置卷积4.3.1 基本的思想及其过程 可视化技术揭露了激发模型中每层单独的特征图。 可视化技术允许观察在训练阶段特征的演变过程且诊断出模型的潜在问题。 可视化技术用到了多层解卷积网络，即由特征激活返回到输入像素空间。 可视化技术进行了分类器输出的敏感性分析，即通过阻止部分输入图像来揭示那部分对于分类是重要的。 可视化技术提供了一个非参数的不变性来展示来自训练集的哪一块激活哪个特征图，不仅需要裁剪输入图片，而且自上而下的投影来揭露来自每块的结构激活一个特征图。 可视化技术依赖于解卷积操作，即卷积操作的逆过程，将特征映射到像素上。 4.3.2 卷积与转置卷积&nbsp;&nbsp;&nbsp;&nbsp;下图为卷积过程 &nbsp;&nbsp;&nbsp;&nbsp;下图为转置卷积过程 &nbsp;&nbsp;&nbsp;&nbsp;下面首先介绍转置卷积中涉及到的几种操作：反池化操作：池化操作是非可逆的，但是我们可以用一组转换变量switch在每个池化区域中通过记录最大值的位置来获得一个近似值。在转置卷积网络中，反池化操作使用这些转换来放置上述最大值的位置，保存激活的位置，其余位置都置0。激活函数：卷积网中使用非线性的ReLU来确保所有输出值总是正值。在反卷积网中也利用了ReLU。转置卷积：为了实现转置卷积，转置卷积网络使用相同卷积核的转置作为新的卷积核进行计算。&nbsp;&nbsp;&nbsp;&nbsp;上图左半部分是一个转置卷积层，右半部分为一个卷积层。反卷积层将会重建一个来自下一层的卷积特征近似版本。图中使用switch来记录在卷积网中进行最大池化操作时每个池化区域的局部最大值的位置，经过非池化操作之后，原来的非最大值的位置都置为0。### 4.3.3 卷积可视化&nbsp;&nbsp;&nbsp;&nbsp;预处理：网络对输入图片进行预处理，裁剪图片中间的256x256区域，并减去整个图像每个像素的均值，然后用10个不同的对256x256图像进行224x224的裁剪（中间区域加上四个角落，以及他们的水平翻转图像），对以128个图片分的块进行随机梯度下降法来更新参数。起始学习率为0.01，动量为0.9，当验证集误差不再变化时时，手动调整学习率。在全连接网络中使用概率为0.5的dropout，并且所有权值都初始化为0.01，偏置设为0。&nbsp;&nbsp;&nbsp;&nbsp;特征可视化：当输入存在一定的变化时，网络的输出结果保持不变。下图即在一个已经训练好的网络中可视化后的图。在可视化结果的右边是对应的输入图片，与重构特征相比，输入图片之间的差异性很大，而重构特征只包含那些具有判别能力的纹理特征。&nbsp;&nbsp;&nbsp;&nbsp;由上图可以看到第二层应对角落和其他边缘或者颜色的结合；第三层有更加复杂的不变性，捕捉到了相似的纹理；第四层显示了特定类间显著的差异性；第五层显示了有显著构成变化的整个物体。&nbsp;&nbsp;&nbsp;&nbsp;训练时的特征演变过程：当输入图片中的最强刺激源发生变化时，对应的输出特征轮廓发生剧烈变化。经过一定次数的迭代以后，底层特征趋于稳定，但更高层的特征则需要更多的迭代次数才能收敛，这表明：只有所有层都收敛时，这个分类模型才是有效的。&nbsp;&nbsp;&nbsp;&nbsp;特征不变性: 一般来说，就深度模型来说，只要深度超过七层，微小的变化对于模型的第一层都有比较大的影响，但对于较深层几乎没有没有影响。对于图像的平移、尺度、旋转的变化来说，网络的输出对于平移和尺度变化都是稳定的，但却不具有旋转不变性，除非目标图像时旋转对称的。下图为分别对平移，尺度，旋转做的分析图。&nbsp;&nbsp;&nbsp;&nbsp;上图按行顺序分别为对5类图像进行不同程度的垂直方向上的平移、尺度变换、旋转对输出结果影响的分析图。按列顺序分别为原始变换图像，第一层中原始图片和变换后的图片的欧氏距离，第7层中原始图片和变换后的图片的欧氏距离，变换后图片被正确分类的概率图。 &nbsp;&nbsp;&nbsp;&nbsp;可视化不仅能够看到一个训练完的模型的内部操作，而且还能帮助选择好的网络结构。 ### 4.3.4 ZFNet和AlexNet比较&nbsp;&nbsp;&nbsp;&nbsp;ZFNet的网络结构实际上与AlexNet没有什么很大的变化，差异表现在AlexNet用了两块GPU的稀疏连接结构，而ZFNet只用了一块GPU的稠密连接结构；同时，由于可视化可以用来选择好的网络结构，通过可视化发现AlexNet第一层中有大量的高频和低频信息的混合，却几乎没有覆盖到中间的频率信息；且第二层中由于第一层卷积用的步长为4太大了，导致了有非常多的混叠情况；因此改变了AlexNet的第一层即将滤波器的大小11x11变成7x7，并且将步长4变成了2，下图为AlexNet网络结构与ZFNet的比较。## 4.4 VGGNet### 4.4.1 模型结构### 4.4.2 模型特点1. 整个网络都使用了同样大小的卷积核尺寸（3 * 3）和最大池化尺寸（2 * 2）2. 1 * 1卷积的意义主要在于线性变换，而输入通道数和输出通道数不变，没有发生降维。3. 两个3 * 3的卷积层串联相当于1个5 * 5的卷积层，即一个像素会跟周围5 * 5的像素产生关联，可以说感受野大小为5 * 5。而3个3 * 3的卷积层串联的效果则相当于1个7 * 7的卷积层。除此之外，3个串联的3 * 3的卷积层，拥有比1个7 * 7的卷积层更少的参数量，只有后者的(3 * 3 * 3)/(7 * 7)=55%。最重要的是，3个3 * 3的卷积层拥有比1个7 * 7的卷积层更多的非线性变换（前者可以使用三次ReLU激活函数，而后者只有一次），使得CNN对特征的学习能力更强。4. VGGNet在训练时有一个小技巧，先训练级别A的简单网络，再复用A网络的权重来初始化后面的几个复杂模型，这样训练收敛的速度更快。在预测时，VGG采用Multi-Scale的方法，将图像scale到一个尺寸Q，并将图片输入卷积网络计算。然后在最后一个卷积层使用滑窗的方式进行分类预测，将不同窗口的分类结果平均，再将不同尺寸Q的结果平均得到最后结果，这样可提高图片数据的利用率并提升预测准确率。在训练中，VGGNet还使用了Multi-Scale的方法做数据增强，将原始图像缩放到不同尺寸S，然后再随机裁切224*224的图片，这样能增加很多数据量，对于防止模型过拟合有很不错的效果。## 4.5 Network in Network### 4.5.1 模型结构### 4.5.2 模型创新点&nbsp;&nbsp;&nbsp;&nbsp;论文的创新点：1. 提出了抽象能力更高的Mlpconv层2. 提出了Global Average Pooling（全局平均池化）层- Mlpconv层 &nbsp;&nbsp;&nbsp;&nbsp; 传统的卷积神经网络一般来说是由线性卷积层、池化层、全连接层堆叠起来的网络，卷积层通过线性滤波器进行线性卷积运算，然后在接个非线性激活函数最终生成特征图。而这种卷积滤波器是一种GLM:(Generalized linear model)广义线性模型。然而GLM的抽象能力是比较低水平的。 &nbsp;&nbsp;&nbsp;&nbsp; 抽象：指得到对同一概念的不同变体保持不变的特征。 &nbsp;&nbsp;&nbsp;&nbsp; 一般用CNN进行特征提取时，其实就隐含地假设了特征是线性可分的，可实际问题往往是难以线性可分的。一般来说我们所要提取的特征一般是高度非线性的。在传统的CNN中，也许我们可以用超完备的滤波器，来提取各种潜在的特征。比如我们要提取某个特征，于是我就用了一大堆的滤波器，把所有可能的提取出来，这样就可以把我想要提取的特征也覆盖到，然而这样存在一个缺点，那就是网络太恐怖了，参数太多了。&nbsp;&nbsp;&nbsp;&nbsp;我们知道CNN高层特征其实是低层特征通过某种运算的组合。所以论文就根据这个想法，提出在每个局部感受野中进行更加复杂的运算，提出了对卷积层的改进算法：MLP卷积层。（这里也不知道是否有道理，因为在后面的深层网络没有提出此种说法，还是按照传统的cnn方法使用多个滤波器去学习同一特征的不同变体）。MLP中的激活函数采用的是整流线性单元（即ReLU:max（wx+b,0)。MLP的优点：1. 非常有效的通用函数近似器2. 可用BP算法训练，可以完美地融合进CNN3. 其本身也是一种深度模型，可以特征再利用 全局平均池化层 &nbsp;&nbsp;&nbsp;&nbsp; 另一方面，传统的CNN最后一层都是全连接层，参数个数非常之多，容易引起过拟合（如Alexnet），一个CNN模型，大部分的参数都被全连接层给占用了，所以论文提出采用了全局均值池化替代全连接层。与传统的全连接层不同，我们对每个特征图一整张图片进行全局均值池化，这样每张特征图都可以得到一个输出。这样采用均值池化，连参数都省了，可以大大减小网络参数，避免过拟合，另一方面它有一个特点，每张特征图相当于一个输出特征，然后这个特征就表示了我们输出类的特征。 全局平均池化的优势： 通过加强特征图与类别的一致性，让卷积结构更简单 不需要进行参数优化，所以这一层可以避免过拟合 它对空间信息进行了求和，因而对输入的空间变换更具有稳定性 &nbsp;&nbsp;&nbsp;&nbsp;在采用了微神经网络后，让局部模型有更强的抽象能力，从而让全局平均池化能具有特征图与类别之间的一致性，同时相比传统CNN采用的全连接层，不易过拟合（因为全局平均池化本身就是一种结构性的规则项）（PS:经典CNN容易过拟合，并严重依赖用dropout进行规则化）。 4.6 GoogleNet4.6.1 模型结构 4.6.2 Inception 结构 对上图做以下说明： 采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合； 之所以卷积核大小采用1、3和5，主要是为了方便对齐。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以直接拼接在一起了； 文章说很多地方都表明pooling挺有效，所以Inception里面也嵌入了。 网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。 但是，使用5x5的卷积核仍然会带来巨大的计算量。 为此，文章借鉴NIN2，采用1x1卷积核来进行降维。 例如：上一层的输出为100x100x128，经过具有256个输出的5x5卷积层之后(stride=1，padding=2)，输出数据为100x100x256。其中，卷积层的参数为128x5x5x256。假如上一层输出先经过具有32个输出的1x1卷积层，再经过具有256个输出的5x5卷积层，那么最终的输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256，大约减少了4倍。 具体改进后的Inception Module如下图： 4.7 Inception 系列4.7.1 Inception v1&nbsp;&nbsp;&nbsp;&nbsp;相比于GoogLeNet之前的众多卷积神经网络而言，inception v1采用在同一层中提取不同的特征（使用不同尺寸的卷积核），并提出了卷积核的并行合并（也称为Bottleneck layer），如下图 这样的结构主要有以下改进： 一层block就包含1x1卷积，3x3卷积，5x5卷积，3x3池化(使用这样的尺寸不是必需的，可以根据需要进行调整)。这样，网络中每一层都能学习到“稀疏”（3x3. 5x5）或“不稀疏”（1x1）的特征，既增加了网络的宽度，也增加了网络对尺度的适应性； 通过deep concat在每个block后合成特征，获得非线性属性。 虽然这样提高了性能，但是网络的计算量实在是太大了，因此GoogLeNet借鉴了Network-in-Network的思想，使用1x1的卷积核实现降维操作，以此来减小网络的参数量(这里就不对两种结构的参数量进行定量比较了)，如图所示。 &nbsp;&nbsp;&nbsp;&nbsp;最后实现的inception v1网络是上图结构的顺序连接，其中不同inception模块之间使用2x2的最大池化进行下采样，如表所示。 如表所示，实现的网络仍有一层全连接层，该层的设置是为了迁移学习的实现（下同）。在之前的网络中，最后都有全连接层，经实验证明，全连接层并不是很必要的，因为可能会带来以下三点不便： 网络的输入需要固定 参数量多 易发生过拟合实验证明，将其替换为平均池化层（或者1x1卷积层）不仅不影响精度，还可以减少。 4.7.2 Inception v2在V1的基础之上主要做了以下改进： 使用BN层，将每一层的输出都规范化到一个N(0,1)的正态分布，这将有助于训练，因为下一层不必学习输入数据中的偏移，并且可以专注与如何更好地组合特征（也因为在v2里有较好的效果，BN层几乎是成了深度网络的必备）；&nbsp;&nbsp;&nbsp;&nbsp;（在Batch-normalized论文中只增加了BN层，而之后的Inception V3的论文提及到的inception v2还做了下面的优化） 使用2个3x3的卷积代替梯度（特征图，下同）为35x35中的5x5的卷积，这样既可以获得相同的视野(经过2个3x3卷积得到的特征图大小等于1个5x5卷积得到的特征图)，还具有更少的参数，还间接增加了网络的深度，如下图。 3x3的卷积核表现的不错，那更小的卷积核是不是会更好呢？比如2x2。对此，v2在17x17的梯度中使用1 * n和n * 1这种非对称的卷积来代替n * n的对称卷积，既降低网络的参数，又增加了网络的深度（实验证明，该结构放于网络中部，取n=7，准确率更高），如下。（基于原则3） 在梯度为8x8时使用可以增加滤波器输出的模块（如下图），以此来产生高维的稀疏特征。 输入从224x224变为229x229。 最后实现的Inception v2的结构如下表。 &nbsp;&nbsp;&nbsp;&nbsp;经过网络的改进，inception v2得到更低的识别误差率，与其他网络识别误差率对比如表所示。 &nbsp;&nbsp;&nbsp;&nbsp;如表，inception v2相比inception v1在imagenet的数据集上，识别误差率由29%降为23.4%。 4.7.3 Inception v3&nbsp;&nbsp;&nbsp;&nbsp;inception模块之间特征图的缩小，主要有下面两种方式： &nbsp;&nbsp;&nbsp;&nbsp;右图是先进行inception操作，再进行池化来下采样，但是这样参数量明显多于左图(比较方式同前文的降维后inception模块)，因此v2采用的是左图的方式，即在不同的inception之间（35/17/8的梯度）采用池化来进行下采样。 &nbsp;&nbsp;&nbsp;&nbsp;但是，左图这种操作会造成表达瓶颈问题，也就是说特征图的大小不应该出现急剧的衰减(只经过一层就骤降)。如果出现急剧缩减，将会丢失大量的信息，对模型的训练造成困难。&nbsp;&nbsp;&nbsp;&nbsp;因此，在2015年12月提出的Inception V3结构借鉴inception的结构设计了采用一种并行的降维结构，如下图： &nbsp;&nbsp;&nbsp;&nbsp;具体来说，就是在35/17/8之间分别采用下面这两种方式来实现特征图尺寸的缩小，如下图： figure 5’ 35/17之间的特征图尺寸减小 figure 6’ 17/8之间的特征图尺寸缩小 这样就得到Inception v3的网络结构，如表所示。 4.7.4 Inception V4&nbsp;&nbsp;&nbsp;&nbsp;其实，做到现在，Inception模块感觉已经做的差不多了，再做下去准确率应该也不会有大的改变。但是谷歌这帮人还是不放弃，非要把一个东西做到极致，改变不了Inception模块，就改变其他的。 &nbsp;&nbsp;&nbsp;&nbsp;因此，作者Christian Szegedy设计了Inception v4的网络，将原来卷积、池化的顺次连接（网络的前几层）替换为stem模块，来获得更深的网络结构。stem模块结构如下： stem模块 &nbsp;&nbsp;&nbsp;&nbsp;Inception v4 中的Inception模块（分别为Inception A Inception B Inception C） &nbsp;&nbsp;&nbsp;&nbsp;Inception v4中的reduction模块（分别为reduction A reduction B） &nbsp;&nbsp;&nbsp;&nbsp;最终得到的Inception v4结构如下图。 4.7.5 Inception-ResNet-v2&nbsp;&nbsp;&nbsp;&nbsp;ResNet的结构既可以加速训练，还可以提升性能（防止梯度消失）；Inception模块可以在同一层上获得稀疏或非稀疏的特征。有没有可能将两者进行优势互补呢？ &nbsp;&nbsp;&nbsp;&nbsp;Christian Szegedy等人将两个模块的优势进行了结合，设计出了Inception-ResNet网络。 &nbsp;&nbsp;&nbsp;&nbsp;(Inception-ResNet有v1和v2两个版本，v2表现更好且更复杂，这里只介绍了v2) &nbsp;&nbsp;&nbsp;&nbsp;Inception-ResNet的成功，主要是它的Inception-ResNet模块。 &nbsp;&nbsp;&nbsp;&nbsp;Inception-ResNet v2中的Inception-ResNet模块如下图： &nbsp;&nbsp;&nbsp;&nbsp;Inception-ResNet模块（分别为Inception-ResNet-A Inception-ResNet-B Inception-ResNet-C） &nbsp;&nbsp;&nbsp;&nbsp;Inception-ResNet模块之间特征图尺寸的减小如下图。（类似于Inception v4） &nbsp;&nbsp;&nbsp;&nbsp;Inception-ResNet-v2中的reduction模块（分别为reduction A reduction B） &nbsp;&nbsp;&nbsp;&nbsp;最终得到的Inception-ResNet-v2网络结构如图(stem模块同Inception v4)。 4.8 ResNet及其变体&nbsp;&nbsp;&nbsp;&nbsp;自从AlexNet在LSVRC2012分类比赛中取得胜利之后，深度残差网络（Deep Residual Network）可以说成为过去几年中，在计算机视觉、深度学习社区领域中最具突破性的成果了。ResNet可以实现高达数百，甚至数千个层的训练，且仍能获得超赞的性能。 &nbsp;&nbsp;&nbsp;&nbsp;得益于其强大的表征能力，许多计算机视觉应用在图像分类以外领域的性能得到了提升，如对象检测和人脸识别。 &nbsp;&nbsp;&nbsp;&nbsp;自从2015年ResNet进入人们的视线，并引发人们思考之后，许多研究界人员已经开始研究其成功的秘诀，并在架构中纳入了许多新的改进。本文分为两部分，第一部分我将为那些不熟悉ResNet的人提供一些相关的背景知识，第二部分我将回顾一些我最近读过的关于ResNet架构的不同变体及其论文的相关阐述。 4.8.1 重新审视ResNet&nbsp;&nbsp;&nbsp;&nbsp;根据泛逼近性原理（universal approximation theorem），我们知道，如果给定足够的容量，一个具有单层的前馈网络足以表示任何函数。然而，该层可能是巨大的，且网络可能容易过度拟合数据。因此，研究界有一个共同的趋势，即我们的网络架构需要更深。 &nbsp;&nbsp;&nbsp;&nbsp;自从AlexNet投入使用以来，最先进的卷积神经网络（CNN）架构越来越深。虽然AlexNet只有5层卷积层，但VGG网络和GoogleNet（代号也为Inception_v1）分别有19层和22层。 &nbsp;&nbsp;&nbsp;&nbsp;但是，如果只是通过简单地将层叠加在一起，增加网络深度并不会起到什么作用。随着网络层数的增加，就会出现梯度消失问题，这就会造成网络是难以进行训练，因为梯度反向传播到前层，重复乘法可能使梯度无穷小，这造成的结果就是，随着网络加深，其性能趋于饱和，或者甚至开始迅速退化。 &nbsp;&nbsp;&nbsp;&nbsp;增加网络深度导致性能下降 &nbsp;&nbsp;&nbsp;&nbsp;其实早在ResNet之前，已经有过好几种方法来处理梯度消失问题，例如，在中间层增加辅助损失作为额外的监督，但遗憾的是，似乎没有一个方法可以真正解决这个问题。 &nbsp;&nbsp;&nbsp;&nbsp;ResNet的核心思想是引入所谓的“恒等映射（identity shortcut connection）”，可以跳过一层或多层，如下图所示： 4.8.2 残差块&nbsp;&nbsp;&nbsp;&nbsp;Deep Residual Learning for Image Recognition的作者认为，堆积网络层数不应该降低网络性能，因为我们可以简单地在当前网络上堆积身份映射（层不做任何事情），并且所得到的架构将执行相同的操作。这表明，较深的模型所产生的训练误差不应该比较浅的模型高。他们假设让堆积层适应残差映射比使它们直接适应所需的底层映射要容易得多。下图的残差块可以明确地使它做到这一点。 4.8.3 ResNet架构&nbsp;&nbsp;&nbsp;&nbsp;事实上，ResNet并不是第一个利用short cut、Highway Networks引入门控近路连接的。这些参数化门控制允许多少信息流过近路（shortcut）。类似的想法可以在长短期记忆网络（LSTM）单元中找到，其中存在参数化的忘记门，其控制多少信息将流向下一个时间步。因此，ResNet可以被认为是Highway Networks的一种特殊情况。 &nbsp;&nbsp;&nbsp;&nbsp;然而，实验表明，Highway Networks的性能并不如ResNet，因为Highway Networks的解决方案空间包含ResNet，因此它应该至少表现得像ResNet一样好。这就表明，保持这些“梯度公路”干净简洁比获取更大的解决方案空间更为重要。 &nbsp;&nbsp;&nbsp;&nbsp;照着这种直觉，论文作者改进了残差块，并提出了一个残差块的预激活变体，其中梯度可以畅通无阻地通过快速连接到任何其他的前层。论文的实验结果表明，使用原始的残差块，训练1202层ResNet所展示的性能比其训练110层对等物要差得多。 4.8.4 ResNeXt&nbsp;&nbsp;&nbsp;&nbsp;S. Xie，R. Girshick，P. Dollar，Z. Tu和 K. He在Aggregated Residual Transformations for Deep Neural Networks中提出了一个代号为ResNeXt的ResNet变体，它具有以下构建块： &nbsp;&nbsp;&nbsp;&nbsp;左：《Deep Residual Learning for Image Recognition》中所提及的构建块，右图： ResNeXt构建块 基数=32 &nbsp;&nbsp;&nbsp;&nbsp;这可能看起来很熟悉，因为它非常类似于《IEEE计算机视觉与模式识别会议论文集》中《Going deeper with convolutions》的Inception模块，它们都遵循“拆分-转换-合并”范式，除了在这个变体中，不同路径的输出通过将它们相加在一起而被合并，而在《Going deeper with convolutions》中它们是深度连接的。另一个区别是，在《Going deeper with convolutions》中，每个路径彼此互不相同（1x1,3x3和5x5卷积），而在此架构中，所有路径共享相同的拓扑。 &nbsp;&nbsp;&nbsp;&nbsp;作者介绍了一个称为 “基数（cardinality）”的超参数——独立路径的数量，以提供调整模型容量的新方式。实验表明，可以通过增加基数，而不是深度或宽度，来更加有效地获得准确度。作者指出，与Inception相比，这种新颖的架构更容易适应新的数据集/任务，因为它具有一个简单的范式，且只有一个超参数被调整，而Inception却具有许多超参数（如每个路径中卷积层内核大小）待调整。 &nbsp;&nbsp;&nbsp;&nbsp;这个新颖的构建块有如下三种等效形式： 实际上，“分割-变换-合并”通常是通过点分组卷积层来完成的，它将其输入分成特征映射组，并分别执行正常卷积，其输出被深度级联，然后馈送到1x1卷积层。 4.8.5 ResNet作为小型网络的组合&nbsp;&nbsp;&nbsp;&nbsp;Deep Networks with Stochastic Depth提出了一种反直觉的方式，训练一个非常深层的网络，通过在训练期间随机丢弃它的层，并在测试时间内使用完整的网络。Veit等人有一个更反直觉的发现：我们实际上可以删除一些已训练的ResNet的一些层，但仍然具有可比性能。这使得ResNet架构更加有趣，该论文亦降低了VGG网络的层，并大大降低了其性能。该论文首先提供了ResNet的一个简单的视图，使事情更清晰。在我们展开网络架构之后，这是很显而易见的，具有i个残差块的ResNet架构具有$2^{i}$个不同的路径（因为每个残差块提供两个独立的路径）。 &nbsp;&nbsp;&nbsp;&nbsp;鉴于上述发现，我们很容易发现为什么在ResNet架构中删除几层，对于其性能影响不大——架构具有许多独立的有效路径，在我们删除了几层之后，它们大部分保持不变。相反，VGG网络只有一条有效的路径，所以删除一层是唯一的途径。 &nbsp;&nbsp;&nbsp;&nbsp;作者还进行了实验，表明ResNet中的路径集合具有集合行为。他们是通过在测试时间删除不同数量的层，然后查看网络的性能是否与已删除层的数量平滑相关，这样的方式做到的。结果表明，网络确实表现得像集合，如下图所示： 4.8.6 ResNet中路径的特点&nbsp;&nbsp;&nbsp;&nbsp;最后，作者研究了ResNet中路径的特点： &nbsp;&nbsp;&nbsp;&nbsp;很明显，所有可能的路径长度的分布都遵循二项式分布，如（a）所示。大多数路径经过19到35个残差块。 &nbsp;&nbsp;&nbsp;&nbsp;调查路径长度与经过其的梯度大小之间的关系，同时获得长度为k的路径的梯度幅度，作者首先将一批数据馈送给网络，随机抽取k个残差块。当反向传播梯度时，它们仅传播到采样残余块的权重层。（b）表明随着路径变长，梯度的大小迅速下降。 &nbsp;&nbsp;&nbsp;&nbsp;我们现在可以将每个路径长度的频率与其预期的梯度大小相乘，以了解每个长度的路径对于训练有多少帮助，如（c）所示。令人惊讶的是，大多数贡献来自长度为9至18的路径，但它们仅占总路径的一小部分，如（a）所示。这是一个非常有趣的发现，因为它表明ResNet并没有解决长路径上的梯度消失问题，而是通过缩短其有效路径，ResNet实际上能够实现训练非常深度的网络。 &nbsp;&nbsp;&nbsp;&nbsp;答案来源：ResNet有多大威力？最近又有了哪些变体？一文弄清 4.9 为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？ 评测对比：为了让自己的结果更有说服力，在发表自己成果的时候会同一个标准的baseline及在baseline上改进而进行比较，常见的比如各种检测分割的问题都会基于VGG或者Resnet101这样的基础网络。 时间和精力有限：在科研压力和工作压力中，时间和精力只允许大家在有限的范围探索。 模型创新难度大：进行基本模型的改进需要大量的实验和尝试，并且需要大量的实验积累和强大灵感，很有可能投入产出比比较小。 资源限制：创造一个新的模型需要大量的时间和计算资源，往往在学校和小型商业团队不可行。 在实际的应用场景中，其实是有大量的非标准模型的配置。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习基础问题]]></title>
    <url>%2F2017%2F04%2F10%2F%E7%AC%AC%E4%B8%89%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[3.1 基本概念3.1.1 神经网络组成？为了描述神经网络，我们先从最简单的神经网络说起。 感知机 简单的感知机如下图所示： 其输出为： $$output =\left{\begin{aligned}0, \quad if \sum_i w_i x_i \le threshold \1, \quad if \sum_i w_i x_i &gt; threshold\end{aligned}\right.$$ 假如把感知机想象成一个加权投票机制，比如 3 位评委给一个歌手打分，打分分别为 4 分、1 分、-3 分，这 3 位评分的权重分别是 1、3、2，则该歌手最终得分为 $ 4 ^ 1 + 1 ^ 3 + (-3) ^ 2 = 1 $。按照比赛规则，选取的 threshold 为 3，说明只有歌手的综合评分大于 3 时，才可顺利晋级。对照感知机，该选手被淘汰，因为 $$\sum_i w_i x_i &lt; threshold=3, output = 0$$ 用 $ -b $ 代替 threshold。输出变为： $$output = \left{\begin{aligned}0, \quad if w \cdot x + b \le threshold \1, \quad if w \cdot x + b &gt; threshold\end{aligned}\right.$$ 设置合适的 $ x $ 和 $ b $，一个简单的感知机单元的与非门表示如下： 当输入为 $ 0,1 $ 时，感知机输出为 $ 0 ^ (-2) + 1 ^ (-2) + 3 = 1 $。 复杂一些的感知机由简单的感知机单元组合而成： Sigmoid单元 感知机单元的输出只有 0 和 1，实际情况中，更多的输出类别不止 0 和 1，而是 $ [0, 1] $ 上的概率值，这时候就需要 sigmoid 函数把任意实数映射到 $ [0, 1] $ 上。 神经元的输入 $$z = \sum_i w_i x_i + b$$ 假设神经元的输出采用 sigmoid 激活函数 $$\sigma(z) = \frac{1}{1+e^{-z}}$$ sigmoid 激活函数图像如下图所示： 全连接神经网络即第 $ i $ 层的每个神经元和第 $ i-1 $ 层的每个神经元都有连接。 输出层可以不止有 1 个神经元。隐藏层可以只有 1 层，也可以有多层。输出层为多个神经元的神经网络例如下图： 3.1.2神经网络有哪些常用模型结构？答案来源：25张图让你读懂神经网络架构 下图包含了大部分常用的模型： 3.1.3如何选择深度学习开发平台？现有的深度学习开源平台主要有 Caffe, Torch, MXNet, CNTK, Theano, TensorFlow, Keras 等。那如何选择一个适合自己的平台呢，下面列出一些衡量做参考。 参考1：与现有编程平台、技能整合的难易程度 主要是前期积累的开发经验和资源，比如编程语言，前期数据集存储格式等。 参考2: 与相关机器学习、数据处理生态整合的紧密程度 深度学习研究离不开各种数据处理、可视化、统计推断等软件包。考虑建模之前，是否具有方便的数据预处理工具？建模之后，是否具有方便的工具进行可视化、统计推断、数据分析？ 参考3：对数据量及硬件的要求和支持 深度学习在不同应用场景的数据量是不一样的，这也就导致我们可能需要考虑分布式计算、多 GPU 计算的问题。例如，对计算机图像处理研究的人员往往需要将图像文件和计算任务分部到多台计算机节点上进行执行。当下每个深度学习平台都在快速发展，每个平台对分布式计算等场景的支持也在不断演进。 参考4：深度学习平台的成熟程度 成熟程度的考量是一个比较主观的考量因素，这些因素可包括：社区的活跃程度；是否容易和开发人员进行交流；当前应用的势头。 参考5：平台利用是否多样性？ 有些平台是专门为深度学习研究和应用进行开发的，有些平台对分布式计算、GPU 等构架都有强大的优化，能否用这些平台/软件做其他事情？比如有些深度学习软件是可以用来求解二次型优化；有些深度学习平台很容易被扩展，被运用在强化学习的应用中。 3.1.4为什么使用深层表示? 深度神经网络的多层隐藏层中，前几层能学习一些低层次的简单特征，后几层能把前面简单的特征结合起来，去学习更加复杂的东西。比如刚开始检测到的是边缘信息，而后检测更为细节的信息。 深层的网络隐藏单元数量相对较少，隐藏层数目较多，如果浅层的网络想要达到同样的计算结果则需要指数级增长的单元数量才能达到。 3.1.5为什么深层神经网络难以训练？答案来源： 为什么深层神经网络难以训练 为什么很难训练深度神经网络 梯度消失 梯度消失是指通过隐藏层从后向前看，梯度会变的越来越小，说明前面层的学习会显著慢于后面层的学习，所以学习会卡住，除非梯度变大。下图是不同隐含层的学习速率； 梯度爆炸 又称exploding gradient problem，在深度网络或循环神经网络（RNN）等网络结构中，梯度可在网络更新的过程中不断累积，变成非常大的梯度，导致网络权重值的大幅更新，使得网络不稳定；在极端情况下，权重值甚至会溢出，变为NaN值，再也无法更新。 具体可参考文献：A Gentle Introduction to Exploding Gradients in Neural Networks 权重矩阵的退化导致模型的有效自由度减少。参数空间中学习的退化速度减慢，导致减少了模型的有效维数，网络的可用自由度对学习中梯度范数的贡献不均衡，随着相乘矩阵的数量（即网络深度）的增加，矩阵的乘积变得越来越退化； 在有硬饱和边界的非线性网络中（例如 ReLU 网络），随着深度增加，退化过程会变得越来越快。Duvenaud 等人 2014 年的论文里展示了关于该退化过程的可视化： 随着深度的增加，输入空间（左上角所示）会在输入空间中的每个点处被扭曲成越来越细的单丝，只有一个与细丝正交的方向影响网络的响应。沿着这个方向，网络实际上对变化变得非常敏感。 3.1.6 深度学习和机器学习有什么不同？机器学习：利用计算机、概率论、统计学等知识，输入数据，让计算机学会新知识。机器学习的过程，就是通过训练数据寻找目标函数。 深度学习是机器学习的一种，现在深度学习比较火爆。在传统机器学习中，手工设计特征对学习效果很重要，但是特征工程非常繁琐。而深度学习能够从大数据中自动学习特征，这也是深度学习在大数据时代受欢迎的一大原因。 3.2 网络操作与计算3.2.1前向传播与反向传播？答案来源：神经网络中前向传播和反向传播解析 在神经网络的计算中，主要由前向传播(foward propagation，FP)和反向传播(backward propagation，BP)。 前向传播 假设上一层结点 $ i,j,k,… $ 等一些结点与本层的结点 $ w $ 有连接，那么结点 $ w $ 的值怎么算呢？就是通过上一层的 $ i,j,k,… $ 等结点以及对应的连接权值进行加权和运算，最终结果再加上一个偏置项（图中为了简单省略了），最后在通过一个非线性函数（即激活函数），如 ReLu，sigmoid 等函数，最后得到的结果就是本层结点 $ w $ 的输出。 最终不断的通过这种方法一层层的运算，得到输出层结果。 反向传播 由于我们前向传播最终得到的结果，以分类为例，最终总是有误差的，那么怎么减少误差呢，当前应用广泛的一个算法就是梯度下降算法，但是求梯度就要求偏导数，下面以图中字母为例讲解一下： 设最终中误差为 $ E $，对于输出那么 $ E $ 对于输出节点 $ y_l $ 的偏导数是 $ y_l - t_l $，其中 $ t_l $ 是真实值，$ \frac{\partial y_l}{\partial z_l} $ 是指上面提到的激活函数，$ z_l $ 是上面提到的加权和，那么这一层的 $ E $ 对于 $ z_l $ 的偏导数为 $ \frac{\partial E}{\partial z_l} = \frac{\partial E}{\partial y_l} \frac{\partial y_l}{\partial z_l} $。同理，下一层也是这么计算，只不过 $ \frac{\partial E}{\partial y_k} $ 计算方法变了，一直反向传播到输入层，最后有 $ \frac{\partial E}{\partial x_i} = \frac{\partial E}{\partial y_j} \frac{\partial y_j}{\partial z_j} $，且 $ \frac{\partial z_j}{\partial x_i} = w_i j $。然后调整这些过程中的权值，再不断进行前向传播和反向传播的过程，最终得到一个比较好的结果； 3.2.2如何计算神经网络的输出？答案来源：零基础入门深度学习(3) - 神经网络和反向传播算法 如上图，输入层有三个节点，我们将其依次编号为 1、2、3；隐藏层的 4 个节点，编号依次为 4、5、6、7；最后输出层的两个节点编号为 8、9。比如，隐藏层的节点 4，它和输入层的三个节点 1、2、3 之间都有连接，其连接上的权重分别为是 $ w_{41}, w_{42}, w_{43} $。 为了计算节点 4 的输出值，我们必须先得到其所有上游节点（也就是节点 1、2、3）的输出值。节点 1、2、3 是输入层的节点，所以，他们的输出值就是输入向量本身。按照上图画出的对应关系，可以看到节点 1、2、3 的输出值分别是 $ x_1, x_2, x_3 $。 $$a_4 = \sigma(w^T \cdot a) = \sigma(w_{41}x_4 + w_{42}x_2 + w_{43}a_3 + w_{4b})$$ 其中 $ w_{4b} $ 是节点 4 的偏置项 同样，我们可以继续计算出节点 5、6、7 的输出值 $ a_5, a_6, a_7 $。 计算输出层的节点 8 的输出值 $ y_1 $： $$y_1 = \sigma(w^T \cdot a) = \sigma(w_{84}a_4 + w_{85}a_5 + w_{86}a_6 + w_{87}a_7 + w_{8b})$$ 其中 $ w_{8b} $ 是节点 8 的偏置项。 同理，我们还可以计算出 $ y_2 $。这样输出层所有节点的输出值计算完毕，我们就得到了在输入向量 $ x_1, x_2, x_3, x_4 $ 时，神经网络的输出向量 $ y_1, y_2 $， 。这里我们也看到，输出向量的维度和输出层神经元个数相同。 3.2.3如何计算卷积神经网络输出值？答案来源：零基础入门深度学习(4) - 卷积神经网络 假设有一个 5*5 的图像，使用一个 3*3 的 filter 进行卷积，想得到一个 3*3 的 Feature Map，如下所示： $ x_{i,j} $ 表示图像第 $ i $ 行第 $ j $ 列元素。$ w_{m,n} $ 表示 filter 第 $ m $ 行第 $ n $ 列权重。 $ w_b $ 表示 filter 的偏置项。 表示 feature map 第 $ i $ 行第 $ j $ 列元素。 $ f $ 表示激活函数，这里以 relu 函数为例。 卷积计算公式如下： $$a_{i,j} = f(\sum_{m=0}^2 \sum_{n=0}^2 w_{m,n} x_{i+m, j+n} + w_b )$$ 当步长为 1 时，计算 feature map 元素 $ a_{0,0} $ 如下： $$a_{0,0} = f(\sum_{m=0}^2 \sum_{n=0}^2 w_{m,n} x_{0+m, 0+n} + w_b ) = relu(w_{0,0} x_{0,0} + w_{0,1} x_{0,1} + w_{0,2} x_{0,2} + w_{1,0} x_{1,0} + w_{1,1} x_{1,1} + w_{1,2} x_{1,2} + w_{2,0} x_{2,0} + w_{2,1} x_{2,1} + w_{2,2} x_{2,2}) \ = 1 + 0 + 1 + 0 + 1 + 0 + 0 + 0 + 1 \ = 4$$ 结果如下： 其计算过程图示如下： 以此类推，计算出全部的Feature Map。 当步幅为 2 时，Feature Map计算如下 注：图像大小、步幅和卷积后的Feature Map大小是有关系的。它们满足下面的关系： $$W_2 = (W_1 - F + 2P)/S + 1H_2 = (H_1 - F + 2P)/S + 1$$ 其中 $ W_2 $， 是卷积后 Feature Map 的宽度；$ W_1 $ 是卷积前图像的宽度；$ F $ 是 filter 的宽度；$ P $ 是 Zero Padding 数量，Zero Padding 是指在原始图像周围补几圈 0，如果 P 的值是 1，那么就补 1 圈 0；S 是步幅；$ H_2 $ 卷积后 Feature Map 的高度；$ H_1 $ 是卷积前图像的宽度。 举例：假设图像宽度 $ W_1 = 5 $，filter 宽度 $ F=3 $，Zero Padding $ P=0 $，步幅 $ S=2 $，$ Z $ 则 $$W_2 = (W_1 - F + 2P)/S + 1 = (5-3+0)/2 + 1 = 2$$ 说明 Feature Map 宽度是2。同样，我们也可以计算出 Feature Map 高度也是 2。 如果卷积前的图像深度为 $ D $，那么相应的 filter 的深度也必须为 $ D $。深度大于 1 的卷积计算公式： $$a_{i,j} = f(\sum_{d=0}^{D-1} \sum_{m=0}^{F-1} \sum_{n=0}^{F-1} w_{d,m,n} x_{d,i+m,j+n} + w_b)$$ 其中，$ D $ 是深度；$ F $ 是 filter 的大小；$ w_{d,m,n} $ 表示 filter 的第 $ d $ 层第 $ m $ 行第 $ n $ 列权重；$ a_{d,i,j} $ 表示 feature map 的第 $ d $ 层第 $ i $ 行第 $ j $ 列像素；其它的符号含义前面相同，不再赘述。 每个卷积层可以有多个 filter。每个 filter 和原始图像进行卷积后，都可以得到一个 Feature Map。卷积后 Feature Map 的深度(个数)和卷积层的 filter 个数是相同的。下面的图示显示了包含两个 filter 的卷积层的计算。7*7*3 输入，经过两个 3*3*3 filter 的卷积(步幅为 2)，得到了 3*3*2 的输出。图中的 Zero padding 是 1，也就是在输入元素的周围补了一圈 0。Zero padding 对于图像边缘部分的特征提取是很有帮助的。 以上就是卷积层的计算方法。这里面体现了局部连接和权值共享：每层神经元只和上一层部分神经元相连(卷积计算规则)，且 filter 的权值对于上一层所有神经元都是一样的。对于包含两个 $ 3 ^ 3 ^ 3 $ 的 fitler 的卷积层来说，其参数数量仅有 $ (3 ^ 3 ^ 3+1) ^ 2 = 56 $ 个，且参数数量与上一层神经元个数无关。与全连接神经网络相比，其参数数量大大减少了。 3.2.4 如何计算 Pooling 层输出值输出值？Pooling 层主要的作用是下采样，通过去掉 Feature Map 中不重要的样本，进一步减少参数数量。Pooling 的方法很多，最常用的是 Max Pooling。Max Pooling 实际上就是在 n*n 的样本中取最大值，作为采样后的样本值。下图是 2*2 max pooling： 除了 Max Pooing 之外，常用的还有 Mean Pooling ——取各样本的平均值。对于深度为 $ D $ 的 Feature Map，各层独立做 Pooling，因此 Pooling 后的深度仍然为 $ D $。 3.2.5 实例理解反向传播答案来源：一文弄懂神经网络中的反向传播法——BackPropagation 一个典型的三层神经网络如下所示： 其中 Layer $ L_1 $ 是输入层，Layer $ L_2 $ 是隐含层，Layer $ L_3 $ 是输出层。 假设输入数据集为 $ D={x_1, x_2, …, x_n} $，输出数据集为 $ y_1, y_2, …, y_n $。 如果输入和输出是一样，即为自编码模型。如果原始数据经过映射，会得到不同与输入的输出。 假设有如下的网络层： 输入层包含神经元 $ i_1, i_2 $，偏置 $ b_1 $；隐含层包含神经元 $ h_1, h_2 $，偏置 $ b_2 $，输出层为 $ o_1, o_2 $，$ w_i $ 为层与层之间连接的权重，激活函数为 sigmoid 函数。对以上参数取初始值，如下图所示： 其中： 输入数据 $ i1=0.05, i2 = 0.10 $ 输出数据 $ o1=0.01, o2=0.99 $; 初始权重 $ w1=0.15, w2=0.20, w3=0.25,w4=0.30, w5=0.40, w6=0.45, w7=0.50, w8=0.55 $ 目标：给出输入数据 $ i1,i2 $ (0.05和0.10)，使输出尽可能与原始输出 $ o1,o2 $，(0.01和0.99)接近。 前向传播 输入层 –&gt; 输出层 计算神经元 $ h1 $ 的输入加权和： $$net_{h1} = w_1 ^ i_1 + w_2 ^ i_2 + b_1 ^ 1 net_{h1} = 0.15 ^ 0.05 + 0.2 ^ 0.1 + 0.35 ^ 1 = 0.3775$$ 神经元 $ h1 $ 的输出 $ o1 $ ：（此处用到激活函数为 sigmoid 函数）： $$out_{h1} = \frac{1}{1 + e^{-net_{h1}}} = \frac{1}{1 + e^{-0.3775}} = 0.593269992$$ 同理，可计算出神经元 $ h2 $ 的输出 $ o1 $： $$out_{h2} = 0.596884378$$ 隐含层–&gt;输出层： 计算输出层神经元 $ o1 $ 和 $ o2 $ 的值： $$net_{o1} = w_5 ^ out_{h1} + w_6 ^ out_{h2} + b_2 ^ 1 net_{o1} = 0.4 ^ 0.593269992 + 0.45 ^ 0.596884378 + 0.6 ^ 1 = 1.105905967 out_{o1} = \frac{1}{1 + e^{-net_{o1}}} = \frac{1}{1 + e^{1.105905967}} = 0.75136079$$ 这样前向传播的过程就结束了，我们得到输出值为 $ [0.75136079 , 0.772928465] $，与实际值 $ [0.01 , 0.99] $ 相差还很远，现在我们对误差进行反向传播，更新权值，重新计算输出。 反向传播 计算总误差 总误差：(square error) $$E_{total} = \sum \frac{1}{2}(target - output)^2$$ 但是有两个输出，所以分别计算 $ o1 $ 和 $ o2 $ 的误差，总误差为两者之和： $E_{o1} = \frac{1}{2}(target_{o1} - out_{o1})^2= \frac{1}{2}(0.01 - 0.75136507)^2 = 0.274811083$ $E_{o2} = 0.023560026$ $E_{total} = E_{o1} + E_{o2} = 0.274811083 + 0.023560026 = 0.298371109$ 隐含层 –&gt; 输出层的权值更新： 以权重参数 $ w5 $ 为例，如果我们想知道 $ w5 $ 对整体误差产生了多少影响，可以用整体误差对 $ w5 $ 求偏导求出：（链式法则） $$\frac{\partial E_{total}}{\partial w5} = \frac{\partial E_{total}}{\partial out_{o1}} ^ \frac{\partial out_{o1}}{\partial net_{o1}} ^ \frac{\partial net_{o1}}{\partial w5}$$ 下面的图可以更直观的看清楚误差是怎样反向传播的： 3.2.6 神经网络更“深”有什么意义？前提：在一定范围内。 在神经元数量相同的情况下，深层网络结构具有更大容量，分层组合带来的是指数级的表达空间，能够组合成更多不同类型的子结构，这样可以更容易地学习和表示各种特征。 隐藏层增加则意味着由激活函数带来的非线性变换的嵌套层数更多，就能构造更复杂的映射关系。 3.3 超参数3.3.1 什么是超参数？超参数:比如算法中的 learning rate （学习率）、iterations (梯度下降法循环的数量)、（隐藏层数目）、（隐藏层单元数目）、choice of activation function（激活函数的选择）都需要根据实际情况来设置，这些数字实际上控制了最后的参数和的值，所以它们被称作超参数。 3.3.2 如何寻找超参数的最优值？在使用机器学习算法时，总有一些难搞的超参数。例如权重衰减大小，高斯核宽度等等。算法不会设置这些参数，而是需要你去设置它们的值。设置的值对结果产生较大影响。常见设置超参数的做法有： 猜测和检查：根据经验或直觉，选择参数，一直迭代。 网格搜索：让计算机尝试在一定范围内均匀分布的一组值。 随机搜索：让计算机随机挑选一组值。 贝叶斯优化：使用贝叶斯优化超参数，会遇到贝叶斯优化算法本身就需要很多的参数的困难。 在良好初始猜测的前提下进行局部优化：这就是 MITIE 的方法，它使用 BOBYQA 算法，并有一个精心选择的起始点。由于 BOBYQA 只寻找最近的局部最优解，所以这个方法是否成功很大程度上取决于是否有一个好的起点。在 MITIE 的情况下，我们知道一个好的起点，但这不是一个普遍的解决方案，因为通常你不会知道好的起点在哪里。从好的方面来说，这种方法非常适合寻找局部最优解。稍后我会再讨论这一点。 最新提出的 LIPO 的全局优化方法。这个方法没有参数，而且经验证比随机搜索方法好。 3.3.3 超参数搜索一般过程？超参数搜索一般过程： 将数据集划分成训练集、验证集及测试集。 在训练集上根据模型的性能指标对模型参数进行优化。 在验证集上根据模型的性能指标对模型的超参数进行搜索。 步骤 2 和步骤 3 交替迭代，最终确定模型的参数和超参数，在测试集中验证评价模型的优劣。 其中，搜索过程需要搜索算法，一般有：网格搜索、随机搜过、启发式智能搜索、贝叶斯搜索。 3.4 激活函数3.4.1 为什么需要非线性激活函数？为什么需要激活函数？ 激活函数对模型学习、理解非常复杂和非线性的函数具有重要作用。 激活函数可以引入非线性因素。如果不使用激活函数，则输出信号仅是一个简单的线性函数。线性函数一个一级多项式，线性方程的复杂度有限，从数据中学习复杂函数映射的能力很小。没有激活函数，神经网络将无法学习和模拟其他复杂类型的数据，例如图像、视频、音频、语音等。 激活函数可以把当前特征空间通过一定的线性映射转换到另一个空间，让数据能够更好的被分类。 为什么激活函数需要非线性函数？ 假若网络中全部是线性部件，那么线性的组合还是线性，与单独一个线性分类器无异。这样就做不到用非线性来逼近任意函数。 使用非线性激活函数 ，以便使网络更加强大，增加它的能力，使它可以学习复杂的事物，复杂的表单数据，以及表示输入输出之间非线性的复杂的任意函数映射。使用非线性激活函数，能够从输入输出之间生成非线性映射。 3.4.2 常见的激活函数及图像 sigmoid 激活函数 函数的定义为：$ f(x) = \frac{1}{1 + e^{-x}} $，其值域为 $ (0,1) $。 函数图像如下： tanh激活函数 函数的定义为：$ f(x) = tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} $，值域为 $ (-1,1) $。 函数图像如下： Relu激活函数 函数的定义为：$ f(x) = max(0, x) $ ，值域为 $ [0,+∞) $； 函数图像如下： Leak Relu 激活函数 函数定义为： $ f(x) = \left{\begin{aligned}ax, \quad x0\end{aligned}\right. $，值域为 $ (-∞,+∞) $。 图像如下（$ a = 0.5 $）： SoftPlus 激活函数 函数的定义为：$ f(x) = ln( 1 + e^x) $，值域为 $ (0,+∞) $。 函数图像如下: softmax 函数 函数定义为： $ \sigma(z)_j = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} $。 Softmax 多用于多分类神经网络输出。 3.4.3 常见激活函数的导数计算？对常见激活函数，导数计算如下： 3.4.4 激活函数有哪些性质？ 非线性： 当激活函数是线性的，一个两层的神经网络就可以基本上逼近所有的函数。但如果激活函数是恒等激活函数的时候，即 $ f(x)=x $，就不满足这个性质，而且如果 MLP 使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的； 可微性： 当优化方法是基于梯度的时候，就体现了该性质； 单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数； $ f(x)≈x $： 当激活函数满足这个性质的时候，如果参数的初始化是随机的较小值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要详细地去设置初始值； 输出值的范围： 当激活函数输出值是有限的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的 Learning Rate。 3.4.5 如何选择激活函数？选择一个适合的激活函数并不容易，需要考虑很多因素，通常的做法是，如果不确定哪一个激活函数效果更好，可以把它们都试试，然后在验证集或者测试集上进行评价。然后看哪一种表现的更好，就去使用它。 以下是常见的选择情况： 如果输出是 0、1 值（二分类问题），则输出层选择 sigmoid 函数，然后其它的所有单元都选择 Relu 函数。 如果在隐藏层上不确定使用哪个激活函数，那么通常会使用 Relu 激活函数。有时，也会使用 tanh 激活函数，但 Relu 的一个优点是：当是负值的时候，导数等于 0。 sigmoid 激活函数：除了输出层是一个二分类问题基本不会用它。 tanh 激活函数：tanh 是非常优秀的，几乎适合所有场合。 ReLu 激活函数：最常用的默认函数，如果不确定用哪个激活函数，就使用 ReLu 或者 Leaky ReLu，再去尝试其他的激活函数。 如果遇到了一些死的神经元，我们可以使用 Leaky ReLU 函数。 3.4.6 使用 ReLu 激活函数的优点？ 在区间变动很大的情况下，ReLu 激活函数的导数或者激活函数的斜率都会远大于 0，在程序实现就是一个 if-else 语句，而 sigmoid 函数需要进行浮点四则运算，在实践中，使用 ReLu 激活函数神经网络通常会比使用 sigmoid 或者 tanh 激活函数学习的更快。 sigmoid 和 tanh 函数的导数在正负饱和区的梯度都会接近于 0，这会造成梯度弥散，而 Relu 和Leaky ReLu 函数大于 0 部分都为常数，不会产生梯度弥散现象。 需注意，Relu 进入负半区的时候，梯度为 0，神经元此时不会训练，产生所谓的稀疏性，而 Leaky ReLu 不会产生这个问题。 3.4.7什么时候可以用线性激活函数？ 输出层，大多使用线性激活函数。 在隐含层可能会使用一些线性激活函数。 一般用到的线性激活函数很少。 3.4.8 怎样理解 Relu（&lt; 0 时）是非线性激活函数？Relu 激活函数图像如下： 根据图像可看出具有如下特点： 单侧抑制； 相对宽阔的兴奋边界； 稀疏激活性； ReLU 函数从图像上看，是一个分段线性函数，把所有的负值都变为 0，而正值不变，这样就成为单侧抑制。 因为有了这单侧抑制，才使得神经网络中的神经元也具有了稀疏激活性。 稀疏激活性：从信号方面来看，即神经元同时只对输入信号的少部分选择性响应，大量信号被刻意的屏蔽了，这样可以提高学习的精度，更好更快地提取稀疏特征。当 $ x0 $ 时，则不存在饱和问题。ReLU 能够在 $ x&gt;0 $ 时保持梯度不衰减，从而缓解梯度消失问题。 3.4.9 Softmax 函数如何应用于多分类？softmax 用于多分类过程中，它将多个神经元的输出，映射到 $ (0,1) $ 区间内，可以看成概率来理解，从而来进行多分类！ 假设我们有一个数组，$ V_i $ 表示 $ V $ 中的第 $ i $ 个元素，那么这个元素的 softmax 值就是 $$S_i = \frac{e^{V_i}}{\sum_j e^{V_j}}$$ 从下图看，神经网络中包含了输入层，然后通过两个特征层处理，最后通过 softmax 分析器就能得到不同条件下的概率，这里需要分成三个类别，最终会得到 $ y=0, y=1, y=2 $ 的概率值。 继续看下面的图，三个输入通过 softmax 后得到一个数组 $ [0.05 , 0.10 , 0.85] $，这就是 soft 的功能。 更形象的映射过程如下图所示： softmax 直白来说就是将原来输出是 $ 3,1,-3 $ 通过 softmax 函数一作用，就映射成为 $ (0,1) $ 的值，而这些值的累和为 $ 1 $（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标！ 3.4.10 交叉熵代价函数定义及其求导推导。神经元的输出就是 a = σ(z)，其中$z=\sum w_{j}i_{j}+b$是输⼊的带权和。 $C=-\frac{1}{n}\sum[ylna+(1-y)ln(1-a)]$ 其中 n 是训练数据的总数，求和是在所有的训练输⼊ x 上进⾏的， y 是对应的⽬标输出。 表达式是否解决学习缓慢的问题并不明显。实际上，甚⾄将这个定义看做是代价函数也不是显⽽易⻅的！在解决学习缓慢前，我们来看看交叉熵为何能够解释成⼀个代价函数。 将交叉熵看做是代价函数有两点原因。 第⼀，它是⾮负的， C &gt; 0。可以看出：式子中的求和中的所有独⽴的项都是负数的，因为对数函数的定义域是 (0，1)，并且求和前⾯有⼀个负号，所以结果是非负。 第⼆，如果对于所有的训练输⼊ x，神经元实际的输出接近⽬标值，那么交叉熵将接近 0。 假设在这个例⼦中， y = 0 ⽽ a ≈ 0。这是我们想到得到的结果。我们看到公式中第⼀个项就消去了，因为 y = 0，⽽第⼆项实际上就是 − ln(1 − a) ≈ 0。反之， y = 1 ⽽ a ≈ 1。所以在实际输出和⽬标输出之间的差距越⼩，最终的交叉熵的值就越低了。（这里假设输出结果不是0，就是1，实际分类也是这样的） 综上所述，交叉熵是⾮负的，在神经元达到很好的正确率的时候会接近 0。这些其实就是我们想要的代价函数的特性。其实这些特性也是⼆次代价函数具备的。所以，交叉熵就是很好的选择了。但是交叉熵代价函数有⼀个⽐⼆次代价函数更好的特性就是它避免了学习速度下降的问题。为了弄清楚这个情况，我们来算算交叉熵函数关于权重的偏导数。我们将$a={\varsigma}(z)$代⼊到 公式中应⽤两次链式法则，得到： $\begin{eqnarray}\frac{\partial C}{\partial w_{j}}&amp;=&amp;-\frac{1}{n}\sum \frac{\partial }{\partial w_{j}}[ylna+(1-y)ln(1-a)]\&amp;=&amp;-\frac{1}{n}\sum \frac{\partial }{\partial a}[ylna+(1-y)ln(1-a)]\frac{\partial a}{\partial w_{j}}\&amp;=&amp;-\frac{1}{n}\sum (\frac{y}{a}-\frac{1-y}{1-a})\frac{\partial a}{\partial w_{j}}\&amp;=&amp;-\frac{1}{n}\sum (\frac{y}{\varsigma(z)}-\frac{1-y}{1-\varsigma(z)})\frac{\partial \varsigma(z)}{\partial w_{j}}\&amp;=&amp;-\frac{1}{n}\sum (\frac{y}{\varsigma(z)}-\frac{1-y}{1-\varsigma(z)}){\varsigma}’(z)x_{j}\end{eqnarray}$ 根据$\varsigma(z)=\frac{1}{1+e^{-z}}$ 的定义，和⼀些运算，我们可以得到 ${\varsigma}’(z)=\varsigma(z)(1-\varsigma(z))$。化简后可得： $\frac{\partial C}{\partial w_{j}}=\frac{1}{n}\sum x_{j}({\varsigma}(z)-y)$ 这是⼀个优美的公式。它告诉我们权重学习的速度受到$\varsigma(z)-y$，也就是输出中的误差的控制。更⼤的误差，更快的学习速度。这是我们直觉上期待的结果。特别地，这个代价函数还避免了像在⼆次代价函数中类似⽅程中${\varsigma}’(z)$导致的学习缓慢。当我们使⽤交叉熵的时候，${\varsigma}’(z)$被约掉了，所以我们不再需要关⼼它是不是变得很⼩。这种约除就是交叉熵带来的特效。实际上，这也并不是⾮常奇迹的事情。我们在后⾯可以看到，交叉熵其实只是满⾜这种特性的⼀种选择罢了。 根据类似的⽅法，我们可以计算出关于偏置的偏导数。我这⾥不再给出详细的过程，你可以轻易验证得到： $\frac{\partial C}{\partial b}=\frac{1}{n}\sum ({\varsigma}(z)-y)$ 再⼀次, 这避免了⼆次代价函数中类似${\varsigma}’(z)$项导致的学习缓慢。 3.4.11 为什么Tanh收敛速度比Sigmoid快？$tanh^{,}(x)=1-tanh(x)^{2}\in (0,1)$ $s^{,}(x)=s(x)*(1-s(x))\in (0,\frac{1}{4}]$ 由上面两个公式可知tanh(x)梯度消失的问题比sigmoid轻，所以Tanh收敛速度比Sigmoid快。 3.5 Batch_Size3.5.1 为什么需要 Batch_Size？Batch的选择，首先决定的是下降的方向。 如果数据集比较小，可采用全数据集的形式，好处是： 由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。 由于不同权重的梯度值差别巨大，因此选取一个全局的学习率很困难。 Full Batch Learning 可以使用 Rprop 只基于梯度符号并且针对性单独更新各权值。 对于更大的数据集，假如采用全数据集的形式，坏处是： 随着数据集的海量增长和内存限制，一次性载入所有的数据进来变得越来越不可行。 以 Rprop 的方式迭代，会由于各个 Batch 之间的采样差异性，各次梯度修正值相互抵消，无法修正。这才有了后来 RMSProp 的妥协方案。 3.5.2 Batch_Size 值的选择假如每次只训练一个样本，即 Batch_Size = 1。线性神经元在均方误差代价函数的错误面是一个抛物面，横截面是椭圆。对于多层神经元、非线性网络，在局部依然近似是抛物面。此时，每次修正方向以各自样本的梯度方向修正，横冲直撞各自为政，难以达到收敛。 既然 Batch_Size 为全数据集或者Batch_Size = 1都有各自缺点，可不可以选择一个适中的Batch_Size值呢？ 此时，可采用批梯度下降法（Mini-batches Learning）。因为如果数据集足够充分，那么用一半（甚至少得多）的数据训练算出来的梯度与用全部数据训练出来的梯度是几乎一样的。 3.5.3 在合理范围内，增大Batch_Size有何好处？ 内存利用率提高了，大矩阵乘法的并行化效率提高。 跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。 在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。 3.5.4 盲目增大 Batch_Size 有何坏处？ 内存利用率提高了，但是内存容量可能撑不住了。 跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。 Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。 3.5.5 调节 Batch_Size 对训练效果影响到底如何？ Batch_Size 太小，模型表现效果极其糟糕(error飙升)。 随着 Batch_Size 增大，处理相同数据量的速度越快。 随着 Batch_Size 增大，达到相同精度所需要的 epoch 数量越来越多。 由于上述两种因素的矛盾， Batch_Size 增大到某个时候，达到时间上的最优。 由于最终收敛精度会陷入不同的局部极值，因此 Batch_Size 增大到某些时候，达到最终收敛精度上的最优。 3.5.6 受限于客观条件无法给足够的Batch Size怎么办？在极小的情况下（低于十），建议使用Group Norm。 3.6 归一化3.6.1 归一化含义？归一化的具体作用是归纳统一样本的统计分布性。归一化在 $ 0-1$ 之间是统计的概率分布，归一化在$ -1–+1$ 之间是统计的坐标分布。归一化有同一、统一和合一的意思。无论是为了建模还是为了计算，首先基本度量单位要同一，神经网络是以样本在事件中的统计分别几率来进行训练（概率计算）和预测的，且 sigmoid 函数的取值是 0 到 1 之间的，网络最后一个节点的输出也是如此，所以经常要对样本的输出归一化处理。归一化是统一在 $ 0-1 $ 之间的统计概率分布，当所有样本的输入信号都为正值时，与第一隐含层神经元相连的权值只能同时增加或减小，从而导致学习速度很慢。另外在数据中常存在奇异样本数据，奇异样本数据存在所引起的网络训练时间增加，并可能引起网络无法收敛。为了避免出现这种情况及后面数据处理的方便，加快网络学习速度，可以对输入信号进行归一化，使得所有样本的输入信号其均值接近于 0 或与其均方差相比很小。 3.6.2 为什么要归一化？ 为了后面数据处理的方便，归一化的确可以避免一些不必要的数值问题。 为了程序运行时收敛加快。 下面图解。 同一量纲。样本数据的评价标准不一样，需要对其量纲化，统一评价标准。这算是应用层面的需求。 避免神经元饱和。啥意思？就是当神经元的激活在接近 0 或者 1 时会饱和，在这些区域，梯度几乎为 0，这样，在反向传播过程中，局部梯度就会接近 0，这会有效地“杀死”梯度。 保证输出数据中数值小的不被吞食。 3.6.3 为什么归一化能提高求解最优解速度？ 上图是代表数据是否均一化的最优解寻解过程（圆圈可以理解为等高线）。左图表示未经归一化操作的寻解过程，右图表示经过归一化后的寻解过程。 当使用梯度下降法寻求最优解时，很有可能走“之字型”路线（垂直等高线走），从而导致需要迭代很多次才能收敛；而右图对两个原始特征进行了归一化，其对应的等高线显得很圆，在梯度下降进行求解时能较快的收敛。 因此如果机器学习模型使用梯度下降法求最优解时，归一化往往非常有必要，否则很难收敛甚至不能收敛。 3.6.4 3D 图解未归一化例子： 假设 $ w1 $ 的范围在 $ [-10, 10] $，而 $ w2 $ 的范围在 $ [-100, 100] $，梯度每次都前进 1 单位，那么在 $ w1 $ 方向上每次相当于前进了 $ 1/20 $，而在 $ w2 $ 上只相当于 $ 1/200 $！某种意义上来说，在 $ w2 $ 上前进的步长更小一些,而 $ w1 $ 在搜索过程中会比 $ w2 $ “走”得更快。 这样会导致，在搜索过程中更偏向于 $ w1 $ 的方向。走出了“L”形状，或者成为“之”字形。 3.6.5 归一化有哪些类型？ 线性归一化 $$x^{\prime} = \frac{x-min(x)}{max(x) - min(x)}$$ 适用范围：比较适用在数值比较集中的情况。 缺点：如果 max 和 min 不稳定，很容易使得归一化结果不稳定，使得后续使用效果也不稳定。 标准差标准化 $$x^{\prime} = \frac{x-\mu}{\sigma}$$ 含义：经过处理的数据符合标准正态分布，即均值为 0，标准差为 1 其中 $ \mu $ 为所有样本数据的均值，$ \sigma $ 为所有样本数据的标准差。 非线性归一化 适用范围：经常用在数据分化比较大的场景，有些数值很大，有些很小。通过一些数学函数，将原始值进行映射。该方法包括 $ log $、指数，正切等。 3.6.6 局部响应归一化作用LRN 是一种提高深度学习准确度的技术方法。LRN 一般是在激活、池化函数后的一种方法。 在 ALexNet 中，提出了 LRN 层，对局部神经元的活动创建竞争机制，使其中响应比较大对值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。 3.6.7理解局部响应归一化公式答案来源：深度学习的局部响应归一化LRN(Local Response Normalization)理解 局部响应归一化原理是仿造生物学上活跃的神经元对相邻神经元的抑制现象（侧抑制），根据论文其公式如下： $$b_{x,y}^i = a_{x,y}^i / (k + \alpha \sum_{j=max(0, i-n/2)}^{min(N-1, i+n/2)}(a_{x,y}^j)^2 )^\beta$$ 其中，1) $ a $：表示卷积层（包括卷积操作和池化操作）后的输出结果，是一个四维数组[batch,height,width,channel]。 batch：批次数(每一批为一张图片)。 height：图片高度。 width：图片宽度。 channel：通道数。可以理解成一批图片中的某一个图片经过卷积操作后输出的神经元个数，或理解为处理后的图片深度。 2) $ a_{x,y}^i $ 表示在这个输出结构中的一个位置 $ [a,b,c,d] $，可以理解成在某一张图中的某一个通道下的某个高度和某个宽度位置的点，即第 $ a $ 张图的第 $ d $ 个通道下的高度为b宽度为c的点。 3) $ N $：论文公式中的 $ N $ 表示通道数 (channel)。 4) $ a $，$ n/2 $， $ k $ 分别表示函数中的 input,depth_radius,bias。参数 $ k, n, \alpha, \beta $ 都是超参数，一般设置 $ k=2, n=5, \alpha=1^e-4, \beta=0.75 $ 5) $ \sum $：$ \sum $ 叠加的方向是沿着通道方向的，即每个点值的平方和是沿着 $ a $ 中的第 3 维 channel 方向的，也就是一个点同方向的前面 $ n/2 $ 个通道（最小为第 $ 0 $ 个通道）和后 $ n/2 $ 个通道（最大为第 $ d-1 $ 个通道）的点的平方和(共 $ n+1 $ 个点)。而函数的英文注解中也说明了把 input 当成是 $ d $ 个 3 维的矩阵，说白了就是把 input 的通道数当作 3 维矩阵的个数，叠加的方向也是在通道方向。 简单的示意图如下： 3.6.8 什么是批归一化（Batch Normalization）以前在神经网络训练中，只是对输入层数据进行归一化处理，却没有在中间层进行归一化处理。要知道，虽然我们对输入数据进行了归一化处理，但是输入数据经过 $ \sigma(WX+b) $ 这样的矩阵乘法以及非线性运算之后，其数据分布很可能被改变，而随着深度网络的多层运算之后，数据分布的变化将越来越大。如果我们能在网络的中间也进行归一化处理，是否对网络的训练起到改进作用呢？答案是肯定的。 这种在神经网络中间层也进行归一化处理，使训练效果更好的方法，就是批归一化Batch Normalization（BN）。 3.6.9 批归一化（BN）算法的优点下面我们来说一下BN算法的优点： 减少了人为选择参数。在某些情况下可以取消 dropout 和 L2 正则项参数,或者采取更小的 L2 正则项约束参数； 减少了对学习率的要求。现在我们可以使用初始很大的学习率或者选择了较小的学习率，算法也能够快速训练收敛； 可以不再使用局部响应归一化。BN 本身就是归一化网络(局部响应归一化在 AlexNet 网络中存在) 破坏原来的数据分布，一定程度上缓解过拟合（防止每批训练中某一个样本经常被挑选到，文献说这个可以提高 1% 的精度）。 减少梯度消失，加快收敛速度，提高训练精度。 3.6.10 批归一化（BN）算法流程下面给出 BN 算法在训练时的过程 输入：上一层输出结果 $ X = {x_1, x_2, …, x_m} $，学习参数 $ \gamma, \beta $ 算法流程： 计算上一层输出数据的均值 $$\mu_{\beta} = \frac{1}{m} \sum_{i=1}^m(x_i)$$ 其中，$ m $ 是此次训练样本 batch 的大小。 计算上一层输出数据的标准差 $$\sigma_{\beta}^2 = \frac{1}{m} \sum_{i=1}^m (x_i - \mu_{\beta})^2$$ 归一化处理，得到 $$\hat x_i = \frac{x_i + \mu_{\beta}}{\sqrt{\sigma_{\beta}^2} + \epsilon}$$ 其中 $ \epsilon $ 是为了避免分母为 0 而加进去的接近于 0 的很小值 重构，对经过上面归一化处理得到的数据进行重构，得到 $$y_i = \gamma \hat x_i + \beta$$ 其中，$ \gamma, \beta $ 为可学习参数。 注：上述是 BN 训练时的过程，但是当在投入使用时，往往只是输入一个样本，没有所谓的均值 $ \mu_{\beta} $ 和标准差 $ \sigma_{\beta}^2 $。此时，均值 $ \mu_{\beta} $ 是计算所有 batch $ \mu_{\beta} $ 值的平均值得到，标准差 $ \sigma_{\beta}^2 $ 采用每个batch $ \sigma_{\beta}^2 $ 的无偏估计得到。 3.6.11 批归一化和群组归一化批量归一化（Batch Normalization，以下简称 BN）是深度学习发展中的一项里程碑式技术，可让各种网络并行训练。但是，批量维度进行归一化会带来一些问题——批量统计估算不准确导致批量变小时，BN 的误差会迅速增加。在训练大型网络和将特征转移到计算机视觉任务中（包括检测、分割和视频），内存消耗限制了只能使用小批量的 BN。 何恺明团队在群组归一化（Group Normalization） 中提出群组归一化 Group Normalization (简称 GN) 作为 BN 的替代方案。 GN 将通道分成组，并在每组内计算归一化的均值和方差。GN 的计算与批量大小无关，并且其准确度在各种批量大小下都很稳定。在 ImageNet 上训练的 ResNet-50上，GN 使用批量大小为 2 时的错误率比 BN 的错误率低 10.6％ ;当使用典型的批量时，GN 与 BN 相当，并且优于其他标归一化变体。而且，GN 可以自然地从预训练迁移到微调。在进行 COCO 中的目标检测和分割以及 Kinetics 中的视频分类比赛中，GN 可以胜过其竞争对手，表明 GN 可以在各种任务中有效地取代强大的 BN。 3.6.12 Weight Normalization和Batch Normalization答案来源：Weight Normalization 相比batch Normalization 有什么优点呢？ Weight Normalization 和 Batch Normalization 都属于参数重写（Reparameterization）的方法，只是采用的方式不同，Weight Normalization 是对网络权值$ W $ 进行 normalization，因此也称为 Weight Normalization；Batch Normalization 是对网络某一层输入数据进行 normalization。Weight Normalization相比Batch Normalization有以下三点优势： Weight Normalization 通过重写深度学习网络的权重W的方式来加速深度学习网络参数收敛，没有引入 minbatch 的依赖，适用于 RNN（LSTM）网络（Batch Normalization 不能直接用于RNN，进行 normalization 操作，原因在于：1) RNN 处理的 Sequence 是变长的；2) RNN 是基于 time step 计算，如果直接使用 Batch Normalization 处理，需要保存每个 time step 下，mini btach 的均值和方差，效率低且占内存）。 Batch Normalization 基于一个 mini batch 的数据计算均值和方差，而不是基于整个 Training set 来做，相当于进行梯度计算式引入噪声。因此，Batch Normalization 不适用于对噪声敏感的强化学习、生成模型（Generative model：GAN，VAE）使用。相反，Weight Normalization 对通过标量 $ g $ 和向量 $ v $ 对权重 $ W $ 进行重写，重写向量 $ v $ 是固定的，因此，基于 Weight Normalization 的 Normalization 可以看做比 Batch Normalization 引入更少的噪声。 不需要额外的存储空间来保存 mini batch 的均值和方差，同时实现 Weight Normalization 时，对深度学习网络进行正向信号传播和反向梯度计算带来的额外计算开销也很小。因此，要比采用 Batch Normalization 进行 normalization 操作时，速度快。 但是 Weight Normalization 不具备 Batch Normalization 把网络每一层的输出 Y 固定在一个变化范围的作用。因此，采用 Weight Normalization 进行 Normalization 时需要特别注意参数初始值的选择。 3.6.13 Batch Normalization在什么时候用比较合适？在CNN中，BN应作用在非线性映射前。在神经网络训练时遇到收敛速度很慢，或梯度爆炸等无法训练的状况时可以尝试BN来解决。另外，在一般使用情况下也可以加入BN来加快训练速度，提高模型精度。 BN比较适用的场景是：每个mini-batch比较大，数据分布比较接近。在进行训练之前，要做好充分的shuffle，否则效果会差很多。另外，由于BN需要在运行过程中统计每个mini-batch的一阶统计量和二阶统计量，因此不适用于动态的网络结构和RNN网络。 3.7 预训练与微调(fine tuning)3.7.1 为什么无监督预训练可以帮助深度学习？答案来源：为什么无监督的预训练可以帮助深度学习 深度网络存在问题: 网络越深，需要的训练样本数越多。若用监督则需大量标注样本，不然小规模样本容易造成过拟合。深层网络特征比较多，会出现的多特征问题主要有多样本问题、规则化问题、特征选择问题。 多层神经网络参数优化是个高阶非凸优化问题，经常得到收敛较差的局部解； 梯度扩散问题，BP算法计算出的梯度随着深度向前而显著下降，导致前面网络参数贡献很小，更新速度慢。 解决方法： 逐层贪婪训练，无监督预训练（unsupervised pre-training）即训练网络的第一个隐藏层，再训练第二个…最后用这些训练好的网络参数值作为整体网络参数的初始值。 经过预训练最终能得到比较好的局部最优解。 3.7.2 什么是模型微调fine tuning用别人的参数、修改后的网络和自己的数据进行训练，使得参数适应自己的数据，这样一个过程，通常称之为微调（fine tuning). 模型的微调举例说明： 我们知道，CNN 在图像识别这一领域取得了巨大的进步。如果想将 CNN 应用到我们自己的数据集上，这时通常就会面临一个问题：通常我们的 dataset 都不会特别大，一般不会超过 1 万张，甚至更少，每一类图片只有几十或者十几张。这时候，直接应用这些数据训练一个网络的想法就不可行了，因为深度学习成功的一个关键性因素就是大量带标签数据组成的训练集。如果只利用手头上这点数据，即使我们利用非常好的网络结构，也达不到很高的 performance。这时候，fine-tuning 的思想就可以很好解决我们的问题：我们通过对 ImageNet 上训练出来的模型（如CaffeNet,VGGNet,ResNet) 进行微调，然后应用到我们自己的数据集上。 3.7.3 微调时候网络参数是否更新？会更新。 finetune 的过程相当于继续训练，跟直接训练的区别是初始化的时候。 直接训练是按照网络定义指定的方式初始化。 finetune是用你已经有的参数文件来初始化。 3.7.4 fine-tuning 模型的三种状态 状态一：只预测，不训练。特点：相对快、简单，针对那些已经训练好，现在要实际对未知数据进行标注的项目，非常高效； 状态二：训练，但只训练最后分类层。特点：fine-tuning的模型最终的分类以及符合要求，现在只是在他们的基础上进行类别降维。 状态三：完全训练，分类层+之前卷积层都训练特点：跟状态二的差异很小，当然状态三比较耗时和需要训练GPU资源，不过非常适合fine-tuning到自己想要的模型里面，预测精度相比状态二也提高不少。 3.8 权重偏差初始化3.8.1 全都初始化为 0偏差初始化陷阱： 都初始化为 0。 产生陷阱原因：因为并不知道在训练神经网络中每一个权重最后的值，但是如果进行了恰当的数据归一化后，我们可以有理由认为有一半的权重是正的，另一半是负的。令所有权重都初始化为 0，如果神经网络计算出来的输出值是一样的，神经网络在进行反向传播算法计算出来的梯度值也一样，并且参数更新值也一样。更一般地说，如果权重初始化为同一个值，网络就是对称的。 形象化理解：在神经网络中考虑梯度下降的时候，设想你在爬山，但身处直线形的山谷中，两边是对称的山峰。由于对称性，你所在之处的梯度只能沿着山谷的方向，不会指向山峰；你走了一步之后，情况依然不变。结果就是你只能收敛到山谷中的一个极大值，而走不到山峰上去。 3.8.2 全都初始化为同样的值偏差初始化陷阱： 都初始化为一样的值。以一个三层网络为例：首先看下结构 它的表达式为： $$a_1^{(2)} = f(W_{11}^{(1)} x_1 + W_{12}^{(1)} x_2 + W_{13}^{(1)} x_3 + b_1^{(1)}) a_2^{(2)} = f(W_{21}^{(1)} x_1 + W_{22}^{(1)} x_2 + W_{23}^{(1)} x_3 + b_2^{(1)}) a_3^{(2)} = f(W_{31}^{(1)} x_1 + W_{32}^{(1)} x_2 + W_{33}^{(1)} x_3 + b_3^{(1)}) h_{W,b}(x) = a_1^{(3)} = f(W_{11}^{(2)} a_1^{(2)} + W_{12}^{(2)} a_2^{(2)} + W_{13}^{(2)} a_3^{(2)} + b_1^{(2)})$$ 如果每个权重都一样，那么在多层网络中，从第二层开始，每一层的输入值都是相同的了也就是$ a1=a2=a3=…. $，既然都一样，就相当于一个输入了，为啥呢？？ 如果是反向传递算法（如果这里不明白请看上面的连接），其中的偏置项和权重项的迭代的偏导数计算公式如下 $$\frac{\partial}{\partial W_{ij}^{(l)}} J(W,b;x,y) = a_j^{(l)} \delta_i^{(l+1)} \frac{\partial}{\partial b_{i}^{(l)}} J(W,b;x,y) = \delta_i^{(l+1)}$$ $ \delta $ 的计算公式 $$\delta_i^{(l)} = (\sum_{j=1}^{s_{t+1}} W_{ji}^{(l)} \delta_j^{(l+1)} ) f^{\prime}(z_i^{(l)})$$ 如果用的是 sigmoid 函数 $$f^{\prime}(z_i^{(l)}) = a_i^{(l)}(1-a_i^{(l)})$$ 把后两个公式代入，可以看出所得到的梯度下降法的偏导相同，不停的迭代，不停的相同，不停的迭代，不停的相同……，最后就得到了相同的值（权重和截距）。 3.8.3 初始化为小的随机数将权重初始化为很小的数字是一个普遍的打破网络对称性的解决办法。这个想法是，神经元在一开始都是随机的、独一无二的，所以它们会计算出不同的更新，并将自己整合到整个网络的各个部分。一个权重矩阵的实现可能看起来像 $ W=0.01∗np.random.randn(D,H) $，其中 randn 是从均值为 0 的单位标准高斯分布进行取样。通过这个公式(函数)，每个神经元的权重向量初始化为一个从多维高斯分布取样的随机向量，所以神经元在输入空间中指向随机的方向(so the neurons point in random direction in the input space). 应该是指输入空间对于随机方向有影响)。其实也可以从均匀分布中来随机选取小数，但是在实际操作中看起来似乎对最后的表现并没有太大的影响。 备注：警告：并不是数字越小就会表现的越好。比如，如果一个神经网络层的权重非常小，那么在反向传播算法就会计算出很小的梯度(因为梯度 gradient 是与权重成正比的)。在网络不断的反向传播过程中将极大地减少“梯度信号”，并可能成为深层网络的一个需要注意的问题。 3.8.4 用 $ 1/\sqrt n $ 校准方差上述建议的一个问题是，随机初始化神经元的输出的分布有一个随输入量增加而变化的方差。结果证明，我们可以通过将其权重向量按其输入的平方根(即输入的数量)进行缩放，从而将每个神经元的输出的方差标准化到 1。也就是说推荐的启发式方法 (heuristic) 是将每个神经元的权重向量按下面的方法进行初始化: $ w=np.random.randn(n)/\sqrt n $，其中 n 表示输入的数量。这保证了网络中所有的神经元最初的输出分布大致相同，并在经验上提高了收敛速度。 3.8.5 稀疏初始化(Sparse Initialazation)另一种解决未校准方差问题的方法是把所有的权重矩阵都设为零，但是为了打破对称性，每个神经元都是随机连接地(从如上面所介绍的一个小的高斯分布中抽取权重)到它下面的一个固定数量的神经元。一个典型的神经元连接的数目可能是小到 10 个。 3.8.6 初始化偏差将偏差初始化为零是可能的，也是很常见的，因为非对称性破坏是由权重的小随机数导致的。因为 ReLU 具有非线性特点，所以有些人喜欢使用将所有的偏差设定为小的常数值如 0.01，因为这样可以确保所有的 ReLU 单元在最开始就激活触发(fire)并因此能够获得和传播一些梯度值。然而，这是否能够提供持续的改善还不太清楚(实际上一些结果表明这样做反而使得性能更加糟糕)，所以更通常的做法是简单地将偏差初始化为 0. 3.9 Softmax3.9.1 Softmax 定义及作用Softmax 是一种形如下式的函数： $$P(i) = \frac{exp(\theta_i^T x)}{\sum_{k=1}^{K} exp(\theta_i^T x)}$$ 其中，$ \theta_i $ 和 $ x $ 是列向量，$ \theta_i^T x $ 可能被换成函数关于 $ x $ 的函数 $ f_i(x) $ 通过 softmax 函数，可以使得 $ P(i) $ 的范围在 $ [0,1] $ 之间。在回归和分类问题中，通常 $ \theta $ 是待求参数，通过寻找使得 $ P(i) $ 最大的 $ \theta_i $ 作为最佳参数。 但是，使得范围在 $ [0,1] $ 之间的方法有很多，为啥要在前面加上以 $ e $ 的幂函数的形式呢？参考 logistic 函数： $$P(i) = \frac{1}{1+exp(-\theta_i^T x)}$$ 这个函数的作用就是使得 $ P(i) $ 在负无穷到 0 的区间趋向于 0， 在 0 到正无穷的区间趋向 1,。同样 softmax 函数加入了 $ e $ 的幂函数正是为了两极化：正样本的结果将趋近于 1，而负样本的结果趋近于 0。这样为多类别提供了方便（可以把 $ P(i) $ 看做是样本属于类别的概率）。可以说，Softmax 函数是 logistic 函数的一种泛化。 softmax 函数可以把它的输入，通常被称为 logits 或者 logit scores，处理成 0 到 1 之间，并且能够把输出归一化到和为 1。这意味着 softmax 函数与分类的概率分布等价。它是一个网络预测多酚类问题的最佳输出激活函数。 3.9.2 Softmax 推导3.10 理解 One Hot Encodeing 原理及作用？问题由来 在很多机器学习任务中，特征并不总是连续值，而有可能是分类值。 例如，考虑一下的三个特征： 12[&quot;male&quot;, &quot;female&quot;] [&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;][&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;] 如果将上述特征用数字表示，效率会高很多。例如： 12[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;] 表示为 [0, 1, 3][&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;] 表示为 [1, 2, 1] 但是，即使转化为数字表示后，上述数据也不能直接用在我们的分类器中。因为，分类器往往默认数据数据是连续的（可以计算距离？），并且是有序的（而上面这个 0 并不是说比 1 要高级）。但是，按照我们上述的表示，数字并不是有序的，而是随机分配的。 独热编码 为了解决上述问题，其中一种可能的解决方法是采用独热编码（One-Hot Encoding）。独热编码即 One-Hot 编码，又称一位有效编码，其方法是使用N位状态寄存器来对 N 个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候，其中只有一位有效。 例如： 12自然状态码为：000,001,010,011,100,101独热编码为：000001,000010,000100,001000,010000,100000 可以这样理解，对于每一个特征，如果它有 m 个可能值，那么经过独热编码后，就变成了 m 个二元特征（如成绩这个特征有好，中，差变成 one-hot 就是 100, 010, 001）。并且，这些特征互斥，每次只有一个激活。因此，数据会变成稀疏的。 这样做的好处主要有： 解决了分类器不好处理属性数据的问题； 在一定程度上也起到了扩充特征的作用。 3.11 常用的优化器有哪些分别列举 1234567891011Optimizer：tf.train.GradientDescentOptimizertf.train.AdadeltaOptimizertf.train.AdagradOptimizertf.train.AdagradDAOptimizertf.train.MomentumOptimizertf.train.AdamOptimizertf.train.FtrlOptimizertf.train.ProximalGradientDescentOptimizertf.train.ProximalAdagradOptimizertf.train.RMSPropOptimizer 3.12 Dropout 系列问题3.12.1 为什么要正则化？ 深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于避免过拟合或减少你的网络误差。 如果你怀疑神经网络过度拟合了数据，即存在高方差问题，那么最先想到的方法可能是正则化，另一个解决高方差的方法就是准备更多数据，这也是非常可靠的办法，但你可能无法时时准备足够多的训练数据，或者，获取更多数据的成本很高，但正则化有助于避免过度拟合，或者减少网络误差。 3.12.2 为什么正则化有利于预防过拟合？ 左图是高偏差，右图是高方差，中间是Just Right，这几张图我们在前面课程中看到过。 3.12.3 理解dropout正则化Dropout可以随机删除网络中的神经单元，它为什么可以通过正则化发挥如此大的作用呢？ 直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施dropout的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；L2对不同权重的衰减是不同的，它取决于激活函数倍增的大小。 3.12.4 dropout率的选择 经过交叉验证，隐含节点 dropout 率等于 0.5 的时候效果最好，原因是 0.5 的时候 dropout 随机生成的网络结构最多。 dropout 也可以被用作一种添加噪声的方法，直接对 input 进行操作。输入层设为更接近 1 的数。使得输入变化不会太大（0.8） 对参数 $ w $ 的训练进行球形限制 (max-normalization)，对 dropout 的训练非常有用。 球形半径 $ c $ 是一个需要调整的参数，可以使用验证集进行参数调优。 dropout 自己虽然也很牛，但是 dropout、max-normalization、large decaying learning rates and high momentum 组合起来效果更好，比如 max-norm regularization 就可以防止大的learning rate 导致的参数 blow up。 使用 pretraining 方法也可以帮助 dropout 训练参数，在使用 dropout 时，要将所有参数都乘以 $ 1/p $。 3.12.5 dropout有什么缺点？dropout一大缺点就是代价函数J不再被明确定义，每次迭代，都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。定义明确的代价函数J每次迭代后都会下降，因为我们所优化的代价函数J实际上并没有明确定义，或者说在某种程度上很难计算，所以我们失去了调试工具来绘制这样的图片。我通常会关闭dropout函数，将keep-prob的值设为1，运行代码，确保J函数单调递减。然后打开dropout函数，希望在dropout过程中，代码并未引入bug。我觉得你也可以尝试其它方法，虽然我们并没有关于这些方法性能的数据统计，但你可以把它们与dropout方法一起使用。 3.13 深度学习中常用的数据增强方法（Data Augmentation）？（贡献者：黄钦建－华南理工大学） Color Jittering：对颜色的数据增强：图像亮度、饱和度、对比度变化（此处对色彩抖动的理解不知是否得当）； PCA Jittering：首先按照RGB三个颜色通道计算均值和标准差，再在整个训练集上计算协方差矩阵，进行特征分解，得到特征向量和特征值，用来做PCA Jittering； Random Scale：尺度变换； Random Crop：采用随机图像差值方式，对图像进行裁剪、缩放；包括Scale Jittering方法（VGG及ResNet模型使用）或者尺度和长宽比增强变换； Horizontal/Vertical Flip：水平/垂直翻转； Shift：平移变换； Rotation/Reflection：旋转/仿射变换； Noise：高斯噪声、模糊处理； Label Shuffle：类别不平衡数据的增广； 3.14 如何理解 Internal Covariate Shift？（贡献者：黄钦建－华南理工大学）深度神经网络模型的训练为什么会很困难？其中一个重要的原因是，深度神经网络涉及到很多层的叠加，而每一层的参数更新会导致上层的输入数据分布发生变化，通过层层叠加，高层的输入分布变化会非常剧烈，这就使得高层需要不断去重新适应底层的参数更新。为了训好模型，我们需要非常谨慎地去设定学习率、初始化权重、以及尽可能细致的参数更新策略。 Google 将这一现象总结为 Internal Covariate Shift，简称 ICS。 什么是 ICS 呢？ 大家都知道在统计机器学习中的一个经典假设是“源空间（source domain）和目标空间（target domain）的数据分布（distribution）是一致的”。如果不一致，那么就出现了新的机器学习问题，如 transfer learning / domain adaptation 等。而 covariate shift 就是分布不一致假设之下的一个分支问题，它是指源空间和目标空间的条件概率是一致的，但是其边缘概率不同。 大家细想便会发现，的确，对于神经网络的各层输出，由于它们经过了层内操作作用，其分布显然与各层对应的输入信号分布不同，而且差异会随着网络深度增大而增大，可是它们所能“指示”的样本标记（label）仍然是不变的，这便符合了covariate shift的定义。由于是对层间信号的分析，也即是“internal”的来由。 那么ICS会导致什么问题？ 简而言之，每个神经元的输入数据不再是“独立同分布”。 其一，上层参数需要不断适应新的输入数据分布，降低学习速度。 其二，下层输入的变化可能趋向于变大或者变小，导致上层落入饱和区，使得学习过早停止。 其三，每层的更新都会影响到其它层，因此每层的参数更新策略需要尽可能的谨慎。 3.15 什么时候用local-conv？什么时候用全卷积？(贡献者：梁志成-魅族科技)1.当数据集具有全局的局部特征分布时，也就是说局部特征之间有较强的相关性，适合用全卷积。 2.在不同的区域有不同的特征分布时，适合用local-Conv。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基础问题]]></title>
    <url>%2F2017%2F03%2F28%2F%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[2.1 各种常见算法图示 回归算法 基于实例的算法 正则化方法 决策树学习 贝叶斯方法 基于核的算法 聚类算法 关联规则学习 人工神经网络 深度学习 降低维度算法 集成算法 2.2 监督学习、非监督学习、半监督学习、弱监督学习？根据数据类型的不同，对一个问题的建模有不同的方式。依据不同的学习方式和输入数据，机器学习主要分为以下四种学习方式。 监督学习： 监督学习是使用已知正确答案的示例来训练网络。已知数据和其一一对应的标签，训练一个智能算法，将输入数据映射到标签的过程。 监督式学习的常见应用场景如分类问题和回归问题。 常见算法有逻辑回归（Logistic Regression）和反向传递神经网络（Back Propagation Neural Network） 非监督式学习： 在非监督式学习中，数据并不被特别标识，适用于你具有数据集但无标签的情况。学习模型是为了推断出数据的一些内在结构。 常见的应用场景包括关联规则的学习以及聚类等。 常见算法包括Apriori算法以及k-Means算法。 半监督式学习： 在此学习方式下，输入数据部分被标记，部分没有被标记，这种学习模型可以用来进行预测。 应用场景包括分类和回归，算法包括一些对常用监督式学习算法的延伸，通过对已标记数据建模，在此基础上，对未标记数据进行预测。 常见算法如图论推理算法（Graph Inference）或者拉普拉斯支持向量机（Laplacian SVM）等。 弱监督学习： 弱监督学习可以看做是有多个标记的数据集合，次集合可以是空集，单个元素，或包含多种情况（没有标记，有一个标记，和有多个标记）的多个元素。 数据集的标签是不可靠的，这里的不可靠可以是标记不正确，多种标记，标记不充分，局部标记等。 已知数据和其一一对应的弱标签，训练一个智能算法，将输入数据映射到一组更强的标签的过程。标签的强弱指的是标签蕴含的信息量的多少，比如相对于分割的标签来说，分类的标签就是弱标签。 举例，告诉一张包含气球的图片，需要得出气球在图片中的位置及气球和背景的分割线，这就是已知弱标签学习强标签的问题。 在企业数据应用的场景下， 人们最常用的可能就是监督式学习和非监督式学习的模型。 在图像识别等领域，由于存在大量的非标识的数据和少量的可标识数据， 目前半监督式学习是一个很热的话题。 2.3 监督学习有哪些步骤监督式学习：监督学习是使用已知正确答案的示例来训练网络。每组训练数据有一个明确的标识或结果，想象一下，我们可以训练一个网络，让其从照片库中（其中包含气球的照片）识别出气球的照片。以下就是我们在这个假设场景中所要采取的步骤。步骤1：数据集的创建和分类首先，浏览你的照片（数据集），确定所有包含气球的照片，并对其进行标注。然后，将所有照片分为训练集和验证集。目标就是在深度网络中找一函数，这个函数输入是任意一张照片，当照片中包含气球时，输出1，否则输出0。步骤2：训练选择合适的模型，模型可通过以下激活函数对每张照片进行预测。既然我们已经知道哪些是包含气球的图片，那么我们就可以告诉模型它的预测是对还是错。然后我们会将这些信息反馈（feed back）给网络。该算法使用的这种反馈，就是一个量化“真实答案与模型预测有多少偏差”的函数的结果。这个函数被称为成本函数（cost function），也称为目标函数（objective function），效用函数（utility function）或适应度函数（fitness function）。然后，该函数的结果用于修改一个称为反向传播（backpropagation）过程中节点之间的连接强度和偏差。我们会为每个图片都重复一遍此操作，而在每种情况下，算法都在尽量最小化成本函数。其实，我们有多种数学技术可以用来验证这个模型是正确还是错误的，但我们常用的是一个非常常见的方法，我们称之为梯度下降（gradient descent）。步骤3：验证当处理完训练集所有照片，接着要去测试该模型。利用验证集来来验证训练有素的模型是否可以准确地挑选出含有气球在内的照片。在此过程中，通常会通过调整和模型相关的各种事物（超参数）来重复步骤2和3，诸如里面有多少个节点，有多少层，哪些数学函数用于决定节点是否亮起，如何在反向传播阶段积极有效地训练权值等等。步骤4：测试及应用当有了一个准确的模型，就可以将该模型部署到你的应用程序中。你可以将模型定义为API调用，并且你可以从软件中调用该方法，从而进行推理并给出相应的结果。 2.4 多实例学习？多示例学习(multiple instance learning) ：已知包含多个数据的数据包和数据包的标签，训练智能算法，将数据包映射到标签的过程，在有的问题中也同时给出包内每个数据的标签。比如说一段视频由很多张图组成，假如10000张，那么我们要判断视频里是否包含某一物体，比如气球。单张标注每一帧是否有气球太耗时，通常人们看一遍说这个视频里是否有气球，就得到了多示例学习的数据。10000帧的数据不是每一个都有气球出现，只要有一帧有气球，那么我们就认为这个数据包是有气球的。只有当所有的视频帧都没有气球，才是没有气球的。从这里面学习哪一段视频（10000张）是否有气球出现就是多实例学习的问题。 2.5 分类网络和回归的区别？2.3小节介绍了包含气球照片的数据集整理。当照片中包含气球时，输出1，否则输出0。此步骤通常称为分类任务（categorization task）。在这种情况下，我们进行的通常是一个结果为yes or no的训练。但事实上，监督学习也可以用于输出一组值，而不仅仅是0或1。例如，我们可以训练一个网络，用它来输出一张图片上有气球的概率，那么在这种情况下，输出值就是0到1之间的任意值。这些任务我们称之为回归。 2.6 什么是神经网络？神经网络就是按照一定规则将多个神经元连接起来的网络。不同的神经网络，具有不同的连接规则。例如全连接(full connected, FC)神经网络，它的规则包括： 有三种层：输入层，输出层，隐藏层。 同一层的神经元之间没有连接。 full connected的含义：第 N 层的每个神经元和第 N-1 层的所有神经元相连，第 N-1 层神经元的输出就是第 N 层神经元的输入。 每个连接都有一个权值。神经网络架构下面这张图就是一个神经网络系统，它由很多层组成。输入层负责接收信息，比如一只猫的图片。输出层是计算机对这个输入信息的判断结果，它是不是猫。隐藏层就是对输入信息的传递和加工处理。 2.7 理解局部最优与全局最优笑谈局部最优和全局最优 柏拉图有一天问老师苏格拉底什么是爱情？苏格拉底叫他到麦田走一次，摘一颗最大的麦穗回来，不许回头，只可摘一次。柏拉图空着手出来了，他的理由是，看见不错的，却不知道是不是最好的，一次次侥幸，走到尽头时，才发现还不如前面的，于是放弃。苏格拉底告诉他：“这就是爱情。”这故事让我们明白了一个道理，因为生命的一些不确定性，所以全局最优解是很难寻找到的，或者说根本就不存在，我们应该设置一些限定条件，然后在这个范围内寻找最优解，也就是局部最优解——有所斩获总比空手而归强，哪怕这种斩获只是一次有趣的经历。柏拉图有一天又问什么是婚姻？苏格拉底叫他到彬树林走一次,选一棵最好的树做圣诞树，也是不许回头，只许选一次。这次他一身疲惫地拖了一棵看起来直挺、翠绿，却有点稀疏的杉树回来，他的理由是，有了上回的教训，好不容易看见一棵看似不错的，又发现时间、体力已经快不够用了，也不管是不是最好的，就拿回来了。苏格拉底告诉他：“这就是婚姻。 优化问题一般分为局部最优和全局最优。 局部最优，就是在函数值空间的一个有限区域内寻找最小值；而全局最优，是在函数值空间整个区域寻找最小值问题。 函数局部最小点是那种它的函数值小于或等于附近点的点。但是有可能大于较远距离的点。 全局最小点是那种它的函数值小于或等于所有的可行点。 2.8 分类算法2.8.1 常用分类算法的优缺点？ 算法 优点 缺点 Bayes 贝叶斯分类法 1）所需估计的参数少，对于缺失数据不敏感。2）有着坚实的数学基础，以及稳定的分类效率。 1）假设属性之间相互独立，这往往并不成立。（喜欢吃番茄、鸡蛋，却不喜欢吃番茄炒蛋）。2）需要知道先验概率。3）分类决策存在错误率。 Decision Tree决策树 1）不需要任何领域知识或参数假设。2）适合高维数据。3）简单易于理解。4）短时间内处理大量数据，得到可行且效果较好的结果。5）能够同时处理数据型和常规性属性。 1）对于各类别样本数量不一致数据，信息增益偏向于那些具有更多数值的特征。2）易于过拟合。3）忽略属性之间的相关性。4）不支持在线学习。 SVM支持向量机 1）可以解决小样本下机器学习的问题。2）提高泛化性能。3）可以解决高维、非线性问题。超高维文本分类仍受欢迎。4）避免神经网络结构选择和局部极小的问题。 1）对缺失数据敏感。2）内存消耗大，难以解释。3）运行和调差略烦人。 KNN K近邻 1）思想简单，理论成熟，既可以用来做分类也可以用来做回归； 2）可用于非线性分类； 3）训练时间复杂度为O(n)； 4）准确度高，对数据没有假设，对outlier不敏感； 1）计算量太大2）对于样本分类不均衡的问题，会产生误判。3）需要大量的内存。4）输出的可解释性不强。 Logistic Regression逻辑回归 1）速度快。2）简单易于理解，直接看到各个特征的权重。3）能容易地更新模型吸收新的数据。4）如果想要一个概率框架，动态调整分类阀值。 特征处理复杂。需要归一化和较多的特征工程。 Neural Network 神经网络 1）分类准确率高。2）并行处理能力强。3）分布式存储和学习能力强。4）鲁棒性较强，不易受噪声影响。 1）需要大量参数（网络拓扑、阀值、阈值）。2）结果难以解释。3）训练时间过长。 Adaboosting 1）adaboost是一种有很高精度的分类器。2）可以使用各种方法构建子分类器，Adaboost算法提供的是框架。3）当使用简单分类器时，计算出的结果是可以理解的。而且弱分类器构造极其简单。4）简单，不用做特征筛选。5）不用担心overfitting。 对outlier比较敏感 2.8.2 正确率能很好的评估分类算法吗？不同算法有不同特点，在不同数据集上有不同的表现效果，根据特定的任务选择不同的算法。如何评价分类算法的好坏，要做具体任务具体分析。对于决策树，主要用正确率去评估，但是其他算法，只用正确率能很好的评估吗？答案是否定的。正确率确实是一个很直观很好的评价指标，但是有时候正确率高并不能完全代表一个算法就好。比如对某个地区进行地震预测，地震分类属性分为0：不发生地震、1发生地震。我们都知道，不发生的概率是极大的，对于分类器而言，如果分类器不加思考，对每一个测试样例的类别都划分为0，达到99%的正确率，但是，问题来了，如果真的发生地震时，这个分类器毫无察觉，那带来的后果将是巨大的。很显然，99%正确率的分类器并不是我们想要的。出现这种现象的原因主要是数据分布不均衡，类别为1的数据太少，错分了类别1但达到了很高的正确率缺忽视了研究者本身最为关注的情况。 2.8.3 分类算法的评估方法？ 几个常用的术语这里首先介绍几个常见的 模型评价术语，现在假设我们的分类目标只有两类，计为正例（positive）和负例（negative）分别是：1) True positives(TP): 被正确地划分为正例的个数，即实际为正例且被分类器划分为正例的实例数（样本数）；2) False positives(FP): 被错误地划分为正例的个数，即实际为负例但被分类器划分为正例的实例数；3) False negatives(FN):被错误地划分为负例的个数，即实际为正例但被分类器划分为负例的实例数；4) True negatives(TN): 被正确地划分为负例的个数，即实际为负例且被分类器划分为负例的实例数。 上图是这四个术语的混淆矩阵。1）P=TP+FN表示实际为正例的样本个数。2）True、False描述的是分类器是否判断正确。3）Positive、Negative是分类器的分类结果，如果正例计为1、负例计为-1，即positive=1、negative=-1。用1表示True，-1表示False，那么实际的类标=TF*PN，TF为true或false，PN为positive或negative。4）例如True positives(TP)的实际类标=1*1=1为正例，False positives(FP)的实际类标=(-1)*1=-1为负例，False negatives(FN)的实际类标=(-1)*(-1)=1为正例，True negatives(TN)的实际类标=1*(-1)=-1为负例。 评价指标 1) 正确率（accuracy） 正确率是我们最常见的评价指标，accuracy = (TP+TN)/(P+N)，正确率是被分对的样本数在所有样本数中的占比，通常来说，正确率越高，分类器越好。 2) 错误率（error rate) 错误率则与正确率相反，描述被分类器错分的比例，error rate = (FP+FN)/(P+N)，对某一个实例来说，分对与分错是互斥事件，所以accuracy =1 - error rate。 3) 灵敏度（sensitive） sensitive = TP/P，表示的是所有正例中被分对的比例，衡量了分类器对正例的识别能力。 4) 特效度（specificity) specificity = TN/N，表示的是所有负例中被分对的比例，衡量了分类器对负例的识别能力。 5) 精度（precision） 精度是精确性的度量，表示被分为正例的示例中实际为正例的比例，precision=TP/(TP+FP)。 6) 召回率（recall） 召回率是覆盖面的度量，度量有多个正例被分为正例，recall=TP/(TP+FN)=TP/P=sensitive，可以看到召回率与灵敏度是一样的。 7) 其他评价指标 计算速度：分类器训练和预测需要的时间； 鲁棒性：处理缺失值和异常值的能力； 可扩展性：处理大数据集的能力； 可解释性：分类器的预测标准的可理解性，像决策树产生的规则就是很容易理解的，而神经网络的一堆参数就不好理解，我们只好把它看成一个黑盒子。 8) 查准率和查全率反映了分类器分类性能的两个方面。如果综合考虑查准率与查全率，可以得到新的评价指标F1测试值，也称为综合分类率：$F1=\frac{2 \times precision \times recall}{precision + recall}$ 为了综合多个类别的分类情况，评测系统整体性能，经常采用的还有微平均F1（micro-averaging）和宏平均F1（macro-averaging ）两种指标。宏平均F1与微平均F1是以两种不同的平均方式求的全局的F1指标。其中宏平均F1的计算方法先对每个类别单独计算F1值，再取这些F1值的算术平均值作为全局指标。而微平均F1的计算方法是先累加计算各个类别的a、b、c、d的值，再由这些值求出F1值。由两种平均F1的计算方式不难看出，宏平均F1平等对待每一个类别，所以它的值主要受到稀有类别的影响，而微平均F1平等考虑文档集中的每一个文档，所以它的值受到常见类别的影响比较大。 ROC曲线和PR曲线 References[1] 李航. 统计学习方法[M]. 北京:清华大学出版社,2012. 2.8.4 什么样的分类器是最好的？对某一个任务，某个具体的分类器不可能同时满足或提高所有上面介绍的指标。如果一个分类器能正确分对所有的实例，那么各项指标都已经达到最优，但这样的分类器往往不存在。比如之前说的地震预测，既然不能百分百预测地震的发生，但实际情况中能容忍一定程度的误报。假设在1000次预测中，共有5次预测发生了地震，真实情况中有一次发生了地震，其他4次则为误报。正确率由原来的999/1000=99.9下降为996/10000=99.6。召回率由0/1=0%上升为1/1=100%。对此解释为，虽然预测失误了4次，但真的地震发生前，分类器能预测对，没有错过，这样的分类器实际意义更为重大，正是我们想要的。在这种情况下，在一定正确率前提下，要求分类器的召回率尽量高。 2.9 逻辑回归2.9.1 理解逻辑回归回归划分：广义线性模型家族里，依据因变量不同，可以有如下划分： 如果是连续的，就是多重线性回归； 如果是二项分布，就是Logistic回归； 如果是Poisson分布，就是Poisson回归； 如果是负二项分布，就是负二项回归。Logistic回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最常用的就是二分类的Logistic回归。 Logistic回归的适用性： 用于概率预测。用于可能性预测时，得到的结果有可比性。比如根据模型进而预测在不同的自变量情况下，发生某病或某种情况的概率有多大； 用于分类。实际上跟预测有些类似，也是根据模型，判断某人属于某病或属于某种情况的概率有多大，也就是看一下这个人有多大的可能性是属于某病。进行分类时，仅需要设定一个阈值即可，可能性高于阈值是一类，低于阈值是另一类。 寻找危险因素。寻找某一疾病的危险因素等。 仅能用于线性问题。只有当目标和特征是线性关系时，才能用逻辑回归。在应用逻辑回归时注意两点：一是当知道模型是非线性时，不适用逻辑回归；二是当使用逻辑回归时，应注意选择和目标为线性关系的特征。 各特征之间不需要满足条件独立假设，但各个特征的贡献独立计算。 2.9.2 逻辑回归与朴素贝叶斯有什么区别？ 逻辑回归是判别模型， 朴素贝叶斯是生成模型，所以生成和判别的所有区别它们都有。 朴素贝叶斯属于贝叶斯，逻辑回归是最大似然，两种概率哲学间的区别。 朴素贝叶斯需要独立假设。 逻辑回归需要求特征参数间是线性的。 2.9.3线性回归与逻辑回归的区别？（贡献者：黄钦建－华南理工大学）线性回归的样本的输出，都是连续值，$ y\in (-\infty ,+\infty )$，而逻辑回归中$y\in (0,1)$，只能取0和1。 对于拟合函数也有本质上的差别： 线性回归：$f(x)=\theta ^{T}x=\theta _{1}x _{1}+\theta _{2}x _{2}+…+\theta _{n}x _{n}$ 逻辑回归：$f(x)=P(y=1|x;\theta )=g(\theta ^{T}x)$，其中，$g(z)=\frac{1}{1+e^{-z}}$ 可以看出，线性回归的拟合函数，是对f(x)的输出变量y的拟合，而逻辑回归的拟合函数是对为1类的样本的概率的拟合。 那么，为什么要以1类样本的概率进行拟合呢，为什么可以这样拟合呢？ $\theta ^{T}x=0$就相当于是1类和0类的决策边界： 当$\theta ^{T}x&gt;0$，则y&gt;0.5；若$\theta ^{T}x\rightarrow +\infty $，则$y \rightarrow 1 $，即y为1类; 当$\theta ^{T}x&lt;0$，则y&lt;0.5；若$\theta ^{T}x\rightarrow -\infty $，则$y \rightarrow 0 $，即y为0类; 这个时候就能看出区别来了，在线性回归中$\theta ^{T}x$为预测值的拟合函数；而在逻辑回归中$\theta ^{T}x$为决策边界。 线性回归 逻辑回归 目的 预测 分类 $y^{(i)}$ 未知 （0,1） 函数 拟合函数 预测函数 参数计算方式 最小二乘法 极大似然估计 下面具体解释一下： 拟合函数和预测函数什么关系呢？其实就是将拟合函数做了一个逻辑函数的转换，转换后使得$y^{(i)} \in (0,1)$; 最小二乘和最大似然估计可以相互替代吗？回答当然是不行了。我们来看看两者依仗的原理：最大似然估计是计算使得数据出现的可能性最大的参数，依仗的自然是Probability。而最小二乘是计算误差损失。 2.9.4 Factorization Machines(FM)模型原理1.FM旨在解决稀疏数据的特征组合问题,某些特征经过关联之后,就会与label之间的相关性就会提高,例如设备id与ip地址之间的特征交叉就会更好的与label之间有相关性.2.FM为二阶多项式模型􏰠􏰡􏱔􏰼􏰝􏱗􏱞􏰨􏱈􏱣􏱤􏱥􏰠􏰡􏰼􏰝􏱕􏱗􏱁􏰇• 假设有D维特征，𝑥 , … , 𝑥 ，若采用线性模型，则$y = w_{0} +\sum_{j = 1}^{D} w_{i}x_{j}$• 若考虑二阶特征组合，得到模型$y = w_{0} +\sum_{j = 1}^{D} w_{i}x_{j} + \sum_{i = 1}^{D}\sum_{j = i + 1}^{D}w_{ij}x_{i}x_{j}$􏰃􏰇􏰠􏰡􏰤􏰥􏱿􏰃􏰝􏰶􏰙􏰩 􏱂􏰨􏰐􏲀􏰠􏰡􏰰– 组合特征的参数一共有D(D-1)/2个，任意两个参数都是独立的– 􏲇数􏱜据􏱜稀􏲈疏􏲉使􏰨得􏱈二􏱣􏲊次􏲋项􏰽参􏰾数􏰿的􏰇训􏲌练􏲍很􏰪􏱂困􏰠难:. 每个样本都需要大量非0的$x_{j}$和$x_{i}$样本. 训练样本不足会导致$w_{ij}$不准确FM采用类似model-based协同过滤中的矩阵分解方式对二次 􏱽􏱩􏱪􏰗􏰹􏰺􏱓􏱀􏱁􏰹􏰺􏱕􏱾􏰇􏱩􏱣􏰠􏰡􏰤􏰥􏰝􏱿􏰃􏰇􏰠多项式的系数进行有效表示:$y = w_{0} +\sum_{j = 1}^{D} w_{i}x_{j} + \sum_{i = 1}^{D}\sum_{j = i + 1}^{D}&lt;v_{i}, v_{j}&gt;x_{i}x_{j}$􏰃􏰇􏰠􏰡􏰤􏰥􏱿􏰃􏰝􏰶􏰙􏰩– 􏲇FM为进一步对隐含向量只􏲎取􏲏K􏲐维􏲑从而$&lt;v_{i}, v_{j}&gt; = \sum_{k = 1}^{K} v_{i,k}v_{j,k}$– 二项式参数之前的D(D-1)/2变成了KD个 大大降低了计算量.􏰱􏰛􏰜􏲁􏲂􏰿􏲃􏲄􏰝􏲅􏰇􏰹􏰺􏰽􏰾􏰿􏲆􏰻 2.10 代价函数2.10.1 为什么需要代价函数？ 为了得到训练逻辑回归模型的参数，需要一个代价函数，通过训练代价函数来得到参数。 用于找到最优解的目的函数。 2.10.2 代价函数作用原理在回归问题中，通过代价函数来求解最优解，常用的是平方误差代价函数。有如下假设函数： $$h(x) = A + Bx$$ 假设函数中有$A$和$B$两个参数，当参数发生变化时，假设函数状态也会随着变化。如下图所示 想要你和图中的离散点，我们需要尽可能找到最优的$A$和$B$来使这条直线更能代表所有数据。如何找到最优解呢，这就需要使用代价函数来求解，以平方误差代价函数为例，假设函数为$h(x)=\theta_0x$。平方误差代价函数的主要思想平方误差代价函数的主要思想就是将实际数据给出的值与拟合出的线的对应值做差，求出拟合出的直线与实际的差距。在实际应用中，为了避免因个别极端数据产生的影响，采用类似方差再取二分之一的方式来减小个别数据的影响。因此，引出代价函数： $$J(\theta_0, \theta_1) = \frac{1}{m}\sum_{i=1}^m(h(x^{(i)})-y^{(i)})^2$$ 最优解即为代价函数的最小值$\min J(\theta_0, \theta_1)$。如果是1个参数，代价函数一般通过二维曲线便可直观看出。如果是2个参数，代价函数通过三维图像可看出效果，参数越多，越复杂。当参数为2个时，代价函数是三维图像。 2.10.3 为什么代价函数要非负？目标函数存在一个下界，在优化过程当中，如果优化算法能够使目标函数不断减小，根据单调有界准则，这个优化算法就能证明是收敛有效的。只要设计的目标函数有下界，基本上都可以，代价函数非负更为方便。 2.10.4 常见代价函数？ 二次代价函数(quadratic cost)： $$J = \frac{1}{2n}\sum_x\Vert y(x)-a^L(x)\Vert^2$$ 其中，$J$表示代价函数，$x$表示样本，$y$示实际值，$a$表示输出值，$n$表示样本的总数。使用一个样本为例简单说明，此时二次代价函数为： $$J = \frac{(y-a)^2}{2}$$ 假如使用梯度下降法(Gradient descent)来调整权值参数的大小，权值$w$和偏置$b$的梯度推导如下： $$\frac{\delta J}{\delta w}=(a-y)\delta’(z)x$$，$$\frac{\delta J}{\delta b}=(a-y)\delta’(z)$$ 其中，$z$表示神经元的输入，$\theta$表示激活函数。权值$w$和偏置$b$的梯度跟激活函数的梯度成正比，激活函数的梯度越大，权值$w$和偏置$b$的大小调整得越快，训练收敛得就越快。 注：神经网络常用的激活函数为sigmoid函数，该函数的曲线如下所示： 假设目标是收敛到1.0。0.82离目标比较远，梯度比较大，权值调整比较大。0.98离目标比较近，梯度比较小，权值调整比较小。调整方案合理。假如目标是收敛到0。0.82目标比较近，梯度比较大，权值调整比较大。0.98离目标比较远，梯度比较小，权值调整比较小。调整方案不合理。原因：初始的代价（误差）越大，导致训练越慢。 交叉熵代价函数(cross-entropy)：交叉熵代价函数： $$J = \frac{1}{n}\sum_x[y\ln a + (1-y)\ln{(1-a)}]$$ 其中，$J$表示代价函数，$x$表示样本，$y$表示实际值，$a$表示输出值，$n$表示样本的总数。权值$w$和偏置$b$的梯度推导如下： $$\frac{\delta J}{\delta w_j}=\frac{1}{n}\sum_{x}(\delta{(a)}-y)\;，\frac{\delta J}{\delta b}=\frac{1}{n}\sum_{x}(\delta{(z)}-y)$$ 当误差越大时，梯度就越大，权值$w$和偏置$b$调整就越快，训练的速度也就越快。二次代价函数适合输出神经元是线性的情况，交叉熵代价函数适合输出神经元是S型函数的情况。 对数释然代价函数(log-likelihood cost)：对数释然函数常用来作为softmax回归的代价函数。深度学习中普遍的做法是将softmax作为最后一层，此时常用的代价函数是对数释然代价函数。 对数似然代价函数与softmax的组合和交叉熵与sigmoid函数的组合非常相似。对数释然代价函数在二分类时可以化简为交叉熵代价函数的形式。在tensorflow中： 与sigmoid搭配使用的交叉熵函数：tf.nn.sigmoid_cross_entropy_with_logits()。 与softmax搭配使用的交叉熵函数：tf.nn.softmax_cross_entropy_with_logits()。 2.10.5 为什么用交叉熵代替二次代价函数 为什么不用二次方代价函数由2.18节可知，权值$w$和偏置$b$的偏导数为$\frac{\delta J}{\delta w}=(a-y)\delta’(z)x$，$\frac{\delta J}{\delta b}=(a-y)\delta’(z)$， 偏导数受激活函数的导数影响，sigmoid函数导数在输出接近0和1时非常小，会导致一些实例在刚开始训练时学习得非常慢。 为什么要用交叉熵交叉熵函数权值$w$和偏置$b$的梯度推导为： $$\frac{\delta J}{\delta w_j}=\frac{1}{n}\sum_{x}(\delta{(a)}-y)\;，\frac{\delta J}{\delta b}=\frac{1}{n}\sum_{x}(\delta{(z)}-y)$$ 由以上公式可知，权重学习的速度受到$\delta{(z)}-y$影响，更大的误差，就有更快的学习速度，避免了二次代价函数方程中因$\delta’{(z)}$导致的学习缓慢的情况。 2.11 损失函数2.11.1 什么是损失函数？损失函数（Loss function）又叫做误差函数，用来衡量算法的运行情况，估量模型的预测值 与真实值 的不一致程度，是一个非负实值函数,通常使用 来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。 2.11.2 常见的损失函数机器学习通过对算法中的目标函数进行不断求解优化，得到最终想要的结果。分类和回归问题中，通常使用损失函数或代价函数作为目标函数。损失函数用来评价预测值和真实值不一样的程度。通常损失函数越好，模型的性能也越好。损失函数可分为经验风险损失函数和结构风险损失函数。经验风险损失函数指预测结果和实际结果的差别，结构风险损失函数是在经验风险损失函数上加上正则项。下面介绍常用的损失函数： 0-1损失函数如果预测值和目标值相等，值为0，如果不相等，值为1. $$L(Y, f(x)) =\begin{cases}1,&amp; Y\ne f(x)\0,&amp; Y = f(x)\end{cases}$$ 一般的在实际使用中，相等的条件过于严格，可适当放宽条件： $$L(Y, f(x)) =\begin{cases}1,&amp; |Y-f(x)|\ge T\0,&amp; |Y-f(x)|&lt; T\end{cases}$$ 绝对值损失函数和0-1损失函数相似，绝对值损失函数表示为： $$L(Y, f(x)) = |Y-f(x)|​$$ 平方损失函数 $$L(Y, f(x)) = \sum_N{(Y-f(x))}^2$$ 这点可从最小二乘法和欧几里得距离角度理解。最小二乘法的原理是，最优拟合曲线应该使所有点到回归直线的距离和最小。 log对数损失函数 $$L(Y, P(Y|X)) = -\log{P(Y|X)}$$ 常见的逻辑回归使用的就是对数损失函数，有很多人认为逻辑回归的损失函数式平方损失，其实不然。逻辑回归它假设样本服从伯努利分布，进而求得满足该分布的似然函数，接着取对数求极值等。逻辑回归推导出的经验风险函数是最小化负的似然函数，从损失函数的角度看，就是log损失函数。 指数损失函数指数损失函数的标准形式为： $$L(Y, f(x)) = \exp{-yf(x)}$$ 例如AdaBoost就是以指数损失函数为损失函数。 Hinge损失函数Hinge损失函数的标准形式如下： $$L(Y) = \max{(0, 1-ty)}$$ 其中y是预测值，范围为(-1,1),t为目标值，其为-1或1. 在线性支持向量机中，最优化问题可等价于 $$\underset{\min}{w,b}\sum_{i=1}^N (1-y_i(wx_i+b))+\lambda\Vert w^2\Vert$$ 上式相似于下式 $$\frac{1}{m}\sum_{i=1}^{N}l(wx_i+by_i) + \Vert w^2\Vert$$ 其中$l(wx_i+by_i)$是Hinge损失函数，$\Vert w^2\Vert$可看做为正则化项。 2.11.3 逻辑回归为什么使用对数损失函数？假设逻辑回归模型TODO假设逻辑回归模型的概率分布是伯努利分布，其概率质量函数为TODO其似然函数为TODO对数似然函数为TODO对数函数在单个数据点上的定义为TODO则全局样本损失函数为：TODO由此可看出，对数损失函数与极大似然估计的对数似然函数本质上是相同的。所以逻辑回归直接采用对数损失函数。 2.11.4 对数损失函数是如何度量损失的？举例：高斯分布中，我们需要确定均值 和标注差 。如何确定这两个参数？最大似然估计是比较常用的方法。最大似然的目标是找到一些参数值，这些参数值对应的分布可以最大化观测到数据的概率。因为需要计算观测到所有数据的全概率，即所有观测到的数据点的联合概率。现考虑如下简化情况： 假设观测到每个数据点的概率和其他数据点的概率是独立的。 取自然对数。假设观测到单个数据点TODO的概率为：TODO其联合概率为TODO对上式取自然对数，可得：TODO根据对数定律，上式可以化简为：TODO求导：TODO上式左半部分为对数损失函数。损失函数越小越好，因此我们令对数损失函数为0，可得：TODO同理，可计算TODO。 2.12 梯度下降2.12.1 机器学习中为什么需要梯度下降？ 梯度下降是迭代法的一种,可以用于求解最小二乘问题。 在求解机器学习算法的模型参数，即无约束优化问题时，主要有梯度下降法（Gradient Descent）和最小二乘法。 在求解损失函数的最小值时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数和模型参数值。 如果我们需要求解损失函数的最大值，可通过梯度上升法来迭代。梯度下降法和梯度上升法可相互转换。 在机器学习中，梯度下降法主要有随机梯度下降法和批量梯度下降法。 2.12.2 梯度下降法缺点？ 靠近极小值时收敛速度减慢。 直线搜索时可能会产生一些问题。 可能会“之字形”地下降。 梯度概念需注意： 梯度是一个向量，即有方向有大小； 梯度的方向是最大方向导数的方向； 梯度的值是最大方向导数的值。 2.12.3 梯度下降法直观理解？梯度下降法经典图示: 形象化举例： 由上图，假如最开始，我们在一座大山上的某处位置，因为到处都是陌生的，不知道下山的路，所以只能摸索着根据直觉，走一步算一步，在此过程中，每走到一个位置的时候，都会求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的位置向下走一步，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。不断循环求梯度，就这样一步步的走下去，一直走到我们觉得已经到了山脚。当然这样走下去，有可能我们不能走到山脚，而是到了某一个局部的山峰低处。由此，从上面的解释可以看出，梯度下降不一定能够找到全局的最优解，有可能是一个局部最优解。当然，如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。 核心思想归纳： 初始化参数，随机选取取值范围内的任意数； 迭代操作：a) 计算当前梯度；b）修改新的变量；c）计算朝最陡的下坡方向走一步；d）判断是否需要终止，如否，返回a)； 得到全局最优解或者接近全局最优解。 2.12.4 梯度下降法算法描述？ 确定优化模型的假设函数及损失函数。举例，对于线性回归，假设函数为：TODO其中，TODO分别为模型参数、每个样本的特征值。对于假设函数，损失函数为：TODO 相关参数初始化。主要初始化TODO、算法迭代步长TODO、终止距离TODO。初始化时可以根据经验初始化，即TODO初始化为0，步长TODO初始化为1。当前步长记为TODO。当然，也可随机初始化。 迭代计算。 1) 计算当前位置时损失函数的梯度，对TODO，其梯度表示为：TODO 2) 计算当前位置下降的距离。TODO 3) 判断是否终止。确定是否所有TODO梯度下降的距离TODO都小于终止距离TODO，如果都小于TODO，则算法终止，当然的值即为最终结果，否则进入下一步。4) 更新所有的TODO，更新后的表达式为：TODO5) 更新完毕后转入1)。 举例。以线性回归为例。假设样本是TODO损失函数为TODO在计算中，TODO的偏导数计算如下：TODO令上式 。4)中TODO的更新表达式为： TODO由此，可看出，当前位置的梯度方向由所有样本决定，上式中TODO的目的是为了便于理解。 2.12.5 如何对梯度下降法进行调优？实际使用梯度下降法时，各项参数指标不能一步就达到理想状态，对梯度下降法调优主要体现在以下几个方面： 算法迭代步长$\alpha$选择。在算法参数初始化时，有时根据经验将步长 初始化为1。实际取值取决于数据样本。可以从大到小，多取一些值，分别运行算法看迭代效果，如果损失函数在变小，则取值有效。如果取值无效，说明要增大步长。但步长太大，有时会导致迭代速度过快，错过最优解。步长太小，迭代速度慢，算法运行时间长。 参数的初始值选择。初始值不同，获得的最小值也有可能不同，梯度下降有可能得到的是局部最小值。如果损失函数是凸函数，则一定是最优解。由于有局部最优解的风险，需要多次用不同初始值运行算法，关键损失函数的最小值，选择损失函数最小化的初值。 标准化处理。由于样本不同，特征取值范围也不同，导致迭代速度慢。为了减少特征取值的影响，可对特征数据标准化，使新期望为0，新方差为1，可节省算法运行时间。 2.12.7 随机梯度和批量梯度区别？随机梯度下降和批量梯度下降是两种主要梯度下降法，其目的是增加某些限制来加速运算求解。引入随机梯度下降法与mini-batch梯度下降法是为了应对大数据量的计算而实现一种快速的求解。下面通过介绍两种梯度下降法的求解思路，对其进行比较。假设函数为TODO损失函数为TODO其中，TODO为样本个数，TODO为参数个数。 1、 批量梯度下降的求解思路如下： a) 得到每个TODO对应的梯度：TODO b) 由于是求最小化风险函数，所以按每个参数TODO的梯度负方向更新TODO：TODO c) 从上式可以注意到，它得到的虽然是一个全局最优解，但每迭代一步，都要用到训练集所有的数据，如果样本数据 很大，这种方法迭代速度就很慢。相比而言，随机梯度下降可避免这种问题。 2、随机梯度下降的求解思路如下：a) 相比批量梯度下降对应所有的训练样本，随机梯度下降法中损失函数对应的是训练集中每个样本的粒度。损失函数可以写成如下这种形式， TODO b）对每个参数TODO按梯度方向更新 ： TODO c) 随机梯度下降是通过每个样本来迭代更新一次。随机梯度下降伴随的一个问题是噪音较批量梯度下降要多，使得随机梯度下降并不是每次迭代都向着整体最优化方向。 小结：随机梯度下降法、批量梯度下降法相对来说都比较极端，简单对比如下：批量梯度下降：a）采用所有数据来梯度下降。b) 批量梯度下降法在样本量很大的时候，训练速度慢。 随机梯度下降：a) 随机梯度下降用一个样本来梯度下降。b) 训练速度很快。c) 随机梯度下降法仅仅用一个样本决定梯度方向，导致解有可能不是最优。d) 收敛速度来说，随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。 下面介绍能结合两种方法优点的小批量梯度下降法。 3、 小批量（mini-batch）梯度下降的求解思路如下对于总数为$m$个样本的数据，根据样本的数据，选取其中的$n(1&lt; n&lt; m)$个子样本来迭代。其参数$\theta$按梯度方向更新$\theta_i$公式如下：TODO 2.12.8 各种梯度下降法性能比较下表简单对比随机梯度下降(SGD)、批量梯度下降（BGD）、小批量梯度下降（mini-batch GD）、和online GD的区别，主要区别在于如何选取训练数据： BGD SGD GD Mini-batch GD Online GD 训练集 固定 固定 固定 实时更新 单次迭代样本数 整个训练集 单个样本 训练集的子集 根据具体算法定 算法复杂度 高 低 一般 低 时效性 低 一般 一般 高 收敛性 稳定 不稳定 较稳定 不稳定 BGD、SGD、Mini-batch GD,前面均已讨论过，这里介绍一下Online GD。 Online GD于mini-batch GD/SGD的区别在于，所有训练数据只用一次，然后丢弃。这样做的优点在于可预测最终模型的变化趋势。 Online GD在互联网领域用的较多，比如搜索广告的点击率(CTR)预估模型，网民的点击行为会随着时间改变。用普通的BGD算法（每天更新一次）一方面耗时较长（需要对所有历史数据重新训练）；另一方面，无法及时反馈用户的点击行为迁移。而Online GD算法可以实时的依据网民的点击行为进行迁移。 2.13 计算图的导数计算图解？计算图导数计算是反向传播，利用链式法则和隐式函数求导。 假设TODO在点TODO处偏导连续，TODO是关于TODO的函数，在TODO点可导，求TODO在TODO点的导数。 根据链式法则有TODO 为了便于理解，下面举例说明。假设$f(x)$是关于a,b,c的函数。链式求导法则如下： $$\frac{dJ}{du}=\frac{dJ}{dv}\frac{dv}{du},\frac{dJ}{db}=\frac{dJ}{du}\frac{du}{db},\frac{dJ}{da}=\frac{dJ}{du}\frac{du}{da}$$ 链式法则用文字描述:“由两个函数凑起来的复合函数，其导数等于里边函数代入外边函数的值之导数，乘以里边函数的导数。 例： $$f(x)=x^2,g(x)=2x+1$$ 则 $${f[g(x)]}’=2[g(x)]g’(x)=2[2x+1]2=8x+1$$ 2.14 线性判别分析（LDA）2.14.1 线性判别分析（LDA）思想总结线性判别分析（Linear Discriminant Analysis，LDA）是一种经典的降维方法。 和PCA不考虑样本类别输出的无监督降维技术不同，LDA是一种监督学习的降维技术，数据集的每个样本有类别输出。 LDA分类思想简单总结如下： 多维空间中，数据处理分类问题较为复杂，LDA算法将多维空间中的数据投影到一条直线上，将d维数据转化成1维数据进行处理。 对于训练数据，设法将多维数据投影到一条直线上，同类数据的投影点尽可能接近，异类数据点尽可能远离。 对数据进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定样本的类别。如果用一句话概括LDA思想，即“投影后类内方差最小，类间方差最大”。 2.14.2 图解LDA核心思想假设有红、蓝两类数据，这些数据特征均为二维，如下图所示。我们的目标是将这些数据投影到一维，让每一类相近的数据的投影点尽可能接近，不同类别数据尽可能远，即图中红色和蓝色数据中心之间的距离尽可能大。 左图和右图是两种不同的投影方式。 左图思路：让不同类别的平均点距离最远的投影方式。 右图思路：让同类别的数据挨得最近的投影方式。 从上图直观看出，右图红色数据和蓝色数据在各自的区域来说相对集中，根据数据分布直方图也可看出，所以右图的投影效果好于左图，左图中间直方图部分有明显交集。 以上例子是基于数据是二维的，分类后的投影是一条直线。如果原始数据是多维的，则投影后的分类面是一低维的超平面。 2.14.3 二类LDA算法原理？输入：数据集TODO，其中样本TODO是n维向量，TODO，TODO降维后的目标维度TODO。定义 TODO为第TODO类样本个数； TODO为第TODO类样本的集合； TODO为第TODO类样本的均值向量； TODO为第TODO类样本的协方差矩阵。 其中TODO，TODO。 假设投影直线是向量TODO，对任意样本TODO，它在直线TODO上的投影为TODO，两个类别的中心点TODO在直线TODO的投影分别为TODO、TODO。 LDA的目标是让两类别的数据中心间的距离TODO尽量大，与此同时，希望同类样本投影点的协方差TODO、TODO尽量小，最小化TODO。定义类内散度矩阵TODO 类间散度矩阵TODO 据上分析，优化目标为TODO 根据广义瑞利商的性质，矩阵TODO的最大特征值为TODO的最大值，矩阵TODO的最大特征值对应的特征向量即为TODO。 2.14.4 LDA算法流程总结？LDA算法降维流程如下： 输入：数据集TODO，其中样本TODO是n维向量，TODO，降维后的目标维度TODO。 输出：降维后的数据集TODO。 步骤： 计算类内散度矩阵 。 计算类间散度矩阵 。 计算矩阵 。 计算矩阵 的最大的d个特征值。 计算d个特征值对应的d个特征向量，记投影矩阵为 。 转化样本集的每个样本，得到新样本 。 输出新样本集 2.14.5 LDA和PCA区别？ 异同点 LDA PCA 相同点 1. 两者均可以对数据进行降维；2. 两者在降维时均使用了矩阵特征分解的思想；3. 两者都假设数据符合高斯分布； 不同点 有监督的降维方法 无监督的降维方法 降维最多降到k-1维 降维多少没有限制 可以用于降维，还可以用于分类 只用于降维 选择分类性能最好的投影方向 选择样本点投影具有最大方差的方向 更明确，更能反映样本间差异 目的较为模糊 2.14.6 LDA优缺点？ 优缺点 简要说明 优点 1. 可以使用类别的先验知识；2. 以标签，类别衡量差异性的有监督降维方式，相对于PCA的模糊性，其目的更明确，更能反映样本间的差异； 缺点 1. LDA不适合对非高斯分布样本进行降维；2. LDA降维最多降到k-1维；3. LDA在样本分类信息依赖方差而不是均值时，降维效果不好；4. LDA可能过度拟合数据。 2.15 主成分分析（PCA）2.15.1 主成分分析（PCA）思想总结 PCA就是将高维的数据通过线性变换投影到低维空间上去。 投影思想：找出最能够代表原始数据的投影方法。被PCA降掉的那些维度只能是那些噪声或是冗余的数据。 去冗余：去除可以被其他向量代表的线性相关向量，这部分信息量是多余的。 去噪声，去除较小特征值对应的特征向量，特征值的大小反映了变换后在特征向量方向上变换的幅度，幅度越大，说明这个方向上的元素差异也越大，要保留。 对角化矩阵，寻找极大线性无关组，保留较大的特征值，去除较小特征值，组成一个投影矩阵，对原始样本矩阵进行投影，得到降维后的新样本矩阵。 完成PCA的关键是——协方差矩阵。协方差矩阵，能同时表现不同维度间的相关性以及各个维度上的方差。协方差矩阵度量的是维度与维度之间的关系，而非样本与样本之间。 之所以对角化，因为对角化之后非对角上的元素都是0，达到去噪声的目的。对角化后的协方差矩阵，对角线上较小的新方差对应的就是那些该去掉的维度。所以我们只取那些含有较大能量(特征值)的维度，其余的就舍掉，即去冗余。 2.15.2 图解PCA核心思想PCA可解决训练数据中存在数据特征过多或特征累赘的问题。核心思想是将m维特征映射到n维（n &lt; m），这n维形成主元，是重构出来最能代表原始数据的正交特征。 假设数据集是m个n维，$(x^{(1)}, x^{(2)}, \cdots, x^{(m)})$。如果n=2,需要降维到$n’=1$，现在想找到某一维度方向代表这两个维度的数据。下图有$u_1, u_2$两个向量方向，但是哪个向量才是我们所想要的，可以更好代表原始数据集的呢？ 从图可看出，$u_1$比$u_2$好，为什么呢？有以下两个主要评价指标： 样本点到这个直线的距离足够近。 样本点在这个直线上的投影能尽可能的分开。 如果我们需要降维的目标维数是其他任意维，则： 样本点到这个超平面的距离足够近。 样本点在这个超平面上的投影能尽可能的分开。 2.15.3 PCA算法推理下面以基于最小投影距离为评价指标推理： 假设数据集是m个n维，TODO，且数据进行了中心化。经过投影变换得到新坐标为TODO，其中TODO是标准正交基，即TODO，TODO。经过降维后，新坐标为TODO，其中TODO是降维后的目标维数。样本点TODO在新坐标系下的投影为TODO，其中TODO是TODO在低维坐标系里第j维的坐标。如果用TODO去恢复TODO，则得到的恢复数据为TODO，其中TODO为标准正交基组成的矩阵。 考虑到整个样本集，样本点到这个超平面的距离足够近，目标变为最小化TODO。对此式进行推理，可得：TODO 在推导过程中，分别用到了TODO，矩阵转置公式TODO，TODO，TODO以及矩阵的迹，最后两步是将代数和转为矩阵形式。由于TODO的每一个向量TODO是标准正交基，TODO是数据集的协方差矩阵，TODO是一个常量。最小化TODO又可等价于 TODO 利用拉格朗日函数可得到TODO 对TODO求导，可得TODO，也即TODO。 是TODO个特征向量组成的矩阵， 为TODO的特征值。TODO即为我们想要的矩阵。对于原始数据，只需要TODO，就可把原始数据集降维到最小投影距离的TODO维数据集。 基于最大投影方差的推导，这里就不再赘述，有兴趣的同仁可自行查阅资料。 2.15.4 PCA算法流程总结输入：TODO维样本集TODO，目标降维的维数TODO。 输出：降维后的新样本集TODO。 主要步骤如下： 对所有的样本进行中心化，TODO。 计算样本的协方差矩阵TODO。 对协方差矩阵TODO进行特征值分解。 取出最大的TODO个特征值对应的特征向量TODO。 标准化特征向量，得到特征向量矩阵TODO。 转化样本集中的每个样本TODO。 得到输出矩阵TODO。注：在降维时，有时不明确目标维数，而是指定降维到的主成分比重阈值TODO。假设TODO个特征值为TODO，则TODO可从TODO得到。 2.15.5 PCA算法主要优缺点 优缺点 简要说明 优点 1. 仅仅需要以方差衡量信息量，不受数据集以外的因素影响。 2.各主成分之间正交，可消除原始数据成分间的相互影响的因素。3. 计算方法简单，主要运算是特征值分解，易于实现。 缺点 1.主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强。2. 方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响。 2.15.6 降维的必要性及目的降维的必要性： 多重共线性–预测变量之间相互关联。多重共线性会导致解空间的不稳定，从而可能导致结果的不连贯。 高维空间本身具有稀疏性。一维正态分布有68%的值落于正负标准差之间，而在十维空间上只有0.02%。 过多的变量，对查找规律造成冗余麻烦。 仅在变量层面上分析可能会忽略变量之间的潜在联系。例如几个预测变量可能落入仅反映数据某一方面特征的一个组内。 降维的目的： 减少预测变量的个数。 确保这些变量是相互独立的。 提供一个框架来解释结果。关特征，特别是重要特征更能在数据中明确的显示出来；如果只有两维或者三维的话，更便于可视化展示。 数据在低维下更容易处理、更容易使用。 去除数据噪声。 降低算法运算开销。 2.15.7 KPCA与PCA的区别？应用PCA算法的前提是假设存在一个线性的超平面，进而投影。那如果数据不是线性的呢？该怎么办？这时候就需要KPCA，数据集从TODO维映射到线性可分的高维TODO，然后再从TODO维降维到一个低维度TODO。 KPCA用到了核函数思想，使用了核函数的主成分分析一般称为核主成分分析(Kernelized PCA, 简称KPCA）。 假设高维空间数据由TODO维空间的数据通过映射TODO产生。 TODO维空间的特征分解为：TODO其映射为TODO 通过在高维空间进行协方差矩阵的特征值分解，然后用和PCA一样的方法进行降维。由于KPCA需要核函数的运算，因此它的计算量要比PCA大很多。 2.16 模型评估2.16.1 模型评估常用方法？一般情况来说，单一评分标准无法完全评估一个机器学习模型。只用good和bad偏离真实场景去评估某个模型，都是一种欠妥的评估方式。下面介绍常用的分类模型和回归模型评估方法。 分类模型常用评估方法： 指标 描述 Scikit-learn函数 Precision 精准度 from sklearn.metrics import precision_score Recall 召回率 from sklearn.metrics import recall_score F1 F1值 from sklearn.metrics import f1_score Confusion Matrix 混淆矩阵 from sklearn.metrics import confusion_matrix ROC ROC曲线 from sklearn.metrics import roc AUC ROC曲线下的面积 from sklearn.metrics import auc precision 查准率 recall 查全率 P-R曲线 查准率为纵轴，查全率为横轴，作图 回归模型常用评估方法： 指标 描述 Scikit-learn函数 Mean Square Error (MSE, RMSE) 平均方差 from sklearn.metrics import mean_squared_error Absolute Error (MAE, RAE) 绝对误差 from sklearn.metrics import mean_absolute_error, median_absolute_error R-Squared R平方值 from sklearn.metrics import r2_score 2.16.2 机器学习中的Bias，Error和Variance有什么区别和联系？（贡献者：黄钦建－华南理工大学） Bias(偏差)，Error(误差)，和Variance(方差) 对于Bias： Bias衡量模型拟合训练数据的能力（训练数据不一定是整个 training dataset，而是只用于训练它的那一部分数据，例如：mini-batch）。 Bias 越小，拟合能力越高（可能产生overfitting）；反之，拟合能力越低（可能产生underfitting）。 对于Variance： Variance衡量模型的泛化的能力。 Variance越小，模型的泛化的能力越高；反之，模型的泛化的能力越低。 训练误差大，测试误差小 → Bias大 训练误差小，测试误差大→ Variance大 → 降VC维 训练误差大，测试误差大→ 升VC维 2.16.3 经验误差与泛化误差误差（error）：一般地，我们把学习器的实际预测输出与样本的真是输出之间的差异称为“误差” 经验误差（empirical error）：也叫训练误差（training error）。模型在训练集上的误差。 泛化误差（generalization error）：模型在新样本集（测试集）上的误差称为“泛化误差”。 2.16.4 图解欠拟合、过拟合根据不同的坐标方式，欠拟合与过拟合图解不同。 横轴为训练样本数量，纵轴为误差 如上图所示，我们可以直观看出欠拟合和过拟合的区别： 模型欠拟合：在训练集以及测试集上同时具有较高的误差，此时模型的偏差较大； 模型过拟合：在训练集上具有较低的误差，在测试集上具有较高的误差，此时模型的方差较大。 模型正常：在训练集以及测试集上，同时具有相对较低的偏差以及方差。 横轴为模型复杂程度，纵轴为误差 模型欠拟合：模型在点A处，在训练集以及测试集上同时具有较高的误差，此时模型的偏差较大。 模型过拟合：模型在点C处，在训练集上具有较低的误差，在测试集上具有较高的误差，此时模型的方差较大。 模型正常：模型复杂程度控制在点B处为最优。 横轴为正则项系数，纵轴为误差 模型欠拟合：模型在点C处，在训练集以及测试集上同时具有较高的误差，此时模型的偏差较大。 模型过拟合：模型在点A处，在训练集上具有较低的误差，在测试集上具有较高的误差，此时模型的方差较大。 它通常发生在模型过于复杂的情况下，如参数过多等，会使得模型的预测性能变弱，并且增加数据的波动性。虽然模型在训练时的效果可以表现的很完美，基本上记住了数据的全部特点，但这种模型在未知数据的表现能力会大减折扣，因为简单的模型泛化能力通常都是很弱的。 模型正常：模型复杂程度控制在点B处为最优。 2.16.5 如何解决过拟合与欠拟合？如何解决欠拟合： 添加其他特征项。组合、泛化、相关性、上下文特征、平台特征等特征是特征添加的重要手段，有时候特征项不够会导致模型欠拟合。 添加多项式特征。例如将线性模型添加二次项或三次项使模型泛化能力更强。例如，FM模型、FFM模型，其实就是线性模型，增加了二阶多项式，保证了模型一定的拟合程度。 可以增加模型的复杂程度。 减小正则化系数。正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。 如何解决过拟合： 重新清洗数据，数据不纯会导致过拟合，此类情况需要重新清洗数据。 增加训练样本数量。 降低模型复杂程度。 增大正则项系数。 采用dropout方法，dropout方法，通俗的讲就是在训练的时候让神经元以一定的概率不工作。 early stoping。 减少迭代次数。 增大学习率。 添加噪声数据。 树结构中，可以对树进行剪枝。 欠拟合和过拟合这些方法，需要根据实际问题，实际模型，进行选择。 2.16.6 交叉验证的主要作用？为了得到更为稳健可靠的模型，对模型的泛化误差进行评估，得到模型泛化误差的近似值。当有多个模型可以选择时，我们通常选择“泛化误差”最小的模型。 交叉验证的方法有许多种，但是最常用的是：留一交叉验证、k折交叉验证 2.16.7 k折交叉验证？ 将含有N个样本的数据集，分成K份，每份含有N/K个样本。选择其中1份作为测试集，另外K-1份作为训练集，测试集就有K种情况。 在每种情况中，用训练集训练模型，用测试集测试模型，计算模型的泛化误差。 交叉验证重复K次，每份验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测，得到模型最终的泛化误差。 将K种情况下，模型的泛化误差取均值，得到模型最终的泛化误差。注： 一般2&lt;=K&lt;=10。 k折交叉验证的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10折交叉验证是最常用的。 训练集中样本数量要足够多，一般至少大于总样本数的50%。 训练集和测试集必须从完整的数据集中均匀取样。均匀取样的目的是希望减少训练集、测试集与原数据集之间的偏差。当样本数量足够多时，通过随机取样，便可以实现均匀取样的效果。 2.16.8 混淆矩阵第一种混淆矩阵: 真实情况T or F 预测为正例1，P 预测为负例0，N 本来label标记为1，预测结果真为T、假为F TP(预测为1，实际为1) FN(预测为0，实际为1) 本来label标记为0，预测结果真为T、假为F FP(预测为1，实际为0) TN(预测为0，实际也为0) 第二种混淆矩阵: 预测情况P or N 实际label为1,预测对了为T 实际label为0,预测对了为T 预测为正例1，P TP(预测为1，实际为1) FP(预测为1，实际为0) 预测为负例0，N FN(预测为0，实际为1) TN(预测为0，实际也为0) 2.16.9 错误率及精度 错误率（Error Rate）：分类错误的样本数占样本总数的比例。 精度（accuracy）：分类正确的样本数占样本总数的比例。 2.16.10 查准率与查全率将算法预测的结果分成四种情况： 正确肯定（True Positive,TP）：预测为真，实际为真 正确否定（True Negative,TN）：预测为假，实际为假 错误肯定（False Positive,FP）：预测为真，实际为假 错误否定（False Negative,FN）：预测为假，实际为真 则： 查准率（Precision）=TP/（TP+FP） 理解：预测出为阳性的样本中，正确的有多少。区别准确率（正确预测出的样本，包括正确预测为阳性、阴性，占总样本比例）。例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。 查全率（Recall）=TP/（TP+FN） 理解：正确预测为阳性的数量占总样本中阳性数量的比例。例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。 2.16.11 ROC与AUCROC全称是“受试者工作特征”（Receiver Operating Characteristic）。 ROC曲线的面积就是AUC（Area Under the Curve）。 AUC用于衡量“二分类问题”机器学习算法性能（泛化能力）。 ROC曲线，通过将连续变量设定出多个不同的临界值，从而计算出一系列真正率和假正率，再以假正率为纵坐标、真正率为横坐标绘制成曲线，曲线下面积越大，诊断准确性越高。在ROC曲线上，最靠近坐标图左上方的点为假正率和真正率均较高的临界值。 对于分类器，或者说分类算法，评价指标主要有precision，recall，F-score。下图是一个ROC曲线的示例。 ROC曲线的横坐标为false positive rate（FPR），纵坐标为true positive rate（TPR）。其中TODO, TODO,下面着重介绍ROC曲线图中的四个点和一条线。第一个点，(0,1)，即FPR=0, TPR=1，这意味着FN（false negative）=0，并且FP（false positive）=0。意味着这是一个完美的分类器，它将所有的样本都正确分类。第二个点，(1,0)，即FPR=1，TPR=0，意味着这是一个最糟糕的分类器，因为它成功避开了所有的正确答案。第三个点，(0,0)，即FPR=TPR=0，即FP（false positive）=TP（true positive）=0，可以发现该分类器预测所有的样本都为负样本（negative）。第四个点，（1,1），即FPR=TPR=1，分类器实际上预测所有的样本都为正样本。经过以上分析，ROC曲线越接近左上角，该分类器的性能越好。 ROC曲线所覆盖的面积称为AUC（Area Under Curve），可以更直观的判断学习器的性能，AUC越大则性能越好。 2.16.12 如何画ROC曲线？http://blog.csdn.net/zdy0_2004/article/details/44948511下图是一个示例，图中共有20个测试样本，“Class”一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本），“Score”表示每个测试样本属于正样本的概率。 步骤：1、假设已经得出一系列样本被划分为正类的概率，按照大小排序。2、从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。 举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。3、每次选取一个不同的threshold，得到一组FPR和TPR，即ROC曲线上的一点。以此共得到20组FPR和TPR的值。其中FPR和TPR简单理解如下：4、根据3）中的每个坐标点点，画图。 2.16.13 如何计算TPR，FPR？1、分析数据y_true = [0, 0, 1, 1]；scores = [0.1, 0.4, 0.35, 0.8]；2、列表样本 预测属于P的概率(score) 真实类别y[0] 0.1 Ny[2] 0.35 Py[1] 0.4 Ny[3] 0.8 P3、将截断点依次取为score值，计算TPR和FPR。当截断点为0.1时：说明只要score&gt;=0.1，它的预测类别就是正例。 因为4个样本的score都大于等于0.1，所以，所有样本的预测类别都为P。scores = [0.1, 0.4, 0.35, 0.8]；y_true = [0, 0, 1, 1]；y_pred = [1, 1, 1, 1]；正例与反例信息如下：真实值 预测值正例 反例正例 TP=2 FN=0反例 FP=2 TN=0由此可得：TPR = TP/(TP+FN) = 1；FPR = FP/(TN+FP) = 1； 当截断点为0.35时：scores = [0.1, 0.4, 0.35, 0.8]y_true = [0, 0, 1, 1]y_pred = [0, 1, 1, 1]正例与反例信息如下：真实值 预测值正例 反例正例 TP=2 FN=0反例 FP=1 TN=1由此可得：TPR = TP/(TP+FN) = 1；FPR = FP/(TN+FP) = 0.5； 当截断点为0.4时：scores = [0.1, 0.4, 0.35, 0.8]；y_true = [0, 0, 1, 1]；y_pred = [0, 1, 0, 1]；正例与反例信息如下：真实值 预测值正例 反例正例 TP=1 FN=1反例 FP=1 TN=1由此可得：TPR = TP/(TP+FN) = 0.5；FPR = FP/(TN+FP) = 0.5； 当截断点为0.8时：scores = [0.1, 0.4, 0.35, 0.8]；y_true = [0, 0, 1, 1]；y_pred = [0, 0, 0, 1]；正例与反例信息如下：真实值 预测值正例 反例正例 TP=1 FN=1反例 FP=0 TN=2由此可得：TPR = TP/(TP+FN) = 0.5；FPR = FP/(TN+FP) = 0；4、根据TPR、FPR值，以FPR为横轴，TPR为纵轴画图。 2.16.14 如何计算Auc？a.将坐标点按照横着FPR排序b.计算第i个坐标点和第i+1个坐标点的间距 dx；c.获取第i（或者i+1）个坐标点的纵坐标y；d.计算面积微元ds = ydx;e.对面积微元进行累加，得到AUC。 2.16.15 为什么使用Roc和Auc评价分类器？模型有很多评估方法，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变换的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。 2.16.17 直观理解AUChttp://blog.csdn.net/cherrylvlei/article/details/52958720AUC是ROC右下方的曲线面积。下图展现了三种AUC的值： AUC是衡量二分类模型优劣的一种评价指标，表示正例排在负例前面的概率。其他评价指标有精确度、准确率、召回率，而AUC比这三者更为常用。因为一般在分类模型中，预测结果都是以概率的形式表现，如果要计算准确率，通常都会手动设置一个阈值来将对应的概率转化成类别，这个阈值也就很大程度上影响了模型准确率的计算。我们不妨举一个极端的例子：一个二类分类问题一共10个样本，其中9个样本为正例，1个样本为负例，在全部判正的情况下准确率将高达90%，而这并不是我们希望的结果，尤其是在这个负例样本得分还是最高的情况下，模型的性能本应极差，从准确率上看却适得其反。而AUC能很好描述模型整体性能的高低。这种情况下，模型的AUC值将等于0（当然，通过取反可以解决小于50%的情况，不过这是另一回事了）。 2.16.18 代价敏感错误率与代价曲线http://blog.csdn.net/cug_lzt/article/details/78295140 不同的错误会产生不同代价。以二分法为例，设置代价矩阵如下： 当判断正确的时候，值为0，不正确的时候，分别为$Cost_{01}$和$Cost_{10}$ 。 $Cost_{10}$:表示实际为反例但预测成正例的代价。 $Cost_{01}$:表示实际为正例但是预测为反例的代价。 代价敏感错误率：$\frac{样本中由模型得到的错误值与代价乘积之和}{总样本}$ 其数学表达式为： $D^{+}、D^{-}$分别代表样例集 的正例子集和反例子集。 代价曲线：在均等代价时，ROC曲线不能直接反应出模型的期望总体代价，而代价曲线可以。代价曲线横轴为[0,1]的正例函数代价： $P(+)Cost=\frac{pCost_{01}}{pCost_{01}+(1-p)*Cost_{10}}$ 其中p是样本为正例的概率。 代价曲线纵轴维[0,1]的归一化代价：$Cost_{norm}=\frac{FNRpCost_{01}+FNR(1-p)Cost_{10}}{pCost_{01}+(1-p)Cost_{10}}$ 其中FPR为假正例率，FNR=1-TPR为假反利率。 注：ROC每个点，对应代价平面上一条线。 例如，ROC上(TPR,FPR),计算出FNR=1-TPR，在代价平面上绘制一条从(0,FPR)到(1,FNR)的线段，面积则为该条件下期望的总体代价。所有线段下界面积，所有条件下学习器的期望总体代价。 2.16.19 模型有哪些比较检验方法http://wenwen.sogou.com/z/q721171854.htm正确性分析：模型稳定性分析，稳健性分析，收敛性分析，变化趋势分析，极值分析等。有效性分析：误差分析，参数敏感性分析，模型对比检验等。有用性分析：关键数据求解，极值点，拐点，变化趋势分析，用数据验证动态模拟等。高效性分析：时空复杂度分析与现有进行比较等。 2.16.20 偏差与方差http://blog.csdn.net/zhihua_oba/article/details/78684257 方差公式为： $S_{N}^{2}=\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}$ 泛化误差可分解为偏差、方差与噪声之和，即generalization error=bias+variance+noise。 噪声：描述了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。假定期望噪声为零，则泛化误差可分解为偏差、方差之和，即generalization error=bias+variance。 偏差（bias）：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据，如下图第二行所示。 方差（variance）：描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散，模型的稳定程度越差。如果模型在训练集上拟合效果比较优秀，但是在测试集上拟合效果比较差劣，则方差较大，说明模型的稳定程度较差，出现这种现象可能是由于模型对训练集过拟合造成的。 如下图右列所示。 简单的总结一下：偏差大，会造成模型欠拟合；方差大，会造成模型过拟合。 2.16.21为什么使用标准差？标准差公式为：$S_{N}=\sqrt{\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}$ 样本标准差公式为：$S_{N}=\sqrt{\frac{1}{N-1}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}$ 与方差相比，使用标准差来表示数据点的离散程度有3个好处：1、表示离散程度的数字与样本数据点的数量级一致，更适合对数据样本形成感性认知。 2、表示离散程度的数字单位与样本数据的单位一致，更方便做后续的分析运算。 3、在样本数据大致符合正态分布的情况下，标准差具有方便估算的特性：66.7%的数据点落在平均值前后1个标准差的范围内、95%的数据点落在平均值前后2个标准差的范围内，而99%的数据点将会落在平均值前后3个标准差的范围内。 2.16.22点估计思想点估计：用实际样本的一个指标来估计总体的一个指标的一种估计方法。 点估计举例：比如说，我们想要了解中国人的平均身高，那么在大街上随便找了一个人，通过测量这个人的身高来估计中国人的平均身高水平；或者在淘宝上买东西的时候随便一次买到假货就说淘宝上都是假货等；这些都属于点估计。 点估计主要思想：在样本数据中得到一个指标，通过这个指标来估计总体指标；比如我们用样本均数来估计总体均数，样本均数就是我们要找到的指标。 2.16.23 点估计优良性原则？获取样本均数指标相对来说比较简单，但是并不是总体的所有指标都很容易在样本中得到，比如说总体的标准差用样本的哪个指标来估计呢？ 优良性准则有两大类：一类是小样本准则，即在样本大小固定时的优良性准则；另一类是大样本准则，即在样本大小趋于无穷时的优良性准则。最重要的小样本优良性准则是无偏性及与此相关的一致最小方差无偏计。 样本中用来估计总体的指标要符合以下规则： 1.首先必须是无偏统计量。所谓无偏性，即数学期望等于总体相应的统计量的样本估计量。 2.最小方差准则针对总体样本的无偏估计量不唯一的情况，需选用其他准则，例如最小方差准则。如果一个统计量具有最小方差，也就是说所有的样本点与此统计量的离差平方和最小，则这个统计量被称为最小平方无偏估计量。最大概率准则 4、缺一交叉准则在非参数回归中好像用的是缺一交叉准则 要明白一个原则：计算样本的任何分布、均数、标准差都是没有任何意义的，如果样本的这种计算不能反映总体的某种特性。 2.16.24 点估计、区间估计、中心极限定理之间的联系？https://www.zhihu.com/question/21871331#answer-4090464点估计：是用样本统计量来估计总体参数，因为样本统计量为数轴上某一点值，估计的结果也以一个点的数值表示，所以称为点估计。 区间估计：通过从总体中抽取的样本，根据一定的正确度与精确度的要求，构造出适当的区间，以作为总体的分布参数(或参数的函数)的真值所在范围的估计。中心极限定理：设从均值为、方差为;（有限）的任意一个总体中抽取样本量为n的样本，当n充分大时，样本均值的抽样分布近似服从均值为、方差为的正态分布。 三者之间联系： 1、中心极限定理是推断统计的理论基础，推断统计包括参数估计和假设检验，其中参数估计包括点估计和区间估计，所以说，中心极限定理也是点估计和区间估计的理论基础。 2、参数估计有两种方法：点估计和区间估计，区间估计包含了点估计。 相同点：都是基于一个样本作出； 不同点：点估计只提供单一的估计值，而区间估计基于点估计还提供误差界限，给出了置信区间，受置信度的影响。 2.16.25 类别不平衡产生原因？类别不平衡（class-imbalance）是指分类任务中不同类别的训练样例数目差别很大的情况。 产生原因： 通常分类学习算法都会假设不同类别的训练样例数目基本相同。如果不同类别的训练样例数目差别很大，则会影响学习结果，测试结果变差。例如二分类问题中有998个反例，正例有2个，那学习方法只需返回一个永远将新样本预测为反例的分类器，就能达到99.8%的精度；然而这样的分类器没有价值。 2.16.26 常见的类别不平衡问题解决方法http://blog.csdn.net/u013829973/article/details/77675147 防止类别不平衡对学习造成的影响，在构建分类模型之前，需要对分类不平衡性问题进行处理。主要解决方法有： 1、扩大数据集 增加包含小类样本数据的数据，更多的数据能得到更多的分布信息。 2、对大类数据欠采样 减少大类数据样本个数，使与小样本个数接近。缺点：欠采样操作时若随机丢弃大类样本，可能会丢失重要信息。代表算法：EasyEnsemble。利用集成学习机制，将大类划分为若干个集合供不同的学习器使用。相当于对每个学习器都进行了欠采样，但在全局来看却不会丢失重要信息。 3、对小类数据过采样 过采样：对小类的数据样本进行采样来增加小类的数据样本个数。 代表算法：SMOTE和ADASYN。 SMOTE：通过对训练集中的小类数据进行插值来产生额外的小类样本数据。 新的少数类样本产生的策略：对每个少数类样本a，在a的最近邻中随机选一个样本b，然后在a、b之间的连线上随机选一点作为新合成的少数类样本。ADASYN：根据学习难度的不同，对不同的少数类别的样本使用加权分布，对于难以学习的少数类的样本，产生更多的综合数据。 通过减少类不平衡引入的偏差和将分类决策边界自适应地转移到困难的样本两种手段，改善了数据分布。 4、使用新评价指标 如果当前评价指标不适用，则应寻找其他具有说服力的评价指标。比如准确度这个评价指标在类别不均衡的分类任务中并不适用，甚至进行误导。因此在类别不均衡分类任务中，需要使用更有说服力的评价指标来对分类器进行评价。 5、选择新算法 不同的算法适用于不同的任务与数据，应该使用不同的算法进行比较。 6、数据代价加权 例如当分类任务是识别小类，那么可以对分类器的小类样本数据增加权值，降低大类样本的权值，从而使得分类器将重点集中在小类样本身上。 7、转化问题思考角度 例如在分类问题时，把小类的样本作为异常点，将问题转化为异常点检测或变化趋势检测问题。 异常点检测即是对那些罕见事件进行识别。变化趋势检测区别于异常点检测在于其通过检测不寻常的变化趋势来识别。 8、将问题细化分析 对问题进行分析与挖掘，将问题划分成多个更小的问题，看这些小问题是否更容易解决。 2.17 决策树2.17.1 决策树的基本原理决策树是一种分而治之(Divide and Conquer)的决策过程。一个困难的预测问题, 通过树的分支节点, 被划分成两个或多个较为简单的子集，从结构上划分为不同的子问题。将依规则分割数据集的过程不断递归下去(Recursive Partitioning)。随着树的深度不断增加，分支节点的子集越来越小，所需要提的问题数也逐渐简化。当分支节点的深度或者问题的简单程度满足一定的停止规则(Stopping Rule)时, 该分支节点会停止劈分，此为自上而下的停止阈值(Cutoff Threshold)法；有些决策树也使用自下而上的剪枝(Pruning)法。 2.17.2 决策树的三要素？一棵决策树的生成过程主要分为以下3个部分: 特征选择：从训练数据中众多的特征中选择一个特征作为当前节点的分裂标准，如何选择特征有着很多不同量化评估标准标准，从而衍生出不同的决策树算法。 决策树生成：根据选择的特征评估标准，从上至下递归地生成子节点，直到数据集不可分则停止决策树停止生长。树结构来说，递归结构是最容易理解的方式。 剪枝：决策树容易过拟合，一般来需要剪枝，缩小树结构规模、缓解过拟合。剪枝技术有预剪枝和后剪枝两种。 2.17.3 决策树学习基本算法 2.17.4 决策树算法优缺点决策树算法的优点： 1、理解和解释起来简单，决策树模型易想象。 2、相比于其他算法需要大量数据集而已，决策树算法要求的数据集不大。 3、决策树算法的时间复杂度较小，为用于训练决策树的数据点的对数。 4、相比于其他算法智能分析一种类型变量，决策树算法可处理数字和数据的类别。 5、能够处理多输出的问题。 6、对缺失值不敏感。 7、可以处理不相关特征数据。 8、效率高，决策树只需要一次构建，反复使用，每一次预测的最大计算次数不超过决策树的深度。 决策树算法的缺点： 1、对连续性的字段比较难预测。 2、容易出现过拟合。 3、当类别太多时，错误可能就会增加的比较快。 4、信息缺失时处理起来比较困难，忽略了数据集中属性之间的相关性。 5、在处理特征关联性比较强的数据时表现得不是太好。 6、对于各类别样本数量不一致的数据，在决策树当中,信息增益的结果偏向于那些具有更多数值的特征。 2.17.5熵的概念以及理解熵：度量随机变量的不确定性。 定义：假设随机变量X的可能取值有$x_{1},x_{2},…,x_{n}$，对于每一个可能的取值$x_{i}$，其概率为$P(X=x_{i})=p_{i},i=1,2…,n$。随机变量的熵为： $H(X)=-\sum_{i=1}^{n}p_{i}log_{2}p_{i}$ 对于样本集合 ，假设样本有k个类别，每个类别的概率为$\frac{|C_{k}|}{|D|}$,其中 ${|C_{k}|}{|D|}$为类别为k的样本个数,$|D|$为样本总数。样本集合D的熵为：$H(D)=-\sum_{k=1}^{k}\frac{|C_{k}|}{|D|}log_{2}\frac{|C_{k}|}{|D|}$ 2.17.6 信息增益的理解定义：以某特征划分数据集前后的熵的差值。熵可以表示样本集合的不确定性，熵越大，样本的不确定性就越大。因此可以使用划分前后集合熵的差值来衡量使用当前特征对于样本集合D划分效果的好坏。假设划分前样本集合D的熵为H(D)。使用某个特征A划分数据集D，计算划分后的数据子集的熵为H(D|A)。 则信息增益为： $g(D,A)=H(D)-H(D|A)$ 注：在决策树构建的过程中我们总是希望集合往最快到达纯度更高的子集合方向发展，因此我们总是选择使得信息增益最大的特征来划分当前数据集D。 思想：计算所有特征划分数据集D，得到多个特征划分数据集D的信息增益，从这些信息增益中选择最大的，因而当前结点的划分特征便是使信息增益最大的划分所使用的特征。 另外这里提一下信息增益比相关知识： 信息增益比=惩罚参数X信息增益。 信息增益比本质：在信息增益的基础之上乘上一个惩罚参数。特征个数较多时，惩罚参数较小；特征个数较少时，惩罚参数较大。 惩罚参数：数据集D以特征A作为随机变量的熵的倒数。 2.17.7 剪枝处理的作用及策略？剪枝处理是决策树学习算法用来解决过拟合的一种办法。 在决策树算法中，为了尽可能正确分类训练样本， 节点划分过程不断重复， 有时候会造成决策树分支过多，以至于将训练样本集自身特点当作泛化特点， 而导致过拟合。 因此可以采用剪枝处理来去掉一些分支来降低过拟合的风险。 剪枝的基本策略有预剪枝(prepruning)和后剪枝(postprunint)。 预剪枝：在决策树生成过程中，在每个节点划分前先估计其划分后的泛化性能， 如果不能提升，则停止划分，将当前节点标记为叶结点。 后剪枝：生成决策树以后，再自下而上对非叶结点进行考察， 若将此节点标记为叶结点可以带来泛化性能提升，则修改之。 2.18 支持向量机2.18.1 什么是支持向量机SVM - Support Vector Machine。支持向量机，其含义是通过支持向量运算的分类器。其中“机”的意思是机器，可以理解为分类器。 什么是支持向量呢？在求解的过程中，会发现只根据部分数据就可以确定分类器，这些数据称为支持向量。 见下图，在一个二维环境中，其中点R，S，G点和其它靠近中间黑线的点可以看作为支持向量，它们可以决定分类器，也就是黑线的具体参数。 2.18.2 支持向量机解决的问题？https://www.cnblogs.com/steven-yang/p/5658362.html解决的问题： 线性分类 在训练数据中，每个数据都有n个的属性和一个二类类别标志，我们可以认为这些数据在一个n维空间里。我们的目标是找到一个n-1维的超平面（hyperplane），这个超平面可以将数据分成两部分，每部分数据都属于同一个类别。 其实这样的超平面有很多，我们要找到一个最佳的。因此，增加一个约束条件：这个超平面到每边最近数据点的距离是最大的。也成为最大间隔超平面（maximum-margin hyperplane）。这个分类器也成为最大间隔分类器（maximum-margin classifier）。 支持向量机是一个二类分类器。 非线性分类 SVM的一个优势是支持非线性分类。它结合使用拉格朗日乘子法和KKT条件，以及核函数可以产生非线性分类器。 分类器1 - 线性分类器 是一个线性函数，可以用于线性分类。一个优势是不需要样本数据。 classifier 1:f(x)=xwT+b(1)(1)f(x)=xwT+b ww 和 bb 是训练数据后产生的值。 分类器2 - 非线性分类器 支持线性分类和非线性分类。需要部分样本数据（支持向量），也就是$\alpha_i \ne 0$ 的数据。 $$w=∑ni=1αiyixiw=∑i=1nαiyixi$$ classifier 2: f(x)=∑ni=1αiyiK(xi,x)+bherexi : training data iyi : label value of training data iαi : Lagrange multiplier of training data iK(x1,x2)=exp(−∥x1−x2∥22σ2) : kernel function(2)(2)f(x)=∑i=1nαiyiK(xi,x)+bherexi : training data iyi : label value of training data iαi : Lagrange multiplier of training data iK(x1,x2)=exp(−‖x1−x2‖22σ2) : kernel function αα, σσ 和 bb 是训练数据后产生的值。可以通过调节σσ来匹配维度的大小，σσ越大，维度越低。 2.18.3 核函数作用？核函数目的：把原坐标系里线性不可分的数据用Kernel投影到另一个空间，尽量使得数据在新的空间里线性可分。 核函数方法的广泛应用,与其特点是分不开的： 1）核函数的引入避免了“维数灾难”,大大减小了计算量。而输入空间的维数n对核函数矩阵无影响，因此，核函数方法可以有效处理高维输入。 2）无需知道非线性变换函数Φ的形式和参数. 3）核函数的形式和参数的变化会隐式地改变从输入空间到特征空间的映射，进而对特征空间的性质产生影响，最终改变各种核函数方法的性能。 4）核函数方法可以和不同的算法相结合，形成多种不同的基于核函数技术的方法，且这两部分的设计可以单独进行，并可以为不同的应用选择不同的核函数和算法。 2.18.4 对偶问题2.18.5 理解支持向量回归http://blog.csdn.net/liyaohhh/article/details/51077082 2.18.6 理解SVM（核函数）http://blog.csdn.net/Love_wanling/article/details/69390047 2.18.7 常见的核函数有哪些？http://blog.csdn.net/Love_wanling/article/details/69390047 本文将遇到的核函数进行收集整理，分享给大家。http://blog.csdn.net/wsj998689aa/article/details/47027365 1.Linear Kernel线性核是最简单的核函数，核函数的数学公式如下： $k(x,y)=xy$ 如果我们将线性核函数应用在KPCA中，我们会发现，推导之后和原始PCA算法一模一样，很多童鞋借此说“kernel is shit！！！”，这是不对的，这只是线性核函数偶尔会出现等价的形式罢了。 2.Polynomial Kernel 多项式核实一种非标准核函数，它非常适合于正交归一化后的数据，其具体形式如下： $k(x,y)=(ax^{t}y+c)^{d}$ 这个核函数是比较好用的，就是参数比较多，但是还算稳定。 3.Gaussian Kernel 这里说一种经典的鲁棒径向基核，即高斯核函数，鲁棒径向基核对于数据中的噪音有着较好的抗干扰能力，其参数决定了函数作用范围，超过了这个范围，数据的作用就“基本消失”。高斯核函数是这一族核函数的优秀代表，也是必须尝试的核函数，其数学形式如下： $k(x,y)=exp(-\frac{\left | x-y \right |^{2}}{2\sigma ^{2}})$ 虽然被广泛使用，但是这个核函数的性能对参数十分敏感，以至于有一大把的文献专门对这种核函数展开研究，同样，高斯核函数也有了很多的变种，如指数核，拉普拉斯核等。 4.Exponential Kernel 指数核函数就是高斯核函数的变种，它仅仅是将向量之间的L2距离调整为L1距离，这样改动会对参数的依赖性降低，但是适用范围相对狭窄。其数学形式如下： $k(x,y)=exp(-\frac{\left | x-y \right |}{2\sigma ^{2}})$ 5.Laplacian Kernel 拉普拉斯核完全等价于指数核，唯一的区别在于前者对参数的敏感性降低，也是一种径向基核函数。 $k(x,y)=exp(-\frac{\left | x-y \right |}{\sigma })$ 6.ANOVA Kernel ANOVA 核也属于径向基核函数一族，其适用于多维回归问题，数学形式如下： $k(x,y)=exp(-\sigma(x^{k}-y^{k})^{2})^{d}$ 7.Sigmoid Kernel Sigmoid 核来源于神经网络，现在已经大量应用于深度学习，是当今机器学习的宠儿，它是S型的，所以被用作于“激活函数”。关于这个函数的性质可以说好几篇文献，大家可以随便找一篇深度学习的文章看看。 $k(x,y)=tanh(ax^{t}y+c)$ 8.Rational Quadratic Kernel二次有理核完完全全是作为高斯核的替代品出现，如果你觉得高斯核函数很耗时，那么不妨尝试一下这个核函数，顺便说一下，这个核函数作用域虽广，但是对参数十分敏感，慎用！！！！ $k(x,y)=1-\frac{\left | x-y \right |^{2}}{\left | x-y \right |^{2}+c}$ 2.18.8 软间隔与正则化2.18.9 SVM主要特点及缺点？http://www.elecfans.com/emb/fpga/20171118582139_2.html 3.3.2.1 SVM有如下主要几个特点： (1)非线性映射是SVM方法的理论基础,SVM利用内积核函数代替向高维空间的非线性映射；(2)对特征空间划分的最优超平面是SVM的目标,最大化分类边际的思想是SVM方法的核心；(3)支持向量是SVM的训练结果,在SVM分类决策中起决定作用的是支持向量。(4)SVM 是一种有坚实理论基础的新颖的小样本学习方法。它基本上不涉及概率测度及大数定律等,因此不同于现有的统计方法。从本质上看,它避开了从归纳到演绎的传统过程,实现了高效的从训练样本到预报样本的“转导推理”,大大简化了通常的分类和回归等问题。(5)SVM 的最终决策函数只由少数的支持向量所确定,计算的复杂性取决于支持向量的数目,而不是样本空间的维数,这在某种意义上避免了“维数灾难”。(6)少数支持向量决定了最终结果,这不但可以帮助我们抓住关键样本、“剔除”大量冗余样本,而且注定了该方法不但算法简单,而且具有较好的“鲁棒”性。这种“鲁棒”性主要体现在:①增、删非支持向量样本对模型没有影响;②支持向量样本集具有一定的鲁棒性;③有些成功的应用中,SVM 方法对核的选取不敏感 3.3.2.2 SVM的两个不足：(1) SVM算法对大规模训练样本难以实施由 于SVM是借助二次规划来求解支持向量，而求解二次规划将涉及m阶矩阵的计算（m为样本的个数），当m数目很大时该矩阵的存储和计算将耗费大量的机器内存 和运算时间。针对以上问题的主要改进有有J.Platt的SMO算法、T.Joachims的SVM、C.J.C.Burges等的PCGC、张学工的 CSVM以及O.L.Mangasarian等的SOR算法。(2) 用SVM解决多分类问题存在困难经典的支持向量机算法只给出了二类分类的算法，而在数据挖掘的实际应用中，一般要解决多类的分类问题。可以通过多个二类支持向量机的组合来解决。主要有一对多组合模式、一对一组合模式和SVM决策树；再就是通过构造多个分类器的组合来解决。主要原理是克服SVM固有的缺点，结合其他算法的优势，解决多类问题的分类精度。如：与粗集理论结合，形成一种优势互补的多类问题的组合分类器。 2.19 贝叶斯2.19.1 图解极大似然估计极大似然估计 http://blog.csdn.net/zengxiantao1994/article/details/72787849 极大似然估计的原理，用一张图片来说明，如下图所示： 总结起来，最大似然估计的目的就是：利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。 原理：极大似然估计是建立在极大似然原理的基础上的一个统计方法，是概率论在统计学中的应用。极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。通过若干次试验，观察其结果，利用试验结果得到某个参数值能够使样本出现的概率为最大，则称为极大似然估计。 由于样本集中的样本都是独立同分布，可以只考虑一类样本集D，来估计参数向量θ。记已知的样本集为： $D=x_{1},x_{2},…,x_{n}$ 似然函数（linkehood function）：联合概率密度函数$P(D|\theta )$称为相对于$x_{1},x_{2},…,x_{n}$的θ的似然函数。 $l(\theta )=p(D|\theta ) =p(x_{1},x_{2},…,x_{N}|\theta )=\prod_{i=1}^{N}p(x_{i}|\theta )$ 如果$\hat{\theta}$是参数空间中能使似然函数$l(\theta)$最大的θ值，则$\hat{\theta}$应该是“最可能”的参数值，那么$\hat{\theta}$就是θ的极大似然估计量。它是样本集的函数，记作： $\hat{\theta}=d(x_{1},x_{2},…,x_{N})=d(D)$ $\hat{\theta}(x_{1},x_{2},…,x_{N})$称为极大似然函数估计值。 2.19.2 朴素贝叶斯分类器和一般的贝叶斯分类器有什么区别？2.19.3 朴素与半朴素贝叶斯分类器2.19.4 贝叶斯网三种典型结构2.19.5 什么是贝叶斯错误率2.19.6 什么是贝叶斯最优错误率2.20 EM算法解决问题及实现流程1.EM算法要解决的问题 我们经常会从样本观察数据中，找出样本的模型参数。 最常用的方法就是极大化模型分布的对数似然函数。 但是在一些情况下，我们得到的观察数据有未观察到的隐含数据，此时我们未知的有隐含数据和模型参数，因而无法直接用极大化对数似然函数得到模型分布的参数。怎么办呢？这就是EM算法可以派上用场的地方了。 EM算法解决这个的思路是使用启发式的迭代方法，既然我们无法直接求出模型分布参数，那么我们可以先猜想隐含数据（EM算法的E步），接着基于观察数据和猜测的隐含数据一起来极大化对数似然，求解我们的模型参数（EM算法的M步)。由于我们之前的隐藏数据是猜测的，所以此时得到的模型参数一般还不是我们想要的结果。不过没关系，我们基于当前得到的模型参数，继续猜测隐含数据（EM算法的E步），然后继续极大化对数似然，求解我们的模型参数（EM算法的M步)。以此类推，不断的迭代下去，直到模型分布参数基本无变化，算法收敛，找到合适的模型参数。 从上面的描述可以看出，EM算法是迭代求解最大值的算法，同时算法在每一次迭代时分为两步，E步和M步。一轮轮迭代更新隐含数据和模型分布参数，直到收敛，即得到我们需要的模型参数。 一个最直观了解EM算法思路的是K-Means算法，见之前写的K-Means聚类算法原理。 在K-Means聚类时，每个聚类簇的质心是隐含数据。我们会假设KK个初始化质心，即EM算法的E步；然后计算得到每个样本最近的质心，并把样本聚类到最近的这个质心，即EM算法的M步。重复这个E步和M步，直到质心不再变化为止，这样就完成了K-Means聚类。 当然，K-Means算法是比较简单的，实际中的问题往往没有这么简单。上面对EM算法的描述还很粗糙，我们需要用数学的语言精准描述。 2.EM算法流程 现在我们总结下EM算法的流程。 输入：观察数据x=(x(1),x(2),…x(m))x=(x(1),x(2),…x(m))，联合分布p(x,z|θ)p(x,z|θ), 条件分布p(z|x,θ)p(z|x,θ), 最大迭代次数JJ。 1) 随机初始化模型参数θθ的初值θ0θ0。 2） for j from 1 to J开始EM算法迭代： a) E步：计算联合分布的条件概率期望：Qi(z(i))=P(z(i)|x(i)，θj))Qi(z(i))=P(z(i)|x(i)，θj))L(θ,θj)=∑i=1m∑z(i)Qi(z(i))logP(x(i)，z(i)|θ)L(θ,θj)=∑i=1m∑z(i)Qi(z(i))logP(x(i)，z(i)|θ) b) M步：极大化L(θ,θj)L(θ,θj),得到θj+1θj+1:θj+1=argmaxθL(θ,θj)θj+1=argmaxθL(θ,θj) c) 如果θj+1θj+1已收敛，则算法结束。否则继续回到步骤a)进行E步迭代。 输出：模型参数θθ。 2.21 降维和聚类2.21.1 为什么会产生维数灾难？http://blog.csdn.net/chenjianbo88/article/details/52382943 假设地球上猫和狗的数量是无限的。由于有限的时间和计算能力，我们仅仅选取了10张照片作为训练样本。我们的目的是基于这10张照片来训练一个线性分类器，使得这个线性分类器可以对剩余的猫或狗的照片进行正确分类。我们从只用一个特征来辨别猫和狗开始： 从图2可以看到，如果仅仅只有一个特征的话，猫和狗几乎是均匀分布在这条线段上，很难将10张照片线性分类。那么，增加一个特征后的情况会怎么样： 增加一个特征后，我们发现仍然无法找到一条直线将猫和狗分开。所以，考虑需要再增加一个特征： 此时，我们终于找到了一个平面将猫和狗分开。需要注意的是，只有一个特征时，假设特征空间是长度为5的线段，则样本密度是10/5=2。有两个特征时，特征空间大小是55=25，样本密度是10/25=0.4。有三个特征时，特征空间大小是55*5=125，样本密度是10/125=0.08。如果继续增加特征数量，样本密度会更加稀疏，也就更容易找到一个超平面将训练样本分开。因为随着特征数量趋向于无限大，样本密度非常稀疏，训练样本被分错的可能性趋向于零。当我们将高维空间的分类结果映射到低维空间时，一个严重的问题出现了： 从图5可以看到将三维特征空间映射到二维特征空间后的结果。尽管在高维特征空间时训练样本线性可分，但是映射到低维空间后，结果正好相反。事实上，增加特征数量使得高维空间线性可分，相当于在低维空间内训练一个复杂的非线性分类器。不过，这个非线性分类器太过“聪明”，仅仅学到了一些特例。如果将其用来辨别那些未曾出现在训练样本中的测试样本时，通常结果不太理想。这其实就是我们在机器学习中学过的过拟合问题。 尽管图6所示的只采用2个特征的线性分类器分错了一些训练样本，准确率似乎没有图4的高，但是，采用2个特征的线性分类器的泛化能力比采用3个特征的线性分类器要强。因为，采用2个特征的线性分类器学习到的不只是特例，而是一个整体趋势，对于那些未曾出现过的样本也可以比较好地辨别开来。换句话说，通过减少特征数量，可以避免出现过拟合问题，从而避免“维数灾难”。 图7从另一个角度诠释了“维数灾难”。假设只有一个特征时，特征的值域是0到1，每一只猫和狗的特征值都是唯一的。如果我们希望训练样本覆盖特征值值域的20%，那么就需要猫和狗总数的20%。我们增加一个特征后，为了继续覆盖特征值值域的20%就需要猫和狗总数的45%(0.45^2=0.2)。继续增加一个特征后，需要猫和狗总数的58%(0.58^3=0.2)。随着特征数量的增加，为了覆盖特征值值域的20%，就需要更多的训练样本。如果没有足够的训练样本，就可能会出现过拟合问题。 通过上述例子，我们可以看到特征数量越多，训练样本就会越稀疏，分类器的参数估计就会越不准确，更加容易出现过拟合问题。“维数灾难”的另一个影响是训练样本的稀疏性并不是均匀分布的。处于中心位置的训练样本比四周的训练样本更加稀疏。 假设有一个二维特征空间，如图8所示的矩形，在矩形内部有一个内切的圆形。由于越接近圆心的样本越稀疏，因此，相比于圆形内的样本，那些位于矩形四角的样本更加难以分类。那么，随着特征数量的增加，圆形的面积会不会变化呢？这里我们假设超立方体(hypercube)的边长d=1，那么计算半径为0.5的超球面(hypersphere)的体积(volume)的公式为：$V(d)=\frac{\pi ^{\frac{d}{2}}}{\Gamma (\frac{d}{2}+1)}0.5^{d}$ 从图9可以看出随着特征数量的增加，超球面的体积逐渐减小直至趋向于零，然而超立方体的体积却不变。这个结果有点出乎意料，但部分说明了分类问题中的“维数灾难”：在高维特征空间中，大多数的训练样本位于超立方体的角落。 图10显示了不同维度下，样本的分布情况。在8维特征空间中，共有2^8=256个角落，而98%的样本分布在这些角落。随着维度的不断增加，公式2将趋向于0，其中dist_max和dist_min分别表示样本到中心的最大与最小距离。 因此，在高维特征空间中对于样本距离的度量失去意义。由于分类器基本都依赖于如Euclidean距离，Manhattan距离等，所以在特征数量过大时，分类器的性能就会出现下降。 所以，我们如何避免“维数灾难”？图1显示了分类器的性能随着特征个数的变化不断增加，过了某一个值后，性能不升反降。这里的某一个值到底是多少呢？目前，还没有方法来确定分类问题中的这个阈值是多少，这依赖于训练样本的数量，决策边界的复杂性以及分类器的类型。理论上，如果训练样本的数量无限大，那么就不会存在“维数灾难”，我们可以采用任意多的特征来训练分类器。事实上，训练样本的数量是有限的，所以不应该采用过多的特征。此外，那些需要精确的非线性决策边界的分类器，比如neural network，knn，decision trees等的泛化能力往往并不是很好，更容易发生过拟合问题。因此，在设计这些分类器时应当慎重考虑特征的数量。相反，那些泛化能力较好的分类器，比如naive Bayesian，linear classifier等，可以适当增加特征的数量。 如果给定了N个特征，我们该如何从中选出M个最优的特征？最简单粗暴的方法是尝试所有特征的组合，从中挑出M个最优的特征。事实上，这是非常花时间的，或者说不可行的。其实，已经有许多特征选择算法(feature selection algorithms)来帮助我们确定特征的数量以及选择特征。此外，还有许多特征抽取方法(feature extraction methods)，比如PCA等。交叉验证(cross-validation)也常常被用于检测与避免过拟合问题。 参考资料：[1] Vincent Spruyt. The Curse of Dimensionality in classification. Computer vision for dummies. 2014. [Link] 2.21.2 怎样避免维数灾难解决维度灾难问题： 主成分分析法PCA，线性判别法LDA 奇异值分解简化数据、拉普拉斯特征映射 Lassio缩减系数法、小波分析法、 2.21.3 聚类和降维有什么区别与联系？聚类用于找寻数据内在的分布结构,既可以作为一个单独的过程，比如异常检测等等。也可作为分类等其他学习任务的前驱过程。聚类是标准的无监督学习。 1) 在一些推荐系统中需确定新用户的类型，但定义“用户类型”却可能不太容易,此时往往可先对原油的用户数据进行聚类,根据聚类结果将每个簇定义为一个类,然后再基于这些类训练分类模型,用于判别新用户的类型。 2）而降维则是为了缓解维数灾难的一个重要方法，就是通过某种数学变换将原始高维属性空间转变为一个低维“子空间”。其基于的假设就是，虽然人们平时观测到的数据样本虽然是高维的，但是实际上真正与学习任务相关的是个低维度的分布。从而通过最主要的几个特征维度就可以实现对数据的描述，对于后续的分类很有帮助。比如对于Kaggle上的泰坦尼克号生还问题。通过给定一个人的许多特征如年龄、姓名、性别、票价等，来判断其是否能在海难中生还。这就需要首先进行特征筛选，从而能够找出主要的特征，让学习到的模型有更好的泛化性。 聚类和降维都可以作为分类等问题的预处理步骤。 但是他们虽然都能实现对数据的约减。但是二者适用的对象不同，聚类针对的是数据点，而降维则是对于数据的特征。另外它们着很多种实现方法。聚类中常用的有K-means、层次聚类、基于密度的聚类等；降维中常用的则PCA、Isomap、LLE等。 2.21.4 四种聚类方法之比较http://www.cnblogs.com/William_Fire/archive/2013/02/09/2909499.html 聚类分析是一种重要的人类行为，早在孩提时代，一个人就通过不断改进下意识中的聚类模式来学会如何区分猫狗、动物植物。目前在许多领域都得到了广泛的研究和成功的应用，如用于模式识别、数据分析、图像处理、市场研究、客户分割、Web文档分类等[1]。 聚类就是按照某个特定标准(如距离准则)把一个数据集分割成不同的类或簇，使得同一个簇内的数据对象的相似性尽可能大，同时不在同一个簇中的数据对象的差异性也尽可能地大。即聚类后同一类的数据尽可能聚集到一起，不同数据尽量分离。 聚类技术[2]正在蓬勃发展，对此有贡献的研究领域包括数据挖掘、统计学、机器学习、空间数据库技术、生物学以及市场营销等。各种聚类方法也被不断提出和改进，而不同的方法适合于不同类型的数据，因此对各种聚类方法、聚类效果的比较成为值得研究的课题。 1 聚类算法的分类 目前，有大量的聚类算法[3]。而对于具体应用，聚类算法的选择取决于数据的类型、聚类的目的。如果聚类分析被用作描述或探查的工具，可以对同样的数据尝试多种算法，以发现数据可能揭示的结果。 主要的聚类算法可以划分为如下几类：划分方法、层次方法、基于密度的方法、基于网格的方法以及基于模型的方法[4-6]。 每一类中都存在着得到广泛应用的算法，例如：划分方法中的k-means[7]聚类算法、层次方法中的凝聚型层次聚类算法[8]、基于模型方法中的神经网络[9]聚类算法等。目前,聚类问题的研究不仅仅局限于上述的硬聚类，即每一个数据只能被归为一类，模糊聚类[10]也是聚类分析中研究较为广泛的一个分支。模糊聚类通过隶 属函数来确定每个数据隶属于各个簇的程度，而不是将一个数据对象硬性地归类到某一簇中。目前已有很多关于模糊聚类的算法被提出，如著名的FCM算法等。本文主要对k-means聚类算法、凝聚型层次聚类算法、神经网络聚类算法之SOM,以及模糊聚类的FCM算法通过通用测试数据集进行聚类效果的比较和分析。 2 四种常用聚类算法研究 2.1 k-means聚类算法 k-means是划分方法中较经典的聚类算法之一。由于该算法的效率高，所以在对大规模数据进行聚类时被广泛应用。目前，许多算法均围绕着该算法进行扩展和改进。 k-means算法以k为参数，把n个对象分成k个簇，使簇内具有较高的相似度，而簇间的相似度较低。k-means算法的处理过程如下：首先，随机地 选择k个对象，每个对象初始地代表了一个簇的平均值或中心;对剩余的每个对象，根据其与各簇中心的距离，将它赋给最近的簇;然后重新计算每个簇的平均值。 这个过程不断重复，直到准则函数收敛。通常，采用平方误差准则，其定义如下： $E=\sum_{i=1}^{k}\sum_{p\subset C}|p-m_{i}|^{2}$ 这里E是数据库中所有对象的平方误差的总和，p是空间中的点，mi是簇Ci的平均值[9]。该目标函数使生成的簇尽可能紧凑独立，使用的距离度量是欧几里得距离,当然也可以用其他距离度量。k-means聚类算法的算法流程如下：输入：包含n个对象的数据库和簇的数目k；输出：k个簇，使平方误差准则最小。步骤： (1) 任意选择k个对象作为初始的簇中心； (2) repeat； (3) 根据簇中对象的平均值，将每个对象(重新)赋予最类似的簇； (4) 更新簇的平均值，即计算每个簇中对象的平均值； (5) until不再发生变化。 2.2 层次聚类算法根据层次分解的顺序是自底向上的还是自上向下的，层次聚类算法分为凝聚的层次聚类算法和分裂的层次聚类算法。 凝聚型层次聚类的策略是先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到所有对象都在一个簇中，或者某个终结条件被满足。绝大多数层次聚类属于凝聚型层次聚类，它们只是在簇间相似度的定义上有所不同。四种广泛采用的簇间距离度量方法如下： 这里给出采用最小距离的凝聚层次聚类算法流程： (1) 将每个对象看作一类，计算两两之间的最小距离； (2) 将距离最小的两个类合并成一个新类； (3) 重新计算新类与所有类之间的距离； (4) 重复(2)、(3)，直到所有类最后合并成一类。 2.21.5 SOM聚类算法SOM神经网络[11]是由芬兰神经网络专家Kohonen教授提出的，该算法假设在输入对象中存在一些拓扑结构或顺序，可以实现从输入空间(n维)到输出平面(2维)的降维映射，其映射具有拓扑特征保持性质,与实际的大脑处理有很强的理论联系。 SOM网络包含输入层和输出层。输入层对应一个高维的输入向量，输出层由一系列组织在2维网格上的有序节点构成，输入节点与输出节点通过权重向量连接。 学习过程中，找到与之距离最短的输出层单元，即获胜单元，对其更新。同时，将邻近区域的权值更新，使输出节点保持输入向量的拓扑特征。 算法流程： (1) 网络初始化，对输出层每个节点权重赋初值；(2) 将输入样本中随机选取输入向量，找到与输入向量距离最小的权重向量；(3) 定义获胜单元，在获胜单元的邻近区域调整权重使其向输入向量靠拢；(4) 提供新样本、进行训练；(5) 收缩邻域半径、减小学习率、重复，直到小于允许值，输出聚类结果。 2.21.6 FCM聚类算法1965年美国加州大学柏克莱分校的扎德教授第一次提出了‘集合’的概念。经过十多年的发展，模糊集合理论渐渐被应用到各个实际应用方面。为克服非此即彼的分类缺点，出现了以模糊集合论为数学基础的聚类分析。用模糊数学的方法进行聚类分析，就是模糊聚类分析[12]。 FCM算法是一种以隶属度来确定每个数据点属于某个聚类程度的算法。该聚类算法是传统硬聚类算法的一种改进。 算法流程： (1) 标准化数据矩阵； (2) 建立模糊相似矩阵，初始化隶属矩阵； (3) 算法开始迭代，直到目标函数收敛到极小值； (4) 根据迭代结果，由最后的隶属矩阵确定数据所属的类，显示最后的聚类结果。 3 四种聚类算法试验 3.1 试验数据 实验中，选取专门用于测试分类、聚类算法的国际通用的UCI数据库中的IRIS[13]数据集，IRIS数据集包含150个样本数据，分别取自三种不同 的莺尾属植物setosa、versicolor和virginica的花朵样本,每个数据含有4个属性，即萼片长度、萼片宽度、花瓣长度，单位为cm。 在数据集上执行不同的聚类算法，可以得到不同精度的聚类结果。 3.2 试验结果说明 文中基于前面所述各算法原理及算法流程，用matlab进行编程运算，得到表1所示聚类结果。 如表1所示，对于四种聚类算法，按三方面进行比较： (1)聚错样本数：总的聚错的样本数，即各类中聚错的样本数的和； (2)运行时间：即聚类整个 过程所耗费的时间，单位为s； (3)平均准确度：设原数据集有k个类,用ci表示第i类，ni为ci中样本的个数，mi为聚类正确的个数,则mi/ni为 第i类中的精度，则平均精度为： $avg=\frac{1}{k}\sum_{i=1}^{k}\frac{m_{i}}{n_{i}}$ 2.22 GBDT和随机森林的区别GBDT和随机森林的相同点：1、都是由多棵树组成2、最终的结果都是由多棵树一起决定 GBDT和随机森林的不同点：1、组成随机森林的树可以是分类树，也可以是回归树；而GBDT只由回归树组成2、组成随机森林的树可以并行生成；而GBDT只能是串行生成3、对于最终的输出结果而言，随机森林采用多数投票等；而GBDT则是将所有结果累加起来，或者加权累加起来4、随机森林对异常值不敏感，GBDT对异常值非常敏感5、随机森林对训练集一视同仁，GBDT是基于权值的弱分类器的集成6、随机森林是通过减少模型方差提高性能，GBDT是通过减少模型偏差提高性能 2.23 大数据与深度学习之间的关系大数据通常被定义为“超出常用软件工具捕获，管理和处理能力”的数据集。 机器学习关心的问题是如何构建计算机程序使用经验自动改进。 数据挖掘**是从数据中提取模式的特定算法的应用。在数据挖掘中，重点在于算法的应用，而不是算法本身。 机器学习和数据挖掘之间的关系如下：数据挖掘是一个过程，在此过程中机器学习算法被用作提取数据集中的潜在有价值模式的工具。大数据与深度学习关系总结如下： 深度学习是一种模拟大脑的行为。可以从所学习对象的机制以及行为等等很多相关联的方面进行学习，模仿类型行为以及思维。 深度学习对于大数据的发展有帮助。深度学习对于大数据技术开发的每一个阶段均有帮助，不管是数据的分析还是挖掘还是建模，只有深度学习，这些工作才会有可能一一得到实现。 深度学习转变了解决问题的思维。很多时候发现问题到解决问题，走一步看一步不是一个主要的解决问题的方式了，在深度学习的基础上，要求我们从开始到最后都要基于哦那个一个目标，为了需要优化的那个最终目的去进行处理数据以及将数据放入到数据应用平台上去。 大数据的深度学习需要一个框架。在大数据方面的深度学习都是从基础的角度出发的，深度学习需要一个框架或者一个系统总而言之，将你的大数据通过深度分析变为现实这就是深度学习和大数据的最直接关系。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习数学基础问题]]></title>
    <url>%2F2017%2F03%2F20%2F%E7%AC%AC%E4%B8%80%E7%AB%A0_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[1.1 标量、向量、矩阵、张量之间的联系标量（scalar)​一个标量表示一个单独的数，它不同于线性代数中研究的其他大部分对象（通常是多个数的数组）。我们用斜体表示标量。标量通常被赋予小写的变量名称。 向量（vector）​一个向量表示一组有序排列的数。通过次序中的索引，我们可以确定每个单独的数。通常我们赋予向量粗体的小写变量名称，比如xx。向量中的元素可以通过带脚标的斜体表示。向量$X$的第一个元素是$X_1$，第二个元素是$X_2$，以此类推。我们也会注明存储在向量中的元素的类型（实数、虚数等）。 矩阵（matrix）​矩阵是具有相同特征和纬度的对象的集合，表现为一张二维数据表。其意义是一个对象表示为矩阵中的一行，一个特征表示为矩阵中的一列，每个特征都有数值型的取值。通常会赋予矩阵粗体的大写变量名称，比如$A$。 张量（tensor）​在某些情况下，我们会讨论坐标超过两维的数组。一般地，一个数组中的元素分布在若干维坐标的规则网格中，我们将其称之为张量。使用 $A$ 来表示张量“A”。张量$A$中坐标为$(i,j,k)$的元素记作$A_{(i,j,k)}$。 四者之间关系 标量是0阶张量，向量是一阶张量。举例：​标量就是知道棍子的长度，但是你不会知道棍子指向哪儿。​向量就是不但知道棍子的长度，还知道棍子指向前面还是后面。​张量就是不但知道棍子的长度，也知道棍子指向前面还是后面，还能知道这棍子又向上/下和左/右偏转了多少。 1.2 张量与矩阵的区别？ 从代数角度讲， 矩阵它是向量的推广。向量可以看成一维的“表格”（即分量按照顺序排成一排）， 矩阵是二维的“表格”（分量按照纵横位置排列）， 那么$n$阶张量就是所谓的$n$维的“表格”。 张量的严格定义是利用线性映射来描述。 从几何角度讲， 矩阵是一个真正的几何量，也就是说，它是一个不随参照系的坐标变换而变化的东西。向量也具有这种特性。 张量可以用3×3矩阵形式来表达。 表示标量的数和表示矢量的三维数组也可分别看作1×1，1×3的矩阵。 1.3 矩阵和向量相乘结果​ 一个$m$行$n$列的矩阵和$n$行向量相乘，最后得到就是一个$m$行的向量。运算法则就是矩阵中的每一行数据看成一个行向量与该向量作点乘。 1.4 向量和矩阵的范数归纳向量的范数​ 定义一个向量为：$\vec{a}=[-5, 6, 8, -10]$。任意一组向量设为$\vec{x}=(x_1,x_2,…,x_N)$。其不同范数求解如下： 向量的1范数：向量的各个元素的绝对值之和，上述向量$\vec{a}$的1范数结果就是：29。 $$\Vert\vec{x}\Vert_1=\sum_{i=1}^N\vert{x_i}\vert$$ 向量的2范数：向量的每个元素的平方和再开平方根，上述$\vec{a}$的2范数结果就是：15。 $$\Vert\vec{x}\Vert_2=\sqrt{\sum_{i=1}^N{\vert{x_i}\vert}^2}$$ 向量的负无穷范数：向量的所有元素的绝对值中最小的：上述向量$\vec{a}$的负无穷范数结果就是：5。 $$\Vert\vec{x}\Vert_{-\infty}=\min{|{x_i}|}$$ 向量的正无穷范数：向量的所有元素的绝对值中最大的：上述向量$\vec{a}$的负无穷范数结果就是：10。 $$\Vert\vec{x}\Vert_{+\infty}=\max{|{x_i}|}$$ 向量的p范数：向量元素绝对值的p次方和的1/p次幂。 $$L_p=\Vert\vec{x}\Vert_p=\sqrt[p]{\sum_{i=1}^{N}|{x_i}|^p}$$ 矩阵的范数 ​定义一个矩阵$A=[-1, 2, -3; 4, -6, 6]$。 任意矩阵定义为：$A_{m\times n}$，其元素为 $a_{ij}$。 矩阵的范数定义为 $$\Vert{A}\Vert_p :=\sup_{x\neq 0}\frac{\Vert{Ax}\Vert_p}{\Vert{x}\Vert_p}$$ ​当向量取不同范数时, 相应得到了不同的矩阵范数。 矩阵的1范数（列范数）：矩阵的每一列上的元素绝对值先求和，再从中取个最大的,（列和最大），上述矩阵$A$的1范数先得到$[5,8,9]$，再取最大的最终结果就是：9。 $$\Vert A\Vert_1=\max_{1\le j\le n}\sum_{i=1}^m|{a_{ij}}|$$ 矩阵的2范数：矩阵$A^TA$的最大特征值开平方根，上述矩阵$A$的2范数得到的最终结果是：10.0623。 $$\Vert A\Vert_2=\sqrt{\lambda_{max}(A^T A)}$$ 其中， $\lambda_{max}(A^T A)$ 为 $A^T A$ 的特征值绝对值的最大值。 矩阵的无穷范数（行范数）：矩阵的每一行上的元素绝对值先求和，再从中取个最大的，（行和最大），上述矩阵$A$的1范数先得到$[6；16]$，再取最大的最终结果就是：16。 $$\Vert A\Vert_{\infty}=\max_{1\le i \le n}\sum_{j=1}^n |{a_{ij}}|$$ 矩阵的核范数：矩阵的奇异值（将矩阵svd分解）之和，这个范数可以用来低秩表示（因为最小化核范数，相当于最小化矩阵的秩——低秩），上述矩阵A最终结果就是：10.9287。 矩阵的L0范数：矩阵的非0元素的个数，通常用它来表示稀疏，L0范数越小0元素越多，也就越稀疏，上述矩阵$A$最终结果就是：6。 矩阵的L1范数：矩阵中的每个元素绝对值之和，它是L0范数的最优凸近似，因此它也可以表示稀疏，上述矩阵$A$最终结果就是：22。 矩阵的F范数：矩阵的各个元素平方之和再开平方根，它通常也叫做矩阵的L2范数，它的优点在它是一个凸函数，可以求导求解，易于计算，上述矩阵A最终结果就是：10.0995。 $$\Vert A\Vert_F=\sqrt{(\sum_{i=1}^m\sum_{j=1}^n{| a_{ij}|}^2)}$$ 矩阵的L21范数：矩阵先以每一列为单位，求每一列的F范数（也可认为是向量的2范数），然后再将得到的结果求L1范数（也可认为是向量的1范数），很容易看出它是介于L1和L2之间的一种范数，上述矩阵$A$最终结果就是：17.1559。 矩阵的 p范数 $$\Vert A\Vert_p=\sqrt[p]{(\sum_{i=1}^m\sum_{j=1}^n{| a_{ij}|}^p)}$$ 1.5 如何判断一个矩阵为正定？ 顺序主子式全大于0； 存在可逆矩阵$C$使$C^TC$等于该矩阵； 正惯性指数等于$n$； 合同于单位矩阵$E$（即：规范形为$E$） 标准形中主对角元素全为正； 特征值全为正； 是某基的度量矩阵。 1.6 导数偏导计算导数定义: ​导数代表了在自变量变化趋于无穷小的时候，函数值的变化与自变量的变化的比值。几何意义是这个点的切线。物理意义是该时刻的（瞬时）变化率。​ 注意：在一元函数中，只有一个自变量变动，也就是说只存在一个方向的变化率，这也就是为什么一元函数没有偏导数的原因。在物理学中有平均速度和瞬时速度之说。平均速度有 $$v=\frac{s}{t}$$ ​其中$v$表示平均速度，$s$表示路程，$t$表示时间。这个公式可以改写为 $$\bar{v}=\frac{\Delta s}{\Delta t}=\frac{s(t_0+\Delta t)-s(t_0)}{\Delta t}$$ ​其中$\Delta s$表示两点之间的距离，而$\Delta t$表示走过这段距离需要花费的时间。当$\Delta t$趋向于0（$\Delta t \to 0$）时，也就是时间变得很短时，平均速度也就变成了在$t_0$时刻的瞬时速度，表示成如下形式： $$v(t_0)=\lim_{\Delta t \to 0}{\bar{v}}=\lim_{\Delta t \to 0}{\frac{\Delta s}{\Delta t}}=\lim_{\Delta t \to 0}{\frac{s(t_0+\Delta t)-s(t_0)}{\Delta t}}$$ ​实际上，上式表示的是路程$s$关于时间$t$的函数在$t=t_0$处的导数。一般的，这样定义导数：如果平均变化率的极限存在，即有 $$\lim_{\Delta x \to 0}{\frac{\Delta y}{\Delta x}}=\lim_{\Delta x \to 0}{\frac{f(x_0+\Delta x)-f(x_0)}{\Delta x}}$$ ​则称此极限为函数 $y=f(x)$ 在点 $x_0$ 处的导数。记作 $f’(x_0)$ 或 $y’\vert_{x=x_0}$ 或 $\frac{dy}{dx}\vert_{x=x_0}$ 或 $\frac{df(x)}{dx}\vert_{x=x_0}$。 ​通俗地说，导数就是曲线在某一点切线的斜率。 偏导数: ​既然谈到偏导数，那就至少涉及到两个自变量。以两个自变量为例，z=f（x,y），从导数到偏导数，也就是从曲线来到了曲面。曲线上的一点，其切线只有一条。但是曲面上的一点，切线有无数条。而偏导数就是指多元函数沿着坐标轴的变化率。​ 注意：直观地说，偏导数也就是函数在某一点上沿坐标轴正方向的的变化率。 ​设函数$z=f(x,y)$在点$(x_0,y_0)$的领域内有定义，当$y=y_0$时，$z$可以看作关于$x$的一元函数$f(x,y_0)$，若该一元函数在$x=x_0$处可导，即有 $$\lim_{\Delta x \to 0}{\frac{f(x_0+\Delta x,y_0)-f(x_0,y_0)}{\Delta x}}=A$$ ​函数的极限$A$存在。那么称$A$为函数$z=f(x,y)$在点$(x_0,y_0)$处关于自变量$x$的偏导数，记作$f_x(x_0,y_0)$或$\frac{\partial z}{\partial x}\vert_{y=y_0}^{x=x_0}$或$\frac{\partial f}{\partial x}\vert_{y=y_0}^{x=x_0}$或$z_x\vert_{y=y_0}^{x=x_0}$。 ​偏导数在求解时可以将另外一个变量看做常数，利用普通的求导方式求解，比如$z=3x^2+xy$关于$x$的偏导数就为$z_x=6x+y$，这个时候$y$相当于$x$的系数。 ​某点$(x_0,y_0)$处的偏导数的几何意义为曲面$z=f(x,y)$与面$x=x_0$或面$y=y_0$交线在$y=y_0$或$x=x_0$处切线的斜率。 1.7 导数和偏导数有什么区别？​导数和偏导没有本质区别，如果极限存在，都是当自变量的变化量趋于0时，函数值的变化量与自变量变化量比值的极限。 一元函数，一个$y$对应一个$x$，导数只有一个。 二元函数，一个$z$对应一个$x$和一个$y$，有两个导数：一个是$z$对$x$的导数，一个是$z$对$y$的导数，称之为偏导。 求偏导时要注意，对一个变量求导，则视另一个变量为常数，只对改变量求导，从而将偏导的求解转化成了一元函数的求导。 1.8 特征值分解与特征向量 特征值分解可以得到特征值与特征向量； 特征值表示的是这个特征到底有多重要，而特征向量表示这个特征是什么。 如果说一个向量$\vec{v}$是方阵$A$的特征向量，将一定可以表示成下面的形式： $$A\nu = \lambda \nu$$ $\lambda$为特征向量$\vec{v}$对应的特征值。特征值分解是将一个矩阵分解为如下形式：​$$A=Q\sum Q^{-1}$$ 其中，$Q$是这个矩阵$A$的特征向量组成的矩阵，$\sum$是一个对角矩阵，每一个对角线元素就是一个特征值，里面的特征值是由大到小排列的，这些特征值所对应的特征向量就是描述这个矩阵变化方向（从主要的变化到次要的变化排列）。也就是说矩阵$A$的信息可以由其特征值和特征向量表示。 1.9 奇异值与特征值有什么关系?​那么奇异值和特征值是怎么对应起来的呢？我们将一个矩阵$A$的转置乘以$A$，并对$AA^T$求特征值，则有下面的形式： $$(A^TA)V = \lambda V$$ 这里$V$就是上面的右奇异向量，另外还有： $$\sigma_i = \sqrt{\lambda_i}, u_i=\frac{1}{\sigma_i}A\mu_i$$ 这里的$\sigma$就是奇异值，$u$就是上面说的左奇异向量。【证明那个哥们也没给】​奇异值$\sigma$跟特征值类似，在矩阵$\sum$中也是从大到小排列，而且$\sigma$的减少特别的快，在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上了。也就是说，我们也可以用前$r$（$r$远小于$m、n$）个的奇异值来近似描述矩阵，即部分奇异值分解： $$A_{m\times n}\approx U_{m \times r}\sum_{r\times r}V_{r \times n}^T$$ 右边的三个矩阵相乘的结果将会是一个接近于$A$的矩阵，在这儿，$r$越接近于$n$，则相乘的结果越接近于$A$。 1.10 机器学习为什么要使用概率？​事件的概率是衡量该事件发生的可能性的量度。虽然在一次随机试验中某个事件的发生是带有偶然性的，但那些可在相同条件下大量重复的随机试验却往往呈现出明显的数量规律。​机器学习除了处理不确定量，也需处理随机量。不确定性和随机性可能来自多个方面，使用概率论来量化不确定性。​概率论在机器学习中扮演着一个核心角色，因为机器学习算法的设计通常依赖于对数据的概率假设。 ​ 例如在机器学习（Andrew Ng）的课中，会有一个朴素贝叶斯假设就是条件独立的一个例子。该学习算法对内容做出假设，用来分辨电子邮件是否为垃圾邮件。假设无论邮件是否为垃圾邮件，单词x出现在邮件中的概率条件独立于单词y。很明显这个假设不是不失一般性的，因为某些单词几乎总是同时出现。然而，最终结果是，这个简单的假设对结果的影响并不大，且无论如何都可以让我们快速判别垃圾邮件。 1.11 变量与随机变量有什么区别？随机变量（random variable） ​表示随机现象（在一定条件下，并不总是出现相同结果的现象称为随机现象）中各种结果的实值函数（一切可能的样本点）。例如某一时间内公共汽车站等车乘客人数，电话交换台在一定时间内收到的呼叫次数等，都是随机变量的实例。​随机变量与模糊变量的不确定性的本质差别在于，后者的测定结果仍具有不确定性，即模糊性。 变量与随机变量的区别：​当变量的取值的概率不是1时,变量就变成了随机变量；当随机变量取值的概率为1时,随机变量就变成了变量。 比如：​ 当变量$x$值为100的概率为1的话,那么$x=100$就是确定了的,不会再有变化,除非有进一步运算.​ 当变量$x$的值为100的概率不为1,比如为50的概率是0.5,为100的概率是0.5,那么这个变量就是会随不同条件而变化的,是随机变量,取到50或者100的概率都是0.5,即50%。 1.12 常见概率分布(https://wenku.baidu.com/view/6418b0206d85ec3a87c24028915f804d2b168707) 1.13 举例理解条件概率​条件概率公式如下： $$P(A/B) = P(A\cap B) / P(B)$$ ​说明：在同一个样本空间$\Omega$中的事件或者子集$A$与$B$，如果随机从$\Omega$中选出的一个元素属于$B$，那么下一个随机选择的元素属于$A$ 的概率就定义为在$B$的前提下$A$的条件概率。 ​根据文氏图，可以很清楚地看到在事件B发生的情况下，事件A发生的概率就是$P(A\bigcap B)$除以$P(B)$。​举例：一对夫妻有两个小孩，已知其中一个是女孩，则另一个是女孩子的概率是多少？（面试、笔试都碰到过）​穷举法：已知其中一个是女孩，那么样本空间为男女，女女，女男，则另外一个仍然是女生的概率就是1/3。​条件概率法：$P(女|女)=P(女女)/P(女)$,夫妻有两个小孩，那么它的样本空间为女女，男女，女男，男男，则$P(女女)$为1/4，$P（女）= 1-P(男男)=3/4$,所以最后$1/3$。这里大家可能会误解，男女和女男是同一种情况，但实际上类似姐弟和兄妹是不同情况。 1.14 联合概率与边缘概率联系区别？区别：​联合概率：联合概率指类似于$P(X=a,Y=b)$这样，包含多个条件，且所有条件同时成立的概率。联合概率是指在多元的概率分布中多个随机变量分别满足各自条件的概率。​边缘概率：边缘概率是某个事件发生的概率，而与其它事件无关。边缘概率指类似于$P(X=a)$，$P(Y=b)$这样，仅与单个随机变量有关的概率。 联系：​联合分布可求边缘分布，但若只知道边缘分布，无法求得联合分布。 1.15 条件概率的链式法则​由条件概率的定义，可直接得出下面的乘法公式：​乘法公式 设$A, B$是两个事件，并且$P(A) &gt; 0$, 则有 $$P(AB) = P(B|A)P(A)$$ ​推广 $$P(ABC)=P(C|AB)P(B|A)P(A)$$ ​一般地，用归纳法可证：若$P(A_1A_2…A_n)&gt;0$，则有 $$P(A_1A_2…A_n)=P(A_n|A_1A_2…A_{n-1})P(A_{n-1}|A_1A_2…A_{n-2})…P(A_2|A_1)P(A_1)=P(A_1)\prod_{i=2}^{n}P(A_i|A_1A_2…A_{i-1})$$ ​任何多维随机变量联合概率分布，都可以分解成只有一个变量的条件概率相乘形式。 1.16 独立性和条件独立性独立性​两个随机变量$x$和$y$，概率分布表示成两个因子乘积形式，一个因子只包含$x$，另一个因子只包含$y$，两个随机变量相互独立(independent)。​条件有时为不独立的事件之间带来独立，有时也会把本来独立的事件，因为此条件的存在，而失去独立性。​举例：$P(XY)=P(X)P(Y)$, 事件$X$和事件$Y$独立。此时给定$Z$， $$P(X,Y|Z) \not = P(X|Z)P(Y|Z)$$ ​事件独立时，联合概率等于概率的乘积。这是一个非常好的数学性质，然而不幸的是，无条件的独立是十分稀少的，因为大部分情况下，事件之间都是互相影响的。 条件独立性​给定$Z$的情况下,$X$和$Y$条件独立，当且仅当 $$X\bot Y|Z \iff P(X,Y|Z) = P(X|Z)P(Y|Z)$$ ​$X$和$Y$的关系依赖于$Z$，而不是直接产生。 举例定义如下事件：$X$：明天下雨；$Y$：今天的地面是湿的；$Z$：今天是否下雨；$Z$事件的成立，对$X$和$Y$均有影响，然而，在$Z$事件成立的前提下，今天的地面情况对明天是否下雨没有影响。 1.17 期望、方差、协方差、相关系数总结期望​在概率论和统计学中，数学期望（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和。它反映随机变量平均取值的大小。 线性运算： $E(ax+by+c) = aE(x)+bE(y)+c$ ​推广形式： $E(\sum_{k=1}^{n}{a_kx_k+c}) = \sum_{k=1}^{n}{a_kE(x_k)+c}$ 函数期望：设$f(x)$为$x$的函数，则$f(x)$的期望为 离散函数： $E(f(x))=\sum_{k=1}^{n}{f(x_k)P(x_k)}$ 连续函数： $E(f(x))=\int_{-\infty}^{+\infty}{f(x)p(x)dx}$ 注意： 函数的期望不等于期望的函数，即$E(f(x))=f(E(x))$ 一般情况下，乘积的期望不等于期望的乘积。 如果$X$和$Y$相互独立，则$E(xy)=E(x)E(y)​$。 方差 ​概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。方差是一种特殊的期望。定义为： $$Var(x) = E((x-E(x))^2)$$ 方差性质： 1）$Var(x) = E(x^2) -E(x)^2$2）常数的方差为0;3）方差不满足线性性质;4）如果$X$和$Y$相互独立, $Var(ax+by)=a^2Var(x)+b^2Var(y)$ 协方差​协方差是衡量两个变量线性相关性强度及变量尺度。 两个随机变量的协方差定义为： $$Cov(x,y)=E((x-E(x))(y-E(y)))$$ ​方差是一种特殊的协方差。当$X=Y$时，$Cov(x,y)=Var(x)=Var(y)$。 协方差性质： 1）独立变量的协方差为0。2）协方差计算公式： $$Cov(\sum_{i=1}^{m}{a_ix_i}, \sum_{j=1}^{m}{b_jy_j}) = \sum_{i=1}^{m} \sum_{j=1}^{m}{a_ib_jCov(x_iy_i)}$$ 3）特殊情况： $$Cov(a+bx, c+dy) = bdCov(x, y)$$ 相关系数​相关系数是研究变量之间线性相关程度的量。两个随机变量的相关系数定义为： $$Corr(x,y) = \frac{Cov(x,y)}{\sqrt{Var(x)Var(y)}}$$ 相关系数的性质：1）有界性。相关系数的取值范围是 ，可以看成无量纲的协方差。2）值越接近1，说明两个变量正相关性（线性）越强。越接近-1，说明负相关性越强，当为0时，表示两个变量没有相关性。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第九讲 背包问题问法的变化]]></title>
    <url>%2F2016%2F12%2F19%2F%E7%AC%AC%E4%B9%9D%E8%AE%B2%20%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%E9%97%AE%E6%B3%95%E7%9A%84%E5%8F%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[第九讲 背包问题问法的变化 以上涉及的各种背包问题都是要求在背包容量（费用）的限制下求可以取到的最大价值，但背包问题还有很多种灵活的问法，在这里值得提一下。但是我认为，只要深入理解了求背包问题最大价值的方法，即使问法变化了，也是不难想出算法的。 例如，求解最多可以放多少件物品或者最多可以装满多少背包的空间。这都可以根据具体问题利用前面的方程求出所有状态的值（f数组）之后得到。 还有，如果要求的是“总价值最小”“总件数最小”，只需简单的将上面的状态转移方程中的max改成min即可。 下面说一些变化更大的问法。 输出方案一般而言，背包问题是要求一个最优值，如果要求输出这个最优值的方案，可以参照一般动态规划问题输出方案的方法：记录下每个状态的最优值是由状态转移方程的哪一项推出来的，换句话说，记录下它是由哪一个策略推出来的。便可根据这条策略找到上一个状态，从上一个状态接着向前推即可。 还是以01背包为例，方程为f[i][v]=max{f[i-1][v],f[i-1][v-c[i]]+w[i]}。再用一个数组g[i][v]，设g[i][v]=0表示推出f[i][v]的值时是采用了方程的前一项（也即f[i][v]=f[i-1][v]），g[i][v]表示采用了方程的后一项。注意这两项分别表示了两种策略：未选第i个物品及选了第i个物品。那么输出方案的伪代码可以这样写（设最终状态为f[N][V]）： i=N v=V while(i&gt;0) if(g[i][v]==0) print &quot;未选第i项物品&quot; else if(g[i][v]==1) print &quot;选了第i项物品&quot; v=v-c[i] 另外，采用方程的前一项或后一项也可以在输出方案的过程中根据f[i][v]的值实时地求出来，也即不须纪录g数组，将上述代码中的g[i][v]==0改成f[i][v]==f[i-1][v]，g[i][v]==1改成f[i][v]==f[i-1][v-c[i]]+w[i]也可。 输出字典序最小的最优方案这里“字典序最小”的意思是1..N号物品的选择方案排列出来以后字典序最小。以输出01背包最小字典序的方案为例。 一般而言，求一个字典序最小的最优方案，只需要在转移时注意策略。首先，子问题的定义要略改一些。我们注意到，如果存在一个选了物品1的最优方案，那么答案一定包含物品1，原问题转化为一个背包容量为v-c[1]，物品为2..N的子问题。反之，如果答案不包含物品1，则转化成背包容量仍为V，物品为2..N的子问题。不管答案怎样，子问题的物品都是以i..N而非前所述的1..i的形式来定义的，所以状态的定义和转移方程都需要改一下。但也许更简易的方法是先把物品逆序排列一下，以下按物品已被逆序排列来叙述。 在这种情况下，可以按照前面经典的状态转移方程来求值，只是输出方案的时候要注意：从N到1输入时，如果f[i][v]==f[i-1][i-v]及f[i][v]==f[i-1][f-c[i]]+w[i]同时成立，应该按照后者（即选择了物品i）来输出方案。 求方案总数对于一个给定了背包容量、物品费用、物品间相互关系（分组、依赖等）的背包问题，除了再给定每个物品的价值后求可得到的最大价值外，还可以得到装满背包或将背包装至某一指定容量的方案总数。 对于这类改变问法的问题，一般只需将状态转移方程中的max改成sum即可。例如若每件物品均是完全背包中的物品，转移方程即为 f[i][v]=sum{f[i-1][v],f[i][v-c[i]]} 初始条件f[0][0]=1。 事实上，这样做可行的原因在于状态转移方程已经考察了所有可能的背包组成方案。 最优方案的总数这里的最优方案是指物品总价值最大的方案。以01背包为例。 结合求最大总价值和方案总数两个问题的思路，最优方案的总数可以这样求：f[i][v]意义同前述，g[i][v]表示这个子问题的最优方案的总数，则在求f[i][v]的同时求g[i][v]的伪代码如下： for i=1..N for v=0..V f[i][v]=max{f[i-1][v],f[i-1][v-c[i]]+w[i]} g[i][v]=0 if(f[i][v]==f[i-1][v]) inc(g[i][v],g[i-1][v]) if(f[i][v]==f[i-1][v-c[i]]+w[i]) inc(g[i][v],g[i-1][v-c[i]]) 如果你是第一次看到这样的问题，请仔细体会上面的伪代码。 求次优解、第K优解对于求次优解、第K优解类的问题，如果相应的最优解问题能写出状态转移方程、用动态规划解决，那么求次优解往往可以相同的复杂度解决，第K优解则比求最优解的复杂度上多一个系数K。 其基本思想是将每个状态都表示成有序队列，将状态转移方程中的max/min转化成有序队列的合并。这里仍然以01背包为例讲解一下。 首先看01背包求最优解的状态转移方程：f[i][v]=max{f[i-1][v],f[i-1][v-c[i]]+w[i]}。如果要求第K优解，那么状态f[i][v]就应该是一个大小为K的数组f[i][v][1..K]。其中f[i][v][k]表示前i个物品、背包大小为v时，第k优解的值。“f[i][v]是一个大小为K的数组”这一句，熟悉C语言的同学可能比较好理解，或者也可以简单地理解为在原来的方程中加了一维。显然f[i][v][1..K]这K个数是由大到小排列的，所以我们把它认为是一个有序队列。 然后原方程就可以解释为：f[i][v]这个有序队列是由f[i-1][v]和f[i-1][v-c[i]]+w[i]这两个有序队列合并得到的。有序队列f[i-1][v]即f[i-1][v][1..K]，f[i-1][v-c[i]]+w[i]则理解为在f[i-1][v-c[i]][1..K]的每个数上加上w[i]后得到的有序队列。合并这两个有序队列并将结果的前K项储存到f[i][v][1..K]中的复杂度是O(K)。最后的答案是f[N][V][K]。总的复杂度是O(VNK)。 为什么这个方法正确呢？实际上，一个正确的状态转移方程的求解过程遍历了所有可用的策略，也就覆盖了问题的所有方案。只不过由于是求最优解，所以其它在任何一个策略上达不到最优的方案都被忽略了。如果把每个状态表示成一个大小为K的数组，并在这个数组中有序的保存该状态可取到的前K个最优值。那么，对于任两个状态的max运算等价于两个由大到小的有序队列的合并。 另外还要注意题目对于“第K优解”的定义，将策略不同但权值相同的两个方案是看作同一个解还是不同的解。如果是前者，则维护有序队列时要保证队列里的数没有重复的。 小结显然，这里不可能穷尽背包类动态规划问题所有的问法。甚至还存在一类将背包类动态规划问题与其它领域（例如数论、图论）结合起来的问题，在这篇论背包问题的专文中也不会论及。但只要深刻领会前述所有类别的背包问题的思路和状态转移方程，遇到其它的变形问法，只要题目难度还属于NOIP，应该也不难想出算法。 触类旁通、举一反三，应该也是一个OIer应有的品质吧。]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法:背包问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第八讲 背包问题——泛化物品]]></title>
    <url>%2F2016%2F12%2F18%2F%E7%AC%AC%E5%85%AB%E8%AE%B2%20%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%E2%80%94%E2%80%94%E6%B3%9B%E5%8C%96%E7%89%A9%E5%93%81%2F</url>
    <content type="text"><![CDATA[第八讲 泛化物品 定义考虑这样一种物品，它并没有固定的费用和价值，而是它的价值随着你分配给它的费用而变化。这就是泛化物品的概念。 更严格的定义之。在背包容量为V的背包问题中，泛化物品是一个定义域为0..V中的整数的函数h，当分配给它的费用为v时，能得到的价值就是h(v)。 这个定义有一点点抽象，另一种理解是一个泛化物品就是一个数组h[0..V]，给它费用v，可得到价值h[V]。 一个费用为c价值为w的物品，如果它是01背包中的物品，那么把它看成泛化物品，它就是除了h(c)=w其它函数值都为0的一个函数。如果它是完全背包中的物品，那么它可以看成这样一个函数，仅当v被c整除时有h(v)=v/cw，其它函数值均为0。如果它是多重背包中重复次数最多为n的物品，那么它对应的泛化物品的函数有h(v)=v/cw仅当v被c整除且v/c&lt;=n，其它情况函数值均为0。 一个物品组可以看作一个泛化物品h。对于一个0..V中的v，若物品组中不存在费用为v的的物品，则h(v)=0，否则h(v)为所有费用为v的物品的最大价值。P07中每个主件及其附件集合等价于一个物品组，自然也可看作一个泛化物品。 泛化物品的和如果面对两个泛化物品h和l，要用给定的费用从这两个泛化物品中得到最大的价值，怎么求呢？事实上，对于一个给定的费用v，只需枚举将这个费用如何分配给两个泛化物品就可以了。同样的，对于0..V的每一个整数v，可以求得费用v分配到h和l中的最大价值f(v)。也即 f(v)=max{h(k)+l(v-k)|0&lt;=k&lt;=v} 可以看到，f也是一个由泛化物品h和l决定的定义域为0..V的函数，也就是说，f是一个由泛化物品h和l决定的泛化物品。 由此可以定义泛化物品的和：h、l都是泛化物品，若泛化物品f满足以上关系式，则称f是h与l的和。这个运算的时间复杂度取决于背包的容量，是O(V^2)。 泛化物品的定义表明：在一个背包问题中，若将两个泛化物品代以它们的和，不影响问题的答案。事实上，对于其中的物品都是泛化物品的背包问题，求它的答案的过程也就是求所有这些泛化物品之和的过程。设此和为s，则答案就是s[0..V]中的最大值。 背包问题的泛化物品一个背包问题中，可能会给出很多条件，包括每种物品的费用、价值等属性，物品之间的分组、依赖等关系等。但肯定能将问题对应于某个泛化物品。也就是说，给定了所有条件以后，就可以对每个非负整数v求得：若背包容量为v，将物品装入背包可得到的最大价值是多少，这可以认为是定义在非负整数集上的一件泛化物品。这个泛化物品——或者说问题所对应的一个定义域为非负整数的函数——包含了关于问题本身的高度浓缩的信息。一般而言，求得这个泛化物品的一个子域（例如0..V）的值之后，就可以根据这个函数的取值得到背包问题的最终答案。 综上所述，一般而言，求解背包问题，即求解这个问题所对应的一个函数，即该问题的泛化物品。而求解某个泛化物品的一种方法就是将它表示为若干泛化物品的和然后求之。 小结本讲可以说都是我自己的原创思想。具体来说，是我在学习函数式编程的 Scheme 语言时，用函数编程的眼光审视各类背包问题得出的理论。这一讲真的很抽象，也许在“模型的抽象程度”这一方面已经超出了NOIP的要求，所以暂且看不懂也没关系。相信随着你的OI之路逐渐延伸，有一天你会理解的。 我想说：“思考”是一个OIer最重要的品质。简单的问题，深入思考以后，也能发现更多。]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法:背包问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第七讲 有依赖的背包问题]]></title>
    <url>%2F2016%2F12%2F17%2F%E7%AC%AC%E4%B8%83%E8%AE%B2%20%E6%9C%89%E4%BE%9D%E8%B5%96%E7%9A%84%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[第七讲 有依赖的背包问题 简化的问题这种背包问题的物品间存在某种“依赖”的关系。也就是说，i依赖于j，表示若选物品i，则必须选物品j。为了简化起见，我们先设没有某个物品既依赖于别的物品，又被别的物品所依赖；另外，没有某件物品同时依赖多件物品。 算法这个问题由NOIP2006金明的预算方案一题扩展而来。遵从该题的提法，将不依赖于别的物品的物品称为“主件”，依赖于某主件的物品称为“附件”。由这个问题的简化条件可知所有的物品由若干主件和依赖于每个主件的一个附件集合组成。 按照背包问题的一般思路，仅考虑一个主件和它的附件集合。可是，可用的策略非常多，包括：一个也不选，仅选择主件，选择主件后再选择一个附件，选择主件后再选择两个附件……无法用状态转移方程来表示如此多的策略。（事实上，设有n个附件，则策略有2^n+1个，为指数级。） 考虑到所有这些策略都是互斥的（也就是说，你只能选择一种策略），所以一个主件和它的附件集合实际上对应于P06中的一个物品组，每个选择了主件又选择了若干个附件的策略对应于这个物品组中的一个物品，其费用和价值都是这个策略中的物品的值的和。但仅仅是这一步转化并不能给出一个好的算法，因为物品组中的物品还是像原问题的策略一样多。 再考虑P06中的一句话： 可以对每组中的物品应用P02中“一个简单有效的优化”。 这提示我们，对于一个物品组中的物品，所有费用相同的物品只留一个价值最大的，不影响结果。所以，我们可以对主件i的“附件集合”先进行一次01背包，得到费用依次为0..V-c[i]所有这些值时相应的最大价值f’[0..V-c[i]]。那么这个主件及它的附件集合相当于V-c[i]+1个物品的物品组，其中费用为c[i]+k的物品的价值为f’[k]+w[i]。也就是说原来指数级的策略中有很多策略都是冗余的，通过一次01背包后，将主件i转化为V-c[i]+1个物品的物品组，就可以直接应用P06的算法解决问题了。 较一般的问题更一般的问题是：依赖关系以图论中“森林”的形式给出（森林即多叉树的集合），也就是说，主件的附件仍然可以具有自己的附件集合，限制只是每个物品最多只依赖于一个物品（只有一个主件）且不出现循环依赖。 解决这个问题仍然可以用将每个主件及其附件集合转化为物品组的方式。唯一不同的是，由于附件可能还有附件，就不能将每个附件都看作一个一般的01背包中的物品了。若这个附件也有附件集合，则它必定要被先转化为物品组，然后用分组的背包问题解出主件及其附件集合所对应的附件组中各个费用的附件所对应的价值。 事实上，这是一种树形DP，其特点是每个父节点都需要对它的各个儿子的属性进行一次DP以求得自己的相关属性。这已经触及到了“泛化物品”的思想。看完P08后，你会发现这个“依赖关系树”每一个子树都等价于一件泛化物品，求某节点为根的子树对应的泛化物品相当于求其所有儿子的对应的泛化物品之和。 小结NOIP2006的那道背包问题我做得很失败，写了上百行的代码，却一分未得。后来我通过思考发现通过引入“物品组”和“依赖”的概念可以加深对这题的理解，还可以解决它的推广问题。用物品组的思想考虑那题中极其特殊的依赖关系：物品不能既作主件又作附件，每个主件最多有两个附件，可以发现一个主件和它的两个附件等价于一个由四个物品组成的物品组，这便揭示了问题的某种本质。 我想说：失败不是什么丢人的事情，从失败中全无收获才是。]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法:背包问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第六讲 分组的背包问题]]></title>
    <url>%2F2016%2F12%2F16%2F%E7%AC%AC%E5%85%AD%E8%AE%B2%20%E5%88%86%E7%BB%84%E7%9A%84%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[第六讲 分组的背包问题 问题有N件物品和一个容量为V的背包。第i件物品的费用是c[i]，价值是w[i]。这些物品被划分为若干组，每组中的物品互相冲突，最多选一件。求解将哪些物品装入背包可使这些物品的费用总和不超过背包容量，且价值总和最大。 算法这个问题变成了每组物品有若干种策略：是选择本组的某一件，还是一件都不选。也就是说设f[k][v]表示前k组物品花费费用v能取得的最大权值，则有： f[k][v]=max{f[k-1][v],f[k-1][v-c[i]]+w[i]|物品i属于组k} 使用一维数组的伪代码如下： for 所有的组k for v=V..0 for 所有的i属于组k f[v]=max{f[v],f[v-c[i]]+w[i]} 注意这里的三层循环的顺序，甚至在本文的第一个beta版中我自己都写错了。“for v=V..0”这一层循环必须在“for 所有的i属于组k”之外。这样才能保证每一组内的物品最多只有一个会被添加到背包中。 另外，显然可以对每组内的物品应用P02中“一个简单有效的优化”。 小结分组的背包问题将彼此互斥的若干物品称为一个组，这建立了一个很好的模型。不少背包问题的变形都可以转化为分组的背包问题（例如P07），由分组的背包问题进一步可定义“泛化物品”的概念，十分有利于解题。]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法:背包问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第五讲 二维费用的背包问题]]></title>
    <url>%2F2016%2F12%2F15%2F%E7%AC%AC%E4%BA%94%E8%AE%B2%20%E4%BA%8C%E7%BB%B4%E8%B4%B9%E7%94%A8%E7%9A%84%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[第五讲 二维费用的背包问题 问题二维费用的背包问题是指：对于每件物品，具有两种不同的费用；选择这件物品必须同时付出这两种代价；对于每种代价都有一个可付出的最大值（背包容量）。问怎样选择物品可以得到最大的价值。设这两种代价分别为代价1和代价2，第i件物品所需的两种代价分别为a[i]和b[i]。两种代价可付出的最大值（两种背包容量）分别为V和U。物品的价值为w[i]。 算法费用加了一维，只需状态也加一维即可。设f[i][v][u]表示前i件物品付出两种代价分别为v和u时可获得的最大价值。状态转移方程就是： f[i][v][u]=max{f[i-1][v][u],f[i-1][v-a[i]][u-b[i]]+w[i]} 如前述方法，可以只使用二维的数组：当每件物品只可以取一次时变量v和u采用逆序的循环，当物品有如完全背包问题时采用顺序的循环。当物品有如多重背包问题时拆分物品。这里就不再给出伪代码了，相信有了前面的基础，你能够自己实现出这个问题的程序。 物品总个数的限制有时，“二维费用”的条件是以这样一种隐含的方式给出的：最多只能取M件物品。这事实上相当于每件物品多了一种“件数”的费用，每个物品的件数费用均为1，可以付出的最大件数费用为M。换句话说，设f[v][m]表示付出费用v、最多选m件时可得到的最大价值，则根据物品的类型（01、完全、多重）用不同的方法循环更新，最后在f[0..V][0..M]范围内寻找答案。 复数域上的背包问题另一种看待二维背包问题的思路是：将它看待成复数域上的背包问题。也就是说，背包的容量以及每件物品的费用都是一个复数。而常见的一维背包问题则是实数域上的背包问题。（注意：上面的话其实不严谨，因为事实上我们处理的都只是整数而已。）所以说，一维背包的种种思想方法，往往可以应用于二位背包问题的求解中，因为只是数域扩大了而已。 作为这种思想的练习，你可以尝试将P11中提到的“子集和问题”扩展到复数域（即二维），并试图用同样的复杂度解决。 小结当发现由熟悉的动态规划题目变形得来的题目时，在原来的状态中加一纬以满足新的限制是一种比较通用的方法。希望你能从本讲中初步体会到这种方法。]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法:背包问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第四讲 混合三种背包问题]]></title>
    <url>%2F2016%2F12%2F13%2F%E7%AC%AC%E5%9B%9B%E8%AE%B2%20%E6%B7%B7%E5%90%88%E4%B8%89%E7%A7%8D%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[第四讲 混合三种背包问题 问题如果将P01、P02、P03混合起来。也就是说，有的物品只可以取一次（01背包），有的物品可以取无限次（完全背包），有的物品可以取的次数有一个上限（多重背包）。应该怎么求解呢？ 01背包与完全背包的混合考虑到在P01和P02中给出的伪代码只有一处不同，故如果只有两类物品：一类物品只能取一次，另一类物品可以取无限次，那么只需在对每个物品应用转移方程时，根据物品的类别选用顺序或逆序的循环即可，复杂度是O(VN)。伪代码如下： for i=1..N if 第i件物品属于01背包 for v=V..0 f[v]=max{f[v],f[v-c[i]]+w[i]}; else if 第i件物品属于完全背包 for v=0..V f[v]=max{f[v],f[v-c[i]]+w[i]}; 再加上多重背包如果再加上有的物品最多可以取有限次，那么原则上也可以给出O(VN)的解法：遇到多重背包类型的物品用单调队列解即可。但如果不考虑超过NOIP范围的算法的话，用P03中将每个这类物品分成O(log n[i])个01背包的物品的方法也已经很优了。 当然，更清晰的写法是调用我们前面给出的三个相关过程。 for i=1..N if 第i件物品属于01背包 ZeroOnePack(c[i],w[i]) else if 第i件物品属于完全背包 CompletePack(c[i],w[i]) else if 第i件物品属于多重背包 MultiplePack(c[i],w[i],n[i]) 在最初写出这三个过程的时候，可能完全没有想到它们会在这里混合应用。我想这体现了编程中抽象的威力。如果你一直就是以这种“抽象出过程”的方式写每一类背包问题的，也非常清楚它们的实现中细微的不同，那么在遇到混合三种背包问题的题目时，一定能很快想到上面简洁的解法，对吗？ 小结有人说，困难的题目都是由简单的题目叠加而来的。这句话是否公理暂且存之不论，但它在本讲中已经得到了充分的体现。本来01背包、完全背包、多重背包都不是什么难题，但将它们简单地组合起来以后就得到了这样一道一定能吓倒不少人的题目。但只要基础扎实，领会三种基本背包问题的思想，就可以做到把困难的题目拆分成简单的题目来解决。]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法:背包问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第三讲 多重背包问题]]></title>
    <url>%2F2016%2F12%2F12%2F%E7%AC%AC%E4%B8%89%E8%AE%B2%20%E5%A4%9A%E9%87%8D%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[第三讲 多重背包问题 题目有N种物品和一个容量为V的背包。第i种物品最多有n[i]件可用，每件费用是c[i]，价值是w[i]。求解将哪些物品装入背包可使这些物品的费用总和不超过背包容量，且价值总和最大。 基本算法这题目和完全背包问题很类似。基本的方程只需将完全背包问题的方程略微一改即可，因为对于第i种物品有n[i]+1种策略：取0件，取1件……取n[i]件。令f[i][v]表示前i种物品恰放入一个容量为v的背包的最大权值，则有状态转移方程： f[i][v]=max{f[i-1][v-k*c[i]]+k*w[i]|0&lt;=k&lt;=n[i]} 复杂度是O(V*Σn[i])。 转化为01背包问题另一种好想好写的基本方法是转化为01背包求解：把第i种物品换成n[i]件01背包中的物品，则得到了物品数为Σn[i]的01背包问题，直接求解，复杂度仍然是O(V*Σn[i])。 但是我们期望将它转化为01背包问题之后能够像完全背包一样降低复杂度。仍然考虑二进制的思想，我们考虑把第i种物品换成若干件物品，使得原问题中第i种物品可取的每种策略——取0..n[i]件——均能等价于取若干件代换以后的物品。另外，取超过n[i]件的策略必不能出现。 方法是：将第i种物品分成若干件物品，其中每件物品有一个系数，这件物品的费用和价值均是原来的费用和价值乘以这个系数。使这些系数分别为1,2,4,…,2^(k-1),n[i]-2^k+1，且k是满足n[i]-2^k+1&gt;0的最大整数。例如，如果n[i]为13，就将这种物品分成系数分别为1,2,4,6的四件物品。 分成的这几件物品的系数和为n[i]，表明不可能取多于n[i]件的第i种物品。另外这种方法也能保证对于0..n[i]间的每一个整数，均可以用若干个系数的和表示，这个证明可以分0..2^k-1和2^k..n[i]两段来分别讨论得出，并不难，希望你自己思考尝试一下。 这样就将第i种物品分成了O(log n[i])种物品，将原问题转化为了复杂度为O(V*Σlog n[i])的01背包问题，是很大的改进。 下面给出O(log amount)时间处理一件多重背包中物品的过程，其中amount表示物品的数量： procedure MultiplePack(cost,weight,amount) if cost*amount&gt;=V CompletePack(cost,weight) return integer k=1 while k&lt;amount ZeroOnePack(k*cost,k*weight) amount=amount-k k=k*2 ZeroOnePack(amount*cost,amount*weight) 希望你仔细体会这个伪代码，如果不太理解的话，不妨翻译成程序代码以后，单步执行几次，或者头脑加纸笔模拟一下，也许就会慢慢理解了。 O(VN)的算法多重背包问题同样有O(VN)的算法。这个算法基于基本算法的状态转移方程，但应用单调队列的方法使每个状态的值可以以均摊O(1)的时间求解。由于用单调队列优化的DP已超出了NOIP的范围，故本文不再展开讲解。我最初了解到这个方法是在楼天成的“男人八题”幻灯片上。 小结这里我们看到了将一个算法的复杂度由O(VΣn[i])改进到O(VΣlog n[i])的过程，还知道了存在应用超出NOIP范围的知识的O(VN)算法。希望你特别注意“拆分物品”的思想和方法，自己证明一下它的正确性，并将完整的程序代码写出来。]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法:背包问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二讲 完全背包问题]]></title>
    <url>%2F2016%2F12%2F11%2F%E7%AC%AC%E4%BA%8C%E8%AE%B2%20%E5%AE%8C%E5%85%A8%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[第二讲 完全背包问题 题目有N种物品和一个容量为V的背包，每种物品都有无限件可用。第i种物品的费用是c[i]，价值是w[i]。求解将哪些物品装入背包可使这些物品的费用总和不超过背包容量，且价值总和最大。 基本思路这个问题非常类似于01背包问题，所不同的是每种物品有无限件。也就是从每种物品的角度考虑，与它相关的策略已并非取或不取两种，而是有取0件、取1件、取2件……等很多种。如果仍然按照解01背包时的思路，令f[i][v]表示前i种物品恰放入一个容量为v的背包的最大权值。仍然可以按照每种物品不同的策略写出状态转移方程，像这样： f[i][v]=max{f[i-1][v-k*c[i]]+k*w[i]|0&lt;=k*c[i]&lt;=v} 这跟01背包问题一样有O(VN)个状态需要求解，但求解每个状态的时间已经不是常数了，求解状态f[i][v]的时间是O(v/c[i])，总的复杂度可以认为是O(V*Σ(V/c[i]))，是比较大的。 将01背包问题的基本思路加以改进，得到了这样一个清晰的方法。这说明01背包问题的方程的确是很重要，可以推及其它类型的背包问题。但我们还是试图改进这个复杂度。 一个简单有效的优化完全背包问题有一个很简单有效的优化，是这样的：若两件物品i、j满足c[i]=w[j]，则将物品j去掉，不用考虑。这个优化的正确性显然：任何情况下都可将价值小费用高得j换成物美价廉的i，得到至少不会更差的方案。对于随机生成的数据，这个方法往往会大大减少物品的件数，从而加快速度。然而这个并不能改善最坏情况的复杂度，因为有可能特别设计的数据可以一件物品也去不掉。 这个优化可以简单的O(N^2)地实现，一般都可以承受。另外，针对背包问题而言，比较不错的一种方法是：首先将费用大于V的物品去掉，然后使用类似计数排序的做法，计算出费用相同的物品中价值最高的是哪个，可以O(V+N)地完成这个优化。这个不太重要的过程就不给出伪代码了，希望你能独立思考写出伪代码或程序。 转化为01背包问题求解既然01背包问题是最基本的背包问题，那么我们可以考虑把完全背包问题转化为01背包问题来解。最简单的想法是，考虑到第i种物品最多选V/c[i]件，于是可以把第i种物品转化为V/c[i]件费用及价值均不变的物品，然后求解这个01背包问题。这样完全没有改进基本思路的时间复杂度，但这毕竟给了我们将完全背包问题转化为01背包问题的思路：将一种物品拆成多件物品。 更高效的转化方法是：把第i种物品拆成费用为c[i]2^k、价值为w[i]2^k的若干件物品，其中k满足c[i]*2^k&lt;=V。这是二进制的思想，因为不管最优策略选几件第i种物品，总可以表示成若干个2^k件物品的和。这样把每种物品拆成O(log V/c[i])件物品，是一个很大的改进。 但我们有更优的O(VN)的算法。 O(VN)的算法这个算法使用一维数组，先看伪代码： for i=1..N for v=0..V f[v]=max{f[v],f[v-cost]+weight} 你会发现，这个伪代码与P01的伪代码只有v的循环次序不同而已。为什么这样一改就可行呢？首先想想为什么P01中要按照v=V..0的逆序来循环。这是因为要保证第i次循环中的状态f[i][v]是由状态f[i-1][v-c[i]]递推而来。换句话说，这正是为了保证每件物品只选一次，保证在考虑“选入第i件物品”这件策略时，依据的是一个绝无已经选入第i件物品的子结果f[i-1][v-c[i]]。而现在完全背包的特点恰是每种物品可选无限件，所以在考虑“加选一件第i种物品”这种策略时，却正需要一个可能已选入第i种物品的子结果f[i][v-c[i]]，所以就可以并且必须采用v=0..V的顺序循环。这就是这个简单的程序为何成立的道理。 值得一提的是，上面的伪代码中两层for循环的次序可以颠倒。这个结论有可能会带来算法时间常数上的优化。 这个算法也可以以另外的思路得出。例如，将基本思路中求解f[i][v-c[i]]的状态转移方程显式地写出来，代入原方程中，会发现该方程可以等价地变形成这种形式： f[i][v]=max{f[i-1][v],f[i][v-c[i]]+w[i]} 将这个方程用一维数组实现，便得到了上面的伪代码。 最后抽象出处理一件完全背包类物品的过程伪代码： procedure CompletePack(cost,weight) for v=cost..V f[v]=max{f[v],f[v-c[i]]+w[i]} 总结完全背包问题也是一个相当基础的背包问题，它有两个状态转移方程，分别在“基本思路”以及“O(VN)的算法“的小节中给出。希望你能够对这两个状态转移方程都仔细地体会，不仅记住，也要弄明白它们是怎么得出来的，最好能够自己想一种得到这些方程的方法。事实上，对每一道动态规划题目都思考其方程的意义以及如何得来，是加深对动态规划的理解、提高动态规划功力的好方法。]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法:背包问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01背包问题]]></title>
    <url>%2F2016%2F12%2F10%2F%E7%AC%AC%E4%B8%80%E8%AE%B2%2001%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[第一讲 01背包问题 题目 有N件物品和一个容量为V的背包。第i件物品的费用是c[i]，价值是w[i]。求解将哪些物品装入背包可使价值总和最大。 基本思路这是最基础的背包问题，特点是：每种物品仅有一件，可以选择放或不放。 用子问题定义状态：即f[i][v]表示前i件物品恰放入一个容量为v的背包可以获得的最大价值。则其状态转移方程便是： f[i][v]=max{f[i-1][v],f[i-1][v-c[i]]+w[i]} 这个方程非常重要，基本上所有跟背包相关的问题的方程都是由它衍生出来的。所以有必要将它详细解释一下：“将前i件物品放入容量为v的背包中”这个子问题，若只考虑第i件物品的策略（放或不放），那么就可以转化为一个只牵扯前i-1件物品的问题。如果不放第i件物品，那么问题就转化为“前i-1件物品放入容量为v的背包中”，价值为f[i-1][v]；如果放第i件物品，那么问题就转化为“前i-1件物品放入剩下的容量为v-c[i]的背包中”，此时能获得的最大价值就是f[i-1][v-c[i]]再加上通过放入第i件物品获得的价值w[i]。 优化空间复杂度以上方法的时间和空间复杂度均为O(VN)，其中时间复杂度应该已经不能再优化了，但空间复杂度却可以优化到O。 先考虑上面讲的基本思路如何实现，肯定是有一个主循环i=1..N，每次算出来二维数组f[i][0..V]的所有值。那么，如果只用一个数组f[0..V]，能不能保证第i次循环结束后f[v]中表示的就是我们定义的状态f[i][v]呢？f[i][v]是由f[i-1][v]和f[i-1][v-c[i]]两个子问题递推而来，能否保证在推f[i][v]时（也即在第i次主循环中推f[v]时）能够得到f[i-1][v]和f[i-1][v-c[i]]的值呢？事实上，这要求在每次主循环中我们以v=V..0的顺序推f[v]，这样才能保证推f[v]时f[v-c[i]]保存的是状态f[i-1][v-c[i]]的值。伪代码如下： for i=1..N for v=V..0 f[v]=max{f[v],f[v-c[i]]+w[i]}; 其中的f[v]=max{f[v],f[v-c[i]]}一句恰就相当于我们的转移方程f[i][v]=max{f[i-1][v],f[i-1][v-c[i]]}，因为现在的f[v-c[i]]就相当于原来的f[i-1][v-c[i]]。如果将v的循环顺序从上面的逆序改成顺序的话，那么则成了f[i][v]由f[i][v-c[i]]推知，与本题意不符，但它却是另一个重要的背包问题P02最简捷的解决方案，故学习只用一维数组解01背包问题是十分必要的。 事实上，使用一维数组解01背包的程序在后面会被多次用到，所以这里抽象出一个处理一件01背包中的物品过程，以后的代码中直接调用不加说明。 过程ZeroOnePack，表示处理一件01背包中的物品，两个参数cost、weight分别表明这件物品的费用和价值。 procedure ZeroOnePack(cost,weight) for v=V..cost f[v]=max{f[v],f[v-cost]+weight} 注意这个过程里的处理与前面给出的伪代码有所不同。前面的示例程序写成v=V..0是为了在程序中体现每个状态都按照方程求解了，避免不必要的思维复杂度。而这里既然已经抽象成看作黑箱的过程了，就可以加入优化。费用为cost的物品不会影响状态f[0..cost-1]，这是显然的。 有了这个过程以后，01背包问题的伪代码就可以这样写： for i=1..N ZeroOnePack(c[i],w[i]); 初始化的细节问题我们看到的求最优解的背包问题题目中，事实上有两种不太相同的问法。有的题目要求“恰好装满背包”时的最优解，有的题目则并没有要求必须把背包装满。一种区别这两种问法的实现方法是在初始化的时候有所不同。 如果是第一种问法，要求恰好装满背包，那么在初始化时除了f[0]为0其它f[1..V]均设为-∞，这样就可以保证最终得到的f[N]是一种恰好装满背包的最优解。 如果并没有要求必须把背包装满，而是只希望价格尽量大，初始化时应该将f[0..V]全部设为0。 为什么呢？可以这样理解：初始化的f数组事实上就是在没有任何物品可以放入背包时的合法状态。如果要求背包恰好装满，那么此时只有容量为0的背包可能被价值为0的“恰好装满”，其它容量的背包均没有合法的解，属于未定义的状态，它们的值就都应该是-∞了。如果背包并非必须被装满，那么任何容量的背包都有一个合法解“什么都不装”，这个解的价值为0，所以初始时状态的值也就全部为0了。 这个小技巧完全可以推广到其它类型的背包问题，后面也就不再对进行状态转移之前的初始化进行讲解。 一个常数优化前面的伪代码中有 for v=V..1，可以将这个循环的下限进行改进。 由于只需要最后f[v]的值，倒推前一个物品，其实只要知道f[v-w[n]]即可。以此类推，对以第j个背包，其实只需要知道到f[v-sum{w[j..n]}]即可，即代码中的 for i=1..N for v=V..0 可以改成 for i=1..n bound=max{V-sum{w[i..n]},c[i]} for v=V..bound 这对于V比较大时是有用的。 小结01背包问题是最基本的背包问题，它包含了背包问题中设计状态、方程的最基本思想，另外，别的类型的背包问题往往也可以转换成01背包问题求解。故一定要仔细体会上面基本思路的得出方法，状态转移方程的意义，以及最后怎样优化的空间复杂度。 01背包的状态转换方程 f[i,j] = Max{ f[i-1,j-Wi]+Pi( j &gt;= Wi ), f[i-1,j] }f[i,j]表示在前i件物品中选择若干件放在承重为 j 的背包中，可以取得的最大价值。Pi表示第i件物品的价值。决策：为了背包中物品总价值最大化，第 i件物品应该放入背包中吗 ？ 题目描述： 假设山洞里共有a,b,c,d ,e这5件宝物（不是5种宝物），它们的重量分别是2,2,6,5,4，它们的价值分别是6,3,5,4,6，现在给你个承重为10的背包, 怎么装背包，可以才能带走最多的财富。 有编号分别为a,b,c,d,e的五件物品，它们的重量分别是2,2,6,5,4，它们的价值分别是6,3,5,4,6，现在给你个承重为10的背包，如何让背包里装入的物品具有最大的价值总和？ name weight value 1 2 3 4 5 6 7 8 9 10a 2 6 0 6 6 9 9 12 12 15 15 15b 2 3 0 3 3 6 6 9 9 9 10 11c 6 5 0 0 0 6 6 6 6 6 10 11d 5 4 0 0 0 6 6 6 6 6 10 10e 4 6 0 0 0 6 6 6 6 6 6 6 只要你能通过找规律手工填写出上面这张表就算理解了01背包的动态规划算法。 首先要明确这张表是至底向上，从左到右生成的。 为了叙述方便，用e2单元格表示e行2列的单元格，这个单元格的意义是用来表示只有物品e时，有个承重为2的背包，那么这个背包的最大价值是0，因为e物品的重量是4，背包装不了。 对于d2单元格，表示只有物品e，d时,承重为2的背包,所能装入的最大价值，仍然是0，因为物品e,d都不是这个背包能装的。 同理，c2=0，b2=3,a2=6。 对于承重为8的背包，a8=15,是怎么得出的呢？ 根据01背包的状态转换方程，需要考察两个值， 一个是f[i-1,j],对于这个例子来说就是b8的值9，另一个是f[i-1,j-Wi]+Pi； 在这里， f[i-1,j]表示我有一个承重为8的背包，当只有物品b,c,d,e四件可选时，这个背包能装入的最大价值 f[i-1,j-Wi]表示我有一个承重为6的背包（等于当前背包承重减去物品a的重量），当只有物品b,c,d,e四件可选时，这个背包能装入的最大价值 f[i-1,j-Wi]就是指单元格b6,值为9，Pi指的是a物品的价值，即6 由于f[i-1,j-Wi]+Pi = 9 + 6 = 15 大于f[i-1,j] = 9，所以物品a应该放入承重为8的背包 以下是actionscript3 的代码 public function get01PackageAnswer(bagItems:Array,bagSize:int):Array { var bagMatrix:Array=[]; var i:int; var item:PackageItem; for(i=0;i&lt;bagItems.length;i++) { bagMatrix[i] = [0]; } for(i=1;i&lt;=bagSize;i++) { for(var j:int=0;j&lt;bagItems.length;j++) { item = bagItems[j] as PackageItem; if(item.weight &gt; i) { //i背包转不下item if(j==0) { bagMatrix[j][i] = 0; } else { bagMatrix[j][i]=bagMatrix[j-1][i]; } } else { //将item装入背包后的价值总和 var itemInBag:int; if(j==0) { bagMatrix[j][i] = item.value; continue; } else { itemInBag = bagMatrix[j-1][i-item.weight]+item.value; } bagMatrix[j][i] = (bagMatrix[j-1][i] &gt; itemInBag ? bagMatrix[j-1][i] : itemInBag) } } } //find answer var answers:Array=[]; var curSize:int = bagSize; for(i=bagItems.length-1;i&gt;=0;i--) { item = bagItems[i] as PackageItem; if(curSize==0) { break; } if(i==0 &amp;&amp; curSize &gt; 0) { answers.push(item.name); break; } if(bagMatrix[i][curSize]-bagMatrix[i-1][curSize-item.weight]==item.value) { answers.push(item.name); curSize -= item.weight; } } return answers; } PackageItem类 public class PackageItem { public var name:String; public var weight:int; public var value:int; public function PackageItem(name:String,weight:int,value:int) { this.name = name; this.weight = weight; this.value = value; } } 测试代码 var nameArr:Array=[‘a’,’b’,’c’,’d’,’e’]; var weightArr:Array=[2,2,6,5,4]; var valueArr:Array=[6,3,5,4,6]; var bagItems:Array=[]; for(var i:int=0;i&lt;nameArr.length;i++) { var bagItem:PackageItem = new PackageItem(nameArr[i],weightArr[i],valueArr[i]); bagItems[i]=bagItem; } var arr:Array = ac.get01PackageAnswer(bagItems,10);]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法:背包问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法基础1()]]></title>
    <url>%2F2016%2F12%2F08%2Fchapter1%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、2、3、4、5、6、 01算法复杂度大O记号同样地出于保守的估计，我们首先关注T(n)的渐进上界。为此可引入所谓“大O记号”（big-O notation） 。具体地，若存在正的常数c和函数f(n)，使得对任何n &gt;&gt; 2都有T(n) &lt;= c∙f(n)则可认为在n足够大之后， f(n)给出了T(n)增长速度的一个渐进上界。此时，记之为：T(n) = O(f(n))由这一定义，可导出大O记号的以下性质：(1) 对于任一常数c &gt; 0，有O(f(n)) = O(c∙f(n))(2) 对于任意常数a &gt; b &gt; 0，有O(n^a + n^b) = O(n^a) 大Ω记号为了对算法的复杂度最好情况做出估计，需要借助另一个记号。如果存在正的常数c和函数g(n)，使得对于任何n &gt;&gt; 2都有T(n)  c∙g(n)就可以认为，在n足够大之后， g(n)给出了T(n)的一个渐进下界。此时，我们记之为：T(n) = Ω(g(n))这里的Ω称作“大Ω记号” （big-Ω notation）。与大O记号恰好相反，大Ω记号是对算法执行效率的乐观估计—对于规模为n的任意输入，算法的运行时间都不低于Ω(g(n))。比如，即便在最好情况下，起泡排序也至少需要T(n) = Ω(n)的计算时间。 大Θ记号借助大O记号、大Ω记号，可以对算法的时间复杂度作出定量的界定，亦即，从渐进的趋势看， T(n)介于Ω(g(n))与O(f(n))之间。若恰巧出现g(n) = f(n)的情况，则可以使用另一记号来表示。如果存在正的常数c1 &lt; c2和函数h(n)，使得对于任何n &gt;&gt; 2都有 c1∙h(n) &lt;= T(n) &lt;= c2∙h(n)就可以认为在n足够大之后， h(n)给出了T(n)的一个确界。此时，我们记之为：T(n) = Θ(h(n))这里的Θ称作“大Θ记号” （big-Θ notation） ，它是对算法复杂度的准确估计 复杂度分析常数O(1) 问题与算法首先考查如下问题：任给一个整数子集S, |S| = n ≥ 3，从中找出一个元素a ∈ S，使得a ≠ max(S)且a ≠ min(S)。亦即，在最大、最小者之外任取一个元素，称作“非极端元素” 或“平常元素” 。任取三个元素x, y, z ∈ S; //既然S是集合，返三个元素必于异通过比较对它们做排序; //设排序结枅为：min{x, y, z}, median(x, y, z), max{x, y, z}输出median(x, y, z); 对数O(logn) 问题与算法123456int i =1,n=1000,j=0; while(i&lt;n)&#123; i*=2; j++; &#125; 每次i乘以2，也就是说，至多经过1 + log2（n）次循环， i必然超过n，从而算法终止由大O记号定义，在用函数logrn界定渐进复杂度时，常底数r的具体取值无所谓，故通常不予专门标出而笼统地记作logn。比如，尽管此处底数为常数2，却可直接记作O(logn)。此类算法称作具有“对数时间复杂度” 线性O(n) 问题与算法考查如下问题：计算给定n个整数的总和。 该问题可由代码1.3中的算法sumI()解决。123456int sumI(int A[], int n) &#123; //数组求和算法（迭代版） int sum = 0; //初始化累计器，O(1) for (int i = 0; i &lt; n; i++) //对全部共O(n)个元素，逐一 sum += A[i]; //累计，O(1) return sum; //返回回累计值，O(1)&#125; //O(1) + O(n)*O(1) + O(1) = O(n+2) = O(n) 首先，对s的初始化需要O(1)时间。算法的主体部分是一个循环，每一轮循环中只需进行一次累加运算，这属于基本操作，可在O(1)时间内完成。每经过一轮循环，都将一个元素累加至s，故总共需要做n轮循环， 于是该算法的运行时间应为：O(1) + O(1)×n = O(n+1) = O(n) 多项式O(polynomial(n))若运行时间可以表示和度量为T(n) = O(f(n))的形式，而且f(x)为多项式，则对应的算法称作“多项式时间复杂度算法” （polynomial-time algorithm)。所实现起泡排序bubblesort()算法的时间复杂度应为T(n) = O(n^2)， 故该算法即属于此类。当然， 以上所介绍的线性时间复杂度算法， 也属于多项式时间复杂度算法的特例，其中线性多项式f(n) = n的次数为1 复杂度层次常用的时间复杂度所耗费的时间从小到大依次是：O(1) &lt; O(logn) &lt; (n) &lt; O(nlogn) &lt; O(n^2) &lt; O(n^3) &lt; O(2^n) &lt; O(n!) &lt; O(n^n) 02递归线性递归数组求和以下仍以下数组求和问题为例，采用线性递归模式设计另一算法。首先注意到，若n =0则总和必为0，这也是最终的平凡情况。否则一般地，数组的总和可理解为前n-1个整数（即A[0,n-2]）之和，再加上A[]的最后一个元素（即A[n-1]）。 按这一思路，可设计出sum()算法如代码1.5所示12345678910111213//线性递归,数组求和public class Test &#123; public static void main(String[] args) &#123; int [] arr = &#123;1,2,3&#125;; int result = func(arr,arr.length); System.out.println(result); &#125; private static int func(int [] arr,int n)&#123; return (n&lt;1) ? 0:func(arr,n-1)+arr[n-1]; // n &lt; 1平凡情况，递归基 //return 0; //直接（非递归式）计算 &#125;&#125; 由此实例可看出递归算法保证有穷性的基本技巧。 具体地，首先必须判断并处理n = 0之类的平凡情况，以免因无限递归而导致系统溢出。这类平凡情况统称“递归基”（base case ofrecursion）。 可能有多种平凡情况，但至少要有一种，且这类情况迟早必出现。比如，算法sum()的递归基只包含一种情况，只需简单地判断n是否已经减小到0 算法sum()是通过更深一层的自我调用来实现的，而且该函数的每一实例对自身的调用至多一次。于是，在每一层次上至多只有一个实例，且它们构成一个线性的次序关系。此类递归模式因而称作“线性递归” （linear recursion） ，它也是递归的最基本形式该图清晰地给出了算法执行的整个过程：首先对参数n进行调用，再转向对参数n-1的调用，再转向对参数n-2的调用， …，直至最终的参数0。在抵达递归基后不再递归，而是将平凡的解（长度为0数组的总和0）返回给对参数1的调用；累加上A[0]之后，再返回给对参数2的调用；累加上A[1]之后，继续返回给对参数3的调用； …；如此依次返回，直到最终返回给对参数n的调用，此时，只需累加A[n-1]即得到整个数组的总和 时间复杂度：具体地， 就以上的sum()算法而言，每一递归实例中非递归部分所涉及的计算无非三类（判断n是否为0、累加sum(n-1)与A[n-1]、返回当前总和） ，而且它们至多各执行一次。鉴于它们均属于常数时间成本的基本操作，每个递归实例实际所需的计算时间都应为常数O(3)。由图还可以看出， 对于长度为n的输入数组，递归深度应为n+1，故整个sum()算法共需运行(n+1) * O(3) = O(n)时间 空间复杂度：在创建了最后一个递归实例（即到达递归基）时，占用的空间量达到最大——准确地说，等于所有递归实例各自所占空间量的总和。这里每一递归实例所需存放的数据，无非是调用参数（数组A的起始地址和长度n）以及用于累加总和的临时变量。这些数据各自只需常数规模的空间，其总量也应为常数。故此可知，sum()算法的空间复杂度线性正比于其递归的深度， 亦即O(n) 递归算法的空间复杂度：递归深度N*每次递归所要的辅助空间， 如果每次递归所需的辅助空间是常数，则递归的空间复杂度是 O(N). 减而治之线性递归模式往往对应于所谓减而治之（decrease-and-conquer） 的算法策略：递归每深入一层，待求解问题的规模都缩减一个常数，直至最终蜕化为平凡的小（简单）问题。按照减而治之策略，此处随着递归的深入，调用参数将单调地线性递减。因此无论最初输入的n有多大，递归调用的总次数都是有限的， 故算法的执行迟早会终止，即满足有穷性。当抵达递归基时，算法将执行非递归的计算（这里是返回0） 递推方程该方法无需绘出具体的调用过程，而是通过对递归模式的数学归纳，导出关于复杂度定界函数的递推方程（组）及其边界条件，从而将复杂度分析的任务转化为递归方程（组）的求解 仍以代码线性递归版sum()算法为例， 将该算法处理长度为n的数组所需的时间成本记作T(n)。我们将该算法的思路重新表述如下：为解决问题sum(A, n)，需递归地解决问题sum(A,n-1)，然后累加上A[n-1]。按照这一新的理解，求解sum(A, n)所需的时间，应该等于求解sum(A,n-1)所需的时间，另加一次整数加法运算所需的时间。 根据以上分析，可以得到关于T(n)的如下一般性的递推关系：T(n) = T(n-1) + O(1) = T(n-1) + c1，其中c1为常数另一方面，当递归过程抵达递归基时，求解平凡问题sum(A, 0)只需（用于直接返回0的）常数时间。如此，即可获得如下边界条件：T(0) = O(1) = c2， 其中c2为常数联立以上两个方程， 最终可以解得：T(n) = c1n + c2 = O(n) 递归算法的空间复杂度：递归深度N*每次递归所要的辅助空间， 如果每次递归所需的辅助空间是常数，则递归的空间复杂度是 O(N). 线性递归版sum()算法共需O(n)的附加空间 多递归基为保证有穷性， 所有递归算法都首先必须设有递归基，且确保对应的语句总能执行到。实际上， 针对算法中可能出现的每一类平凡情况，都需要设置对应的递归基，因此同一算法的递归基可能（显式或隐式地）不止一个。以下考察数组倒置问题， 也就是将数组中各元素的次序前后翻转。 比如，若输入数组为：A[] = {3, 1, 4, 1, 5, 9, 2, 6}则倒置后为：A[] = {6, 2, 9, 5, 1, 4, 1, 3} 12345678910111213//多递归基，数组倒置private static void reserse(int [] a,int left,int right)&#123; if(left&lt;0 || right&gt;=a.length)&#123; return; &#125; if(left &lt; right)&#123; int temp =a[left]; a[left] =a[right]; a[right] = temp; reserse(a,left+1,right-1); &#125; ////else隐含了两种递归基 &#125; 可见，每深入递归一层，待倒置区间的长度 left - right + 1都缩短2个单元。因此， 所有递归实例所对应区间长度的奇偶性一致。需要特别留意的是， 此处递归基实际上分为两种情况： left = right（原数组长度为奇数）或left = right + 1（原数组长度为偶数）。当然，无论如何reverse()算法都必然会终止于这两种平凡情况之一，因此递归的深度应为：[(n + 1) / 2] = O(n)在算法终止之前，递归每深入一层都会通过一次对换使得当前的A[left]与A[right]就位，因此该算法的时间复杂度也应线性正比于递归深度，即O(n)。 二分递归分而治之面对输入规模庞大的应用问题，每每感慨于头绪纷杂而无从下手的你，不妨从先哲孙子的名言中获取灵感“凡治众如治寡，分数是也” 。是的，解决此类问题的有效方法之一，就是将其分解为若干规模更小的子问题， 再通过递归机制分别求解。 这种分解持续进行，直到子问题规模缩减至平凡情况。这也就是所谓的分而治之（divide-and-conquer） 策略 123456789101112//二分递归，数组求和private static int sum(int [] a,int left,int right)&#123; if(left&lt;0 || right&gt;=a.length)&#123; return -1; &#125; if(left == right)&#123; return a[left]; &#125; int medium = (left+right)/2; return sum(a,left,medium) + sum(a,medium+1,right); &#125; 针对n = 8的情况给出了sum(A, 0, 7)执行过程的递归跟踪。其中各方框都标注有对应的lo和hi值， 即子数组区间的起、止单元。可见，按照调用的关系及次序，该方法的所有实例构成一个层次结构（即二叉树）。沿着这个层次结构每下降一层，每个递归实例sum(lo, hi)都分裂为一对更小的实例sum(lo, mi)和sum(mi+1, hi)——准确地说，每经过一次递归调用， 子问题对应的数组区间长度hi-lo+1都将减半。 算法启动后经连续m = log2n次递归调用，数组区间的长度从最初的n首次缩减至1，并到达第一个递归基。实际上，刚到达任一递归基时，已执行的递归调用总是比递归返回多m = log2n次。更一般地，到达区间长度为2^k的任一递归实例之前，已执行的递归调用总是比递归返回多m-k次。因此，递归深度（即任一时刻的活跃递归实例的总数）不会超过m+1。鉴于每个递归实例仅需常数空间， 故除数组本身所占的空间，该算法只需要O(m+1) = O(logn)的附加空间。我们还记得， 代码1.5 中线性递归版sum()算法共需O(n)的附加空间，就这一点而言，新的二分递归版sum()算法有很大改进]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaWeb学习笔记——基础2(CSS&JS)]]></title>
    <url>%2F2016%2F12%2F04%2Fjavaweb_day02-css%26js%E5%8F%82%E8%80%83%2F</url>
    <content type="text"><![CDATA[了解CSS的概念了解CSS的引入方式了解CSS的基本语法和常用的选择器了解CSS的盒子模型,悬浮和定位.了解JS的概念 掌握JS的基本语法,数据类型,能够使用JS完成简单的页面交互 任务 使用CSS完成网站首页的美化 使用CSS完成网站注册页面的美化 使用JS完成简单的数据校验 使用JS完成图片轮播效果 导航 | 目标 | 了解CSS的概念 了解CSS的引入方式了解CSS的基本语法和常用的选择器了解CSS的盒子模型,悬浮和定位.了解JS的概念 掌握JS的基本语法,数据类型,能够使用JS完成简单的页面交互. | 使用CSS对首页进行重新布局：需求分析：在上次的HTML课程中已经使用表格标签对页面进行布局显示了，但是表格标签有一定的缺陷。实际开发中都会采用DIV+CSS的方式进行布局。使用DIV+CSS重新布局网站的首页： 分析：技术分析【HTML的DIV标签】 HTML中有两个块标记：  &lt;div&gt;&lt;/div&gt;  &lt;span&gt;&lt;/span&gt; 【CSS的概述】 什么是CSS： Cascading Style Sheets 层叠样式表. CSS的作用： CSS主要用来修饰HTML的显示.代码复用.将页面元素与样式进行分离. CSS的使用： 语法： 选择器{属性1:属性值;属性2:属性值;..} &lt;style&gt; h2{ color:red; font-size:100px; } &lt;/style&gt; 【CSS的引入方式】 行内样式： 直接在html的元素上使用style的属性编写CSS： &lt;span style=&quot;color:#00FF00 ;font-size: 100px;&quot;&gt;训练营&lt;/span&gt; 内部样式： 在html的\&lt;head>标签中使用\&lt;style>标签来定义CSS &lt;style&gt; span{ color:blue; font-size: 200px; } &lt;/style&gt; 外部样式： 将CSS定义成一个.css的文件，在html中将该文件引入到html中 &lt;link href=&quot;style.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt; 【CSS的基本选择器】 CSS的选择器为了更能精确的找个某个元素来设计的 元素选择器： div{ color: red; } id选择器： &lt;style&gt; #d1{ color: red; } &lt;/style&gt; &lt;div id=&quot;d1&quot;&gt;王凤&lt;/div&gt; ***** id通常都是唯一的. 类选择器： HTML: &lt;div class=&quot;d1&quot;&gt;王守义&lt;/div&gt; &lt;div&gt;王凤&lt;/div&gt; &lt;div class=&quot;d1&quot;&gt;王如花&lt;/div&gt; CSS: &lt;style&gt; .d1{ color: green; } &lt;/style&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115选择器:★ &lt;id选择器&gt;&gt; 要求: html元素必须有id属性且有值 &lt;xxx id="id1"&gt;&lt;/xxx&gt; css中通过"#"引入,后面加上id的值 #id1&#123;...&#125; &lt;class选择器 要求: html元素必须有class属性且有值 &lt;xxx class="cls1"/&gt; css中通过"."引入,后面加上class的值 .cls1&#123;...&#125; &lt;元素选择器&gt; 直接用元素(标签)名即可 xxx&#123;...&#125; 派生的选择器 &lt;属性选择器★&gt; 要求: html元素必须有一个属性不论属性是什么且有值 &lt;xxx nihao="wohenhao"/&gt; css中通过下面的方式使用 元素名[属性="属性值"]&#123;....&#125; 例如: xxx[nihao="wohenhao"]&#123;....&#125; &lt;后代选择器&gt; 选择器 后代选择器&#123;...&#125; &lt;在满足第一个选择器的条件下找后代的选择器,给满足条件的元素添加样式&gt;了解的选择器 锚伪类选择器&lt;锚伪类&gt;&lt;在支持 CSS 的浏览器中，链接的不同状态都可以不同的方式显示，这些状态包括：活动状态，已被访问状态，未被访问状态，和鼠标悬停状态。&gt;a:link &#123;color: #FF0000&#125; /* 未访问的链接 */a:visited &#123;color: #00FF00&#125; /* 已访问的链接 */a:hover &#123;color: #FF00FF&#125; /* 鼠标移动到链接上 */a:active &#123;color: #0000FF&#125; /* 选定的链接 */提示：在 CSS 定义中，a:hover 必须被置于 a:link 和 a:visited 之后，才是有效的。提示：在 CSS 定义中，a:active 必须被置于 a:hover 之后，才是有效的。提示：伪类名称对大小写不敏感。选择器使用小结:id选择器:一个元素(标签)class选择器:一类元素 元素选择器:一种元素属性选择器:元素选择器的特殊用法使用的时候注意:(了解)&lt;若多个样式作用于一个元素的时候 不同的样式,会叠加 相同的样式,最近原则&gt;&lt;若多个选择器作用于一个元素的时候 越特殊优先级越高 id优先级最高 &gt; 属性选择器 &gt; class选择器&gt; 元素选择器&gt;&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt; &lt;/title&gt; &lt;style&gt; #divId1&#123; background-color: teal; width: 50%; &#125; #divId2&#123; background-color: crimson; &#125; .divCls1&#123; background-color: darkturquoise; &#125; div&#123; background-color: rosybrown; &#125; div[att="divatt1"]&#123; background-color: tomato; &#125; span&#123; background-color: lawngreen; &#125; span[att="spanatt1"]&#123; background-color: mediumaquamarine; &#125; &lt;/style&gt; &lt;link rel="stylesheet" href="css/l2.css" type="text/css" /&gt; &lt;/head&gt; &lt;/head&gt; &lt;body&gt; &lt;div id="divId1"&gt;花蝴蝶夫人&lt;/div&gt; &lt;div class="divCls1"&gt;换个地方好感动&lt;/div&gt; &lt;div&gt;股份及回复&lt;/div&gt; &lt;div att="divatt1"&gt;更符合规范化&lt;/div&gt; &lt;span &gt;过分很过分1&lt;/span&gt; &lt;span att="spanatt1"&gt;过分很过分2&lt;/span&gt; &lt;span class="divCls1"&gt;过分很过分3&lt;/span&gt; &lt;span att="spanatt1" class="divCls1" id="divId2"&gt;过分很过分4&lt;/span&gt; &lt;span att="spanatt1" class="divCls1" &gt;过分很过分5&lt;/span&gt; 越特殊优先级越高 id优先级最高 &gt; 属性选择器 &gt; class选择器&gt; 元素选择器 &lt;/body&gt;&lt;/html&gt; 【CSS的悬浮】 CSS的float属性： float属性中常用取值: Left :悬浮到左边 Right :悬浮到右边 使用clear属性清除浮动： Left ：清除左侧浮动 Right ：清除右侧浮动 Both ：清除两侧的浮动 步骤分析： 创建一个外层的div元素 在div中创建代表每块区域div 在每块div引入需要的元素的内容 代码实现：&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;&lt;/title&gt; &lt;link href=&quot;../css/main.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot; /&gt; &lt;style&gt; .content{ border:1px solid blue; height: 600px; background: url(../img/regist_bg.jpg); margin: 10px 0px; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- 创建一个整体的DIV --&gt; &lt;div&gt; &lt;div&gt; &lt;div class=&quot;top&quot;&gt; &lt;img src=&quot;../img/logo2.png&quot; height=&quot;48&quot;/&gt; &lt;/div&gt; &lt;div class=&quot;top&quot;&gt; &lt;img src=&quot;../img/header.png&quot; height=&quot;48&quot;/&gt; &lt;/div&gt; &lt;div class=&quot;top&quot; style=&quot;padding-top: 10px;height: 40px;&quot;&gt; &lt;a href=&quot;#&quot;&gt;登录&lt;/a&gt; &lt;a href=&quot;#&quot;&gt;注册&lt;/a&gt; &lt;a href=&quot;#&quot;&gt;购物车&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;!--清除浮动--&gt; &lt;div class=&quot;clear&quot;&gt;&lt;/div&gt; &lt;!-- 菜单部分的DIV--&gt; &lt;div class=&quot;menu&quot;&gt; &lt;ul&gt; &lt;li style=&quot;display: inline;&quot;&gt;首页&lt;/li&gt; &lt;li style=&quot;display: inline;&quot;&gt;电脑办公&lt;/li&gt; &lt;li style=&quot;display: inline;&quot;&gt;手机数码&lt;/li&gt; &lt;li style=&quot;display: inline;&quot;&gt;鞋靴箱包&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;content&quot;&gt; &lt;div style=&quot;position: absolute;left:400px;top:150px;background-color: white;border:5px solid gray;width: 700px;height: 500px;&quot;&gt; &lt;h3&gt;用户注册&lt;/h3&gt; &lt;form&gt; &lt;table width=&quot;100%&quot; height=&quot;100%&quot; border=&quot;0&quot; align=&quot;center&quot; cellspacing=&quot;10&quot;&gt; &lt;tr&gt; &lt;td&gt;用户名&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;username&quot; placeholder=&quot;请输入用户名&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;密码&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;password&quot; name=&quot;password&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;确认密码&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;password&quot; name=&quot;repassword&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;性别&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;男&quot; checked=&quot;checked&quot;/&gt;男&lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;女&quot;/&gt;女&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Email&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;email&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;name&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;生日&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;birthday&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;验证码&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;checkcode&quot; size=&quot;10&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td colspan=&quot;2&quot;&gt;&lt;input type=&quot;submit&quot; value=&quot;注册&quot; style=&quot;background: url(../img/register.gif);&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div &gt; &lt;div&gt; &lt;img src=&quot;../img/footer.jpg&quot; /&gt; &lt;/div&gt; &lt;div align=&quot;center&quot;&gt; &lt;a href=&quot;../案例一：网站信息页面显示/网站信息页面显示.html&quot;&gt;关于我们&lt;/a&gt; &lt;a href=&quot;&quot;&gt;联系我们&lt;/a&gt; &lt;a href=&quot;&quot;&gt;招贤纳士&lt;/a&gt; &lt;a href=&quot;&quot;&gt;法律声明&lt;/a&gt; &lt;a href=&quot;link.html&quot;&gt;友情链接&lt;/a&gt; &lt;a href=&quot;&quot;&gt;支付方式&lt;/a&gt; &lt;a href=&quot;&quot;&gt;配送方式&lt;/a&gt; &lt;a href=&quot;&quot;&gt;服务声明&lt;/a&gt; &lt;a href=&quot;&quot;&gt;广告声明&lt;/a&gt; &lt;br/&gt; Copyright © 2005-2016 传智商城 版权所有 &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 扩展：CSS的其他的选择器：【CSS的其他选择器】 属性选择器 选中带有某个属性的元素： &lt;style&gt; input[type=&quot;text&quot;]{ background-color: yellow; } input[type=&quot;password&quot;]{ background-color: green; } &lt;/style&gt; 层次选择器： 父选择器 子孙选择器 { } &lt;style&gt; #d1 div{ color: red; } &lt;/style&gt; 伪类选择器： 主要用来描述超链接 &lt;style&gt; a:link{ color:blue; font-size: 40px; } a:visited{ color: red; font-size: 40px; } a:hover{ color: green; font-size: 100px; } a:active{ color: brown; font-size: 200px; } &lt;/style&gt; 使用DIV+CSS对注册页面进行布局：需求分析：使用DIV+CSS对注册页面进行布局。更加灵活！ 分析：技术分析：【CSS的盒子模型】 设置盒子的外边距：margin Margin-top Margin-right Margin-bottom Margin-left 设置盒子的内边距：padding Padding-top Padding-right Padding-bottom Padding-left 步骤分析： 创建一个整体div元素 在里面创建5个分别代表某个部分的DIV 在每个部分中完成单独内容的显示 代码实现：&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;&lt;/title&gt; &lt;link href=&quot;../css/main.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot; /&gt; &lt;style&gt; .content{ border:1px solid blue; height: 600px; background: url(../img/regist_bg.jpg); margin: 10px 0px; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- 创建一个整体的DIV --&gt; &lt;div&gt; &lt;div&gt; &lt;div class=&quot;top&quot;&gt; &lt;img src=&quot;../img/logo2.png&quot; height=&quot;48&quot;/&gt; &lt;/div&gt; &lt;div class=&quot;top&quot;&gt; &lt;img src=&quot;../img/header.png&quot; height=&quot;48&quot;/&gt; &lt;/div&gt; &lt;div class=&quot;top&quot; style=&quot;padding-top: 10px;height: 40px;&quot;&gt; &lt;a href=&quot;#&quot;&gt;登录&lt;/a&gt; &lt;a href=&quot;#&quot;&gt;注册&lt;/a&gt; &lt;a href=&quot;#&quot;&gt;购物车&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;!--清除浮动--&gt; &lt;div class=&quot;clear&quot;&gt;&lt;/div&gt; &lt;!-- 菜单部分的DIV--&gt; &lt;div class=&quot;menu&quot;&gt; &lt;ul&gt; &lt;li style=&quot;display: inline;&quot;&gt;首页&lt;/li&gt; &lt;li style=&quot;display: inline;&quot;&gt;电脑办公&lt;/li&gt; &lt;li style=&quot;display: inline;&quot;&gt;手机数码&lt;/li&gt; &lt;li style=&quot;display: inline;&quot;&gt;鞋靴箱包&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;content&quot;&gt; &lt;div style=&quot;position: absolute;left:400px;top:150px;background-color: white;border:5px solid gray;width: 700px;height: 500px;&quot;&gt; &lt;h3&gt;用户注册&lt;/h3&gt; &lt;form&gt; &lt;table width=&quot;100%&quot; height=&quot;100%&quot; border=&quot;0&quot; align=&quot;center&quot; cellspacing=&quot;10&quot;&gt; &lt;tr&gt; &lt;td&gt;用户名&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;username&quot; placeholder=&quot;请输入用户名&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;密码&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;password&quot; name=&quot;password&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;确认密码&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;password&quot; name=&quot;repassword&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;性别&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;男&quot; checked=&quot;checked&quot;/&gt;男&lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;女&quot;/&gt;女&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Email&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;email&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;name&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;生日&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;birthday&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;验证码&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;checkcode&quot; size=&quot;10&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td colspan=&quot;2&quot;&gt;&lt;input type=&quot;submit&quot; value=&quot;注册&quot; style=&quot;background: url(../img/register.gif);&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div &gt; &lt;div&gt; &lt;img src=&quot;../img/footer.jpg&quot; /&gt; &lt;/div&gt; &lt;div align=&quot;center&quot;&gt; &lt;a href=&quot;../案例一：网站信息页面显示/网站信息页面显示.html&quot;&gt;关于我们&lt;/a&gt; &lt;a href=&quot;&quot;&gt;联系我们&lt;/a&gt; &lt;a href=&quot;&quot;&gt;招贤纳士&lt;/a&gt; &lt;a href=&quot;&quot;&gt;法律声明&lt;/a&gt; &lt;a href=&quot;link.html&quot;&gt;友情链接&lt;/a&gt; &lt;a href=&quot;&quot;&gt;支付方式&lt;/a&gt; &lt;a href=&quot;&quot;&gt;配送方式&lt;/a&gt; &lt;a href=&quot;&quot;&gt;服务声明&lt;/a&gt; &lt;a href=&quot;&quot;&gt;广告声明&lt;/a&gt; &lt;br/&gt; Copyright © 2005-2016 传智商城 版权所有 &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 扩展：扩展属性：【列表属性】 ul li{ list-style-image: url(../img/reg4.gif); } 【颜色取值】 英文取值： color：red 十六进制数： color：#ff0000 Rgb方式： color：rgb(255,0,0) 使用JS完成简单的数据的校验需求分析：使用JS完成对注册页面进行简单的数据的非空校验。在提交表单的时候，不可以出现用户名，密码是空的情况。 分析：技术分析：HTML骨架，CSS美化，JS可以使页面动起来。 【JavaScript的概述】 什么是JavaScript： 运行在浏览器端的脚本语言. JS的组成： ECMAScript：语法，语句. BOM:浏览器对象 DOM:Document Object Model.操作文档中的元素和内容. 在哪些地方使用JS JS增加用户和网站交互 如何使用JS 语法： 区分大小写 语法要求不是特别严格 变量是弱变量类型 var i = 3; var s = “aa”; JS代码需要写在\&lt;script>\&lt;/script> 【JS的数据类型】 原始类型： string number boolean undefined null 引用类型： 基于对象而不是面向对象.内置对象.对象类型的默认值是null. 【JS的运算符和语句】 运算符与Java中一致. 全等于 === ：类型和值都一致返回true 语句与Java一致： 【JS的输出】 alert() 向页面中弹出一个提示框！！ innerHTML: 向页面的某个元素中写一段内容，将原有的东西覆盖 document.write(); 向页面中写内容 步骤分析： JS都是由事件触发的，第一步确定事件。 on… JS的事件都会触发一个函数，编写一个函数。 JS获得操作的对象的元素。 document.getElementById(“”); JS修改这个元素的属性或值。 代码实现：&lt;script&gt; // 第一步确定事件：onsubmit // 第二步编写触发函数： function checkForm(){ // 第三步：通过ID获得元素 var uValue = document.getElementById(&quot;username&quot;).value; // alert(uValue); if(uValue == &quot;&quot;){ alert(&quot;用户名不能为空！&quot;); return false; } // 校验密码 var pValue = document.getElementById(&quot;password&quot;).value; if(pValue == &quot;&quot;){ alert(&quot;密码不能为空！&quot;); return false; } // 校验确认密码 var rpValue = document.getElementById(&quot;repassword&quot;).value; if(rpValue != pValue){ alert(&quot;两次密码输入不一致！&quot;); return false; } // 校验邮箱：使用正则表达式： var eValue = document.getElementById(&quot;email&quot;).value; if(!/^([a-zA-Z0-9_-])+@([a-zA-Z0-9_-])+(.[a-zA-Z0-9_-])+/.test(eValue)){ alert(&quot;邮箱格式不正确！&quot;); return false; } } &lt;/script&gt; 使用JS完成首页上轮播图片效果：需求分析：在网站的首页上图片的轮播，现在页面中图片是静止的。让图片隔5秒自动切换。 分析：技术分析：【修改图片的路径】 获得图片，修改图片的src的属性。 document.getElementById(“img1”).src=”2.jpg”; 【JS中定时操作】 查看BOM中的window对象： setInterval() :隔多少毫秒之后，执行一段代码。重复执行。 setTimeout() :隔多少毫秒之后，执行一段代码。 清除定时： clearInterval() :清除setInterval的定时操作。 clearTimeout() : 清除setTimeout的定时操作。 示例代码： function init(){ // window.setTimeout(“alert(‘aaa’)”,5000); window.setInterval(“alert(‘bbb’)”,5000); } 步骤分析： 步骤一：使用页面加载的事件触发一个函数 步骤二：在函数中设置定时：setInterval设置定时，5秒之后（切换图片-定义一个函数） 步骤三：编写切换图片的函数 步骤四：在函数中获得图片的元素 步骤五：修改图片的src的属性 代码实现：&lt;script&gt; function init(){ // 设置定时 setInterval(&quot;changeImg()&quot;,5000); } // 定义一个全局变量 var i = 1; function changeImg(){ // 获得图片的元素： var img1 = document.getElementById(&quot;img1&quot;); if(i == 3){ i =1; }else{ i++; } // 修改图片的src的属性 img1.src = &quot;../img/&quot;+i+&quot;.jpg&quot;; } &lt;/script&gt;]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>JavaWeb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaWeb学习笔记——基础1(html)]]></title>
    <url>%2F2016%2F12%2F03%2Fjavaweb_day01-%E7%AC%94%E8%AE%B01%2F</url>
    <content type="text"><![CDATA[了解什么是标记语言了解HTML主要特性,主要变化及发展趋势了解HTML的结构标签掌握HTML的主要标签(字体,图片,列表,链接,表单等标签) 今日任务 网站信息页面案例 网站图片信息页面案例 网站友情链接页面案例 网站首页案例 网站注册页面案例 网站后台页面案例 导航 | 目标 | 了解什么是标记语言了解HTML主要特性,主要变化及发展趋势了解HTML的结构标签掌握HTML的主要标签(字体,图片,列表,链接,表单等标签) ||————–|——————————————————————————————————————————| | 1、网站信息页面显示案例：需求分析：在网页中显示一个文字信息页面，显示效果如下： 【HTML的概述】 什么是HTML HTML：Hyper Text Markup Language 超文本标记语言 超文本：比文本功能更加强大 标记语言：通过一组标签对内容进行描述的一门语言 为什么学习HTML HTML是设计页面基础 在哪些地方可以使用HTML 设计页面的时候都可以使用HTML 如何使用HTML HTML的语法和规范 HTML文件的扩展名是.html或者是.htm HTML文件是由头和体组成 HTML这组标签是不区分大小写 HTML的标记通常是由【开始标签】和【结束标签】组成： &lt;b&gt;内容&lt;/b&gt; &lt;br/&gt; 换行 html标签: 声明 子标签: &lt;head&gt;&lt;/head&gt; &lt;body&gt;&lt;/body&gt; head:用来存放当前页面的重要信息,一般不展示在html页面上 常见的子标签: &lt;title&gt;&lt;/title&gt; 网页的标题 body: 要展示的数据放在body中 【HTML的字体标签】123456789101112131415161718192021222324252627282930 &lt;font&gt;标签 &lt;font 属性名=”属性值”&gt;文字&lt;/font&gt;  size:控制字体大小.最小1 最大7  color：控制字体颜色. 使用英文设置 ，使用16进制数设置  face：控制字体. .&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;font&gt;天佑中华&lt;/font&gt;天佑中华&lt;br/&gt; &lt;font size="7"&gt;我个大7&lt;/font&gt;&lt;br /&gt; &lt;font size="100"&gt;我个大100&lt;/font&gt; &lt;font size="1"&gt;我个大1&lt;/font&gt; &lt;br/&gt; &lt;font color="red"&gt;我很红&lt;/font&gt; &lt;font color="#ff0000"&gt;我很红&lt;/font&gt; &lt;font color="#f000ff"&gt;我很红&lt;/font&gt;&lt;br /&gt; &lt;font color="#055000"&gt;我很红&lt;/font&gt; &lt;br /&gt; &lt;font face="黑体" size="6"&gt;我很黑&lt;/font&gt; &lt;/body&gt;&lt;/html&gt; 【HTML的排版标签】12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;hn&gt;标题标签 &lt;h1&gt;b标题&lt;/h1&gt;n取值 :1~6h1最大 h6最小自动换行 且留白 默认加粗常用属性: align:对齐方式 left:左 right:右 center:居中格式: &lt;h2 align="center"&gt;&lt;/h2&gt;&lt;p&gt;段落标签 &lt;p&gt;一段文字&lt;/p&gt;&lt;br/&gt;换行标签 &lt;br/&gt;代表换行&lt;hr/&gt;水平线标签 &lt;hr/&gt;水平线标签&lt;b&gt;字体加粗 &lt;b&gt;文字&lt;/b&gt;&lt;i&gt;斜体标签 &lt;i&gt;斜体&lt;/i&gt;&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;font&gt;天佑中华&lt;/font&gt;天佑中华&lt;br/&gt; &lt;font size="7"&gt;我个大7&lt;/font&gt;&lt;br /&gt; &lt;font size="100"&gt;我个大100&lt;/font&gt; &lt;font size="1"&gt;我个大1&lt;/font&gt; &lt;br/&gt; &lt;font color="red"&gt;我很红&lt;/font&gt; &lt;font color="#ff0000"&gt;我很红&lt;/font&gt; &lt;font color="#f000ff"&gt;我很红&lt;/font&gt;&lt;br /&gt; &lt;font color="#055000"&gt;我很红&lt;/font&gt; &lt;br /&gt; &lt;font face="楷体" size="6"&gt;我很黑&lt;/font&gt;&lt;br /&gt; &lt;p&gt; &lt;i&gt;感受停在我发端的指尖&lt;/i&gt;&lt;br /&gt; 如何瞬间冻结时间&lt;hr /&gt; 记住望着我坚定的双眼&lt;br /&gt; 也许已经没有明天&lt;br /&gt; &lt;b&gt;面对浩瀚的星海&lt;/b&gt;&lt;br /&gt; &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 步骤分析 步骤一：创建一个html文件 步骤二：创建标题标签 步骤三：标题下面会有一个水平线 步骤四：创建段落标签创建四个段落 步骤五：将某些文字设置为红色 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 &lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;页面标题&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- 创建标题标签 --&gt; &lt;h2&gt;公司简介&lt;/h2&gt; &lt;!-- 作者：offline 时间：2016-01-21 描述：水平线 --&gt; &lt;hr /&gt; &lt;!-- 作者：offline 时间：2016-01-21 描述：创建段落标签 --&gt; &lt;p&gt; &lt;b&gt; 腾讯，1998年11月诞生于中国深圳，是一家以互联网为基础的科技与文化公司。&lt;/b&gt; 我们的使命是 “&lt;font color="#ff0000"&gt; 通过互联网服务提升人类生活品质&lt;/font&gt;” 。腾讯秉承着 “&lt;i&gt;&lt;b&gt;一切以用户价值为依归&lt;/b&gt;&lt;/i&gt;”的经营理念，为亿万网民提供优质的互联网综合服务。&lt;/p&gt; &lt;p&gt; 腾讯的战略目标是“连接一切”，我们长期致力于社交平台与数字内容两大核心业务：一方面通过微信与QQ等社交平台，实现人与人、服务及设备的智慧连接；另一方面为数以亿计的用户提供优质的新闻、视频、游戏、音乐、文学、动漫、影业等数字内容产品及相关服务。我们还积极推动金融科技的发展，通过普及移动支付等技术能力，为智慧交通、智慧零售、智慧城市等领域提供有力支持。&lt;/p&gt; &lt;p&gt;腾讯希望成为各行各业的数字化助手，助力数字中国建设。在工业、医疗、零售、教育等各个领域， 腾讯为传统行业的数字化转型升级提供“数字接口”和“数字工具箱”。我们秉持数字工匠精神， 希望用数字创新提升每个人的生活品质。随着“互联网+”战略实施和数字经济的发展， 我们通过战略合作与开放平台，与合作伙伴共建数字生态共同体，推进云计算、大数据、人工智能等前沿科技与各行各业的融合发展及创新共赢。 多年来，腾讯的开放生态带动社会创业就业人次达数千万，相关创业企业估值已达数千亿元。&lt;/p&gt; &lt;p&gt; 腾讯的愿景是成为“最受尊敬的互联网企业”。我们始终坚守“科技向善”的初心， 运用科技手段助力公益事业发展，并将社会责任融入每一个产品。 2007年，腾讯倡导并发起了中国互联网第一家在民政部注册的全国性非公募基金会——腾讯公益慈善基金会。腾讯公益致力于成为“人人可公益的创连者”， 以互联网核心能力推动公益行业的长远发展为己任。腾讯公益联合多方发起了中国首个互联网公益日——99公益日，帮助公益组织和广大爱心网友、企业之间形成良好的公益生态， 让透明化的“指尖公益”融入亿万网民的生活。&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; 2、网站的图片页面显示需求分析：在网页中显示带有图片的页面效果如下： 【HTML的图片标记】&lt;img /&gt; - src：图片的路径 - width：图片宽度 - height：图片的高度 - alt：图片提示 图片路径： 分成相对路径和绝对路径 相对路径: ./ :代表当前路径 ../ :代表上一级路径 步骤分析： 创建一个img标签引入logo图片 创建一个img标签引入header图片 代码实现123456789101112131415161718&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;网站图片页面&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;img src="../img/header.jpg" alt="正品保障" height="60px" /&gt; &lt;img src="../img/3.jpg" title ="商品展示" height="1200px" /&gt; &lt;/body&gt;&lt;/html&gt; 3、网站的列表显示页面需求分析：在页面中列表显示友情链接： 【HTML的列表标签】12345678910111213 无序列表 &lt;ul&gt; &lt;li&gt;内容1&lt;/li&gt; &lt;li&gt;内容2&lt;/li&gt; &lt;/ul&gt; 有序列表 &lt;ol&gt; &lt;li&gt;内容1&lt;/li&gt; &lt;li&gt;内容2&lt;/li&gt; &lt;/ol&gt;常用的子标签 &lt;li&gt;&lt;/li&gt; 列表项(列表内容) 步骤实现 创建一个无序列表显示友情链接 代码实现123456789101112131415161718192021222324252627282930 &lt;ul&gt; &lt;li&gt;百度&lt;/li&gt; &lt;li&gt;传智播客&lt;/li&gt; &lt;li&gt;百合网&lt;/li&gt; &lt;li&gt;世纪佳缘&lt;/li&gt; &lt;/ul&gt;&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;ol type="a"&gt; &lt;li&gt;貂蝉&lt;/li&gt; &lt;li&gt;西施&lt;/li&gt; &lt;li&gt;杨玉环&lt;/li&gt; &lt;li&gt;王昭君&lt;/li&gt; &lt;/ol&gt; &lt;ul type="square"&gt; &lt;li&gt;刘德华&lt;/li&gt; &lt;li&gt;张学友&lt;/li&gt; &lt;li&gt;郭富城&lt;/li&gt; &lt;li&gt;黎明&lt;/li&gt; &lt;/ul&gt; &lt;/body&gt;&lt;/html&gt; 【超链接标签】：【超链接标签】 【超链接标签】 1234567891011121314151617181920212223&lt;a&gt;超链接&lt;/a&gt; href：超链接跳转的路径 target：打开方式  _self：在自身页面打开  _blank：打开一个新窗口&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h2&gt;友情连接&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;&lt;a href="#"&gt;CSDN&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://www.hust.edu.cn" target="_blank"&gt;hust&lt;/a&gt;&lt;/li&gt; &lt;/ol&gt; &lt;/body&gt;&lt;/html&gt; 4、网站的首页显示需求分析：在浏览器中显示网站的首页效果如下： 【HTML的表格标签】表格标签： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697表格标签★ &lt;table&gt;&lt;/table&gt; 常用的子标签 &lt;tr&gt;:行 &lt;tr&gt;&lt;/tr&gt; 常用子标签: &lt;td&gt;:列 &lt;th&gt;:表头单元格 默认居中加粗 注意: 一行必须只有有一个单元格或者一列 ////////////////// table 的常用属性: border:边框 像素值 width: align:表格对齐方式 tr 的常用属性: align:内容对齐 td 的常用属性: align:内容对齐 colspan:跨列合并 值:合并的列数 rowspan:跨行合并 &lt;table&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;table border="1" width="40%" height="150px" align="center" bgcolor="#ffff00"&gt; &lt;!--创建一个4行3列--&gt; &lt;tr&gt; &lt;td&gt;11&lt;/td&gt; &lt;td&gt;12&lt;/td&gt; &lt;td&gt;13&lt;/td&gt; &lt;/tr&gt; &lt;tr align="center"&gt; &lt;td&gt;21&lt;/td&gt; &lt;td&gt;22&lt;/td&gt; &lt;td&gt;23&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;31&lt;/td&gt; &lt;td align="center"&gt;32&lt;/td&gt; &lt;td&gt;33&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;41&lt;/td&gt; &lt;td&gt;42&lt;/td&gt; &lt;td&gt;43&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;hr /&gt; &lt;table border="1" width="40%" height="150px" align="center" &gt; &lt;!--创建一个4行3列--&gt; &lt;tr&gt; &lt;td&gt;11&lt;/td&gt; &lt;td&gt;12&lt;/td&gt; &lt;td&gt;13&lt;/td&gt; &lt;/tr&gt; &lt;tr align="center"&gt; &lt;td&gt;21&lt;/td&gt; &lt;td colspan="2"&gt;22&amp;23&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan="2"&gt;31&amp;41&lt;/td&gt; &lt;td align="center"&gt;32&lt;/td&gt; &lt;td&gt;33&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;42&lt;/td&gt; &lt;td&gt;43&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 表格的属性： border ：表格边框 width ：表格宽度 height ：表格高度 align ：水平方向对齐方式 left center right bgcolor ：背景色 步骤分析： 步骤一：创建8行表格 步骤二：实现第一行，嵌套一个一行三列表格。 步骤三：实现第二行，实现导航，设置背景色。 步骤四：放置一张图片 步骤五：显示热门商品，创建一个三行七列的表格。对表格进行跨行，跨列的操作。 步骤六：引入一张广告图片。 步骤七：显示最新商品，创建一个三行七列的表格。对表格进行跨行，跨列的操作。 步骤八：广告信息 步骤九：链接版权信息。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;网站首页&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;table width="1400" border="0" align="center"&gt; &lt;tr&gt; &lt;td&gt; &lt;!-- LOGO部分 --&gt; &lt;table width="100%"&gt; &lt;tr height="40"&gt; &lt;td&gt; &lt;img src="../img/logo2.png"/&gt; &lt;/td&gt; &lt;td&gt; &lt;img src="../img/header.png"/&gt; &lt;/td&gt; &lt;td&gt; &lt;a href="#"&gt;登录&lt;/a&gt; &lt;a href="../案例五：网站注册页面显示/网站的注册页面.html"&gt;注册&lt;/a&gt; &lt;a href="#"&gt;购物车&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr height="30" bgcolor="black"&gt; &lt;td&gt; &lt;!--导航部分--&gt; &lt;a href="#"&gt;&lt;font color="white"&gt;首页&lt;/font&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="#"&gt;&lt;font color="white"&gt;手机数码&lt;/font&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="#"&gt;&lt;font color="white"&gt;电脑办公&lt;/font&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="#"&gt;&lt;font color="white"&gt;鞋靴箱包&lt;/font&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="#"&gt;&lt;font color="white"&gt;鞋靴箱包&lt;/font&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;img src="../img/1.jpg" width="100%" /&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;table width="100%" border="0"&gt; &lt;tr&gt; &lt;td colspan="7"&gt;&lt;font size="5"&gt;&lt;b&gt;最新商品&lt;/b&gt;&lt;/font&gt;&lt;img src="../img/title2.jpg"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan="2" width="200" height="500"&gt; &lt;img src="../products/hao/big01.jpg" width="100%" height="100%"/&gt; &lt;/td&gt; &lt;td colspan="3" width="600" height="250"&gt; &lt;img src="../products/hao/middle01.jpg" width="100%" height="250"/&gt; &lt;/td&gt; &lt;td width="200" align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="200" align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="200" align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;!--广告--&gt; &lt;a href="#"&gt;&lt;img src="../products/hao/ad.jpg" width="100%"&gt;&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;table width="100%" border="0"&gt; &lt;tr&gt; &lt;td colspan="7"&gt;&lt;font size="5"&gt;&lt;b&gt;最新商品&lt;/b&gt;&lt;/font&gt;&lt;img src="../img/title2.jpg"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan="2" width="200" height="500"&gt; &lt;img src="../products/hao/big01.jpg" width="100%" height="100%"/&gt; &lt;/td&gt; &lt;td colspan="3" width="600" height="250"&gt; &lt;img src="../products/hao/middle01.jpg" width="100%" height="250"/&gt; &lt;/td&gt; &lt;td width="200" align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="200" align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="200" align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;td align="center"&gt; &lt;img src="../products/hao/small03.jpg"/&gt;&lt;br/&gt; &lt;p&gt;&lt;font color="gray"&gt;电磁锅&lt;/font&gt;&lt;/p&gt; &lt;p&gt;&lt;font color="red"&gt;$499&lt;/font&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;img src="../img/footer.jpg" width="100%"/&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="center"&gt; &lt;a href="../案例一：网站信息页面显示/网站信息页面显示.html"&gt;关于我们&lt;/a&gt; &lt;a href=""&gt;联系我们&lt;/a&gt; &lt;a href=""&gt;招贤纳士&lt;/a&gt; &lt;a href=""&gt;法律声明&lt;/a&gt; &lt;a href="../案例三：网站列表页面显示/网站列表页面显示.html"&gt;友情链接&lt;/a&gt; &lt;a href=""&gt;支付方式&lt;/a&gt; &lt;a href=""&gt;配送方式&lt;/a&gt; &lt;a href=""&gt;服务声明&lt;/a&gt; &lt;a href=""&gt;广告声明&lt;/a&gt; &lt;br/&gt; Copyright © 2005-2016 传智商城 版权所有 &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 5、网站的注册页面案例：需求分析：在浏览器中显示如下的效果： 【HTML的表单标签】12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485表单标签：- 需要提交的表单需要使用&lt;form&gt;&lt;/form&gt;括起来 - action：提交路径 - method：提交方式- 文本框: - &lt;input type=”text”/&gt; - name - value - size - maxlength - readonly- 密码框： - &lt;input type=”password”/&gt;- 单选按钮： - &lt;input type=”radio”/&gt; - Checked：默认选中- 复选框 - &lt;input type=”checkbox”/&gt; - Checked：默认选中- 下拉列表框 - &lt;select&gt;&lt;option&gt;&lt;/option&gt;&lt;/select&gt; - Selected：默认选中 - Multiple：全部显示- 文件上传项 - &lt;input type=”file” name=”file”/&gt;- 文本区 - &lt;textarea name=”” cols=”” rows=””&gt;&lt;/textarea&gt;- 提交按钮 - &lt;input type=”submit” value=”注册”&gt;- 重置按钮 - &lt;input type=”reset” value=”重置”&gt;- 普通按钮 - &lt;input type=”button” value=”普通按钮”&gt;- 隐藏字段 - &lt;input type=”hidden” name=”id”/&gt;提交方式：- GET ：默认值 - 提交的数据都会在地址栏中进行显示 - 提交的数据的时候是有大小的限制- POST ： - 提交的数据不会再地址栏中进行显示 - 提交的数据没有大小限制 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114表单: 常用属性: action:信息提交的路径 默认是当前页面 method:表单提交的方式 &lt;"只需要掌握两种 get(默认)和post" "get和post的区别: 1.get请求会把所有的参数追加在地址栏上,post请求不会 2.get请求参数大小有限制,post请求参数大小没有限制 3.post相当于get安全些"&gt; 常见的子标签 input select:下拉选 textarea:文本域 input标签 常用的属性: type: text:文本框 默认 password:密码框 radio:单选框 checkbox:多选框 file:文件框 submit:提交 reset:重置 button:普通按钮 hidden:隐藏域 在页面上显示 提交的时候可以提交过去 image:图片提交 替代submit name: 可以将几个单选框(复选框)设置为一组 要想将信息保存到服务器上必须有name属性 readonly: readonly="readonly" 只读 disabled: disabled="disabled" 禁用 select :下拉选 格式: &lt;select name="pro"&gt; &lt;option&gt;黑龙江&lt;/option&gt; &lt;/select&gt; textarea:文本域 常用的属性: cols:列 rows:行 提交到服务器的内容的格式: key=value&amp; &lt;"对于文本框 密码框 文本域 手写的内容传递过去了" "对于单选框和多选框来说,却没有把值传递过去" 要想把值传递过去 必须设置value属性 若下拉选要想把选中内容的值传递过去,请加上value属性&gt; &lt;默认值: 文本框 密码框:只需要添加value属性 单选框 多选框:添加 checked="checked" 下拉选:添加selected="selected" 文本域:标签体&gt; 当我们提交的时候 发现地址栏变化 ?username=tom&amp;password=123&amp;sex=on&amp;hobby=on&amp;hobby=on&amp;photo=&amp;pro=黑龙江&amp;city=哈尔滨&amp;intr=good+girl&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action="#" method="get"&gt; &lt;input type="hidden" name="id" value="007"/&gt; 姓名:&lt;input name="username" value="xuduoduo"/&gt;&lt;br&gt; 密码:&lt;input type="password" name="password" value="123" disabled="disabled"&gt;&lt;br&gt; 性别:&lt;input type="radio" name="sex" value="1" checked="checked"&gt;男 &lt;input type="radio" name="sex" value="0"&gt;女 &lt;br&gt; 爱好:&lt;input type="checkbox" name="hobby" value="eat"&gt;吃 &lt;input type="checkbox" name="hobby" value="drink" checked="checked"&gt;喝 &lt;input type="checkbox" name="hobby" value="sleep" checked="checked"&gt;睡 &lt;br&gt; 头像:&lt;input type="file" name="photo"&gt;&lt;br&gt; 籍贯: &lt;select name="pro"&gt; &lt;option value="01"&gt;黑龙江&lt;/option&gt; &lt;option value="02"&gt;吉林&lt;/option&gt; &lt;option value="03" selected="selected"&gt;辽宁&lt;/option&gt; &lt;/select&gt; &lt;select name="city"&gt; &lt;option &gt;-请选择-&lt;/option&gt; &lt;option value="0101"&gt;哈尔滨&lt;/option&gt; &lt;option value="0102"&gt;漠河&lt;/option&gt; &lt;option value="0201"&gt;长春&lt;/option&gt; &lt;option value="0202"&gt;吉林&lt;/option&gt; &lt;option&gt;沈阳&lt;/option&gt; &lt;option&gt;锦州&lt;/option&gt; &lt;/select&gt; &lt;br&gt; 自我介绍: &lt;textarea name="intr" cols="40" rows="4"&gt;good!&lt;/textarea&gt; &lt;br&gt; &lt;input type="submit" value="保存"/&gt; &lt;input type="reset" /&gt; &lt;input type="button" value="普通按钮"/&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 步骤分析： 步骤一：创建一个5行表格 步骤二：完成每行显示 步骤三：中间行设置一个背景图片，嵌套一个表格居中显示。在表格中显示表单的内容 代码实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;table border="1" width="100%"&gt; &lt;tr&gt; &lt;td&gt; &lt;!-- LOGO部分 --&gt; &lt;table width="100%"&gt; &lt;tr height="40"&gt; &lt;td&gt; &lt;img src="../img/logo2.png"/&gt; &lt;/td&gt; &lt;td&gt; &lt;img src="../img/header.png"/&gt; &lt;/td&gt; &lt;td&gt; &lt;a href="#"&gt;登录&lt;/a&gt; &lt;a href="#"&gt;注册&lt;/a&gt; &lt;a href="#"&gt;购物车&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr bgcolor="black" height="30"&gt; &lt;td&gt; &lt;a href="#"&gt;&lt;font color="white"&gt;首页&lt;/font&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="#"&gt;&lt;font color="white"&gt;手机数码&lt;/font&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="#"&gt;&lt;font color="white"&gt;电脑办公&lt;/font&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="#"&gt;&lt;font color="white"&gt;鞋靴箱包&lt;/font&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="#"&gt;&lt;font color="white"&gt;鞋靴箱包&lt;/font&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td&gt; &lt;/tr&gt; &lt;tr height="600"&gt; &lt;td&gt; &lt;table width="100%" height="100%" background="../img/regist_bg.jpg"&gt; &lt;tr&gt; &lt;td align="center"&gt; &lt;table width="60%" height="80%" border="1" bgcolor="white"&gt; &lt;tr&gt; &lt;td&gt; &lt;form&gt; &lt;table width="100%" height="100%" border="0" align="center" cellspacing="10"&gt; &lt;tr&gt; &lt;td&gt;用户名&lt;/td&gt; &lt;td&gt;&lt;input type="text" name="username"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;密码&lt;/td&gt; &lt;td&gt;&lt;input type="password" name="password"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;确认密码&lt;/td&gt; &lt;td&gt;&lt;input type="password" name="repassword"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;性别&lt;/td&gt; &lt;td&gt;&lt;input type="radio" name="sex" value="男" checked="checked"/&gt;男&lt;input type="radio" name="sex" value="女"/&gt;女&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Email&lt;/td&gt; &lt;td&gt;&lt;input type="text" name="email"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;&lt;input type="text" name="name"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;生日&lt;/td&gt; &lt;td&gt;&lt;input type="text" name="birthday"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;验证码&lt;/td&gt; &lt;td&gt;&lt;input type="text" name="checkcode" size="10"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td colspan="2"&gt;&lt;input type="submit" value="注册"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/form&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;img src="../img/footer.jpg" width="100%"/&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="center"&gt; &lt;a href="../案例一：网站信息页面显示/网站信息页面显示.html"&gt;关于我们&lt;/a&gt; &lt;a href=""&gt;联系我们&lt;/a&gt; &lt;a href=""&gt;招贤纳士&lt;/a&gt; &lt;a href=""&gt;法律声明&lt;/a&gt; &lt;a href="../案例三：网站列表页面显示/网站列表页面显示.html"&gt;友情链接&lt;/a&gt; &lt;a href=""&gt;支付方式&lt;/a&gt; &lt;a href=""&gt;配送方式&lt;/a&gt; &lt;a href=""&gt;服务声明&lt;/a&gt; &lt;a href=""&gt;广告声明&lt;/a&gt; &lt;br/&gt; Copyright © 2005-2016 传智商城 版权所有 &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 6、网站后台页面显示需求分析：在浏览器中显示网站的后台页面，效果如下图： 【HTML的框架标记frameset】1234567891011 &lt;frameset&gt;&lt;/frameset&gt;* 使用了frameset标签，不需要使用body.* &lt;注意: 最好和body不要共存&gt;* 属性：* rows：横向切分页面* cols：纵向切分页面&lt;frame&gt;标签代表切分每个部分的页面* src：引入页面的路径* 步骤分析： 步骤一：先将页面切分成上下两个部分。 步骤二：将下部分切分成左右两个部分。 步骤三：分别引入不同的页面。 代码实现：12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;frameset rows="15%,*"&gt; &lt;frame src="top.html" /&gt; &lt;frameset cols="15%,*"&gt; &lt;frame src="left.html" /&gt; &lt;frame src="right.html" /&gt; &lt;/frameset&gt; &lt;/frameset&gt;&lt;/html&gt; 扩展需求：点击分类管理，将数据放入到表格中显示到右侧区域中！ 在frame上添加一个属性name，在超链接的target属性上设置这个名称。点击超链接的时候，跳转到指定的位置。 12&lt;h3&gt;&lt;a href="data.html" target="right"&gt;分类管理&lt;/a&gt;&lt;/h3&gt; 总结html 文件/标题/字体标签12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667案例1-网站信息展示需求: 在页面展示一些文字信息,需要排版技术分析: html:超文本标签语言////////////////////html: 作用:展示 超文本:超越了一般文本,描述文本的字体 颜色 图片 标签:标记 html书写规则: 文件的后缀名 .html(建议) 或者 .htm 标签必须用 &lt;&gt; 引起来 已经定义好的标签 属性 格式: key="value" 建议属性的值用引号引起来. 不区分大小写 注意: 最好将所有的内容放在一个标签中 &lt;html&gt;&lt;/html&gt; 有开始标签和结束标签的标签称之为围堵标签 没有结束的标签的称之为空标签 &lt;br/&gt; 开始标签和结束标签之间的内容称之为标签体. &lt;!--注释内容--&gt; html页面中的注释 标签必须正常嵌套, 标签最好关闭文件标签: html标签: 声明当前网页为html页面 子标签: &lt;head&gt;&lt;/head&gt; &lt;body&gt;&lt;/body&gt; head:用来存放当前页面的重要信息,一般不展示在html页面上 常见的子标签: &lt;title&gt;&lt;/title&gt; 网页的标题 body: 要展示的数据放在body中标题标签: &lt;hn&gt;&lt;/hn&gt; n取值 :1~6 h1最大 h6最小 自动换行 且留白 默认加粗 常用属性: align:对齐方式 left:左 right:右 center:居中 格式: &lt;h2 align="center"&gt;&lt;/h2&gt; //////字体标签:(了解)规定文本的字体、字体尺寸、字体颜色。 &lt;font&gt;&lt;/font&gt; 常用属性: face:字体 size:尺寸 color:颜色颜色的取值:(RGB) 方式1: #xxxxxx x为16进制 方式2: 英文单词段落标签: &lt;p&gt;&lt;/p&gt;其他标签: &lt;b&gt;&lt;/b&gt; &lt;strong&gt;&lt;/strong&gt;加粗 &lt;i&gt;&lt;/i&gt; 斜体水平线 &lt;hr/&gt;换行 &lt;br/&gt; 图片标签1234567891011121314151617181920212223242526272829303132//////////////////////////案例1-步骤分析: 1.新建一个html页面 2.标题标签 3.添加一个水平线 4.4个段落 5.添加字体颜色 加粗 斜体/////////////////////案例2-图片网页展示需求: 在一个页面中展示多张图片技术分析: &lt;img/&gt;图片标签:★ &lt;img/&gt; 常用属性: ★src:图片的路径 alt:替代文字 title:移上去显示的文字 width:宽 height:高 大小的写法: 像素:123px 百分比:20% 路径的写法: 相对路径: ./ 或者 什么都不写 当前目录 ../ 上一级目录 绝对路径: 带协议的绝对路径: http://www.itheima.com实现: 列表标签123456789101112131415161718////////////////案例3-列表页面展示需求: 将友情连接的页面通过列表展示出来技术分析: 列表标签列表标签: &lt;ol&gt;&lt;/ol&gt; 有序 &lt;ul&gt;&lt;/ul&gt; 无序 常用的标签 &lt;li&gt;&lt;/li&gt; 列表项超链接标记 &lt;a&gt;&lt;/a&gt; 常用属性: href:跳转路径 target:在那里打开 默认值:_self _blank(在空白页面打开) 表格标签12345678910111213141516////////////////////////案例4-首页信息的展示需求: 通过表格布局将首页信息展示技术分析: 表格表格表格标签★ &lt;table&gt;&lt;/table&gt; 常用的子标签 &lt;tr&gt;:行 &lt;tr&gt;&lt;/tr&gt; 常用子标签: &lt;td&gt;:列 &lt;th&gt;:表头单元格 默认居中加粗 注意: 一行必须只有有一个单元格或者一列 123456789101112131415161718192021222324252627 ////////////////// table 的常用属性: border:边框 像素值 width: align:表格对齐方式 tr 的常用属性: align:内容对齐 td 的常用属性: align:内容对齐 colspan:跨列合并 值:合并的列数 rowspan:跨行合并步骤分析: 1.常见一个8行1列的表格 2.在第一行 放logo 嵌套一个1行3列的表格 3.第2行 放菜单 4.第3行 放图片 5.第4行 热门商品 嵌套一个2行7列的表格 6.第5行 放广告图片 7.第6行 最新商品 嵌套一个2行7列的表格 8.第7行 放一个图片 9.第8行 两个段落 表单标签1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283///////////////////////案例5-表单页面需求: 设计一个表单页面,用来收集用户的数据技术分析: 表单标签表单标签★★★ &lt;form&gt;&lt;/form&gt; 作用: 用来从浏览器端收集用户的信息.步骤分析: 1.在页面中间添加一个表格 2.10行3列表格 3.在表格中添加表单表单子标签 表单: 常用属性: action:信息提交的路径 默认是当前页面 method:表单提交的方式 只需要掌握两种 get(默认)和post get和post的区别: 1.get请求会把所有的参数追加在地址栏上,post请求不会 2.get请求参数大小有限制,post请求参数大小没有限制 3.post相当于get安全些 常见的子标签 input select:下拉选 textarea:文本域 input标签 常用的属性: type: text:文本框 默认 password:密码框 radio:单选框 checkbox:多选框 file:文件框 submit:提交 reset:重置 button:普通按钮 hidden:隐藏域 在页面上显示 提交的时候可以提交过去 image:图片提交 替代submit name: 可以将几个单选框(复选框)设置为一组 要想将信息保存到服务器上必须有name属性 readonly: readonly="readonly" 只读 disabled: disabled="disabled" 禁用 select :下拉选 格式: &lt;select name="pro"&gt; &lt;option&gt;黑龙江&lt;/option&gt; &lt;/select&gt; textarea:文本域 常用的属性: cols:列 rows:行 提交到服务器的内容的格式: key=value&amp; 对于文本框 密码框 文本域 手写的内容传递过去了 对于单选框和多选框来说,却没有把值传递过去 要想把值传递过去 必须设置value属性 若下拉选要想把选中内容的值传递过去,请加上value属性 默认值: 文本框 密码框:只需要添加value属性 单选框 多选框:添加 checked="checked" 下拉选:添加selected="selected" 文本域:标签体 当我们提交的时候 发现地址栏变化 ?username=tom&amp;password=123&amp;sex=on&amp;hobby=on&amp;hobby=on&amp;photo=&amp;pro=黑龙江&amp;city=哈尔滨&amp;intr=good+girl--&gt; frameset:框架集、转义字符、总结123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126/////////////////////////////////案例6-后台管理页面(了解)需求: 开发一个后台管理页面,通过frameset实现技术分析: frameset:框架集 frame:具体实现frameset:框架集(了解) 常用属性: cols:垂直切割 例如: cols="40%,60%" 例如: cols="40%,*,10%" rows:水平切割 常见的子标签: frame 注意: 最好和body不要共存frame:具体实现 常用属性: src:展示的页面的url//////////////补充: 转义字符: 三部分构成 &amp;实体; 掌握的转义字符: &gt; &amp;gt; //greater than &lt; &amp;lt; &amp; &amp;amp; 空格 &amp;nbsp; ////////////////////// meta 元信息 &lt;meta charset="UTF-8"&gt;指定浏览器用什么编码打开此页面///////////////////////////////////////////////////////////////////////////////上午回顾:html 文件标签: &lt;html&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt;&lt;/body&gt; &lt;/html&gt; 排版标签: p br hr 字体 font h1~h6 b strong i 图片★ &lt;img src="图片路径" alt="替代文字" width="" height=""/&gt; 超链接★ &lt;a href="跳转路径" target="_blank"&gt;xxxx&lt;/a&gt; 列表 &lt;ol&gt;&lt;/ol&gt; &lt;ul&gt;&lt;/ul&gt; 列表项 &lt;li&gt;&lt;/li&gt; 表格标签★★ &lt;table border="" width="" align=""&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; td中的重要属性: colspan:列合并 rowspan:行合并 表单标签★★★ form 常用属性: action:提交路径 method:提交方式 get和post 常见的子标签: input select textarea input标签: 10中type text password radio checkbox file submit reset button hidden image 若想将内容发送到服务器,必须有name属性 username=tom select标签: &lt;select name=""&gt; &lt;option value="提交到服务器的值"&gt;展示内容&lt;/option&gt; &lt;/select&gt; textarea:文本域 格式: &lt;textarea cols="" rows="" name=""&gt;&lt;/textarea&gt; 框架(了解) frameset:定义框架集 常用属性: cols: rows: 常见的子标签: frame frame:具体展示 常用属性: src:展示网页的url name:给当前的frame起个名称]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>JavaWeb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础31(类加载器,反射)]]></title>
    <url>%2F2016%2F12%2F02%2Fday33%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、类加载器2、反射构造方法3、反射成员变量4、反射成员方法5、反射配置文件运行类中的方法 1JVM运行时数据区 2类加载器 *A.类的加载当程序要使用某个类时，如果该类还未被加载到内存中，则系统会通过加载，连接，初始化三步来实现对这个类进行初始化。  a 加载…… 就是指将class文件读入内存，并为之创建一个Class文件的对象。……* 任何类被使用时系统都会建立一个Class对象  b 连接…… 验证 是否有正确的内部结构，并和其他类协调一致…… 准备 负责为类的静态成员分配内存，并设置默认初始化值…… 解析 将类的二进制数据中的符号引用替换为直接引用  c 初始化…… 就是之前的初始化步骤（new 对象）……* 注：简单的说就是：把.class文件加载到内存里，并把这个.class文件封装成一个Class类型的对象。 B.类的加载时机以下的情况，会加载这个类。 a. 创建类的实例 b. 类的静态变量，或者为静态变量赋值 c. 类的静态方法 d. 使用反射方式来强制创建某个类或接口对应的java.lang.Class对象 e. 初始化某个类的子类 f. 直接使用java.exe命令来运行某个主类 * C: 类加载器类加载器(Class Loader)：顾名思义，指的是可以加载类的工具。JVM自身定义了三个类加载器：引导类加载器(Bootstrap Class Loader)、拓展类加载器(Extension Class Loader )、应用加载器(Application Class Loader)。当然，我们有时候也会自己定义一些类加载器来满足自身的需要。负责将.class文件加载到内在中，并为之生成对应的Class对象。 * a. Bootstrap ClassLoader 引导类加载器 也被称为根类加载器，负责Java核心类的加载 比如System,String等。在JDK中JRE的lib目录下rt.jar文件中引导类加载器(Bootstrap Class Loader): 该类加载器使JVM使用C/C++底层代码实现的加载器，用以加载JVM运行时所需要的系统类，这些系统类在{JRE_HOME}/lib目录下。由于类加载器是使用平台相关的底层C/C++语言实现的， 所以该加载器不能被Java代码访问到。但是，我们可以查询某个类是否被引导类加载器加载过。我们经常使用的系统类如：java.lang.String,java.lang.Object,java.lang*……. 这些都被放在 {JRE_HOME}/lib/rt.jar包内， 当JVM系统启动的时候，引导类加载器会将其加载到 JVM内存的方法区中。 * b. Extension ClassLoader 扩展类加载器 负责JRE的扩展目录中jar包的加载。* 在JRE的lib目录下ext目录拓展类加载器(Extension Class Loader): 该加载器是用于加载 java 的拓展类 ，拓展类一般会放在 {JRE_HOME}/lib/ext/ 目录下，用来提供除了系统类之外的额外功能。拓展类加载器是是整个JVM加载器的Java代码可以访问到的类加载器的最顶端，即是超级父加载器，拓展类加载器是没有父类加载器的。 * c. Applocatoin ClassLoader 应用类加载器又称为是System ClassLoader 系统类加载器； 负责在JVM启动时加载来自java命令的class文件，以及classpath环境变量所指定的jar包和类路径。 我们用的是System ClassLoader 系统类加载器 应用类加载器(Applocatoin Class Loader): 该类加载器是用于加载用户代码，是用户代码的入口。我经常执行指令 java xxx.x.xxx.x.x.XClass , 实际上，JVM就是使用的AppClassLoader加载 xxx.x.xxx.x.x.XClass 类的。应用类加载器将拓展类加载器当成自己的父类加载器，当其尝试加载类的时候，首先尝试让其父加载器-拓展类加载器加载；如果拓展类加载器加载成功，则直接返回加载结果Class instance;如果加载失败，则会询问是否引导类加载器已经加载了该类；只有没有加载的时候，应用类加载器才会尝试自己加载。由于xxx.x.xxx.x.x.XClass是整个用户代码的入口，在Java虚拟机规范中，称其为 初始类(Initial Class). * d. Customized ClassLoader 用户自定义类加载器用户自定义类加载器（Customized Class Loader）：用户可以自己定义类加载器来加载类。所有的类加载器都要继承java.lang.ClassLoader类。 3类加载过程1、创建一个引导类加载器实例，初步加载系统类到内存方法区区域中：JVM申请好内存空间后，JVM会创建一个引导类加载器（Bootstrap Classloader）实例，引导类加载器是使用C++语言实现的，负责加载JVM虚拟机运行时所需的基本系统级别的类，如java.lang.String, java.lang.Object等等。引导类加载器(Bootstrap Classloader)会读取 {JRE_HOME}/lib 下的jar包和配置，然后将这些系统类加载到方法区内 引导类加载器将类信息加载到方法区中，以特定方式组织，对于某一个特定的类而言，在方法区中它应该有 运行时常量池、类型信息、字段信息、方法信息、类加载器的引用，对应class实例的引用等信息。 类加载器的引用,由于这些类是由引导类加载器(Bootstrap Classloader)进行加载的，而 引导类加载器是有C++语言实现的，所以是无法访问的，故而该引用为NULL 对应class实例的引用， 类加载器在加载类信息放到方法区中后，会创建一个对应的Class 类型的实例放到堆(Heap)中, 作为开发人员访问方法区中类定义的入口和切入点。 当我们在代码中尝试获取系统类如java.lang.Object的类加载器时，你会始终得到NULL： 1234System.out.println(String.class.getClassLoader());//nullSystem.out.println(Object.class.getClassLoader());//nullSystem.out.println(Math.class.getClassLoader());//nullSystem.out.println(System.class.getClassLoader());//null 2、创建JVM 启动器实例 Launcher,并取得类加载器ClassLoader加载过程上述步骤完成，JVM基本运行环境就准备就绪了。接着，我们要让JVM工作起来了：运行我们定义的程序 org.luanlouis,jvm.load.Main。 此时，JVM虚拟机调用已经加载在方法区的类sun.misc.Launcher 的静态方法getLauncher(), 获取sun.misc.Launcher 实例：12sun.misc.Launcher launcher = sun.misc.Launcher.getLauncher(); //获取Java启动器ClassLoader classLoader = launcher.getClassLoader(); //获取类加载器ClassLoader用来加载class到内存来 sun.misc.Launcher 使用了单例模式设计，保证一个JVM虚拟机内只有一个sun.misc.Launcher实例。在Launcher的内部，其定义了两个类加载器(ClassLoader),分别是sun.misc.Launcher.ExtClassLoader和sun.misc.Launcher.AppClassLoader，这两个类加载器分别被称为拓展类加载器(Extension ClassLoader) 和 应用类加载器(Application ClassLoader).如下图所示：图例注释：除了引导类加载器(Bootstrap Class Loader )的所有类加载器，都有一个能力，就是判断某一个类是否被引导类加载器加载过，如果加载过，可以直接返回对应的Class instance，如果没有，则返回null. 图上的指向引导类加载器的虚线表示类加载器的这个有限的访问 引导类加载器的功能。 当AppClassLoader加载类时，会首先尝试让父加载器ExtClassLoader进行加载，如果父加载器ExtClassLoader加载成功，则AppClassLoader直接返回父加载器ExtClassLoader加载的结果；如果父加载器ExtClassLoader加载失败，AppClassLoader则会判断该类是否是引导的系统类(即是否是通过Bootstrap类加载器加载，这会调用Native方法进行查找)；若要加载的类不是系统引导类，那么ClassLoader将会尝试自己加载，加载失败将会抛出“ClassNotFoundException”。 双亲委派模型(parent-delegation model)上面讨论的应用类加载器AppClassLoader的加载类的模式就是我们常说的双亲委派模型(parent-delegation model).对于某个特定的类加载器而言，应该为其指定一个父类加载器，当用其进行加载类的时候： 委托父类加载器帮忙加载； 父类加载器加载不了，则查询引导类加载器有没有加载过该类； 如果引导类加载器没有加载过该类，则当前的类加载器应该自己加载该类； 若加载成功，返回 对应的Class 对象；若失败，抛出异常“ClassNotFoundException”。 请注意：双亲委派模型中的”双亲”并不是指它有两个父类加载器的意思，一个类加载器只应该有一个父加载器。上面的步骤中，有两个角色： 父类加载器(parent classloader)：它可以替子加载器尝试加载类 引导类加载器（bootstrap classloader）: 子类加载器只能判断某个类是否被引导类加载器加载过，而不能委托它加载某个类；换句话说，就是子类加载器不能接触到引导类加载器，引导类加载器对其他类加载器而言是透明的。 一般情况下，双亲加载模型如下所示： 3使用类加载器ClassLoader加载Main类加载顺序： 加载java.lang.Object、java.lang.System、java.io.PrintStream、java,lang.Class AppClassLoader尝试加载这些类的时候，会先委托ExtClassLoader进行加载；而ExtClassLoader发现不是其加载范围，其返回null；AppClassLoader发现父类加载器ExtClassLoader无法加载，则会查询这些类是否已经被BootstrapClassLoader加载过，结果表明这些类已经被BootstrapClassLoader加载过，则无需重复加载，直接返回对应的Class实例； 加载sun.security.pkcs11.P11Util 此在{JRE_HOME}/lib/ext/sunpkcs11.jar包内，属于ExtClassLoader负责加载的范畴。AppClassLoader尝试加载这些类的时候，会先委托ExtClassLoader进行加载；而ExtClassLoader发现其正好属于加载范围，故ExtClassLoader负责将其加载到内存中。ExtClassLoader在加载sun.security.pkcs11.P11Util时也分析这个类内都使用了哪些类，并将这些类先加载内存后，才开始加载sun.security.pkcs11.P11Util，加载成功后直接返回对应的Class&lt;sun.security.pkcs11.P11Util&gt;实例； 加载org.luanlouis.jvm.load.Main AppClassLoader尝试加载这些类的时候，会先委托ExtClassLoader进行加载；而ExtClassLoader发现不是其加载范围，其返回null；AppClassLoader发现父类加载器ExtClassLoader无法加载，则会查询这些类是否已经被BootstrapClassLoader加载过。而结果表明BootstrapClassLoader 没有加载过它，这时候AppClassLoader只能自己动手负责将其加载到内存中，然后返回对应的Class&lt;org.luanlouis.jvm.load.Main&gt;实例引用； 以上三步骤都成功，才表示classLoader.loadClass(“org.luanlouis.jvm.load.Main”)完成，上述操作完成后，JVM内存方法区的格局会如下所示： *A. 反射定义 a. JAVA反射机制是在运行状态中， 对于任意一个类，都能够知道这个类的所有属性和方法； 对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。 b.反射技术 条件：处于 运行状态 已知：一个类或一个对象(根本是已知.class文件) 结果：得到这个类或对象的所有方法和属性 功能： 在运行时判断任意一个对象所属的类； 在运行时构造 任意一个类的对象； 在运行时判断任意一个类所具有的成员变量和方法； 在运行时调用 任意一个对象的方法； 生成动态代理。 注: 要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象。 * B. Class类 Class类及Class对象的了解要想解剖一个类，必须先了解Class对象。阅读API的Class类得知，Class 没有公共构造方法。Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的。 . 得到Class对象 有三个方法 方式一: 通过Object类中的getClass()方法 Person person = new Person(); Class clazz = person.getClass(); 方式二: 通过 类名.class 获取到字节码文件对象（任意数据类型都具备一个class静态属性,看上去要比第一种方式简单）。 Class clazz = Person.class; 方式三: 通过Class类中的方法（将类名作为字符串传递给Class类中的静态方法forName即可）。 Class c3 = Class.forName(“Person”); 注：第三种和前两种的区别是：前两种你必须明确Person类型.后面是指定这种类型的字符串就行.这种扩展更强.我不需要知道你的类.我只提供字符串,按照配置文件加载就可以了 2. 得到Class对象的三个方法代码演示：123456789 代码演示* * 获取.class字节码文件对象的方式* 1：通过Object类中的getClass()方法* 2: 通过 类名.class 获取到字节码文件对象* 3: 反射中的方法,* public static Class&lt;?&gt; forName(String className) throws ClassNotFoundException* 返回与带有给定字符串名的类或接口相关联的 Class 对象 * 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class ReflectDemo &#123; public static void main(String[] args) throws ClassNotFoundException &#123; "// 1： 通过Object类中的getClass()方法" // Person p1 = new Person(); // Class c1 = p1.getClass(); // System.out.println("c1 = "+ c1); "// 2: 通过 类名.class 获取到字节码文件对象" // Class c2 = Person.class; // System.out.println("c2 = "+ c2); System.out.println(c2==c1);//true System.out.println(c2.equals(c1));//true "// 3: 反射中的方法" Class c3 = Class.forName("cn.itcast_01_Reflect.Person");"// 包名.类名" System.out.println("c3 = " + c3); System.out.println(c3==c1);//true System.out.println(c3.equals(c1));//true &#125;&#125;* 注: Class类型的唯一性"因为一个.class文件在内存里只生成一个Class对象，所以无论那一种方法得到Class对象，得到的都是同一个对象。"Person类package cn.itcast_01_Reflect;public class Person &#123; //成员变量 public String name; public int age; private String address; //构造方法 public Person() &#123; System.out.println("空参数构造方法"); &#125; public Person(String name) &#123; this.name = name; System.out.println("带有String的构造方法"); &#125; //私有的构造方法 private Person(String name, int age)&#123; this.name = name; this.age = age; System.out.println("带有String，int的构造方法"); &#125; public Person(String name, int age, String address)&#123; this.name = name; this.age = age; this.address = address; System.out.println("带有String, int, String的构造方法"); &#125; //成员方法 //没有返回值没有参数的方法 public void method1()&#123; System.out.println("没有返回值没有参数的方法"); &#125; //没有返回值，有参数的方法 public void method2(String name)&#123; System.out.println("没有返回值，有参数的方法 name= "+ name); &#125; //有返回值，没有参数 public int method3()&#123; System.out.println("有返回值，没有参数的方法"); return 123; &#125; //有返回值，有参数的方法 public String method4(String name)&#123; System.out.println("有返回值，有参数的方法"); return "哈哈" + name; &#125; //私有方法 private void method5()&#123; System.out.println("私有方法"); &#125; @Override public String toString() &#123; return "Person [name=" + name + ", age=" + age + ", address=" + address+ "]"; &#125;&#125;* 注: Class类型的唯一性因为一个.class文件在内存里只生成一个Class对象，所以无论那一种方法得到Class对象，得到的都是同一个对象。 * C.通过反射获取无参构造方法并使用123456789101112131415161718192021在反射机制中，把类中的成员（构造方法、成员方法、成员变量）都封装成了对应的类进行表示。其中，构造方法使用类Constructor表示。可通过Class类中提供的方法获取构造方法：1.返回一个构造方法public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 获取public修饰, 指定参数类型所对应的构造方法public Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) 获取指定参数类型所对应的构造方法(包含私有的)2.返回多个构造方法public Constructor&lt;?&gt;[] getConstructors() 获取所有的public 修饰的构造方法public Constructor&lt;?&gt;[] getDeclaredConstructors() 获取所有的构造方法(包含私有的)3.运行构造方法创建实例 通过构造方法类Constructor中的方法，创建对象public T newInstance(Object... initargs) 123456789101112131415161718192021222324252627282930313233343536373839404142434445 void test()* a. 得到构造方法public Constructor&lt;?&gt;[] getConstructors() 获取所有的public 修饰的构造方法。 public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 获取public修饰, 指定参数类型所对应的构造方法。 不传参数得到无参构造方法。* b. 运行构造方法public T newInstance(Object... initargs) 使用此 Constructor 对象表示的构造方法来创建该构造方法的声明类的新实例， 并用指定的初始化参数初始化该实例。 因为是无参构造，所以不传参数。* c. 通过反射获取无参构造方法并使用的代码演示：package cn.itcast.demo1;import java.lang.reflect.Constructor;"/* * 通过反射获取class文件中的构造方法,运行构造方法 * 运行构造方法,创建对象 * 获取class文件对象 * 从class文件对象中,获取需要的成员 * * Constructor 描述构造方法对象类 */"public class ReflectDemo1 &#123; public static void main(String[] args) throws Exception &#123; Class c = Class.forName("cn.itcast.demo1.Person"); //使用class文件对象,获取类中的构造方法 // Constructor[] getConstructors() 获取class文件对象中的所有公共的构造方法 /*Constructor[] cons = c.getConstructors(); for(Constructor con : cons)&#123; System.out.println(con); &#125;*/ //获取指定的构造方法,空参数的构造方法 Constructor con = c.getConstructor(); //运行空参数构造方法,Constructor类方法 newInstance()运行获取到的构造方法 Object obj = con.newInstance(); System.out.println(obj.toString()); &#125;&#125; * D. 通过反射获取有参构造方法并使用123456789101112131415161718192021222324252627282930313233* a. 得到有参的构造方法public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 获取public修饰, 指定参数类型所对应的构造方法。 传相应的参数类型得到有参构造方法。* b. 运行构造方法public T newInstance(Object... initargs) 使用此 Constructor 对象表示的构造方法来创建该构造方法的声明类的新实例，并用指定的初始化参数初始化该实例。 因为是有参构造，所以传相应的参数值。* c. 通过反射获取有参构造方法并使用的代码演示：package cn.itcast.demo1;import java.lang.reflect.Constructor;/* * 通过反射,获取有参数的构造方法并运行 * 方法getConstructor,传递可以构造方法相对应的参数列表即可 */public class ReflectDemo2 &#123; public static void main(String[] args)throws Exception &#123; Class c = Class.forName("cn.itcast.demo1.Person"); //获取带有,String和int参数的构造方法 //Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) //Class&lt;?&gt;... parameterTypes 传递要获取的构造方法的参数列表 Constructor con = c.getConstructor(String.class,int.class); //运行构造方法 // T newInstance(Object... initargs) //Object... initargs 运行构造方法后,传递的实际参数 Object obj = con.newInstance("张三",20); System.out.println(obj); &#125;&#125; * E. 通过反射获取有参构造方法并使用快捷方式12345678910111213141516171819202122* a. 使用的前提"类有空参的public构造方法。（如果是同包，默认权限也可以）"* b. 使用的基础Class类的 public T newInstance() 方法 创建此 Class 对象所表示的类的一个新实例。* c. 通过反射获取有参构造方法并使用快捷方式的代码演示：* package cn.itcast.demo1;/* * 反射获取构造方法并运行,有快捷点的方式 * 有前提: * 被反射的类,必须具有空参数构造方法 * 构造方法权限必须public */public class ReflectDemo3 &#123; public static void main(String[] args) throws Exception &#123; Class c = Class.forName("cn.itcast.demo1.Person"); // Class类中定义方法, T newInstance() 直接创建被反射类的对象实例 Object obj = c.newInstance(); System.out.println(obj); &#125;&#125; * F. 通过反射获取私有构造方法并使用1234567891011121314151617AccessibleObject 类是 Field、Method 和 Constructor 对象的父类。"它提供了将反射的对象标记为在使用时取消默认 Java 语言访问控制检查的能力"。对于公共成员、默认（打包）访问成员、受保护成员和私有成员，在分别使用" Field "、" Method "或 "Constructor "对象来设置或获取字段、调用方法，或者创建和初始化类的新实例的时候，"会执行访问检查"常用方法如下： public void setAccessible(boolean flag) throws SecurityException 参数值为 true 则指示反射的对象在使用时应该【取消】 Java 语言访问检查。参数值为 false 则指示反射的对象应该实施 Java 语言访问检查。获取私有构造方法，步骤如下：1. 获取到Class对象2. 获取指定的构造方法3. 暴力访问, 通过setAccessible(boolean flag)方法4. 通过构造方法类Constructor中的方法，创建对象public T newInstance(Object... initargs) 12345678910111213141516171819202122232425262728293031323334353637383940414243* a. 得到私有的构造方法public Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) 获取指定参数类型所对应的构造方法(包含私有的)。public Constructor&lt;?&gt;[] getDeclaredConstructors() 获取所有的构造方法(包含私有的)。* b. 运行私有构造方法public void setAccessible(boolean flag) 将此对象的 accessible 标志设置为指示的布尔值。 设置为true,这个方法保证我们得到的私有构造方法的运行。（取消运行时期的权限检查。）public T newInstance(Object... initargs) 使用此 Constructor 对象表示的构造方法来创建该构造方法的声明类的新实例， 并用指定的初始化参数初始化该实例。 * c. 通过反射获取私有构造方法并使用的代码演示：package cn.itcast.demo1;import java.lang.reflect.Constructor;/* * 反射获取私有的构造方法运行 * 不推荐,破坏了程序的封装性,安全性 * 暴力反射 */public class ReflectDemo4 &#123; public static void main(String[] args) throws Exception&#123; Class c = Class.forName("cn.itcast.demo1.Person"); //Constructor[] getDeclaredConstructors()获取所有的构造方法,包括私有的 /*Constructor[] cons = c.getDeclaredConstructors(); for(Constructor con : cons)&#123; System.out.println(con); &#125;*/ //Constructor getDeclaredConstructor(Class...c)获取到指定参数列表的构造方法 Constructor con = c.getDeclaredConstructor(int.class,String.class); //Constructor类,父类AccessibleObject,定义方法setAccessible(boolean b) con.setAccessible(true); Object obj = con.newInstance(18,"lisi"); System.out.println(obj); &#125;&#125;* 注：不推荐，破坏了程序的封装性,安全性。 * G. 反射获取成员变量并改值123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869* a. 获取成员变量* 得到公共的成员变量 public Field getField(String name) 返回一个 Field 对象，它反映此 Class 对象所表示的类或接口的指定公共成员字段。 public Field[] getFields() 返回一个包含某些 Field 对象的数组，这些对象反映此 Class 对象所表示的类或接口的所有可访问公共字段。 * 得到所有的成员变量( 包括私有的，如果要进行修改私有成员变量，要先进行public void setAccessible(boolean flag) 设置。) public Field getDeclaredField(String name) 返回一个 Field 对象，该对象反映此 Class 对象所表示的类或接口的指定已声明字段。 public Field[] getDeclaredFields() 返回 Field 对象的一个数组，这些对象反映此 Class 对象所表示的类或接口所声明的所有字段。 获取成员变量，步骤如下：1. 获取Class对象2. 获取构造方法3. 通过构造方法，创建对象4. 获取指定的成员变量（私有成员变量，通过setAccessible(boolean flag)方法暴力访问）5. 通过方法，给指定对象的指定成员变量赋值或者获取值 public void set(Object obj, Object value)在指定对象obj中，将此 Field 对象表示的成员变量设置为指定的新值 public Object get(Object obj) 返回指定对象obj中，此 Field 对象表示的成员变量的值* b. 修改成员变量(Field)的值* 修改公共的成员变量 public void set(Object obj, Object value) 将指定对象变量上此 Field 对象表示的字段设置为指定的新值。 obj指的是修改的是那个对象的这个成员变量值。* c. 反射获取成员变量并改值的代码演示package cn.itcast.demo1;import java.lang.reflect.Field;/* * 反射获取成员变量,并修改值 * Person类中的成员String name */public class ReflectDemo5 &#123; public static void main(String[] args) throws Exception&#123; Class c = Class.forName("cn.itcast.demo1.Person"); Object obj = c.newInstance(); //获取成员变量 Class类的方法 getFields() class文件中的所有公共的成员变量 //返回值是Field[] Field类描述成员变量对象的类 Field[] fields = c.getFields(); for(Field f : fields)&#123; System.out.println(f); &#125; //获取指定的成员变量 String name //Class类的方法 Field getField(传递字符串类型的变量名) 获取指定的成员变量 Field field = c.getField("name"); //Field类的方法 void set(Object obj, Object value) ,修改成员变量的值 //Object obj 必须有对象的支持, Object value 修改后的值 field.set(obj,"王五"); System.out.println(obj); //获得指定对象的成员变量的值 System.out.println(field.get(obj)); &#125;&#125; * H. 反射获取空参数成员方法并运行1234567891011121314151617181920212223在反射机制中，把类中的成员方法使用类Method表示。可通过Class类中提供的方法获取成员方法： 返回获取一个方法： public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 获取public 修饰的方法 public Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 获取任意的方法，包含私有的参数1: name 要查找的方法名称； 参数2： parameterTypes 该方法的参数类型 返回获取多个方法： public Method[] getMethods() 获取本类与父类中所有public 修饰的方法public Method[] getDeclaredMethods() 获取本类中所有的方法(包含私有的)获取成员方法，步骤如下：1. 获取Class对象2. 获取构造方法3. 通过构造方法，创建对象 4. 获取指定的方法 5. 执行找到的方法 public Object invoke(Object obj, Object... args) 执行指定对象obj中，当前Method对象所代表的方法，方法要传入的参数通过args指定。. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354* a. 获取空参数成员方法* 得到公共的成员方法public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 返回一个 Method 对象，它反映此 Class 对象所表示的类或接口的指定public成员方法。 public Method[] getMethods() 返回一个包含某些 Method 对象的数组，这些对象反映此 Class对象所表示的类或接口;"（包括那些由该类或接口声明的以及"从超类和超接口继承"的那些的类或接口）"的public member 方法。* 得到全部的成员方法* (包括私有的，如果要使用私有成员方法，要先进行public void setAccessible(boolean flag) 设置。)public Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 返回一个 Method 对象，该对象反映此 Class 对象所表示的类或接口的指定已声明方法。 public Method[] getDeclaredMethods() 返回 Method 对象的一个数组，这些对象反映此 Class 对象表示的类或接口声明的所有方法; 包括公共public、保护protected、默认（包）访问和私有private方法，【但"不包括"继承的方法】。* b. 使用Method方法对象public Object invoke(Object obj, Object... args) 对带有指定参数的指定对象调用由此 Method 对象表示的底层方法。 obj 指的是调这个方法的对象。 args 指的是调用这个方法所要用到的参数列表。 返回值Object就是方法的返回对象。如果方法没有返回值 ，返回的是null.* c. 反射获取空参数成员方法并运行代码演示package cn.itcast.demo1;import java.lang.reflect.Method;/* * 反射获取成员方法并运行 * public void eat()&#123;&#125; */public class ReflectDemo6 &#123; public static void main(String[] args) throws Exception&#123; Class c = Class.forName("cn.itcast.demo1.Person"); Object obj = c.newInstance(); //获取class对象中的成员方法 "// Method[] getMethods()获取的是class文件中的所有公共成员方法,"包括继承的"" // Method类是描述成员方法的对象 Method[] methods = c.getMethods(); for(Method m : methods)&#123; System.out.println(m); &#125; //获取指定的方法eat运行 // Method getMethod(String methodName,Class...c) // methodName获取的方法名 c 方法的参数列表 Method method = c.getMethod("eat"); //使用Method类中的方法,运行获取到的方法eat //Object invoke(Object obj, Object...o) method.invoke(obj); &#125;&#125; * I. 反射获取有参数成员方法并运行1234567891011121314151617181920212223242526272829303132333435* a. 获取有参数成员方法* 得到公共的成员方法 public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 返回一个 Method 对象，它反映此 Class 对象所表示的类或接口的指定公共成员方法。 public Method[] getMethods() 返回一个包含某些 Method 对象的数组，这些对象反映此 Class对象所表示的类或接口（包括那些由该类或接口声明的以及从超类和超接口继承的那些的类或接口）的公共 member 方法。* 得到全部的成员方法(包括私有的，如果要使用私有成员方法，要先进行public void setAccessible(boolean flag) 设置。) public Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 返回一个 Method 对象，该对象反映此 Class 对象所表示的类或接口的指定已声明方法。 public Method[] getDeclaredMethods() 返回 Method 对象的一个数组，这些对象反映此 Class 对象表示的类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。 * b. 使用Method方法对象public Object invoke(Object obj, Object... args) 对带有指定参数的指定对象调用由此 Method 对象表示的底层方法。 obj 指的是调这个方法的对象。 args 指的是调用这个方法所要用到的参数列表。 返回值Object就是方法的返回对象。如果方法没有返回值 ，返回的是null.* c. 反射获取有参数成员方法并运行代码演示package cn.itcast.demo1;import java.lang.reflect.Method;/* * 反射获取有参数的成员方法并执行 * public void sleep(String,int,double)&#123;&#125; */public class ReflectDemo7 &#123; public static void main(String[] args) throws Exception&#123; Class c = Class.forName("cn.itcast.demo1.Person"); Object obj = c.newInstance(); //调用Class类的方法getMethod获取指定的方法sleep Method method = c.getMethod("sleep", String.class,int.class,double.class); //调用Method类的方法invoke运行sleep方法 method.invoke(obj, "休眠",100,888.99); &#125;&#125; * J. 反射与泛型擦除1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253* a. 使用情况* 我们可以通过"反射技术"，来完成向"有泛型约束"的集合中，添加"任意类型"的元素：例如："在泛型为String的集合里，添加Integer的数据"ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(100);* b. 能用泛型擦除的理论伪泛型："在编译后的.class文件"里面是"没有""泛型约束"的，这种现象我们称为"泛型的擦除"。ArrayList&lt;T&gt;：ArrayList&lt;String&gt;或者ArrayList&lt;Integer&gt; "擦除后ArrayList的类型变成Object"; "泛型擦除后类型为变为 T 的父类" 。如：ArrayList&lt;T extends Comaparable&gt; "擦除后ArrayList的类型变成Comaparable""用反射的方法绕过编译，得到Class文件对象，直接调用add方法"。即可向"有泛型约束"的集合中，添加"任意类型"的元素。* c. 反射泛型擦除的代码演示package cn.itcast.demo2;import java.lang.reflect.Method;import java.util.ArrayList;/* * 定义集合类,泛型String * 要求向集合中添加Integer类型 * * 反射方式,获取出集合ArrayList类的class文件对象 * 通过class文件对象,调用add方法 * * 对反射调用方法是否理解 */public class ReflectTest &#123; public static void main(String[] args)throws Exception &#123; ArrayList&lt;String&gt; alist =new ArrayList&lt;&gt;(); alist.add("Hust"); alist.add("哈喽"); //反射方式,获取出集合ArrayList类的class文件对象 Class c=alist.getClass(); Method method = c.getMethod("add", Object.class); //使用invoke运行ArrayList方法add method.invoke(alist,10909092); method.invoke(alist,new Person("李强",21)); method.invoke(alist,123.67676); System.out.println(alist); //获取alist中的Person对象 Object oj =alist.get(3); Person p = (Person) oj; System.out.println(p.name +"&gt;&gt;&gt;"+ p.age); &#125;&#125; * K. 反射通过配置文件来决定运行的步骤12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061* a. 操作依据 通过配置文件得到类名和要运行的方法名,用反射的操作类名得到对象和调用方法* b. 实现步骤: * 1. 准备配置文件,键值对 * 2. IO流读取配置文件 Reader * 3. 文件中的键值对存储到集合中 Properties * 集合保存的键值对,就是类名和方法名 * 4. 反射获取指定类的class文件对象 * 5. class文件对象,获取指定的方法 * 6. 运行方法* c. 代码演示代码：package cn.itcast.demo3;import java.io.FileReader;import java.lang.reflect.Method;import java.util.Properties;"/* * 调用Person方法,调用Student方法,调用Worker方法 * 类不清楚,方法也不清楚 * 通过配置文件实现此功能 * 运行的类名和方法名字,以键值对的形式,写在文本中 * 运行哪个类,读取配置文件即可 * 实现步骤: * 1. 准备配置文件,键值对 * 2. IO流读取配置文件 Reader * 3. 文件中的键值对存储到集合中 Properties * 集合保存的键值对,就是类名和方法名 * 4. 反射获取指定类的class文件对象 * 5. class文件对象,获取指定的方法 * 6. 运行方法 */"public class Test &#123; public static void main(String[] args) throws Exception&#123; //IO流读取配置文件 FileReader r = new FileReader("config.properties"); //创建集合对象 Properties pro = new Properties(); //调用集合方法load,传递流对象 pro.load(r); r.close(); //通过键获取值 String className = pro.getProperty("className"); String methodName = pro.getProperty("methodName"); //反射获取指定类的class文件对象 Class c = Class.forName(className); Object obj = c.newInstance(); //获取指定的方法名 Method method = c.getMethod(methodName); method.invoke(obj); &#125;&#125;config.properties配置文件：#className=cn.itcast.demo3.Student#methodName=studyclassName=cn.itcast.demo3.PersonmethodName=eat#className=cn.itcast.demo3.Worker#methodName=job 总结123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103如何获取.Class文件对象 1, 通过"Object类 getClass()方法"获取 Class对象 2, 通过"类名.class 方式" 获取 Class对象 3, 通过反射的方式, " Class.forName(String classname) 获取Class对象" public static Class&lt;?&gt; forName(String className)throws ClassNotFoundException返回与带有给定字符串名的类或接口相关联的 Class 对象通过反射， 获取类中的构造方法，并完成对象的创建 获取指定的构造方法 public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 获取指定的public修饰的构造方法 public Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) 获取指定的构造方法，包含私有的 获取所有的构造方法 public Constructor&lt;?&gt;[] getConstructors() 获取所有的public 修饰的构造方法 public Constructor&lt;?&gt;[] getDeclaredConstructors() 获取所有的构造方法，包含私有的通过反射， 获取类中的构造方法，并完成对象的创建 步骤： 1，获取字节码文件对象 2,通过字节码文件对象 ，获取到指定的构造方法 getConstructor(参数); 3,通过构造方法，创建对象 public T newInstance(Object... initargs)私有构造方法，创建对象 1，获取字节码文件对象 2,通过字节码文件对象 ，获取到指定的构造方法 getDeclaredConstructor (参数); 3,暴力访问 con.setAccessible(true); 4,通过构造方法，创建对象 public T newInstance(Object... initargs)通过反射，获取Class文件中的方法 获取指定的方法 public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 获取指定的public方法 public Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 获取指定的任意方法，包含私有的 获取所有的方法 public Method[] getMethods() 获取本类与父类中所有public 修饰的方法 public Method[] getDeclaredMethods()获取本类中所有的方法，包含私有的通过反射，调用方法 步骤： 1，获取Class对象 2,获取构造方法，创建对象 3,获取指定的public方法 4,执行方法 public Object invoke(Object obj, Object... args)私有方法的调用： 1，获取Class对象 2,获取构造方法，创建对象 3,获取指定的private方法 4,开启暴力访问 m5.setAccessible(true); 5,执行方法 public Object invoke(Object obj, Object... args)通过反射，获取成员变量(字段) 获取指定的成员变量 public Field getField(String name) 获取public修饰的成员变量 public Field getDeclaredField(String name) 获取任意的成员变量，包含私有 获取所有的成员变量 public Field[] getFields() 获取所有public修饰的成员变量 public Field[] getDeclaredFields() 获取司所有的成员变量，包含私有通过反射，获取成员 变量，并赋值使用 步骤： 1，获取字节码文件对象 2,获取构造方法，创建对象 3,获取指定的成员变量 4,对成员变量赋值\获取值操作 public void set(Object obj, Object value) 赋值 public Object get(Object obj) 获取值私有成员变量的使用 步骤： 1，获取字节码文件对象 2,获取构造方法，创建对象 3,获取指定的成员变量 4,开启暴力访问 5,对成员变量赋值\获取值操作 public void set(Object obj, Object value) 赋值 public Object get(Object obj) 获取值]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础30(网络编程)]]></title>
    <url>%2F2016%2F12%2F01%2Fday32%E7%AC%94%E8%AE%B0%20%2F</url>
    <content type="text"><![CDATA[1、网络三要素及传输协议2、实现UDP协议的发送端和接收端3、实现TCP协议的客户端和服务器4、TCP上传文件案例 01网络模型*A:网络模型 TCP/IP协议中的四层分别是应用层、传输层、网络层和链路层，每层分别负责不同的通信功能，接下来针对这四层进行详细地讲解。 链路层：链路层是用于定义物理传输通道，通常是对某些网络连接设备的驱动协议，例如针对光纤、网线提供的驱动。 网络层：网络层是整个TCP/IP协议的核心，它主要用于将传输的数据进行分组，将分组数据发送到目标计算机或者网络。 传输层：主要使网络程序进行通信，在进行网络通信时，可以采用TCP协议，也可以采用UDP协议。 应用层：主要负责应用程序的协议，例如HTTP协议、FTP协议等。 02IP地址*A:IP地址 在TCP/IP协议中，这个标识号就是IP地址，它可以唯一标识一台计算机， 目前，IP地址广泛使用的版本是IPv4，它是由4个字节大小的二进制数来表示，如：00001010000000000000000000000001。 由于二进制形式表示的IP地址非常不便记忆和处理，因此通常会将IP地址写成十进制的形式， 每个字节用一个十进制数字(0-255)表示，数字间用符号“.”分开，如 “192.168.1.100” 127.0.0.1 为本地主机地址(本地回环地址) 03端口号*A:端口号通过IP地址可以连接到指定计算机，但如果想访问目标计算机中的某个应用程序，还需要指定端口号。在计算机中，不同的应用程序是通过端口号区分的。端口号是用两个字节（16位的二进制数）表示的，它的取值范围是0~65535，其中，0~1023之间的端口号用于一些知名的网络服务和应用，用户的普通应用程序需要使用1024以上的端口号，从而避免端口号被另外一个应用或服务所占用 04InetAddress类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950*A:InetAddress类 * * 表示互联网中的IP地址 * java.net.InetAddress * 静态方法 * static InetAddress getLocalHost() LocalHost"本地主机" * 返回本地主机,返回值InetAddress对象 * * static InetAddress getByName(String hostName)传递主机名,获取IP地址对象; * * 非静态方法 * String getHoustAddress()获取主机IP地址 * String getHoustName()获取主机名 * * public class InetAddressDemo &#123; public static void main(String[] args)throws UnknownHostException &#123; function_1(); &#125; * * static InetAddress getByName(String hostName)传递主机名,获取IP地址对象 * public static void function_1()throws UnknownHostException &#123; InetAddress inet = InetAddress.getByName("www.baidu.com"); System.out.println(inet); &#125; * * static InetAddress getLocalHost() LocalHost本地主机 * public static void function() throws UnknownHostException&#123; InetAddress inet = InetAddress.getLocalHost(); //输出结果就是主机名,和 IP地址 System.out.println(inet.toString()); String ip = inet.getHostAddress(); String name = inet.getHostName(); System.out.println(ip+" "+name); /*String host = inet.toString(); String[] str = host.split("/"); for(String s : str)&#123; System.out.println(s); &#125;*/ &#125; &#125; 05UDP协议A:UDP协议 a:UDP协议概述: UDP是无连接通信协议，即在数据传输时，数据的发送端和接收端不建立逻辑连接。 简单来说，当一台计算机向另外一台计算机发送数据时，发送端不会确认接收端是否存在，就会发出数据，同样接收端在收到数据时，也不会向发送端反馈是否收到数据。 b:UDP协议特点: 由于使用UDP协议消耗资源小，通信效率高，所以通常都会用于音频、视频和普通数据的传输例如视频会议都使用UDP协议， 因为这种情况即使偶尔丢失一两个数据包，也不会对接收结果产生太大影响。 06TCP协议*A:TCP协议TCP协议是面向连接的通信协议，即在传输数据前先在发送端和接收端建立逻辑连接，然后再传输数据，它提供了两台计算机之间可靠无差错的数据传输。在TCP连接中必须要明确客户端与服务器端， 由客户端向服务端发出连接请求，每次连接的创建都需要经过“三次握手”。 第一次握手，客户端向服务器端发出连接请求，等待服务器确认 第二次握手，服务器端向客户端回送一个响应，通知客户端收到了连接请求 第三次握手，客户端再次向服务器端发送确认信息，确认连接 07 UDP:数据包和发送对象介绍*A:数据包和发送对象介绍:DatagramPacket数据包的作用就如同是“集装箱”， 可以将发送端或者接收端的数据封装起来。然而运输货物只有“集装箱”是不够的，还需要有码头。 在程序中需要实现通信只有DatagramPacket数据包也同样不行，为此JDK中提供的一个DatagramSocket类。 DatagramSocket类的作用就类似于“码头”，使用这个类的实例对象就可以发送和接收DatagramPacket数据包 DatagramPacket:封装数据 DatagramSocket:发送DatagramPacket, 即传输数据 *B: DatagramPacket类：在创建发送端和接收端的DatagramPacket对象时，使用的构造方法有所不同： 使用该构造方法在创建DatagramPacket对象时，指定了封装数据的字节数组和数据的大小，没有指定IP地址和端口号。很明显，这样的对象只能用于接收端，不能用于发送端。因为发送端一定要明确指出数据的目的地(ip地址和端口号)，而接收端不需要明确知道数据的来源，只需要接收到数据即可。 ——————————————————————————————————————————————————————————— 使用该构造方法在创建DatagramPacket对象时，不仅指定了封装数据的字节数组和数据的大小，还指定了数据包的目标IP地址（addr）和端口号（port）。该对象通常用于发送端，因为在发送数据时必须指定接收端的IP地址和端口号，就好像发送货物的集装箱上面必须标明接收人的地址一样。 ———————————————————————————————————————————————————————————上面我们讲解了DatagramPacket的构造方法，接下来对DatagramPacket类中的常用方法进行详细地讲解，如下表所示。 *C: DatagramSocket类：DatagramSocket类的作用就类似于码头，使用这个类的实例对象就可以发送和接收DatagramPacket数据包，发送数据的过程如下图所示。 在创建发送端和接收端的DatagramSocket对象时，使用的构造方法也有所不同： 该构造方法用于创建发送端的DatagramSocket对象，在创建DatagramSocket对象时，并没有指定端口号，此时，系统会分配一个没有被其它网络程序所使用的端口号。 ———————————————————————————————————————————————————————————该构造方法既可用于创建接收端的DatagramSocket对象，又可以创建发送端的DatagramSocket对象，在创建接收端的DatagramSocket对象时，必须要指定一个端口号，这样就可以监听指定的端口。———————————————————————————————————————————————————————————上面我们讲解了DatagramSocket的构造方法，接下来对DatagramSocket类中的常用方法进行详细地讲解。 08UDP发送端123456789101112131415161718192021222324252627282930313233343536*A:UDP发送端 * * 实现UDP协议的发送端: * 实现封装数据的类 "java.net.DatagramPacket " "将你的数据包装" * * 实现数据传输的类 "java.net.DatagramSocket " "将数据包发出去" * * 实现步骤: * 1. 创建DatagramPacket对象,"封装数据", "接收的ip地址和端口" * 2. 创建DatagramSocket * 3. 调用DatagramSocket类"方法send",发送数据包 * 4. 关闭资源 * void test() * DatagramPacket构造方法: * DatagramPacket(byte[] buf, int length, InetAddress address, int port) * * DatagramSocket构造方法: * DatagramSocket()空参数 * 方法: coid send(DatagramPacket d) * * public class UDPSend &#123; public static void main(String[] args) throws IOException&#123; //创建数据包对象,封装要发送的数据,接收端IP,端口 byte[] date = "你好UDP".getBytes(); //创建InetAddress对象,封装自己的IP地址 InetAddress inet = InetAddress.getByName("127.0.0.1"); DatagramPacket dp = new DatagramPacket(date, date.length, inet,6000); //创建DatagramSocket对象,数据包的发送和接收对象 DatagramSocket ds = new DatagramSocket(); //调用ds对象的方法send,发送数据包 ds.send(dp); //关闭资源 ds.close(); &#125; &#125; 09UDP接收端123456789101112131415161718192021222324252627282930313233343536373839404142*A:UDP接收端 * * 实现UDP接收端 * 实现封装数据包 java.net.DatagramPacket "将数据接收" * 实现输出传输 java.net.DatagramSocket "接收数据包" * * 实现步骤: * 1. "创建DatagramSocket接收端对象","必须绑定端口号" * 要和发送端端口号一致 * 2. 创建字节数组,接收发来的数据 * 3. 创建数据包对象DatagramPacket * 4. 调用DatagramSocket对象方法 * void receive(DatagramPacket dp)接收数据,数据放在数据包中 * 5. 拆包 * a.发送的IP地址 * 数据包对象DatagramPacket方法: * InetAddress getAddress()获取的是发送端的IP地址对象 * 返回值是InetAddress对象 * * b.接收到的字节个数 * 数据包对象DatagramPacket方法 int getLength() * * c.发送方的端口号 * 数据包对象DatagramPacket方法 int getPort()发送端口 * 6. 关闭资源 * public class UDPReceive &#123; public static void main(String[] args)throws IOException &#123; //创建数据包传输对象DatagramSocket 绑定端口号 DatagramSocket ds = new DatagramSocket(6000); //创建字节数组 byte[] data = new byte[1024]; //创建数据包对象,传递字节数组 DatagramPacket dp = new DatagramPacket(data, data.length); //调用ds对象的方法receive传递数据包 ds.receive(dp); &#125; &#125; 10UDP接收端的拆包12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849*A:UDP接收端的拆包 * * 实现UDP接收端 * 实现封装数据包 java.net.DatagramPacket 将数据接收 * 实现输出传输 java.net.DatagramSocket 接收数据包 * * 实现步骤: * 1. 创建DatagramSocket对象,绑定端口号 * 要和发送端端口号一致 * 2. 创建字节数组,接收发来的数据 * 3. 创建数据包对象DatagramPacket * 4. 调用DatagramSocket对象方法 * void receive(DatagramPacket dp)接收数据,数据放在数据包中 * 5. 拆包 * 发送的IP地址 * 数据包对象DatagramPacket方法getAddress()获取的是发送端的IP地址对象 * 返回值是InetAddress对象 * 接收到的字节个数 * 数据包对象DatagramPacket方法 getLength() * 发送方的端口号 * 数据包对象DatagramPacket方法 getPort()发送端口 * 6. 关闭资源 * public class UDPReceive &#123; public static void main(String[] args)throws IOException &#123; //创建数据包传输对象DatagramSocket 绑定端口号 DatagramSocket ds = new DatagramSocket(6000); //创建字节数组 byte[] data = new byte[1024]; //创建数据包对象,传递字节数组 DatagramPacket dp = new DatagramPacket(data, data.length); //调用ds对象的方法receive传递数据包 ds.receive(dp); //获取发送端的IP地址对象 String ip=dp.getAddress().getHostAddress(); //获取发送的端口号 int port = dp.getPort(); //获取接收到的字节个数 int length = dp.getLength(); System.out.println(new String(data,0,length)+"..."+ip+":"+port); ds.close(); &#125; &#125; 11键盘输入的聊天1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465*A:键盘输入的聊天 *a:发送端: /* * 实现UDP发送,键盘输入的形式 * 输入完毕,发送给接收端 */ public class UDPSend &#123; public static void main(String[] args) throws IOException&#123; Scanner sc = new Scanner(System.in); DatagramSocket ds = new DatagramSocket(); InetAddress inet = InetAddress.getByName("127.0.0.1"); while(true)&#123; String message = sc.nextLine(); if(messege.equals("bye"))&#123; System.out.println("Bye!!!"); ds.close(); break; &#125; byte[] date = message.getBytes(); DatagramPacket dp = new DatagramPacket(date, date.length, inet,6000); ds.send(dp); &#125; &#125; &#125; /* * 实现UDP接收端 * 永不停歇的接收端 */ public class UDPReceive &#123; public static void main(String[] args)throws IOException &#123; //创建数据包传输对象DatagramSocket 绑定端口号 DatagramSocket ds = new DatagramSocket(6000); //创建字节数组 byte[] data = new byte[1024]; //创建数据包对象,传递字节数组 while(true)&#123; DatagramPacket dp = new DatagramPacket(data, data.length); //调用ds对象的方法receive传递数据包 ds.receive(dp); //获取发送端的IP地址对象 String ip=dp.getAddress().getHostAddress(); //获取发送的端口号 int port = dp.getPort(); //获取接收到的字节个数 int length = dp.getLength(); String rsmessege = new String(data,0,length); if(rsmessege.equals("bye"))&#123; System.out.println("Bye!!!"); ds.close(); break; &#125; System.out.println(rsmessege+"..."+ip+":"+port); &#125; &#125; &#125; 12TCP的客户端和服务器*A:TCP的客户端和服务器TCP通信同UDP通信一样，都能实现两台计算机之间的通信，通信的两端都需要创建socket对象。区别在于，UDP中只有发送端和接收端，不区分客户端与服务器端，计算机之间可以任意地发送数据。而TCP通信是严格区分客户端与服务器端的，在通信时，必须先由客户端去连接服务器端才能实现通信，服务器端不可以主动连接客户端，并且服务器端程序需要事先启动，等待客户端的连接。 在JDK中提供了两个类用于实现TCP程序，一个是ServerSocket类，用于表示服务器端，一个是Socket类，用于表示客户端。 通信时，首先创建代表服务器端的ServerSocket对象，该对象相当于开启一个服务，并等待客户端的连接，然后创建代表客户端的Socket对象向服务器端发出连接请求，服务器端响应请求，两者建立连接开始通信。 ServerSocket的构造方法1、使用该构造方法在创建ServerSocket对象时，就可以将其绑定到一个指定的端口号上（参数port就是端口号）。———————————————————————————————————————————————————————————2、ServerSocket的常用方法，如表所示。 ServerSocket对象负责监听某台计算机的某个端口号，在创建ServerSocket对象后，需要继续调用该对象的accept()方法，接收来自客户端的请求。当执行了accept()方法之后，服务器端程序会发生【阻塞】，直到客户端发出连接请求，accept()方法才会返回一个Scoket对象用于和客户端实现通信，程序才能继续向下执行。 Socket的常用构造方法1、使用该构造方法在创建Socket对象时，会根据参数去连接在指定地址和端口上运行的服务器程序，其中参数host接收的是一个字符串类型的IP地址。 ———————————————————————————————————————————————————————————2、该方法在使用上与第二个构造方法类似，参数address用于接收一个InetAddress类型的对象，该对象用于封装一个IP地址。在以上Socket的构造方法中，最常用的是第一个构造方法。———————————————————————————————————————————————————————————3、在Socket类的常用方法中，getInputStream()和getOutStream()方法分别用于获取输入流和输出流。当客户端和服务端建立连接后，数据是以IO流的形式进行交互的，从而实现通信。 接下来通过一张图来描述服务器端和客户端的数据传输，如下图所示。 13TCP的客户端程序1234567891011121314151617181920212223242526272829*A:TCP的客户端程序 * * 实现TCP客户端,连接到服务器 * 和服务器实现数据交换 * 实现TCP客户端程序的类 java.net.Socket * void test() * 构造方法: * Socket(String host, int port) 传递服务器IP和端口号 * 注意:构造方法只要运行,就会和服务器进行连接,连接失败,抛出异常 * * OutputStream getOutputStream() 返回套接字的输出流 * 作用: 将数据输出,输出到服务器 * * InputStream getInputStream() 返回套接字的输入流 * 作用: 从服务器端读取数据 * * 客户端服务器数据交换,必须使用套接字对象Socket中的获取的IO流,自己new流,不行 * public class TCPClient &#123; public static void main(String[] args)throws IOException &#123; //创建Socket对象,连接服务器 Socket socket = new Socket("127.0.0.1", 8888); //通过客户端的套接字对象Socket方法,获取字节输出流,将数据写向服务器 OutputStream out = socket.getOutputStream(); out.write("服务器OK".getBytes()); socket.close(); &#125; &#125; 14TCP的服务器程序以及accept方法1234567891011121314151617181920212223242526A:TCP的服务器程序accept方法 * * 实现TCP服务器程序 * 表示服务器程序的类 java.net.ServerSocket * 构造方法: * ServerSocket(int port) 传递端口号 * * "很重要的事情: 必须要获得客户端的套接字对象Socket" * Socket accept() * public class TCPServer &#123; public static void main(String[] args) throws IOException&#123; ServerSocket server = new ServerSocket(8888); //调用服务器套接字对象中的方法accept() 获取客户端套接字对象 Socket socket = server.accept(); //通过客户端套接字对象,socket获取字节输入流,读取的是客户端发送来的数据 InputStream in = socket.getInputStream(); byte[] data = new byte[1024]; int len = in.read(data); System.out.println(new String(data,0,len)); socket.close(); server.close(); &#125; &#125; 15TCP的服务器程序读取客户端数据12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758A:TCP的服务器程序读取客户端数据 * * 实现TCP客户端,连接到服务器 * 和服务器实现数据交换 * 实现TCP客户端程序的类 java.net.Socket * * 构造方法: * Socket(String host, int port) 传递服务器IP和端口号 * 注意:构造方法只要运行,就会和服务器进行连接,连接失败,抛出异常 * * OutputStream getOutputStream() 返回套接字的输出流 * 作用: 将数据输出,输出到服务器 * * InputStream getInputStream() 返回套接字的输入流 * 作用: 从服务器端读取数据 * * 客户端服务器数据交换,必须使用套接字对象Socket中的获取的IO流,自己new流,不行 * public class TCPClient &#123; public static void main(String[] args)throws IOException &#123; //创建Socket对象,连接服务器 Socket socket = new Socket("127.0.0.1", 8888); //通过客户端的套接字对象Socket方法,获取字节输出流,将数据写向服务器 OutputStream out = socket.getOutputStream(); out.write("服务器OK".getBytes()); socket.close(); &#125; &#125; * * 实现TCP服务器程序 * 表示服务器程序的类 java.net.ServerSocket * 构造方法: * ServerSocket(int port) 传递端口号 * * 很重要的事情: 必须要获得客户端的套接字对象Socket * Socket accept() * public class TCPServer &#123; public static void main(String[] args) throws IOException&#123; ServerSocket server = new ServerSocket(8888); //调用服务器套接字对象中的方法accept() 获取客户端套接字对象 Socket socket = server.accept(); //通过客户端套接字对象,socket获取字节输入流,读取的是客户端发送来的数据 InputStream in = socket.getInputStream(); byte[] data = new byte[1024]; int len = in.read(data); System.out.println(new String(data,0,len)); socket.close(); server.close(); &#125; &#125; 16TCP的服务器和客户端的数据交换1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465A:TCP的服务器和客户端的数据交换 * * 实现TCP客户端,连接到服务器 * 和服务器实现数据交换 * 实现TCP客户端程序的类 java.net.Socket * void test() * 构造方法: * Socket(String host, int port) 传递服务器IP和端口号 * 注意:构造方法只要运行,就会和服务器进行连接,连接失败,抛出异常 * * OutputStream getOutputStream() 返回套接字的输出流 * 作用: 将数据输出,输出到服务器 * * InputStream getInputStream() 返回套接字的输入流 * 作用: 从服务器端读取数据 * * 客户端服务器数据交换,必须使用套接字对象Socket中的获取的IO流,自己new流,不行 * public class TCPClient &#123; public static void main(String[] args)throws IOException &#123; //创建Socket对象,连接服务器 Socket socket = new Socket("127.0.0.1", 8888); //通过客户端的套接字对象Socket方法,获取字节输出流,将数据写向服务器 OutputStream out = socket.getOutputStream(); out.write("服务器OK".getBytes()); //读取服务器发回的数据,使用socket套接字对象中的字节输入流 InputStream in = socket.getInputStream(); byte[] data = new byte[1024]; int len = in.read(data); System.out.println(new String(data,0,len)); socket.close(); &#125; &#125; /* * 实现TCP服务器程序 * 表示服务器程序的类 java.net.ServerSocket * 构造方法: * ServerSocket(int port) 传递端口号 * * 很重要的事情: 必须要获得客户端的套接字对象Socket * Socket accept() */ public class TCPServer &#123; public static void main(String[] args) throws IOException&#123; ServerSocket server = new ServerSocket(8888); //调用服务器套接字对象中的方法accept() 获取客户端套接字对象 Socket socket = server.accept(); //通过客户端套接字对象,socket获取字节输入流,读取的是客户端发送来的数据 InputStream in = socket.getInputStream(); byte[] data = new byte[1024]; int len = in.read(data); System.out.println(new String(data,0,len)); //服务器向客户端回数据,字节输出流,通过客户端套接字对象获取字节输出流 OutputStream out = socket.getOutputStream(); out.write("收到,谢谢".getBytes()); socket.close(); server.close(); &#125; &#125; 17TCP的中的流对象*A:TCP的中的流对象 18TCP文件上传–案例分析*A:图片上传案例分析 19TCP文件上传–客户端12345678910111213141516171819202122232425262728293031323334353637383940*A TCP上传客户端 "/* * 实现TCP图片上传客户端 * 实现步骤: * 1. Socket套接字连接服务器 * 2. 通过Socket获取字节输出流,写图片 * 3. 使用自己的流对象,读取图片数据源 * FileInputStream * 4. 读取图片,使用字节输出流,将图片写到服务器 * 采用字节数组进行缓冲 * 5. 通过Socket套接字获取字节输入流 * 读取服务器发回来的上传成功 * 6. 关闭资源 */" public class TCPClient &#123; public static void main(String[] args) throws IOException&#123; Socket socket = new Socket("127.0.0.1", 8000); //获取字节输出流,图片写到服务器 OutputStream out = socket.getOutputStream(); //创建字节输入流,读取本机上的数据源图片 FileInputStream fis = new FileInputStream("c:\\t.jpg"); //开始读写字节数组 int len = 0 ; byte[] bytes = new byte[1024]; while((len = fis.read(bytes))!=-1)&#123; out.write(bytes, 0, len); &#125; //给服务器写终止序列 //socket.shutdownOutput(); //获取字节输入流,读取服务器的上传成功 InputStream in = socket.getInputStream(); len = in.read(bytes); System.out.println(new String(bytes,0,len)); fis.close(); socket.close(); &#125; &#125; 20TCP文件上传–服务器123456789101112131415161718192021222324252627282930313233343536373839404142A:TCP上传服务器 "/* * TCP图片上传服务器 * 1. ServerSocket套接字对象,监听端口8000 * 2. 方法accept()获取客户端的连接对象 * 3. 客户端连接对象获取字节输入流,读取客户端发送图片 * 4. 创建File对象,绑定上传文件夹 * 判断文件夹存在, 不存,在创建文件夹 * 5. 创建字节输出流,数据目的File对象所在文件夹 * 6. 字节流读取图片,字节流将图片写入到目的文件夹中 * 7. 将上传成功会写客户端 * 8. 关闭资源 * */" public class TCPServer &#123; public static void main(String[] args) throws IOException&#123; ServerSocket server = new ServerSocket(8000); Socket socket = server.accept(); //通过客户端连接对象,获取字节输入流,读取客户端图片 InputStream in = socket.getInputStream(); //将目的文件夹封装到File对象 File upload = new File("d:\\upload"); if(!upload.exists()) upload.mkdirs(); //创建字节输出流,将图片写入到目的文件夹中 FileOutputStream fos = new FileOutputStream(upload+"t.jpg"); //读写字节数组 byte[] bytes = new byte[1024]; int len = 0 ; while((len = in.read(bytes))!=-1)&#123; fos.write(bytes, 0, len); &#125; //通过客户端连接对象获取字节输出流 //上传成功写回客户端 socket.getOutputStream().write("上传成功".getBytes()); fos.close(); socket.close(); server.close(); &#125; &#125; 21TCP文件上传–问题解决上面的代码能实现文件的正确上传，但是不能实现服务器将“上传成功”信息返回给客户端,并且服务器和客户端的运行界面都不能终止：问题在于：read()方法遇到阻塞客户端的read()方法读取的是文件，遇到文件末尾， read()方法会返回-1 服务器端的read()方法读取的是客户端的字节数组，返回的是字节数组的长度&gt;=0；不会返回-1 问题解决：给服务器写终止序列socket.shutdownOutput();//向服务器端写入一个结束标志 123456789101112131415161718192021222324252627282930313233343536373839"/* * 实现TCP图片上传客户端 * 实现步骤: * 1. Socket套接字连接服务器 * 2. 通过Socket获取字节输出流,写图片 * 3. 使用自己的流对象,读取图片数据源 * FileInputStream * 4. 读取图片,使用字节输出流,将图片写到服务器 * 采用字节数组进行缓冲 * 5. 通过Socket套接字获取字节输入流 * 读取服务器发回来的上传成功 * 6. 关闭资源 */"public class TCPClient &#123; public static void main(String[] args) throws IOException&#123; Socket socket = new Socket("127.0.0.1", 8000); //获取字节输出流,图片写到服务器 OutputStream out = socket.getOutputStream(); //创建字节输入流,读取本机上的数据源图片 FileInputStream fis = new FileInputStream("c:\\t.jpg"); //开始读写字节数组 int len = 0 ; byte[] bytes = new byte[1024]; while((len = fis.read(bytes))!=-1)&#123; out.write(bytes, 0, len); &#125; //给服务器写终止序列 socket.shutdownOutput();//想服务器端写入一个结束标志 //获取字节输入流,读取服务器的上传成功 InputStream in = socket.getInputStream(); len = in.read(bytes); System.out.println(new String(bytes,0,len)); fis.close(); socket.close(); &#125;&#125; TCP上传文件名123456789101112131415161718192021222324252627282930313233343536373839404142434445*A:TCP上传文件名 /* * TCP图片上传服务器 * 1. ServerSocket套接字对象,监听端口8000 * 2. 方法accept()获取客户端的连接对象 * 3. 客户端连接对象获取字节输入流,读取客户端发送图片 * 4. 创建File对象,绑定上传文件夹 * 判断文件夹存在, 不存,在创建文件夹 * 5. 创建字节输出流,数据目的File对象所在文件夹 * 6. 字节流读取图片,字节流将图片写入到目的文件夹中 * 7. 将上传成功会写客户端 * 8. 关闭资源 * */ public class TCPServer &#123; public static void main(String[] args) throws IOException&#123; ServerSocket server = new ServerSocket(8000); Socket socket = server.accept(); //通过客户端连接对象,获取字节输入流,读取客户端图片 InputStream in = socket.getInputStream(); //将目的文件夹封装到File对象 File upload = new File("d:\\upload"); if(!upload.exists()) upload.mkdirs(); //防止文件同名被覆盖,从新定义文件名字 //规则: 域名+毫秒值+6位随机数 String filename="itcast"+System.currentTimeMillis()+new Random().nextInt(999999)+".jpg"; //创建字节输出流,将图片写入到目的文件夹中 FileOutputStream fos = new FileOutputStream(upload+File.separator+filename); //读写字节数组 byte[] bytes = new byte[1024]; int len = 0 ; while((len = in.read(bytes))!=-1)&#123; fos.write(bytes, 0, len); &#125; //通过客户端连接对象获取字节输出流 //上传成功写回客户端 socket.getOutputStream().write("上传成功".getBytes()); fos.close(); socket.close(); server.close(); &#125; &#125; 多线程上传案例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152*A:多线程上传案例 public class TCPThreadServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket server = new ServerSocket(8000); while (true) &#123; // 获取到一个客户端,必须开启新线程,为这个客户端服务 Socket socket = server.accept(); new Thread(new Upload(socket)).start(); &#125; &#125; &#125; public class Upload implements Runnable &#123; private Socket socket; public Upload(Socket socket) &#123; this.socket = socket; &#125; public void run() &#123; try &#123; // 通过客户端连接对象,获取字节输入流,读取客户端图片 InputStream in = socket.getInputStream(); // 将目的文件夹封装到File对象 File upload = new File("d:\\upload"); if (!upload.exists()) upload.mkdirs(); // 防止文件同名被覆盖,从新定义文件名字 // 规则: 域名+毫秒值+6位随机数 String filename = "itcast" + System.currentTimeMillis() + new Random().nextInt(999999) + ".jpg"; // 创建字节输出流,将图片写入到目的文件夹中 FileOutputStream fos = new FileOutputStream(upload + File.separator + filename); // 读写字节数组 byte[] bytes = new byte[1024]; int len = 0; while ((len = in.read(bytes)) != -1) &#123; fos.write(bytes, 0, len); &#125; // 通过客户端连接对象获取字节输出流 // 上传成功写回客户端 socket.getOutputStream().write("上传成功".getBytes()); fos.close(); socket.close(); &#125; catch (Exception ex) &#123; &#125; &#125; &#125; 总结 IP地址：用来唯一表示我们自己的电脑的，是一个网络标示 端口号： 用来区别当前电脑中的应用程序的 UDP: 传送速度快，但是容易丢数据，如视频聊天，语音聊天 TCP: 传送稳定，不会丢失数据，如文件的上传、下载 UDP程序交互的流程 发送端1,创建DatagramSocket对象2，创建DatagramPacket对象，并封装数据3，发送数据4，释放流资源 接收端1,创建DatagramSocket对象2,创建DatagramPacket对象3,接收数据存储到DatagramPacket对象中4,获取DatagramPacket对象的内容 5,释放流资源 TCP程序交互的流程 客户端1,创建客户端的Socket对象2,获取Socket的输出流对象3,写数据给服务器4,获取Socket的输入流对象5，使用输入流，读反馈信息6,关闭流资源 服务器端1，创建服务器端ServerSocket对象，指定服务器端端口号2，开启服务器，等待着客户端Socket对象的连接，如有客户端连接，返回客户端的Socket对象3,通过客户端的Socket对象，获取客户端的输入流，为了实现获取客户端发来的数据4,通过客户端的输入流，获取流中的数据5,通过客户端的Socket对象，获取客户端的输出流，为了实现给客户端反馈信息6,通过客户端的输出流，写数据到流中7,关闭流资源]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础29(数据库表项目基础练习)]]></title>
    <url>%2F2016%2F11%2F30%2Fday31%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、管家婆家庭记账项目2、熟练View层、Service层、Dao层之间的方法相互调用操作3、熟练dbutils操作数据库表完成增删改查 01项目训练目标 A: 项目训练目标 a: 项目目标 综合运用前面所学习的知识点 熟练View层、Service层、Dao层之间的方法相互调用操作、 熟练dbutils操作数据库表完成增删改查 了解公司项目开发的流程，充分的掌握项目需求分析、设计与功能的代码实现。提高同学们独立分析需求与功能实现的能力。 02项目中的功能模块 A: 项目中的功能模块 a: 五大模块 查询账务 多条件组合查询账务 添加账务 编辑账务 删除账务03技术的选择和相关jar包 A: 技术的选择和相关jar包 a: apache的commons组件：….. commons-dbutils-1.4.jar：封装并简化了JDBC；….. commons-dbcp-1.4.jar：apache commons提供的数据库连接池组件，命名为DBCP； b:….. commons.pool-1.3.jar：DBCP连接池依赖该jar包；….. mysql-connector-java-5.1.28-bin.jar：MySQL的JDBC驱动包，用JDBC连接MySQL数据库必须使用该JAR包。 04项目中的工具类 A: 项目中的工具类 a: 工具类的介绍 每个项目中都会有很多个工具类，不要求每个工具类对能独立写出来，但是要会使用工具类 JDBCUtils：用来创建数据库连接池对象 123456789101112131415161718192021222324252627282930public class JDBCUtils &#123; private static BasicDataSource datasource =new BasicDataSource(); static &#123; //1.注册驱动, 将驱动类加入到内容 String drivername="com.mysql.jdbc.Driver"; //2.获得数据库连接 DriverManager类中静态方法 //static Connection getConnection(String url, String user, String password) //返回值是Connection接口的实现类,在mysql驱动程序 //url: 数据库地址 jdbc:mysql://连接主机IP:端口号/数据库名字 String url="jdbc:mysql://localhost:3306/qjunbase"; String username = "root"; String password = "root"; datasource.setDriverClassName(drivername); datasource.setUrl(url); datasource.setUsername(username); datasource.setPassword(password); //对象连接池中的连接数量配置,可选的 datasource.setInitialSize(10); datasource.setMaxActive(8); datasource.setMaxIdle(5); datasource.setMinIdle(1); &#125; public static DataSource getDataSource()&#123; return datasource; &#125;&#125; 05数据表的设计 A: 数据表的设计 a: 数据表的设计 表与表之间是有关系的 主表和从表的关系 主表中的主键作为从表中的外键 06创建数据库数据表写入测试数据12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152* A: 创建数据库数据表写入测试数据* a: 创建数据库数据表/*创建管家婆的数据库名字 gjp*/CREATE DATABASE gjp;USE gjp;/*创建数据表,表名账务字段,列主键分类名称 可变字符金额 double账户 可变字符 (支付,收入方法)创建日期 date账务描述 可变字符*/CREATE TABLE gjp_zhangwu(-- 主键zwid INT PRIMARY KEY AUTO_INCREMENT,-- 分类名称 flname VARCHAR(200),-- 金额money DOUBLE,-- 账户zhanghu VARCHAR(100),-- 创建日期createtime DATE,-- 账务描述description VARCHAR(1000));SELECT * FROM gjp_zhangwu;* b: 写入数据-- 写入测试的数据INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (1,'吃饭支出',247,'交通银行','2016-03-02','家庭聚餐');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (2,'工资收入',12345,'现金','2016-03-15','开工资了');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (3,'服装支出',1998,'现金','2016-04-02','买衣服');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (4,'吃饭支出',325,'现金','2016-06-18','朋友聚餐');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (5,'股票收入',8000,'工商银行','2016-10-28','股票大涨');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (6,'股票收入',5000,'工商银行','2016-10-28','股票又大涨');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (7,'工资收入',5000,'交通银行','2016-10-28','又开工资了');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (8,'礼金支出',5000,'现金','2016-10-28','朋友结婚');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (9,'其他支出',1560,'现金','2016-10-29','丢钱了');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (10,'交通支出',2300,'交通银行','2016-10-29','油价还在涨啊');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (11,'吃饭支出',1000,'工商银行','2016-10-29','又吃饭');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (12,'工资收入',1000,'现金','2016-10-30','开资');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (13,'交通支出',2000,'现金','2016-10-30','机票好贵');INSERT INTO gjp_zhangwu(zwid,flname,money,zhangHu,createtime,description) VALUES (14,'工资收入',5000,'现金','2016-10-30','又开资'); 07项目中的分层设计 A: 项目中的分层设计 a: 各层功能介绍….. view层作用: 视图层,即项目中的界面….. controller层作用: 控制层, 获取界面上的数据,为界面设置数据; 将要实现的功能交给业务层处理….. service层作用: 业务层, 功能的实现, 与controller控制层和数据访问层DAO交互, 将对数据库的操作交给DAO数据访问层来处理….. dao层作用: 数据访问层, 用来操作数据库表的数据 ……. database数据库: 这里指MySQL……. domain 实体包: 存放JavaBean……. tools工具包:存放项目中使用到的工具类……. test 测试包: 存放项目功能测试的代码 08创建项目_分层_导入jar包12345678910111213141516* A: 创建项目_分层_导入jar包* a: 创建工程包* cn.itcast.gjp.app: 存放main方法类；* cn.itcast.gjp.domain: 存放JavaBean；* cn.itcast.gjp.view: 存放界面，及表现层类；* cn.itcast.gjp.service: 存放业务层类；* cn.itcast.gjp.dao: 存放数据访问层类;* cn.itcast.gjp.tools:存放工具类* b: 导入jar包* 在项目根路径下建立文件夹lib* 导入以下jar包* mysql-connector-java-5.1.37-bin.jar：数据库驱动* commons-dbutils-1.6.jar：提供QueryRunner类方便进行增删改查操作* commons-dbcp-1.4.jar：* commons-pool-1.5.6.jar：提供高效的数据库连接池技术 * 拷贝以上jar包，选定拷贝的jar包/右键/Build Path/Add to Build Path 首先，完成本项目中类的创建: 复制已编写好的工具类JDBCUtils.java 到 tools包中； 复制jar包mysql-connector-java-5.1.28-bin.jar、commons-dbutils-1.4.jar、commons-dbcp-1.4.jar、commons-pool-1.3.jar，到lib文件夹中，通过Build Path操作，添加到classPath路径中，提供给JDBCUtils使用; 在app包中，创建类MainApp.java，编写main主方法，用来完成本项目的启动 在domain包中，创建类ZhangWu.java，它是用来封装账务信息的JavaBean。 在dao包中，创建类ZhangWuDao.java，给ZhangWuDao类添加一个成员变量QueryRunner对象，因为我们使用dbutils来操作数据库。 在service包中，创建类ZhangWuService.java，给ZhangWuService类添加一个类型为ZhangWuDao的成员变量，因为service依赖dao。 在view包中，创建类MainView.java，给MainView类添加一个类型为ZhangWuService的成员变量，因为本项目中view依赖service。 09创建domain包中的类12345678910111213141516* A: 创建domain包中的类* a: 案例代码public class ZhangWu &#123; private int zwid; private String flname; private double money; private String zhanghu; private String createtime; private String description; //注意生成空参构造、有参构造、set和get方法、toString方法等&#125; 10创建JDBCUtils工具类1234567891011121314151617181920* A：创建JDBCUtils工具类* a: 案例代码public class JDBCUtils&#123;//创建BasicDataSource对象private static BasicDataSource datasource = new BasicDataSource();//静态代码块,实现必要参数设置static&#123; datasource.setDriverClassName("com.mysql.jdbc.Driver"); datasource.setUrl("jdbc:mysql://localhost:3306/gjp"); datasource.setUsername("root"); datasource.setPassword("123"); datasource.setMaxActive(10); datasource.setMaxIdle(5); datasource.setMinIdle(2); datasource.setInitialSize(10);&#125;public static DataSource getDataSource()&#123; return datasource;&#125;&#125; 11创建其他包中的类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152* A: 创建其他包中的类* a: cn.itcast.gjp.dao包中"创建ZhangWuDao类""/** 实现对数据表 gjp_zhangwu 数据增删改查操作* dbuils工具类完成,类成员创建QueryRunner对象,指定数据源*/"public class ZhangWuDao &#123;private QueryRunner qr = new QueryRunner(JDBCUtils.getDataSource());&#125;——————————————————————————————————————————————————————————————————————————————————————* b: cn.itcast.gjp.service包中"创建ZhangWuService类""/** 业务层类* 接收上一层,控制层controller的数据* 经过计算,传递给dao层,操作数据库* 调用dao层中的类,类成员位置,创建Dao类的对象*/"public class ZhangWuService &#123;private ZhangWuDao dao = new ZhangWuDao();&#125;——————————————————————————————————————————————————————————————————————————————————————* c: cn.itcast.gjp.controller包中"建立ZhangWuController类""/** 控制器层* 接收视图层的数据,数据传递给service层* 成员位置,创建service对象*/"public class ZhangWuController &#123;private ZhangWuService service = new ZhangWuService(); &#125;——————————————————————————————————————————————————————————————————————————————————————* d: cn.itcast.gjp.view包中"建立MainView类""/** 试图层,用户看到和操作的界面* 数据传递给controller层实现* 成员位置,创建controller对象*/"public class MainView &#123;private ZhangWuController controller = new ZhangWuController();&#125;——————————————————————————————————————————————————————————————————————————————————————* e: cn.itcast.gjp.app包中"建立MainApp类""/** 主程序类,作用,开启软件程序*/"public class MainApp &#123;public static void main(String[] args) &#123; new MainView().run();&#125;&#125; 12实现用户的界面菜单1234567891011121314151617181920212223242526272829303132333435363738* A: 实现用户的界面菜单* a: 案例核心代码* cn.itcast.gjp.view包中建立MainView类中添加run方法/** 实现界面效果* 接收用户的输入* 根据数据,调用不同的功能方法*/public void run()&#123;//创建Scanner类对象,反复键盘输入Scanner sc = new Scanner(System.in);while(true)&#123; System.out.println("---------------管家婆家庭记账软件---------------"); System.out.println("1.添加账务 2.编辑账务 3.删除账务 4.查询账务 5.退出系统"); System.out.println("请输入要操作的功能序号[1-5]:"); //接收用户的菜单选择 int choose = sc.nextInt(); //对选择的菜单判断,调用不同的功能 switch(choose)&#123; case 1: // 选择添加账务,调用添加账务的方法 break; case 2: // 选择的编辑账务,调用编辑账务方法 break; case 3: // 选择的删除账务,调用删除账务方法 break; case 4: // 选择的是查询账务,调用查询方法 //selectZhangWu(); break; case 5: System.exit(0); break; &#125;&#125;&#125; 13实现查询的界面菜单1234567891011121314151617181920212223242526272829303132333435363738394041* A: 实现查询的界面菜单* a: 案例核心代码* cn.itcast.gjp.view包中建立MainView类中添加selectZhangWu方法、selectAll方法、select方法/* * 定义方法 selectZhangWu() * 显示查询的方式 1 所有查询 2 条件查询 * 接收用户的选择 */ public void selectZhangWu()&#123; System.out.println("1. 查询所有 2. 条件查询"); Scanner sc = new Scanner(System.in); int selectChooser = sc.nextInt(); //判断根据用户的选择,调用不同的功能 switch(selectChooser)&#123; case 1: //选择的查询所有,调用查询所有的方法 selectAll(); break; case 2: //选的条件查询,调用带有查询条件的方法 select(); break; &#125; &#125; /* * 定义方法,实现查询所有的账务数据 */ public void selectAll()&#123; &#125; /* * 定义方法,实现条件查询账务数据 * 提供用户的输入日期,开始日期结束日期 * 就2个日期,传递到controller层 * 调用controller的方法,传递2个日期参数 * 获取到controller查询的结果集,打印出来 */ public void select()&#123; &#125; 14实现查询所有账务的控制,业务层的实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556* A: 实现查询所有账务的控制,业务层的实现* a: 案例核心代码* a: cn.itcast.gjp.dao包中创建ZhangWuDao类/** 实现对数据表 gjp_zhangwu 数据增删改查操作* dbuils工具类完成,类成员创建QueryRunner对象,指定数据源*/public class ZhangWuDao &#123;private QueryRunner qr = new QueryRunner(JDBCUtils.getDataSource());/* * 定义方法,查询数据库,获取所有的账务数据 * 方法,由业务层调用 * 结果集,将所有的账务数据,存储到Bean对象中,存储到集合中 */public List&lt;ZhangWu&gt; selectAll()&#123; return null;&#125;&#125;————————————————————————————————————————————————————————————————————————————————————* b: cn.itcast.gjp.service包中创建ZhangWuService类/* * 业务层类 * 接收上一层,控制层controller的数据 * 经过计算,传递给dao层,操作数据库 * 调用dao层中的类,类成员位置,创建Dao类的对象 */public class ZhangWuService &#123; private ZhangWuDao dao = new ZhangWuDao(); /* * 定义方法,实现查询所有的账务数据 * 此方法,由控制层调用, 去调用dao层的方法 * 返回存储ZhangWu对象的List集合 */ public List&lt;ZhangWu&gt; selectAll()&#123; return dao.selectAll(); &#125;&#125;————————————————————————————————————————————————————————————————————————————————————* c: cn.itcast.gjp.controller包中建立ZhangWuController类/* * 控制器层 * 接收视图层的数据,数据传递给service层 * 成员位置,创建service对象 */public class ZhangWuController &#123; private ZhangWuService service = new ZhangWuService(); /* * 控制层类定义方法,实现查询所有的账务数据 * 本方法由视图层调用,本方法调用service层 */ public List&lt;ZhangWu&gt; selectAll()&#123; return service.selectAll(); &#125; &#125; 15实现查询所有账务的dao层的实现123456789101112131415161718192021222324252627* A: 实现查询所有账务的dao层的实现* a: 案例核心代码* a: cn.itcast.gjp.dao包中创建ZhangWuDao类selectAll方法/** 实现对数据表 gjp_zhangwu 数据增删改查操作* dbuils工具类完成,类成员创建QueryRunner对象,指定数据源*/public class ZhangWuDao &#123;private QueryRunner qr = new QueryRunner(JDBCUtils.getDataSource());/* * 定义方法,查询数据库,获取所有的账务数据 * 方法,由业务层调用 * 结果集,将所有的账务数据,存储到Bean对象中,存储到集合中 */public List&lt;ZhangWu&gt; selectAll()&#123; try&#123; //查询账务数据的SQL语句 String sql = "SELECT * FROM gjp_zhangwu"; //调用qr对象的方法,query方法,结果集BeanListHandler List&lt;ZhangWu&gt; list = qr.query(sql, new BeanListHandler&lt;&gt;(ZhangWu.class)); return list; &#125;catch(SQLException ex)&#123; System.out.println(ex); throw new RuntimeException("查询所有账务失败"); &#125;&#125;&#125; 16实现查询所有账务的view层的实现1234567891011121314151617* A: 实现查询所有账务的view层的实现* a: 案例核心代码* cn.itcast.gjp.view包中建立MainView类selectAll方法/** 定义方法,实现查询所有的账务数据*/public void selectAll()&#123; //调用控制层中的方法,查询所有的账务数据 List&lt;ZhangWu&gt; list = controller.selectAll();//输出表头 System.out.println("ID\t\t类别\t\t账户\t\t金额\t\t时间\t\t说明"); //遍历集合,结果输出控制台 for(ZhangWu zw : list)&#123; System.out.println(zw.getZwid()+"\t\t"+zw.getFlname()+"\t\t"+zw.getZhanghu()+"\t\t"+ zw.getMoney()+"\t\t"+zw.getCreatetime()+"\t"+zw.getDescription()); &#125;&#125; 17实现条件查询账务的菜单实现1234567891011121314151617181920* A: 实现条件查询账务的菜单实现* a: 案例核心代码* cn.itcast.gjp.view包中建立MainView类select方法/** 定义方法,实现条件查询账务数据* 提供用户的输入日期,开始日期结束日期* 就2个日期,传递到controller层* 调用controller的方法,传递2个日期参数* 获取到controller查询的结果集,打印出来*/public void select()&#123; System.out.println("选择条件查询,输入日期格式XXXX-XX-XX"); Scanner sc = new Scanner(System.in); System.out.print("请输入开始日期:"); String startDate = sc.nextLine(); System.out.print("请输入结果日期:"); String endDate = sc.nextLine(); //调用controller层的方法,传递日期,获取查询结果集 &#125; 18实现条件查询账务的控制层,业务层实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859* A: 实现条件查询账务的控制层,业务层实现* a: 案例核心代码* a: cn.itcast.gjp.dao包中创建ZhangWuDao类/* * 实现对数据表 gjp_zhangwu 数据增删改查操作 * dbuils工具类完成,类成员创建QueryRunner对象,指定数据源 */public class ZhangWuDao &#123; private QueryRunner qr = new QueryRunner(JDBCUtils.getDataSource()); /* * 定义方法,查询数据库,带有条件去查询账务表 * 由业务层调用,查询结果集存储到Bean对象,存储到List集合 * 调用者传递2个日期字符串 */ public List&lt;ZhangWu&gt; select(String startDate,String endDate)&#123; return null; &#125;&#125;————————————————————————————————————————————————————————————————————————————————————* b: cn.itcast.gjp.service包中创建ZhangWuService类/* * 业务层类 * 接收上一层,控制层controller的数据 * 经过计算,传递给dao层,操作数据库 * 调用dao层中的类,类成员位置,创建Dao类的对象 */public class ZhangWuService &#123; private ZhangWuDao dao = new ZhangWuDao(); /* * 定义方法,实现条件查询账务 * 方法由控制层调用,传递2个日期字符串 * 调用dao层的方法,传递2个日期字符串 * 获取到查询结果集 */ public List&lt;ZhangWu&gt; select(String startDate,String endDate)&#123; return dao.select(startDate, endDate); &#125;&#125;————————————————————————————————————————————————————————————————————————————————————* c: cn.itcast.gjp.controller包中建立ZhangWuController类/* * 控制器层 * 接收视图层的数据,数据传递给service层 * 成员位置,创建service对象 */public class ZhangWuController &#123; private ZhangWuService service = new ZhangWuService(); /* * 定义方法,实现条件查询账务 * 方法由试图层调用,传递两个日期的字符串 * 调用service层的方法,传递两个日期字符串,获取结果集 * 结果集返回给试图 */ public List&lt;ZhangWu&gt; select(String startDate,String endDate)&#123; return service.select(startDate, endDate); &#125; &#125; 19实现条件查询账务的dao层实现12345678910111213141516171819202122232425262728* A: 实现条件查询账务的dao层实现* a: 案例核心代码* a: cn.itcast.gjp.dao包中创建ZhangWuDao类select方法/* * 实现对数据表 gjp_zhangwu 数据增删改查操作 * dbuils工具类完成,类成员创建QueryRunner对象,指定数据源 */public class ZhangWuDao &#123; private QueryRunner qr = new QueryRunner(JDBCUtils.getDataSource()); /* * 定义方法,查询数据库,带有条件去查询账务表 * 由业务层调用,查询结果集存储到Bean对象,存储到List集合 * 调用者传递2个日期字符串 */ public List&lt;ZhangWu&gt; select(String startDate,String endDate)&#123; try&#123; //拼写条件查询的SQL语句 String sql = "SELECT * FROM gjp_zhangwu WHERE createtime BETWEEN ? AND ?"; //定义对象数组,存储?占位符 Object[] params = &#123;startDate,endDate&#125;; //调用qr对象的方法query查询数据表,获取结果集 return qr.query(sql, new BeanListHandler&lt;&gt;(ZhangWu.class),params); &#125;catch(SQLException ex)&#123; System.out.println(ex); throw new RuntimeException("条件查询失败"); &#125; &#125;&#125; 20实现条件查询账务的view层实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647* A: 实现条件查询账务的view层实现* a: 案例核心代码* cn.itcast.gjp.view包中建立MainView类selectAll方法优化、抽取print方法、select方法/** 定义方法,实现查询所有的账务数据*/public void selectAll()&#123; //调用控制层中的方法,查询所有的账务数据 List&lt;ZhangWu&gt; list = controller.selectAll(); if(list.size()!=0) print(list); else System.out.println("没有查询到数据");&#125;/** 定义方法,实现条件查询账务数据* 提供用户的输入日期,开始日期结束日期* 就2个日期,传递到controller层* 调用controller的方法,传递2个日期参数* 获取到controller查询的结果集,打印出来*/public void select()&#123; System.out.println("选择条件查询,输入日期格式XXXX-XX-XX"); Scanner sc = new Scanner(System.in); System.out.print("请输入开始日期:"); String startDate = sc.nextLine(); System.out.print("请输入结果日期:"); String endDate = sc.nextLine(); //调用controller层的方法,传递日期,获取查询结果集 List&lt;ZhangWu&gt; list = controller.select(startDate, endDate); if(list.size()!=0) print(list); else System.out.println("没有查询到数据");&#125;//输出账务数据方法,接收List集合,遍历集合,输出表格private void print(List&lt;ZhangWu&gt; list) &#123; //输出表头 System.out.println("ID\t\t类别\t\t账户\t\t金额\t\t时间\t\t说明"); //遍历集合,结果输出控制台 for(ZhangWu zw : list)&#123; System.out.println(zw.getZwid()+"\t\t"+zw.getFlname()+"\t\t"+zw.getZhanghu()+"\t\t"+ zw.getMoney()+"\t\t"+zw.getCreatetime()+"\t"+zw.getDescription()); &#125;&#125; 21添加账务功能分析 A: 添加账务功能分析 a: 编写MainView类中addZhangWu方法….. 键盘输入新添加的账务信息….. 调用ZhangWuService类中addZhangWu方法，用来指定账务的添加…..* 添加完毕后，使用输出语句，提示“添加账务成功！” b: 编写ZhangWuService类中addZhangWu方法…..* 调用ZhangWuDao类中addZhangWu方法，用来指定账务的添加 c: 编写ZhangWuDao类中addZhangWu方法…..* 通过QueryRunner对象，调用update方法更新数据库表gjp_zhangwu，完成指定账务添加到数据库表中 22添加账务功能菜单和输入功能实现12345678910111213141516171819202122232425* A: 添加账务功能菜单和输入功能实现 * a: 案例核心代码* cn.itcast.gjp.view包中建立MainView类addZhangWu方法/** 定义方法addZhangWu* 添加账务的方法，用户在界面中选择菜单1的时候调用、* 实现思想：* 接收键盘输入，5项输入，调用controller层方法*/public void addZhangWu() &#123; System.out.println("选择的添加账务功能，请输入以下内容"); Scanner sc = new Scanner(System.in); System.out.println("输入分类名称"); String flname = sc.next(); System.out.println("输入金额"); double money = sc.nextDouble(); System.out.println("输入账户"); String zhanghu = sc.next(); System.out.println("输入日期：格式XXXX-XX-xx"); String createtime = sc.next(); System.out.println("输入具体描述"); String description = sc.next(); //将接收到的数据，调用controller层的方法，传递参数，实现数据添加&#125; 23添加账务功能控制层,业务层实现123456789101112131415161718192021222324252627282930313233* A: 添加账务功能控制层,业务层实现* a: 案例核心代码* cn.itcast.gjp.controller包中的ZhangWuController类addZhangWu方法/* * 定义方法，实现账务添加功能 * 由视图层调用，传递参数(传递过来的参数不能是5个数据，传递的是一个ZhangWu类型的对象) * 本方法调用service层的方法，传递ZhangWu对象，获取到添加后的结果集(添加成功影响的行数，int) * */public void addZhangWu(ZhangWu zw) &#123; service.addZhangWu(zw);&#125;——————————————————————————————————————————————————————————————————————————————————————* cn.itcast.gjp.service包中的ZhangWuService类addZhangWu方法/* * 定义方法，实现添加账务 * 是由控制层调用，传递ZhangWu对象 */public void addZhangWu(ZhangWu zw) &#123; dao.addZhangWu(zw);&#125;——————————————————————————————————————————————————————————————————————————————————————* cn.itcast.gjp.dao包中的ZhangWuDao类addZhangWu方法/* * 定义方法，实现添加账务功能 * 由业务层调用，传递ZhangWu对象 * 将ZhangWu对象中的数据，添加到数据库 */public void addZhangWu(ZhangWu zw) &#123; &#125; 24添加账务功能dao层实现1234567891011121314151617* A: 添加账务功能dao层实现* a: 案例核心代码 * cn.itcast.gjp.dao包中的ZhangWuDao类的addZhangWu方法public void addZhangWu(ZhangWu zw) &#123; try&#123; //拼接添加数据的sql String sql = "INSERT INTO gjp_zhangwu (flname,money,zhanghu,createtime,description) VALUES(?,?,?,?,?)"; //创建对象数组，处处5个占位符的实际参数 //实际参数来源是传递过来的对象ZhangWu Object[] params = &#123;zw.getFlname(),zw.getMoney(),zw.getZhanghu(),zw.getCreatetime(),zw.getDescription()&#125;; //调用qr对象中的方法update执行添加 qr.update(sql, params); &#125;catch(SQLException ex) &#123; System.out.println(ex); throw new RuntimeException("账务添加失败"); &#125;&#125; 25添加账务功能view层实现12345678910111213141516171819202122* A: 添加账务功能view层实现* a: 案例核心代码* cn.itcast.gjp.view包中建立MainView类addZhangWu方法public void addZhangWu() &#123; System.out.println("选择的添加账务功能，请输入以下内容"); Scanner sc = new Scanner(System.in); System.out.println("输入分类名称"); String flname = sc.next(); System.out.println("输入金额"); double money = sc.nextDouble(); System.out.println("输入账户"); String zhanghu = sc.next(); System.out.println("输入日期：格式XXXX-XX-xx"); String createtime = sc.next(); System.out.println("输入具体描述"); String description = sc.next(); //将接收到的数据，调用controller层的方法，传递参数，实现数据添加 //将用户输入的所有参数，封装成ZhangWu对象 ZhangWu zw = new ZhangWu(0, flname, money, zhanghu, createtime, description); controller.addZhangWu(zw); System.out.println("恭喜添加账务成功");&#125; 26编辑账务功能分析 A: 编辑账务功能分析 a: 编写MainView类中editZhangWu方法….. 键盘输入要编辑的账务信息ID号….. 键盘输入要修改的账务信息内容….. 调用ZhangWuService类中editZhangWu方法，用来将指定的账务信息进行更新….. 更新完毕后，使用输出语句，提示 “编辑账务成功！” b: 编写ZhangWuService类中editZhangWu方法…..* 调用ZhangWuDao类中editZhangWu方法，用来将指定的账务信息进行更新 c: 编写ZhangWuDao类中editZhangWu方法…..* 通过QueryRunner对象，调用update方法更新数据库表gjp_zhangwu，完成数据库表中指定账务更新操作 27编辑账务功能功能之前实现查询所有1234567891011* A: 编辑账务功能功能之前实现查询所有* a: 案例核心代码* cn.itcast.gjp.view包中建立MainView类editZhangWu方法public void editZhangWu() &#123; //调用查询所有账务数据的功能，显示出来 //看到所有数据，从中选择一项，进行修改 selectAll(); System.out.println("选择的是编辑功能，请输入数据"); &#125; 28编辑账务功能菜单实现1234567891011121314151617181920212223242526* A: 编辑账务功能菜单实现* a: 案例核心代码* cn.itcast.gjp.view包中建立MainView类editZhangWu方法public void editZhangWu() &#123; //调用查询所有账务数据的功能，显示出来 //看到所有数据，从中选择一项，进行修改 selectAll(); System.out.println("选择的是编辑功能，请输入数据"); Scanner sc = new Scanner(System.in); System.out.print("请输入ID"); int zwid = sc.nextInt(); System.out.println("输入分类名称"); String flname = sc.next(); System.out.println("输入金额"); double money = sc.nextDouble(); System.out.println("输入账户"); String zhanghu = sc.next(); System.out.println("输入日期：格式XXXX-XX-xx"); String createtime = sc.next(); System.out.println("输入具体描述"); String description = sc.next(); //将用户输入的数据，封装到ZhangWu对象中 //用户输入的ID，必须封装到到对象中 ZhangWu zw = new ZhangWu(zwid, flname, money, zhanghu, createtime, description); //调用controller层中的方法，实现编辑账务&#125; 29编辑账务功能控制层,业务层实现12345678910111213141516171819202122232425* A: 编辑账务功能控制层,业务层实现* a: 案例核心代码* cn.itcast.gjp.controller包中的ZhangWuController类editZhangWu方法/* * 定义方法，实现编辑账务功能 * 由视图层调用，传递参数，也是ZhangWu对象 * 调用service层的方法，也是ZhangWu对象 */public void editZhangWu(ZhangWu zw) &#123; service.editZhangWu(zw);&#125;* cn.itcast.gjp.service包中的ZhangWuService类editZhangWu方法/* * 定义方法，实现编辑账务 * 由控制层调用，传递ZhangWu对象 * 调用dao层的方法，传递ZhangWu对象 */public void editZhangWu(ZhangWu zw) &#123; dao.editZhangWu(zw);&#125;* cn.itcast.gjp.dao包中的ZhangWuDao类editZhangWu方法public void editZhangWu(ZhangWu zw) &#123; // TODO Auto-generated method stub &#125; 30编辑账务功能dao层实现12345678910111213141516171819202122* A：编辑账务功能dao层实现* a: 案例核心代码* cn.itcast.gjp.dao包中的ZhangWuDao类editZhangWu方法/* * 定义方法，实现编辑功能 * 由业务层调用，传递ZhangWu对象 * 将对象中的数据，更新到数据表 */public void editZhangWu(ZhangWu zw) &#123; try &#123; //更新数据的SQL String sql = "UPDATE zhangwu SET flname=?,money=?,zhanghu=?,createtime=?,description=? WHERE zwid=?"; //定义对象数组，封装所有数据 Object[] params = &#123;zw.getFlname(),zw.getMoney(),zw.getZhanghu(),zw.getCreatetime(),zw.getDescription(),zw.getZwid()&#125;; //调用qr对象方法update执行更新 qr.update(sql, params); &#125; catch (SQLException ex) &#123; System.out.println(ex); throw new RuntimeException("编辑账务失败"); &#125; &#125; 31编辑账务功能view层实现123456789101112131415161718192021222324252627282930313233343536* A: 编辑账务功能view层实现* a: 案例核心代码* cn.itcast.gjp.view包中建立MainView类editZhangWu方法/* * 定义方法，实现对账务的编辑功能 * 实现思想： * 接收用户的输入的信息 * 封装成ZhangWu对象 * 调用控制层的方法，传递ZhangWu对象，实现编辑 * */public void editZhangWu() &#123; //调用查询所有账务数据的功能，显示出来 //看到所有数据，从中选择一项，进行修改 selectAll(); System.out.println("选择的是编辑功能，请输入数据"); Scanner sc = new Scanner(System.in); System.out.print("请输入ID"); int zwid = sc.nextInt(); System.out.println("输入分类名称"); String flname = sc.next(); System.out.println("输入金额"); double money = sc.nextDouble(); System.out.println("输入账户"); String zhanghu = sc.next(); System.out.println("输入日期：格式XXXX-XX-xx"); String createtime = sc.next(); System.out.println("输入具体描述"); String description = sc.next(); //将用户输入的数据，封装到ZhangWu对象中 //用户输入的ID，必须封装到到对象中 ZhangWu zw = new ZhangWu(zwid, flname, money, zhanghu, createtime, description); //调用controller层中的方法，实现编辑账务 controller.editZhangWu(zw); System.out.println("账务编辑成功");&#125; 32删除账务功能分析 A: 删除账务功能分析 a: 编写MainView类中deleteZhangWu方法….. 键盘输入要删除的账务信息ID号….. 调用ZhangWuService类中deleteZhangWu方法，用来将指定的账务信息删除…..* 删除完毕后，使用输出语句，提示 “删除账务成功！” b: 编写ZhangWuService类中deleteZhangWu方法…..* 调用ZhangWuDao类中deleteZhangWu方法，用来将指定的账务信息删除 c: 编写ZhangWuDao类中deleteZhangWu方法…..* 通过QueryRunner对象，调用update方法更新数据库表gjp_zhangwu，完成数据库表中指定账务删除操作 33删除账务功能菜单实现1234567891011121314151617* A: 删除账务功能菜单实现* a: 案例核心代码* cn.itcast.gjp.view包中建立MainView类deleteZhangWu方法/* * 定义方法，实现账务删除 * 实现思想： * 接收用户的输入，输入一个主键数据 * 调用控制层方法，传递一个主键 */public void deleteZhangWu() &#123; //调用查询所有账务数据的功能，显示出来 //看到所有数据，从中选择一项，进行修改 selectAll(); System.out.println("选择的是删除功能，请输入序号即可"); int zwid = new Scanner(System.in).nextInt(); //调用控制层方法，传递主键id即可&#125; 34删除账务功能控制层,业务层实现123456789101112131415161718192021222324* A: 删除账务功能控制层,业务层实现* a: 案例核心代码* cn.itcast.gjp.controller包中的ZhangWuController类deleteZhangWu方法/* * 定义方法，实现删除功能 * 视图层调用，传递int类型主键 * 调用service层方法，传递int主键 */public void deleteZhangWu(int zwid) &#123; service.deleteZhangWu(zwid);&#125;* cn.itcast.gjp.service包中的ZhangWuService类deleteZhangWu方法/* * 定义方法，实现删除账务功能 * 由控制层调用，传递主键id * 调用dao层方法，传递主键id */public void deleteZhangWu(int zwid) &#123; dao.deleteZhangWu(zwid);&#125;* cn.itcast.gjp.dao包中的ZhangWuDao类deleteZhangWu方法public void deleteZhangWu(int zwid) &#123;&#125; 35删除账务功能dao实现1234567891011121314151617* A: 删除账务功能dao实现* a: 案例核心代码* cn.itcast.gjp.dao包中的ZhangWuDao类deleteZhangWu方法/* * 定义方法，实现删除业务 * 业务层调用，传递主键id */public void deleteZhangWu(int zwid) &#123; try &#123; //拼写删除数据SQL String sql = "DELETE FROM gjp_zhangwu WHERE zwid=?"; qr.update(sql, zwid); &#125; catch (SQLException ex) &#123; System.out.println(ex); throw new RuntimeException("删除账务失败"); &#125;&#125; 36删除账务功能view层实现123456789101112131415161718* A: 删除账务功能view层实现* a: 案例核心代码* cn.itcast.gjp.view包中建立MainView类editZhangWu方法/* * 定义方法，实现账务删除 * 实现思想： * 接收用户的输入，输入一个主键数据 * 调用控制层方法，传递一个主键 */public void deleteZhangWu() &#123; //调用查询所有账务数据的功能，显示出来 //看到所有数据，从中选择一项，进行修改 selectAll(); System.out.println("选择的是删除功能，请输入序号即可"); int zwid = new Scanner(System.in).nextInt(); //调用控制层方法，传递主键id即可 controller.deleteZhangWu(zwid); System.out.println("删除账务成功"); 37总结…..view层的作用是“界面”，用来完成数据显示给用户。当前项目view层中，包含了Controller层代码。…..Controller层的作用是“调度”，调度的是表现层view和业务层Service，主要功能分为：一是把表现层的数据交给业务层处理；二是把业务层返回的数据交给表现层显示。 …..Service层的作用是“业务”，我们也可以把“业务”当成是“功能”。今后要写的大型项目代码量最大的就是Service层。…..DAO层是操作数据库，现在我们使用的是commons-dbutils工具来简化JDBC，所以我们发现代码不多，比较简单。最后我们还会学习其他DAO层的工具，例如：hibernate和mybatis，他们都是JDBC的封装，用来简化JDBC。]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础28(DBUtils, DBCP连接池)]]></title>
    <url>%2F2016%2F11%2F29%2Fday30%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、DBUtils2、DBCP连接池 01DButils工具类的介绍个三个核心类 A: DButils工具类的介绍个三个核心类 a: 概述 DBUtils是java编程中的数据库操作实用工具，小巧简单实用。 DBUtils封装了对JDBC的操作，简化了JDBC操作，可以少写代码。 DBUtils就是JDBC的简化开发工具包。需要项目导入commons-dbutils-1.6.jar才能够正常使用DBUtils工具。 b: Dbutils三个核心功能介绍 QueryRunner中提供对sql语句操作的API.….. update(Connection conn, String sql, Object… params) ，用来完成表数据的增加、删除、更新操作….. query(Connection conn, String sql, ResultSetHandler rsh, Object… params) ，用来完成表数据的查询操作 ResultSetHandler接口，用于定义select操作后，怎样封装结果集. DbUtils类，它就是一个工具类,定义了关闭资源与事务处理的方法 02事务的简单介绍(此知识点后续详细介绍) A: 事务的简单介绍 03QueryRunner类的update方法介绍 A：QueryRunner类的update方法介绍 a: 方法介绍 update(Connection conn, String sql, Object… params) ，用来完成表数据的增加、删除、更新操作 使用QueryRunner类,实现对数据表的insert delete update 调用QueryRunner类的方法 update (Connection con,String sql,Object…param) Object…param 可变参数,Object类型,SQL语句会出现?占位符 数据库连接对象,自定义的工具类传递 123456 int update(Connection conn, String sql, Object... params) ，用来完成表数据的增加、删除、更新操作返回：成功操作的行数：The number of rows updated. &lt;T&gt; T query(Connection conn, String sql, ResultSetHandler&lt;T&gt; rsh, Object... params) ，用来完成表数据的查询操作 04QueryRunner类实现insert添加数据12345678910111213141516171819202122* A: QueryRunner类实现insert添加数据* a: 案例代码public class QueryRunnerDemo &#123; private static Connection con = JDBCUtilsConfig.getConnection(); public static void main(String[] args)throws SQLException &#123; insert(); &#125; /* * 定义方法,使用QueryRunner类的方法update向数据表中,添加数据 */ public static void insert()throws SQLException&#123; //创建QueryRunner类对象 QueryRunner qr = new QueryRunner(); String sql = "INSERT INTO sort (sname,sprice,sdesc)VALUES(?,?,?)"; //将三个?占位符的实际参数,写在数组中 Object[] params = &#123;"体育用品",289.32,"购买体育用品"&#125;; //调用QueryRunner类的方法update执行SQL语句 int row = qr.update(con, sql, params); System.out.println(row); DbUtils.closeQuietly(con); &#125;&#125; 05QueryRunner类实现update修改数据1234567891011121314151617181920212223* A: QueryRunner类实现update修改数据* a: 案例代码public class QueryRunnerDemo &#123; private static Connection con = JDBCUtilsConfig.getConnection(); public static void main(String[] args)throws SQLException &#123; update(); &#125; /* * 定义方法,使用QueryRunner类的方法update将数据表的数据修改 */ public static void update()throws SQLException&#123; //创建QueryRunner类对象 QueryRunner qr = new QueryRunner(); //写修改数据的SQL语句 String sql = "UPDATE sort SET sname=?,sprice=?,sdesc=? WHERE sid=?"; //定义Object数组,存储?中的参数 Object[] params = &#123;"花卉",100.88,"情人节玫瑰花",4&#125;; //调用QueryRunner方法update int row = qr.update(con, sql, params); System.out.println(row); DbUtils.closeQuietly(con); &#125; &#125; 06QueryRunner类实现delete删除数据123456789101112131415161718192021222324252627* A: QueryRunner类实现delete删除数据* a: 案例代码public class QueryRunnerDemo &#123; private static Connection con = JDBCUtilsConfig.getConnection(); public static void main(String[] args)throws SQLException &#123; delete(); &#125; /* * 定义方法,使用QueryRunner类的方法delete将数据表的数据删除 */ public static void delete()throws SQLException&#123; //创建QueryRunner类对象 QueryRunner qr = new QueryRunner(); //写删除的SQL语句 String sql = "DELETE FROM sort WHERE sid=?"; //调用QueryRunner方法update int row = qr.update(con, sql, 8); System.out.println(row); /* * 判断insert,update,delete执行是否成功 * 对返回值row判断 * if(row&gt;0) 执行成功 */ DbUtils.closeQuietly(con); &#125; &#125; 07JavaBean类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051* A: JavaBean类* a: 概念* JavaBean就是一个类，在开发中常用封装数据。具有如下特性 1. "需要实现接口：java.io.Serializable ，通常实现接口这步骤省略了，不会影响程序。" 2. 提供私有字段：private 类型 "字段名"; 3. "提供getter/setter方法：" 4. "提供无参构造"例如：/* * 账务类 */public class ZhangWu implements Serializable &#123; private int id; private String name; private double money; private String parent; public ZhangWu() &#123; super(); &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public double getMoney() &#123; return money; &#125; public void setMoney(double money) &#123; this.money = money; &#125; public String getParent() &#123; return parent; &#125; public void setParent(String parent) &#123; this.parent = parent; &#125; @Override public String toString() &#123; //该方法可以省略 return "ZhangWu [id=" + id + ", name=" + name + ", money=" + money + ", parent=" + parent + "]"; &#125;&#125; 08DBUtils工具类结果集处理的方式12345678910111213141516171819202122232425262728293031* A: DBUtils工具类结果集处理的方式* * a: QueryRunner实现查询操作* &lt;T&gt; T query(Connection conn, String sql, ResultSetHandler&lt;T&gt; rsh, Object... params) ，* 用来完成表数据的查询操作* b: ResultSetHandler结果集处理类* ArrayHandler * 将结果集中的第一条记录封装到一个Object[]数组中，数组中的每一个元素就是这条记录中的每一个字段的值* * ArrayListHandler * 将结果集中的每一条记录都封装到一个Object[]数组中，将这些数组在封装到List集合中。* * BeanHandler * 将结果集中第一条记录封装到一个指定的javaBean中。* * BeanListHandler * 将结果集中每一条记录封装到指定的javaBean中，将这些javaBean在封装到List集合中* * ColumnListHandler * 将结果集中指定的列的字段值，封装到一个List集合中* * ScalarHandler * 它是用于单数据。例如select count(*) from 表操作。* * MapHandler * 将结果集第一行封装到Map集合中,Key 列名, Value 该列数据* * MapListHandler * 将结果集第一行封装到Map集合中,Key 列名, Value 该列数据,Map集合存储到List集合 09QueryRunner类的方法query1234567891011* A: QueryRunner类的方法query* a: QueryRunner数据查询操作* 调用QueryRunner类方法：* &lt;T&gt; T query(Connection con,String sql,ResultSetHandler r, Object..params)* ResultSetHandler r 结果集的处理方式,传递ResultSetHandler接口实现类* Object..params SQL语句中的?占位符* 注意: query方法返回值,返回的是T 泛型, 具体返回值类型,跟随结果集处理方式变化;* b: 案例代码public class QueryRunnerDemo1 &#123; private static Connection con = JDBCUtilsConfig.getConnection();&#125; 10结果集处理ArrayHandler12345678910111213141516171819202122* A: 结果集处理ArrayHandler* 案例代码public class QueryRunnerDemo1 &#123; private static Connection con = JDBCUtilsConfig.getConnection(); public static void main(String[] args) throws SQLException&#123; arrayHandler(); &#125; "/* * 结果集第一种处理方法, ArrayHandler * 将结果集的第一行存储到对象数组中 Object[] */" public static void arrayHandler()throws SQLException&#123; QueryRunner qr = new QueryRunner(); String sql = "SELECT * FROM sort"; //调用方法query执行查询,传递连接对象,SQL语句,结果集处理方式的实现类 //返回对象数组 Object[] result = qr.query(con, sql, new ArrayHandler()); for(Object obj : result)&#123; System.out.print(obj); &#125; &#125; &#125; 11结果集处理ArrayListHandler1234567891011121314151617181920212223242526272829303132* A: 结果集处理ArrayListHandler* * "qr.query(con, sql, new ArrayListHandler());返回的是： "List&lt;Object[]&gt;" "* * a: 案例代码public class QueryRunnerDemo1 &#123; private static Connection con = JDBCUtilsConfig.getConnection(); public static void main(String[] args) throws SQLException&#123; arrayListHandler(); &#125; "/* * 结果集第二种处理方法,ArrayListHandler * 将结果集的"每一行",封装到对象数组中, 出现很多对象数组 * 对象数组存储到List集合： "List&lt;Object[]&gt;" */" public static void arrayListHandler()throws SQLException&#123; QueryRunner qr = new QueryRunner(); String sql = "SELECT * FROM sort"; //调用query方法,结果集处理的参数上,传递实现类ArrayListHandler //方法返回值 每行是一个对象数组,存储到List List&lt;Object[]&gt; result= qr.query(con, sql, new ArrayListHandler()); //集合的遍历 for( Object[] objs : result)&#123; //遍历对象数组 for(Object obj : objs)&#123; System.out.print(obj+" "); &#125; System.out.println(); &#125; &#125;&#125; 12结果集处理BeanHandler123456789101112131415161718192021* A: 结果集处理BeanHandler* a: 案例代码public class QueryRunnerDemo1 &#123; private static Connection con = JDBCUtilsConfig.getConnection(); public static void main(String[] args) throws SQLException&#123; beanHandler(); &#125; "/* * 结果集第三种处理方法,BeanHandler * 将结果集的"一行数据"(默认第一行),封装成JavaBean对象 * 注意: 被封装成数据到JavaBean对象, Sort类"必须"有"空参数构造" */" public static void beanHandler()throws SQLException&#123; QueryRunner qr = new QueryRunner(); String sql = "SELECT * FROM sort "; //调用方法,传递结果集实现类BeanHandler //BeanHandler(Class&lt;T&gt; type) Sort s = qr.query(con, sql, new BeanHandler&lt;Sort&gt;(Sort.class)); System.out.println(s); &#125;&#125; 13结果集处理BeanListHandler123456789101112131415161718192021222324* A: 结果集处理BeanListHandler* a: 案例代码public class QueryRunnerDemo1 &#123;private static Connection con = JDBCUtilsConfig.getConnection();public static void main(String[] args) throws SQLException&#123; beanListHander();&#125;"/* * 结果集第四种处理方法, BeanListHandler * 结果集每一行数据,封装JavaBean对象 * 多个JavaBean对象,存储到List集合 * 返回的是： * "List&lt;T&gt;","具体而言是：List&lt;JavaBean类&gt;" */"public static void beanListHander()throws SQLException&#123; QueryRunner qr = new QueryRunner(); String sql = "SELECT * FROM sort "; //调用方法query,传递结果集处理实现类BeanListHandler List&lt;Sort&gt; list = qr.query(con, sql, new BeanListHandler&lt;Sort&gt;(Sort.class)); for(Sort s : list)&#123; System.out.println(s); &#125;&#125;&#125; 14结果集处理ColumnListHandler123456789101112131415161718192021222324* A: 结果集处理ColumnListHandler* a: 案例代码public class QueryRunnerDemo1 &#123; private static Connection con = JDBCUtilsConfig.getConnection(); public static void main(String[] args) throws SQLException&#123; columnListHandler(); &#125; "/* * 结果集第五种处理方法,ColumnListHandler * 结果集,指定列的数据,存储到List集合 * 返回的是： List&lt;Object&gt; 每个列数据类型不同 */" public static void columnListHandler()throws SQLException&#123; QueryRunner qr = new QueryRunner(); String sql = "SELECT * FROM sort "; //调用方法 query,传递结果集实现类ColumnListHandler //实现类构造方法中,使用字符串的列名 List&lt;Object&gt; list = qr.query(con, sql, new ColumnListHandler&lt;Object&gt;("sname")); for(Object obj : list)&#123; System.out.println(obj); &#125; &#125; &#125; 15结果集处理ScalarHandler12345678910111213141516171819* A: 结果集处理ScalarHandler* a: 案例代码public class QueryRunnerDemo1 &#123; private static Connection con = JDBCUtilsConfig.getConnection(); public static void main(String[] args) throws SQLException&#123; scalarHandler(); &#125; "/* * 结果集第六种处理方法,ScalarHandler * 对于查询后,只有1个结果 */" public static void scalarHandler()throws SQLException&#123; QueryRunner qr = new QueryRunner(); String sql = "SELECT COUNT(*) FROM sort"; //调用方法query,传递结果集处理实现类ScalarHandler long count = qr.query(con, sql, new ScalarHandler&lt;Long&gt;()); System.out.println(count); &#125;&#125; 16结果集处理MapHandler123456789101112131415161718192021222324* A: 结果集处理MapHandler* a: 案例代码public class QueryRunnerDemo1 &#123; private static Connection con = JDBCUtilsConfig.getConnection(); public static void main(String[] args) throws SQLException&#123; mapHandler(); &#125; "/* * 结果集第七种处理方法,MapHandler * 将结果集第一行数据,封装到Map集合中 * Map&lt;键,值&gt; 键:列名 值:这列的数据 */" public static void mapHandler()throws SQLException&#123; QueryRunner qr = new QueryRunner(); String sql = "SELECT * FROM sort"; //调用方法query,传递结果集实现类MapHandler //返回值: Map集合,Map接口实现类, 泛型 Map&lt;String,Object&gt; map = qr.query(con, sql, new MapHandler()); //遍历Map集合 for(String key : map.keySet())&#123; System.out.println(key+".."+map.get(key)); &#125; &#125;&#125; 17结果集处理MapListHandler12345678910111213141516171819202122232425262728* A: 结果集处理MapListHandlerr* a: 案例代码public class QueryRunnerDemo1 &#123; private static Connection con = JDBCUtilsConfig.getConnection(); public static void main(String[] args) throws SQLException&#123; mapListHandler(); &#125; "/* * 结果集第八种处理方法,MapListHandler * 将结果集每一行存储到Map集合,键:列名,值:数据 * Map集合过多,存储到List集合 */" public static void mapListHandler()throws SQLException&#123; QueryRunner qr = new QueryRunner(); String sql = "SELECT * FROM sort"; //调用方法query,传递结果集实现类MapListHandler //返回值List集合, 存储的是Map集合 List&lt;Map&lt;String,Object&gt;&gt; list = qr.query(con, sql, new MapListHandler()); //遍历集合list for( Map&lt;String,Object&gt; map : list )&#123; for(String key : map.keySet())&#123; System.out.print(key+"..."+map.get(key)); &#125; System.out.println(); &#125; &#125;&#125; 18连接池介绍 A: 连接池介绍 a: 连接池介绍* 实际上就是存放连接的池子(容器) 在开发中“获得连接”或“释放资源”是非常消耗系统资源的两个过程 为了解决此类性能问题，通常情况我们采用连接池技术，来共享连接Connection。 这样我们就不需要每次都创建连接、释放连接了，这些操作都交给了连接池 19连接池概念规范和DataSource接口 A: 连接池概念规范和DataSource接口 a: 连接池概念规范 用池来管理Connection，这样可以重复使用Connection。 不用自己来创建Connection，而是通过池来获取Connection对象* 使用完Connection后，调用Connection的close()方法也不会真的关闭Connection，而是把Connection“归还”给池 连接池技术可以完成Connection对象的再次利用 b: DataSource接口 Java为数据库连接池提供了公共的接口：javax.sql.DataSource 各个厂商需要让自己的连接池实现这个接口。这样应用程序可以方便的切换不同厂商的连接池 常见的连接池：DBCP、C3P0 20DBCP连接池介绍 A: DBCP连接池介绍 a: DBCP连接池介绍 DBCP也是一个开源的连接池，是Apache Common成员之一，在企业开发中也比较常见，tomcat内置的连接池 tomcat服务器简单介绍 21导入jar包123456789* A: 导入jar包* a: jar包介绍 * mysql-connector-java-5.1.37-bin.jar：数据库驱动* commons-dbutils-1.6.jar：提供QueryRunner类方便进行增删改查操作* commons-dbcp-1.4.jar：* commons-pool-1.5.6.jar：提供高效的数据库连接池技术* b: 导入jar包* 在项目根路径下建立文件夹lib* 拷贝以上jar包，选定拷贝的jar包/右键/Build Path/Add to Build Path 22BasicDataSource类的使用12345678910111213141516171819202122232425262728* A: BasicDataSource类的使用* a: 案例代码/* * 连接池jar包中,定义好一个类 BasicDataSource * 实现类数据源的规范接口 javax.sql.DataSource */public class DataSoruceDemo &#123; public static void main(String[] args) &#123; //创建DataSource接口的实现类对象 //实现类, org.apache.commons.dbcp BasicDataSource dataSource = new BasicDataSource(); //连接数据库的4个最基本信息,通过对象方法setXXX设置进来 dataSource.setDriverClassName("com.mysql.jdbc.Driver"); dataSource.setUrl("jdbc:mysql://localhost:3306/mybase"); dataSource.setUsername("root"); dataSource.setPassword("123"); try&#123; //调用对象方法getConnection获取数据库的连接 Connection con = dataSource.getConnection(); System.out.println(con); &#125;catch(SQLException ex)&#123;// System.out.println(ex); ex.printStackTrace(); throw new RuntimeException("数据库连接失败"); &#125; &#125;&#125; 23BasicDataSource类的常见配置123456789101112131415* A: BasicDataSource类的常见配置* a: 常见配置分类 属性 描述必须项 driverClassName 数据库驱动名称 url 数据库的地址 username 用户名 password 密码基本项（扩展） maxActive 最大连接数量 minIdle 最小空闲连接 maxIdle 最大空闲连接 initialSize 初始化连接参考文档：http://commons.apache.org/proper/commons-dbcp/configuration.html 24实现数据库连接池工具类123456789101112131415161718192021222324252627282930313233343536* A: 实现数据库连接池工具类* a: 案例代码/* * 使用DBCP实现数据库的连接池 * 连接池配置,自定义类, * 最基本四项完整 * 对于数据库连接池其他配置,自定义 */import javax.sql.DataSource;import org.apache.commons.dbcp.BasicDataSource;public class JDBCUtils&#123; //创建出BasicDataSource类对象 private static BasicDataSource datasource = new BasicDataSource(); //静态代码块,对象BasicDataSource对象中的配置,自定义 static&#123; //数据库连接信息,必须的 datasource.setDriverClassName("com.mysql.jdbc.Driver"); datasource.setUrl("jdbc:mysql://localhost:3306/day33_user"); datasource.setUsername("root"); datasource.setPassword("123"); //对象连接池中的连接数量配置,可选的 datasource.setInitialSize(10);//初始化的连接数 datasource.setMaxActive(8);//最大连接数量 datasource.setMaxIdle(5);//最大空闲数 datasource.setMinIdle(1);//最小空闲 &#125; //定义静态方法,返回BasicDataSource类的对象 public static DataSource getDataSource()&#123; return datasource; &#125;&#125; 25工具类的测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253* A: 工具类的测试* a: 案例代码/* * 测试写好的工具类, * 提供的是一个DataSource接口的数据源 * QueryRunner类构造方法,接收DataSource接口的实现类 * 后面,调用方法update,query,无需传递他们Connection连接对象 */import java.sql.SQLException;import java.util.List;import org.apache.commons.dbutils.QueryRunner;import org.apache.commons.dbutils.handlers.ArrayListHandler;import cn.itcast.jdbcutils.JDBCUtils;public class QueryRunnerDemo&#123; public static void main(String[] args) &#123; select(); &#125; //定义2个方法,实现数据表的添加,数据表查询 //QueryRunner类对象,写在类成员位置 private static QueryRunner qr = new QueryRunner(JDBCUtils.getDataSource()); //数据表查询 public static void select()&#123; String sql = "SELECT * FROM sort"; try&#123; List&lt;Object[]&gt; list = qr.query(sql, new ArrayListHandler()); for(Object[] objs : list)&#123; for(Object obj : objs)&#123; System.out.print(obj+"\t"); &#125; System.out.println(); &#125; &#125;catch(SQLException ex)&#123; throw new RuntimeException("数据查询失败"); &#125; &#125; //数据表添加数据 public static void insert()&#123; String sql = "INSERT INTO sort (sname,sprice,sdesc)VALUES(?,?,?)"; Object[] params = &#123;"坚果",100.12,"刚刚上市的核桃"&#125;; try&#123; int row = qr.update(sql, params); System.out.println(row); &#125;catch(SQLException ex)&#123; throw new RuntimeException("数据添加失败"); &#125; &#125; &#125; 26总结 把今天的知识点总结一遍。]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础27(JDBC,DBUtils)]]></title>
    <url>%2F2016%2F11%2F28%2Fday29%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、JDBC2、DBUtils 01JDBC概念和数据库驱动程序 A: JDBC概念和数据库驱动程序 a: JDBC概述 JDBC（Java Data Base Connectivity,java数据库连接）是一种用于执行SQL语句的Java API，可以为多种关系数据库提供统一访问，它由一组用Java语言编写的类和接口组成。是Java访问数据库的标准规范 JDBC提供了一种基准,据此可以构建更高级的工具和接口，使数据库开发人员能够编写数据库应用程序。 JDBC需要连接驱动，驱动是两个设备要进行通信，满足一定通信数据格式，数据格式由设备提供商规定，设备提供商为设备提供驱动软件，通过软件可以与该设备进行通信。 我们使用的是mysql的驱动mysql-connector-java-5.1.39-bin.jar b: 总结 JDBC是java提供给开发人员的一套操作数据库的接口 数据库驱动就是实现该接口的实现类 02JDBC原理 A: JDBC原理 a: 描述 Java提供访问数据库规范称为JDBC，而生产厂商提供规范的实现类称为驱动 DBC是接口，驱动是接口的实现，没有驱动将无法完成数据库连接，从而不能操作数据库！每个数据库厂商都需要提供自己的驱动，用来连接自己公司的数据库，也就是说驱动一般都由数据库生成厂商提供。 03准备数据12345678910111213141516171819202122* A: 准备数据* a: 创建数据库和表结构 #创建数据库 create database mybase; #使用数据库 use mybase; ###创建分类表 create table sort( sid int PRIMARY KEY AUTO_INCREMENT, sname varchar(100), sprice DOUBLE, sdesc VARCHAR(500) ); * b: 向表中插入数据 #初始化数据 insert into sort(sname,sprice,sdesc) values('家电',2000, '优惠的促销'); insert into sort(sname,sprice,sdesc) values('家具',8900, '家具价格上调,原材料涨价'); insert into sort(sname,sprice,sdesc) values('儿童玩具',290, '赚家长的钱'); insert into sort(sname,sprice,sdesc) values('生鲜',500.99, '生鲜商品'); insert into sort(sname,sprice,sdesc) values('服装',24000, '换季销售'); insert into sort(sname,sprice,sdesc) values('洗涤',50, '洗发水促销'); 04JDBC的开发步骤 A: JDBC的开发步骤 a: 步骤介绍1.注册驱动告知JVM使用的是哪一个数据库的驱动2.获得连接使用JDBC中的类,完成对MySQL数据库的连接3.获得语句执行平台通过连接对象获取对SQL语句的执行者对象4.执行sql语句使用执行者对象,向数据库执行SQL语句获取到数据库的执行后的结果5.处理结果6.释放资源 一堆close() 05导入mysql数据库驱动程序jar包 A: 导入mysql数据库驱动程序jar包 a: 步骤 创建lib目录，用于存放当前项目需要的所有jar包 选择jar包，右键执行build path / Add to Build Path 06注册数据库驱动程序代码：Class.forName(“com.mysql.jdbc.Driver”);JDBC规范定义驱动接口：java.sql.Driver，MySql驱动包提供了实现类：com.mysql.jdbc.DriverDriverManager工具类，提供注册驱动的方法 registerDriver()，方法的参数是java.sql.Driver，所以我们可以通过如下语句进行注册:DriverManager.registerDriver(new com.mysql.jdbc.Driver());以上代码不推荐使用，存在两方面不足1. 硬编码，后期不易于程序扩展和维护2. 驱动被注册两次。 通常开发我们使用Class.forName() 加载一个使用字符串描述的驱动类。如果使用Class.forName()将类加载到内存，该类的静态代码将自动执行。通过查询com.mysql.jdbc.Driver源码，我们发现Driver类“主动”将自己进行注册 123456789101112* A: 注册数据库驱动程序* a: 案例代码public class JDBCDemo &#123; public static void main(String[] args)throws ClassNotFoundException,SQLException&#123; "//1.注册驱动 反射技术,将驱动类加入到内容" // 使用java.sql.DriverManager类静态方法 registerDriver(Driver driver) // Diver是一个接口,参数传递,MySQL驱动程序中的实现类 //DriverManager.registerDriver(new Driver()); //驱动类源代码,注册2次驱动程序 Class.forName("com.mysql.jdbc.Driver"); &#125;&#125; 07获取数据库的连接对象代码：Connection con = DriverManager.getConnection(“jdbc:mysql://localhost:3306/mydatabase”, ”root”, ”root”); 获取连接需要方法 DriverManager.getConnection(url,username,password)，三个参数分别表示，url 需要连接数据库的位置（网址） user用户名 password 密码 url比较复杂，下面是mysql的url：jdbc:mysql://localhost:3306/mydatabase JDBC规定url的格式由三部分组成，每个部分中间使用冒号分隔。 第一部分是jdbc，这是固定的； 第二部分是数据库名称，那么连接mysql数据库，第二部分当然是mysql了； 第三部分是由数据库厂商规定的，我们需要了解每个数据库厂商的要求，mysql的第三部分分别由数据库服务器的IP地址（localhost）、端口号（3306），以及DATABASE名称(mydatabase)组成。url: 数据库地址 &gt;&gt;&gt;&gt;&gt; jdbc:mysql://连接主机IP:端口号/数据库名字 1234567891011121314151617181920212223242526* A：获取数据库的连接对象* a: 案例代码public class JDBCDemo &#123; public static void main(String[] args)throws ClassNotFoundException,SQLException&#123; //1.注册驱动 反射技术,将驱动类加入到内容 // 使用java.sql.DriverManager类静态方法 registerDriver(Driver driver) // Diver是一个接口,参数传递,MySQL驱动程序中的实现类 //DriverManager.registerDriver(new Driver()); //驱动类源代码,注册2次驱动程序 Class.forName("com.mysql.jdbc.Driver"); //2.获得数据库连接 DriverManager类中静态方法 "//static Connection getConnection(String url, String user, String password) " //返回值是Connection接口的实现类,在mysql驱动程序 "//url: 数据库地址 jdbc:mysql://连接主机IP:端口号/数据库名字" String url = "jdbc:mysql://localhost:3296/mybase"; //用户名和密码用自己的 String username="root"; String password="123"; "//Connection 接口在java.sql中" Connection con = DriverManager.getConnection(url, username, password); "//返回值是 Connection 接口的实现类对象,在mysql驱动程序中：com.mysql.jdbc.JDBC4Connection" System.out.println(con); &#125;&#125; 08获取SQL语句的执行对象对象123456789101112131415161718192021222324252627282930* A: 获取SQL语句的执行对象对象* String sql = "某SQL语句";"获取Statement语句执行平台：Statement stmt = con.createStatement();"* a: 案例代码public class JDBCDemo &#123; public static void main(String[] args)throws ClassNotFoundException,SQLException&#123; //1.注册驱动 反射技术,将驱动类加入到内容 // 使用java.sql.DriverManager类静态方法 registerDriver(Driver driver) // Diver是一个接口,参数传递,MySQL驱动程序中的实现类 //DriverManager.registerDriver(new Driver()); //驱动类源代码,注册2次驱动程序 Class.forName("com.mysql.jdbc.Driver"); //2.获得数据库连接 DriverManager类中静态方法 //static Connection getConnection(String url, String user, String password) //返回值是Connection接口的实现类,在mysql驱动程序 //url: 数据库地址 jdbc:mysql://连接主机IP:端口号//数据库名字 String url = "jdbc:mysql://localhost:3296/mybase"; String username="root"; String password="123"; Connection con = DriverManager.getConnection(url, username, password); //3.获得语句执行平台, 通过数据库连接对象,获取到SQL语句的执行者对象 "// con对象调用方法 Statement createStatement() 获取Statement对象,将SQL语句发送到数据库 // 返回值是 Statement接口的实现类对象,,在mysql驱动程序中：com.mysql.jdbc.StatementImpl" Statement stat = con.createStatement(); System.out.println(stat);&#125;&#125; 09执行insert语句获取结果集1234567891011121314String sql = "某SQL语句";获取Statement语句执行平台：Statement stmt = con.createStatement(); 常用方法： int executeUpdate(String sql) --执行insert update delete语句.参数：sql - SQL 数据操作语言（Data Manipulation Language，DML）语句，如 INSERT、UPDATE 或 DELETE；或者不返回任何内容的 SQL 语句，如 DDL 语句。 返回：(1) 对于 SQL 数据操作语言 (DML) 语句，返回【行计数】:操作成功的数据表有多少行，(2) 对于什么都不返回的 SQL 语句，返回 0 ; ResultSet executeQuery(String sql); --执行select语句. boolean execute(String sql); --执行select返回true 执行其他的语句返回false. 1234567891011121314151617181920212223242526272829303132333435363738* A: 执行insert语句获取结果集* a: 案例代码public class JDBCDemo &#123; public static void main(String[] args)throws ClassNotFoundException,SQLException&#123; //1.注册驱动 反射技术,将驱动类加入到内容 // 使用java.sql.DriverManager类静态方法 registerDriver(Driver driver) // Diver是一个接口,参数传递,MySQL驱动程序中的实现类 //DriverManager.registerDriver(new Driver()); //驱动类源代码,注册2次驱动程序 Class.forName("com.mysql.jdbc.Driver"); //2.获得数据库连接 DriverManager类中静态方法 //static Connection getConnection(String url, String user, String password) //返回值是Connection接口的实现类,在mysql驱动程序 //url: 数据库地址 jdbc:mysql://连接主机IP:端口号//数据库名字 String url = "jdbc:mysql://localhost:3296/mybase"; String username="root"; String password="123"; Connection con = DriverManager.getConnection(url, username, password); //3.获得语句执行平台, 通过数据库连接对象,获取到SQL语句的执行者对象 // con对象调用方法 Statement createStatement() 获取Statement对象,将SQL语句发送到数据库 // 返回值是 Statement接口的实现类对象,,在mysql驱动程序 Statement stat = con.createStatement(); // 4.执行sql语句 // 通过执行者对象调用方法执行SQL语句,获取结果 &gt;&gt; int executeUpdate(String sql) 执行数据库中的SQL语句, insert delete update &lt;&lt; "// 返回值int,操作成功的数据表多少行" int row = stat.executeUpdate ("INSERT INTO sort(sname,sprice,sdesc) VALUES('汽车用品',50000,'疯狂涨价')"); System.out.println(row); //6.释放资源 一堆close() stat.close(); con.close();&#125;&#125; 10执行select语句获取结果集12345678910111213 ResultSet executeQuery(String sql); --执行select语句. boolean execute(String sql); --执行select返回true 执行其他的语句返回false.ResultSet实际上就是一张二维的表格，我们可以调用其boolean next()方法指向某行记录，当第一次调用next()方法时，便指向第一行记录的位置，这时就可以使用ResultSet提供的getXXX(int col)方法(与索引从0开始不同，列从1开始)来获取指定列的数据：rs.next();//指向第一行rs.getInt(1);//获取第一行第一列的数据常用方法： Object getObject(int index) / Object getObject(String name) 获得任意对象 String getString(int index) / Object getObject(String name) 获得字符串 int getInt(int index) / Object getObject(String name) 获得整形 double getDouble(int index) / Object getObject(String name) 获得双精度浮点型 1234567891011121314151617181920212223242526272829303132* A: 执行select语句获取结果集* a: 案例代码public class JDBCDemo1 &#123; public static void main(String[] args) throws Exception&#123; //1. 注册驱动 Class.forName("com.mysql.jdbc.Driver"); //2. 获取连接对象 String url = "jdbc:mysql://localhost:3296/mybase"; String username="root"; String password="123"; Connection con = DriverManager.getConnection(url, username, password); //3 .获取执行SQL 语句对象 Statement stat = con.createStatement(); // 拼写查询的SQL String sql = "SELECT * FROM sort"; //4. 调用执行者对象方法,执行SQL语句获取结果集 // ResultSet executeQuery(String sql) 执行SQL语句中的select查询 // 返回值ResultSet接口的实现类对象,实现类在mysql驱动中 ResultSet rs = stat.executeQuery(sql); //5 .处理结果集 // ResultSet接口方法 boolean next() 返回true,有结果集,返回false没有结果集 while(rs.next())&#123; //获取每列数据,使用是ResultSet接口的方法 getXX方法参数中,建议写String列名 System.out.println(rs.getInt("sid")+" "+rs.getString("sname")+ " "+rs.getDouble("sprice")+" "+rs.getString("sdesc")); &#125; rs.close(); stat.close(); con.close();&#125;&#125; 11SQL注入攻击1234567891011121314151617181920212223242526* A: SQL注入攻击* a: 注入问题* 假设有登录案例SQL语句如下:* SELECT * FROM 用户表 WHERE NAME = 用户输入的用户名 AND PASSWORD = 用户输的密码;* 此时，当用户输入正确的账号与密码后，查询到了信息则让用户登录。 但是当用户输入的账号为XXX 密码为：XXX’ OR ‘a’=’a时，则真正执行的代码变为： * SELECT * FROM 用户表 WHERE NAME = ‘XXX’ AND PASSWORD =’ XXX’ OR ’a’=’a’;* 此时，上述查询语句时永远可以查询出结果的。那么用户就直接登录成功了，显然我们不希望看到这样的结果，这便是SQL注入问题。* b: 案例演示CREATE TABLE users( id INT PRIMARY KEY AUTO_INCREMENT, username VARCHAR(100), PASSWORD VARCHAR(100));INSERT INTO users (username,PASSWORD) VALUES ('a','1'),('b','2');SELECT * FROM users;-- 登录查询SELECT * FROM users WHERE username='dsfsdfd' AND PASSWORD='wrethiyu' OR 1=1SELECT * FROM users WHERE username='a' AND PASSWORD='1'OR'1=1'键盘录入：11'OR' 1=1 12SQL注入攻击用户登录案例1234567891011121314151617181920212223242526272829* A: SQL注入攻击用户登录案例* a: 案例代码public class JDBCDemo2 &#123; public static void main(String[] args)throws Exception &#123; Class.forName("com.mysql.jdbc.Driver"); String url = "jdbc:mysql://localhost:3296/mybase"; String username = "root"; String password = "123"; Connection con = DriverManager.getConnection(url, username, password); Statement stat = con.createStatement(); Scanner sc = new Scanner(System.in); String user = sc.nextLine(); String pass = sc.nextLine(); //执行SQL语句,数据表,查询用户名和密码,如果存在,登录成功,不存在登录失败// String sql = "SELECT * FROM users WHERE username='dsfsdfd' AND PASSWORD='wrethiyu' OR 1=1"; String sql = "SELECT * FROM users WHERE username='"+user+"' AND PASSWORD='"+pass+"'"; System.out.println(sql); ResultSet rs = stat.executeQuery(sql); while(rs.next())&#123; System.out.println(rs.getString("username")+" "+rs.getString("password")); &#125; rs.close(); stat.close(); con.close(); &#125;&#125; 13PrepareStatement接口预编译SQL语句123456789101112131415161718* A: PrepareStatement接口预编译SQL语句* a: 预处理对象 * 使用PreparedStatement预处理对象时，建议每条sql语句所有的实际参数，都使用逗号分隔。 * String sql = "insert into sort(sid,sname) values(?,?);"; * String sql ="SELECT * FROM test0120 where username=? and PASSWORD1=?;"; *"方法中参数,SQL语句中的参数全部采用问号？占位符" * PreparedStatement预处理对象代码： * "PreparedStatement psmt = conn.prepareStatement(sql)" * b: 执行SQL语句的方法介绍 * int executeUpdate(); --执行insert update delete语句. * ResultSet executeQuery(); --执行select语句. * boolean execute(); --执行select返回true 执行其他的语句返回false.* c: 设置实际参数 * void setXxx(int index, Xxx xx) &gt;&gt;&gt; void setObject(int index, Object object) * 将指定参数设置为给定Java的xx值。在将此值发送到数据库时，驱动程序将它转换成一个 SQL Xxx类型值。 * 例如： * setString(2, "家用电器") 把SQL语句中第2个位置的占位符？ 替换成实际参数 "家用电器" 1234567891011121314151617181920212223242526272829303132333435363738394041424344* d: 案例代码 /* * Java程序实现用户登录,用户名和密码,数据库检查 * 防止注入攻击 * Statement接口实现类,作用执行SQL语句,返回结果集 * 有一个子接口PreparedStatement (SQL预编译存储,多次高效的执行SQL) * PreparedStatement的实现类数据库的驱动中,如何获取接口的实现类 * * 是Connection数据库连接对象的方法 * PreparedStatement prepareStatement(String sql) */public class JDBCDemo3 &#123; public static void main(String[] args)throws Exception &#123; Class.forName("com.mysql.jdbc.Driver"); String url = "jdbc:mysql://localhost:3296/mybase"; String username = "root"; String password = "123"; Connection con = DriverManager.getConnection(url, username, password); Scanner sc = new Scanner(System.in); String user = sc.nextLine(); String pass = sc.nextLine(); //执行SQL语句,数据表,查询用户名和密码,如果存在,登录成功,不存在登录失败 String sql = "SELECT * FROM users WHERE username=? AND PASSWORD=?"; //调用Connection接口的方法prepareStatement,获取PrepareStatement接口的实现类 //方法中参数,SQL语句中的参数全部采用问号占位符 PreparedStatement pst = con.prepareStatement(sql); System.out.println(pst); //调用pst对象set方法,设置问号占位符上的参数 pst.setObject(1, user); pst.setObject(2, pass); //调用方法,执行SQL,获取结果集 ResultSet rs = pst.executeQuery(); while(rs.next())&#123; System.out.println(rs.getString("username")+" "+rs.getString("password")); &#125; rs.close(); pst.close(); con.close();&#125;&#125; 14PrepareStatement接口预编译SQL语句执行修改12345678910111213141516171819202122232425262728* A: PrepareStatement接口预编译SQL语句执行修改* 案例代码 /* * 使用PrepareStatement接口,实现数据表的更新操作 */public class JDBCDemo &#123; public static void main(String[] args) throws Exception&#123; Class.forName("com.mysql.jdbc.Driver"); String url = "jdbc:mysql://localhost:3296/mybase"; String username="root"; String password="123"; Connection con = DriverManager.getConnection(url, username, password); //拼写修改的SQL语句,参数采用?占位 String sql = "UPDATE sort SET sname=?,sprice=? WHERE sid=?"; //调用数据库连接对象con的方法prepareStatement获取SQL语句的预编译对象 PreparedStatement pst = con.prepareStatement(sql); //调用pst的方法setXXX设置?占位 pst.setObject(1, "汽车美容"); pst.setObject(2, 49988); pst.setObject(3, 7); //调用pst方法执行SQL语句 pst.executeUpdate(); pst.close(); con.close();&#125;&#125; 15PrepareStatement接口预编译SQL语句执行查询123456789101112131415161718192021222324252627* A: PrepareStatement接口预编译SQL语句执行查询* a: 案例代码 /* * PrepareStatement接口实现数据表的查询操作 */public class JDBCDemo1 &#123; public static void main(String[] args) throws Exception&#123; Class.forName("com.mysql.jdbc.Driver"); String url = "jdbc:mysql://localhost:3296/mybase"; String username="root"; String password="123"; Connection con = DriverManager.getConnection(url, username, password); String sql = "SELECT * FROM sort"; PreparedStatement pst = con.prepareStatement(sql); //调用pst对象的方法,执行查询语句,Select ResultSet rs=pst.executeQuery(); while(rs.next())&#123; System.out.println(rs.getString("sid")+" "+rs.getString("sname")+" "+rs.getString("sprice")+" "+rs.getString("sdesc")); &#125; rs.close(); pst.close(); con.close();&#125;&#125; 16JDBC的工具类和测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677* A: JDBC的工具类和测试* a: 案例代码//JDBCUtils工具类代码public class JDBCUtils &#123; private JDBCUtils()&#123;&#125; private static Connection con ; static&#123; try&#123; Class.forName("com.mysql.jdbc.Driver"); String url = "jdbc:mysql://localhost:3296/mybase"; String username="root"; String password="123"; con = DriverManager.getConnection(url, username, password); &#125;catch(Exception ex)&#123; throw new RuntimeException(ex+"数据库连接失败"); &#125; &#125; /* * 定义静态方法,返回数据库的连接对象 */ public static Connection getConnection()&#123; return con; &#125; public static void close(Connection con,Statement stat)&#123; if(stat!=null)&#123; try&#123; stat.close(); &#125;catch(SQLException ex)&#123;&#125; &#125; if(con!=null)&#123; try&#123; con.close(); &#125;catch(SQLException ex)&#123;&#125; &#125; &#125; public static void close(Connection con,Statement stat , ResultSet rs)&#123; if(rs!=null)&#123; try&#123; rs.close(); &#125;catch(SQLException ex)&#123;&#125; &#125; if(stat!=null)&#123; try&#123; stat.close(); &#125;catch(SQLException ex)&#123;&#125; &#125; if(con!=null)&#123; try&#123; con.close(); &#125;catch(SQLException ex)&#123;&#125; &#125; &#125;&#125;//测试JDBCUtils工具类的代码public class TestJDBCUtils &#123; public static void main(String[] args)throws Exception &#123; Connection con = JDBCUtils.getConnection(); PreparedStatement pst = con.prepareStatement("SELECT sname FROM sort"); ResultSet rs = pst.executeQuery(); while(rs.next())&#123; System.out.println(rs.getString("sname")); &#125; JDBCUtils.close(con, pst, rs); &#125;&#125; 17数据表数据存储对象12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576* A: 数据表数据存储对象* a: 准备工作 * 导入jar包 * 拷贝day32定义的工具类JDBCUtils * b: 案例代码 //定义实体类Sortpublic class Sort &#123; private int sid; private String sname; private double sprice; private String sdesc; public Sort(int sid, String sname, double sprice, String sdesc) &#123; this.sid = sid; this.sname = sname; this.sprice = sprice; this.sdesc = sdesc; &#125; public Sort()&#123;&#125; public int getSid() &#123; return sid; &#125; public void setSid(int sid) &#123; this.sid = sid; &#125; public String getSname() &#123; return sname; &#125; public void setSname(String sname) &#123; this.sname = sname; &#125; public double getSprice() &#123; return sprice; &#125; public void setSprice(double sprice) &#123; this.sprice = sprice; &#125; public String getSdesc() &#123; return sdesc; &#125; public void setSdesc(String sdesc) &#123; this.sdesc = sdesc; &#125; @Override public String toString() &#123; return "Sort [sid=" + sid + ", sname=" + sname + ", sprice=" + sprice + ", sdesc=" + sdesc + "]"; &#125; &#125; /* * JDBC读取数据表sort,每行数据封装到Sort类的对象中 * 很多个Sort类对象,存储到List集合中 */public class JDBCDemo &#123; public static void main(String[] args) throws Exception&#123; //使用JDBC工具类,直接获取数据库连接对象 Connection con = JDBCUtils.getConnection(); //连接获取数据库SQL语句执行者对象 PreparedStatement pst = con.prepareStatement("SELECT * FROM sort"); //调用查询方法,获取结果集 ResultSet rs = pst.executeQuery(); //创建集合对象 List&lt;Sort&gt; list = new ArrayList&lt;Sort&gt;(); while(rs.next())&#123; //获取到每个列数据,封装到Sort对象中 Sort s = new Sort(rs.getInt("sid"),rs.getString("sname"),rs.getDouble("sprice"),rs.getString("sdesc")); //封装的Sort对象,存储到集合中 list.add(s); &#125; JDBCUtils.close(con, pst, rs); //遍历List集合 for(Sort s : list)&#123; System.out.println(s); &#125; &#125;&#125; 18properties配置文件12345678910* A: properties配置文件 * a: 相关介绍* 开发中获得连接的4个参数（驱动、URL、用户名、密码）通常都存在配置文件中，"方便后期维护"，程序如果需要更换数据库， 只需要修改配置文件即可。* 通常情况下，我们习惯使用"properties文件"，此文件我们将做如下要求： 1. 文件位置：任意，"建议src下" 2. 文件名称：任意，"扩展名为properties" 3. 文件内容：一行一组数据，"格式是“key=value”". a) key命名自定义，"如果是多个单词，习惯使用点分隔。例如：jdbc.driver" b) value值不支持中文，如果"需要使用非英文字符"，"将进行unicode转换。" 19properties文件的创建和编写12345678* A: properties文件的创建和编写* a: properties文件的创建 * src路径下建立database.properties(其实就是一个文本文件)* b: properties文件的编写(内容如下) driverClass=com.mysql.jdbc.Driver url=jdbc:mysql://localhost:3296/mybase username=root password=123 20加载配置文件(使用类的加载器)1234567891011121314151617181920212223* A: 加载配置文件* a: 案例代码 /* * 加载properties配置文件 * IO读取文件,键值对存储到集合 * 从集合中以键值对方式获取数据库的连接信息,完成数据库的连接 */"//使用类的加载器InputStream in = PropertiesDemo.class.getClassLoader().getResourceAsStream("database.properties");""从用来加载类的搜索路径中打开具有指定名称的资源，以读取该资源。"public class PropertiesDemo &#123; public static void main(String[] args) throws Exception&#123; FileInputStream fis = new FileInputStream("database.properties"); System.out.println(fis); "//使用类的加载器" InputStream in = PropertiesDemo.class.getClassLoader().getResourceAsStream("database.properties"); System.out.println(in); Properties pro = new Properties(); pro.load(in); System.out.println(in); &#125;&#125; 21通过配置文件连接数据库123456789101112131415161718192021222324252627* A: 通过配置文件连接数据库* a: 案例代码 /* * 加载properties配置文件 * IO读取文件,键值对存储到集合 * 从集合中以键值对方式获取数据库的连接信息,完成数据库的连接 */public class PropertiesDemo &#123; public static void main(String[] args) throws Exception&#123; FileInputStream fis = new FileInputStream("database.properties"); System.out.println(fis); //使用类的加载器 InputStream in = PropertiesDemo.class.getClassLoader().getResourceAsStream("database.properties"); System.out.println(in); Properties pro = new Properties(); pro.load(in); //获取集合中的键值对 String driverClass=pro.getProperty("driverClass"); String url = pro.getProperty("url"); String username = pro.getProperty("username"); String password = pro.getProperty("password"); Class.forName(driverClass); Connection con = DriverManager.getConnection(url, username, password); System.out.println(con); &#125;&#125; 22读取配置文件的工具类12345678910111213141516171819202122232425262728293031323334353637383940* A: 读取配置文件的工具类* a: 案例代码/* * 编写数据库连接的工具类,JDBC工具类 * 获取连接对象采用读取配置文件方式 * 读取文件获取连接,执行一次,static&#123;&#125; */public class JDBCUtilsConfig &#123; private static Connection con ; private static String driverClass; private static String url; private static String username; private static String password; static&#123; try&#123; readConfig(); Class.forName(driverClass); con = DriverManager.getConnection(url, username, password); &#125;catch(Exception ex)&#123; throw new RuntimeException("数据库连接失败"); &#125; &#125; private static void readConfig()throws Exception&#123; InputStream in = JDBCUtilsConfig.class.getClassLoader().getResourceAsStream("database.properties"); Properties pro = new Properties(); pro.load(in); driverClass=pro.getProperty("driverClass"); url = pro.getProperty("url"); username = pro.getProperty("username"); password = pro.getProperty("password"); &#125; public static Connection getConnection()&#123; return con; &#125; &#125; 23测试工具类123456789101112131415161718192021* A: 测试工具类* a: 案例代码public class TestJDBCUtils &#123; public static void main(String[] args) &#123; Connection con = JDBCUtilsConfig.getConnection(); System.out.println(con); String sql = "select * from supermaket;"; PreparedStatement pstat = con.prepareStatement(sql); ResultSet rs = pstat.executeQuery(); while(rs.next())&#123; System.out.println(rs.getObject("id")+" "+ rs.getObject("sname")+" "+ rs.getObject("sprice")+" "+ rs.getObject("smessage") ); &#125; con.close(); pstat.close(); rs.close(); &#125;&#125; 24总结 把今天的知识点总结一遍。]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础26(MySQL数据库,SQL语句)]]></title>
    <url>%2F2016%2F11%2F27%2Fday28%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1.MySQL数据库2.SQL语句 01数据库概念 A: 什么是数据库数据库就是存储数据的仓库，其本质是一个文件系统，数据按照特定的格式将数据存储起来，用户可以对数据库中的数据进行增加，修改，删除及查询操作。 B: 什么是数据库管理系统数据库管理系统（DataBase Management System，DBMS）：指一种操作和管理数据库的大型软件，用于建立、使用和维护数据库，对数据库进行统一管理和控制，以保证数据库的安全性和完整性。用户通过数据库管理系统访问数据库中表内的数据。 02常见的数据库 A: 常见的数据库MYSQL ：开源免费的数据库，小型的数据库.已经被Oracle收购了.MySQL6.x版本也开始收费。Oracle ：收费的大型数据库，Oracle公司的产品。Oracle收购SUN公司，收购MYSQL。DB2 ：IBM公司的数据库产品,收费的。常应用在银行系统中.SQLServer：MicroSoft 公司收费的中型的数据库。C#、.net等语言常使用。SyBase ：已经淡出历史舞台。提供了一个非常专业数据建模的工具PowerDesigner。SQLite : 嵌入式的小型数据库，应用在手机端。Java相关的数据库：MYSQL，Oracle．这里使用MySQL数据库。MySQL中可以有多个数据库，数据库是真正存储数据的地方 03数据库和管理系统* A: 数据库管理系统 123456----数据库1 ----数据表1a ----数据表1b----数据库2 -----数据表2a -----数据表2b 04数据表和Java中类的对应关系* A:数据库中以表为组织单位存储数据。 12345表类似我们的Java类，每个字段都有对应的数据类型。 那么用我们熟悉的java程序来与关系型数据对比，就会发现以下对应关系。 "类"----------"表" "类中属性"----------"表中字段" "对象"----------"表中每条记录" 05数据表和Java中类的对应关系用户表举例* A:举例: 账务表 id name age 1 lisi 23 2 wang 24 每一条记录对应一个User的对象 [user1 id = 1 name = lisi age = 23] [user2 id = 2 name = wang age = 24] 06MySQL数据库安装A: 安装步骤参见 day28_source《MySQL安装图解.doc》B: 安装后，MySQL会以windows服务的方式为我们提供数据存储功能。开启和关闭服务的操作：右键点击我的电脑→管理→服务→可以找到MySQL服务开启或停止。 07数据库在系统服务 A：开启服务和关闭服务方式1: 我的电脑—–&gt; (右键)管理—-&gt;服务和应用程序—-&gt;服务—-找到MySQL服务右键启动或关闭方式2: 进入dos窗口 使用命令: net start mysql 开启MySQL服务; 命令:net stop mysql 关闭MySql服务 08MySQL的登录123456* A: MySQL是一个需要账户名密码登录的数据库，登陆后使用，它提供了一个默认的root账号，使用安装时设置的密码即可登录。格式1：cmd&gt; mysql –u用户名 –p密码例如：mysql -uroot –proot格式2：cmd&gt; mysql --host=ip地址 --user=用户名 --password=密码例如：mysql --host=127.0.0.1 --user=root --password=root 09SQLYog软件介绍* A: 具体参见 《SQLYog配置.doc》 10SQL语句介绍和分类 A:SQL介绍 前面学习了接口的代码体现，现在来学习接口的思想，接下里从生活中的例子进行说明。 举例：我们都知道电脑上留有很多个插口，而这些插口可以插入相应的设备，这些设备为什么能插在上面呢？ 主要原因是这些设备在生产的时候符合了这个插口的使用规则，否则将无法插入接口中，更无法使用。发现这个插口的出现让我们使用更多的设备。 结构化查询语言(Structured Query Language)简称SQL，是一种数据库查询和程序设计语言，用于存取数据以及查询、更新和管理关系数据库系统。创建数据库、创建数据表、向数据表中添加一条条数据信息均需要使用SQL语句 1234567891011* B: SQL分类 * 数据定义语言：简称DDL(Data Definition Language)，用来定义数据库对象：数据库，表，列等。关键字：create，alter，drop等 * "数据操作语言：简称DML(Data Manipulation Language)，用来对数据库中表的记录进行更新。关键字：insert，delete，update等"* 数据控制语言：简称DCL(Data Control Language)，用来定义数据库的访问权限和安全级别，及创建用户。* "数据查询语言：简称DQL(Data Query Language)，用来查询数据库中表的记录。关键字：select，from，where等"* C: SQL通用语法"SQL语句可以单行或多行书写，以分号结尾" 可使用空格和缩进来增强语句的可读性 MySQL数据库的SQL语句"不区分大小写"，"建议关键字使用大写"，例如：SELECT * FROM user。 同样可以"使用/**/的方式完成注释" 11数据表中的数据类型123456789101112131415161718192021222324252627* A:MySQL中的我们常使用的数据类型如下 详细的数据类型如下(不建议详细阅读！)分类 类型名称 说明 整数类型 tinyInt 很小的整数 smallint 小的整数 mediumint 中等大小的整数 int(integer) 普通大小的整数小数类型 float 单精度浮点数 double 双精度浮点数 decimal（m,d） 压缩严格的定点数日期类型 year YYYY 1901~2155 time HH:MM:SS -838:59:59~838:59:59 date YYYY-MM-DD 1000-01-01~9999-12-3 datetime YYYY-MM-DD HH:MM:SS 1000-01-01 00:00:00~ 9999-12-31 23:59:59 timestamp YYYY-MM-DD HH:MM:SS 1970~01~01 00:00:01 UTC~2038-01-19 03:14:07UTC文本、二进制类型 CHAR(M) M为0~255之间的整数 VARCHAR(M) M为0~65535之间的整数 TINYBLOB 允许长度0~255字节 BLOB 允许长度0~65535字节 MEDIUMBLOB 允许长度0~167772150字节 LONGBLOB 允许长度0~4294967295字节 TINYTEXT 允许长度0~255字节 TEXT 允许长度0~65535字节 MEDIUMTEXT 允许长度0~167772150字节 LONGTEXT 允许长度0~4294967295字节 VARBINARY(M)允许长度0~M个字节的变长字节字符串 BINARY(M) 允许长度0~M个字节的定长字节字符串 12创建数据库操作12345678910111213141516171819202122232425262728293031* A: 创建数据库 格式: * create database 数据库名; * create database 数据库名 character set 字符集; 例如： #创建数据库 数据库中数据的编码采用的是安装数据库时指定的默认编码 utf8 CREATE DATABASE day21_1; #创建数据库 并指定数据库中数据的编码 CREATE DATABASE day21_2 CHARACTER SET utf8; * B: 查看数据库 查看数据库MySQL服务器中的所有的数据库: show databases; 查看某个数据库的定义的信息: show create database 数据库名; 例如： show create database day21_1; * C: 删除数据库 drop database 数据库名称; 例如： drop database day21_2; * D: 其他的数据库操作命令 切换数据库： use 数据库名; 例如： use day21_1; * E: 查看正在使用的数据库: select database(); 13创建数据表格式1234567891011* A:格式： create table 表名( 字段名 类型(长度) 约束, 字段名 类型(长度) 约束 ); 例如： ###创建分类表 CREATE TABLE sort ( sid INT, #分类ID sname VARCHAR(100) #分类名称 ); 14约束123456789101112131415161718192021222324252627282930313233343536* A: 约束的作用: void test() create table 表名( 列名 类型(长度) 约束, 列名 类型(长度) 约束 ); 限制每一列能写什么数据,不能写什么数据。 * B: 哪些约束: 主键约束 非空约束 唯一约束 外键约束格式：1.在创建表时创建主键，在字段后面加上 primary key.create table tablename( id int primary key, .......) 2. 在创建表时创建主键，在表创建的最后来指定主键 create table tablename( id int， .......， primary key(id))3.删除主键：alter table 表名 drop primary key; alter table sort drop primary key;4.主键自动增长：一般主键是自增长的字段，不需要指定。实现添加自增长语句,主键字段后加auto_increment(只适用MySQL)例如：###创建分类表CREATE TABLE sort ( sid INT PRIMARY KEY auto_increment, #分类ID sname VARCHAR(100) #分类名称); 15SQL代码的保存12* A: 当sql语句执行了，就已经对数据库进行操作了，一般不用保存操作 在SQLyog 中Ctrl + S 保存的是写sql语句。 16创建用户表123456789* A: 创建用户表: 需求:创建用户表,用户编号,姓名,用户的地址 * B: SQL语句 CREAT TABLE users ( uid INT, uname VARCHAR(20), uaddress VARCHAR(200) ); 17主键约束123456789101112131415161718192021* A: 主键是用于标识当前记录的字段。它的特点是非空，唯一。 在开发中一般情况下主键是不具备任何含义，只是用于标识当前记录。 * B: 格式： 1.在创建表时创建主键，在字段后面加上 primary key. create table tablename( id int primary key, ....... ) 2. 在创建表时创建主键，在表创建的最后来指定主键 create table tablename( id int， .......， primary key(id) ) 3.删除主键：alter table 表名 drop primary key; alter table sort drop primary key; 4."主键自动增长"：一般主键是"自增长的字段"，不需要指定。 "实现添加自增长语句,主键字段后加auto_increment(只适用MySQL)" 18常见表的操作12345678910* A:"查看表":"查看数据库中的所有表"： "格式：show tables;" "查看表结构"： 格式：desc 表名; 例如：desc sort;* B:"删除表" * "格式：drop table 表名;" 例如：drop table sort; 19修改表结构1234567891011121314151617181920212223242526272829303132333435* A: "修改表添加列" "alter table 表名 add 列名 类型(长度) 约束;" 例如： #1，为分类表添加一个新的字段为 分类描述 varchar(20) ALTER TABLE sort ADD sdesc VARCHAR(20);* B: "修改表修改列的类型长度及约束" "alter table 表名 modify 列名 类型(长度) 约束; " 例如： #2, 为分类表的分类名称字段进行修改，类型varchar(50) 添加约束 not null ALTER TABLE sort MODIFY sname VARCHAR(50) NOT NULL;* C: "修改表修改列名" "alter table 表名 change 旧列名 新列名 类型(长度) 约束; " 例如： #3, 为分类表的分类名称字段进行更换 更换为 snamesname varchar(30) ALTER TABLE sort CHANGE sname snamename VARCHAR(30);* D: "修改表删除列" "alter table 表名 drop 列名;" 例如： #4, 删除分类表中snamename这列 ALTER TABLE sort DROP snamename;* E: "修改表名" "rename table 表名 to 新表名; " 例如： #5, 为分类表sort 改名成 category RENAME TABLE sort TO category;* F: "修改表的字符集" "salter table 表名 character set 字符集;" 例如： #6, 为分类表 category 的编码表进行修改，修改成 gbk ALTER TABLE category CHARACTER SET gbk; 20数据表添加数据_112345678910* A: -- "向表中插入某些列"* 语法：insert into 表 (列名1,列名2,列名3..) values (值1,值2,值3..); * 举例:INSERT INTO product (id,pname,price) VALUES (1,'笔记本',5555.99);INSERT INTO product (id,pname,price) VALUES (2,'智能手机',9999);* 注意:列表,表名问题对应问题,个数,数据类型 21数据表添加数据_212345678910111213141516171819* A: "添加数据格式,不考虑主键"insert into 表名 (列名) values (值)* 举例:INSERT INTO product (pname,price) VALUE('洗衣机',800);* B: "添加数据格式,所有值全给出"格式insert into 表名 values (值1,值2,值3..); --向表中插入所有列INSERT INOT product VALUES (4,'微波炉',300.25);* C: "添加数据格式,批量写入"格式:insert into 表名 (列名1,列名2,列名3) values (值1,值2,值3),(值1,值2,值3)举例:INSERT INTO product (pname,price) VALUES('智能机器人',25999.22),('彩色电视',1250.36),('沙发',58899.02) 22更新数据12345678910111213141516171819202122232425262728293031* A: "用来修改指定条件的数据，将满足条件的记录指定列修改为指定值" 语法： "update 表名 set 字段名=值,字段名=值;" "update 表名 set 字段名=值,字段名=值 where 条件;" * B: 注意： * " 列名的类型与修改的值要一致. 修改值得时候不能超过最大长度. 值如果是字符串或者日期需要加’’. " * C: 例如： #1，将指定的sname字段中的值 修改成 日用品 UPDATE sort SET sname='日用品'; #2, 将sid为s002的记录中的sname改成 日用品 UPDATE sort SET sname='日用品' WHERE sid='s002'; UPDATE sort SET sname='日用品' WHERE sid='s003';update users set username='欧珀手机 R19',userprice=5612 where userid =3;"修改2行"：update users set username='欧珀手机 R19',userprice=5612 where userid =3 or userid=6;"修改多行"：update users set username='欧珀手机 R19',userprice=8888 where userid in (3,4,6);与 AND或 OR非 NOT等于 =不等于 &lt;&gt;小于等于 &lt;= where userid in (3,4,6) 表示()里的数据都采用 23删除数据12345678910111213141516* A: 语法：1、"delete from 表名 where 条件;" 2、"truncate table 表名;" * B: 面试题： 删除表中所有记录使用delete from 表名; 还是用truncate table 表名; "删除方式：delete 一条一条删除，不清空auto_increment记录数。" " truncate 直接将表删除，重新建表，auto_increment将置为零，从新开始。" * C: 例如： DELETE FROM sort WHERE sname='日用品'; "#表数据清空" DELETE FROM sort; 24命令行乱码问题12345678910111213141516171819A: 问题 我们在dos命令行操作中文时，会报错 insert into user(username,password) values(‘张三’,’123’); ERROR 1366 (HY000): Incorrect string value: '\xD5\xC5\xC8\xFD' for column 'username' at row 1B: 原因:因为mysql的客户端编码的问题我们的是utf8,而系统的cmd窗口编码是gbk1、解决方案（临时解决方案）:修改mysql客户端编码。 show variables like 'character%'; 查看所有mysql的编码 client connetion result 和客户端相关 database server system 和服务器端相关 "将客户端编码修改为gbk". "set character_set_results=gbk; / set names gbk;" 以上操作，"只针对当前窗口有效果"，如果关闭了服务器便失效。2、如果想要永久修改，通过以下方式: "在mysql安装目录下有my.ini文件" "default-character-set=gbk 客户端编码设置 " "character-set-server=utf8 服务器端编码设置" 注意:修改完成配置文件，重启服务 25数据表和测试数据准备123456789101112131415* A: 查询语句，在开发中使用的次数最多，此处使用“zhangwu” 账务表。 创建账务表： CREATE TABLE zhangwu ( id INT PRIMARY KEY AUTO_INCREMENT, -- 账务ID zname VARCHAR(200), -- 账务名称 zmoney DOUBLE -- 金额 ); * B: 插入表记录： INSERT INTO zhangwu(id,name,money) VALUES (1,'吃饭支出',247); INSERT INTO zhangwu(id,name,money) VALUES (2,'工资收入',12345); INSERT INTO zhangwu(id,name,money) VALUES (3,'服装支出',1000); INSERT INTO zhangwu(id,name,money) VALUES (4,'吃饭支出',325); INSERT INTO zhangwu(id,name,money) VALUES (5,'股票收入',8000); INSERT INTO zhangwu(id,name,money) VALUES (6,'打麻将支出',8000); INSERT INTO zhangwu(id,name,money) VALUES (7,null,5000); 26数据的基本查询1234567891011121314151617181920212223242526272829303132333435363738394041* A: "查询指定字段信息" "select 字段1,字段2,...from 表名;" 例如： select id,name from zhangwu;* B: "查询表中所有字段" "select * from 表名; " 例如： select * from zhangwu; 注意:使用"*"在练习、学习过程中可以使用，"在实际开发中，不推荐使用"。 原因，要查询的字段信息不明确，若字段数量很多，会导致查询速度很慢。* C: "distinct用于去除重复记录" "select distinct 字段 from 表名;" 例如： select distinct money from zhangwu;* D: "别名查询，使用的as关键字，as可以省略的." 别名可以给表中的字段，表设置别名。 当查询语句复杂时，使用别名可以极大的简便操作。 "表别名格式": "select * from 表名 as 别名;" 或 "select * from 表名 别名;" "列别名格式"： "select 字段名 as 别名 from 表名;" 或 "select 字段名 别名 from 表名;" 例如 表别名： select * from zhangwu as zw; 列别名： select money as m from zhangwu; select zname as '重新命名列' from zhangwu; 或 select money m from zhangwu; 我们在sql语句的操作中，可以直接对列进行运算。 例如：将所有账务的金额+10000元进行显示. SELECT DISTINCT zmoney+1000 as '资金求和' FROM zhangwu; 27数据的条件查询_11234567891011121314151617181920212223242526272829303132333435363738394041424344 * A:条件查询 "where语句表条件过滤"。满足条件操作，不满足不操作，多用于数据的查询与修改。 * B : 格式 : "select 字段 from 表名 where 条件;" * C: while条件的种类如下： 比较运算符 &gt; &lt; &lt;= &gt;= = &lt;&gt; ---------- 大于、小于、大于(小于)等于、"不等于"————————————————————————————————————————————————————————————————————————BETWEEN ...AND... ----------- 显示在某一区间的值("含头含尾")————————————————————————————————————————————————————————————————————————IN(set) -----------"显示在in列表中的值"，例：in(100,200)————————————————————————————————————————————————————————————————————————"LIKE 通配符" -----------"模糊查询"，Like语句中有两个通配符："% 用来匹配多个字符"；例first_name like ‘a%’;"_ 用来匹配一个字符"。例first_name like ‘a_’;————————————————————————————————————————————————————————————————————————IS NULL ------------判断是否为空is null; 判断为空is not null; 判断不为空————————————————————————————————————————————————————————————————————————* D 逻辑运算符 and ------------ 多个条件同时成立or ------------ 多个条件任一成立not ------------ 不成立，例：where not(salary&gt;100);* E: 例如：查询所有吃饭支出记录SELECT * FROM zhangwu WHERE name = '吃饭支出';查询出金额大于1000的信息SELECT * FROM zhangwu WHERE money &gt;1000;查询出金额在2000-5000之间的账务信息SELECT * FROM zhangwu WHERE money &gt;=2000 AND money &lt;=5000;或SELECT * FROM zhangwu WHERE money BETWEEN 2000 AND 5000;查询出金额是1000或5000或3500的商品信息SELECT * FROM zhangwu WHERE money =1000 OR money =5000 OR money =3500;或SELECT * FROM zhangwu WHERE money IN(1000,5000,3500); 28数据的条件查询_212345678910 * A "模糊查询" "查询出账务名称包含”支出”的账务信息。" SELECT * FROM zhangwu WHERE name LIKE "%支出%"; * B "查询出账务名称中是五个字的账务信息" SELECT * FROM gjp_ledger WHERE ldesc LIKE "_____"; -- 五个下划线_* C "查询出账务名称不为null账务信息" SELECT * FROM zhangwu WHERE name IS NOT NULL; SELECT * FROM zhangwu WHERE NOT (name IS NULL); 29排序查询123456789101112131415161718192021222324* A: 排序查询 使用格式 * "通过order by语句，可以将查询出的结果进行排序"。"放置在select语句的""最后"。 * "SELECT * FROM 表名 ORDER BY 字段ASC;" * ASC 升序 (默认) * DESC 降序 * B: 案例代码 /* 查询,对结果集进行排序 升序,降序,对指定列排序 order by 列名 [desc][asc] desc 降序 asc 升序排列,可以不写 */ -- 查询账务表,价格进行升序 "SELECT * FROM zhangwu ORDER BY zmoney ASC" -- 查询账务表,价格进行降序 SELECT * FROM zhangwu ORDER BY zmoney DESC -- 查询账务表,查询所有的支出,对金额降序排列 -- "先过滤条件 where 查询的结果再排序" SELECT * FROM zhangwu WHERE zname LIKE'%支出%' ORDER BY zmoney DESC 30聚合函数1234567891011121314151617181920212223242526272829303132* A: 聚合函数 * B: 函数介绍 * 之前我们做的查询都是横向查询，它们都是根据条件一行一行的进行判断，而使用聚合函数查询是纵向查询， 它是对一列的值进行计算，然后返回一个单一的值；另外聚合函数会忽略空值。 * count：统计指定列不为NULL的记录行数； * sum：计算指定列的数值和，如果指定列； * max：计算指定列的最大值，如果指定列是字符串类型，那么使用字符串类型不是数值类型，那么计算结果为0排0序运算； * min：计算指定列的最小值，如果指定列是字符串类型，那么使用字符串排序运算； * avg：计算指定列的平均值，如果指定列类型不是数值类型，那么计算结果为0；* C: 案例代码 /* 使用聚合函数查询计算 */ -- count 求和,对表中的数据的个数求和 count(列名) -- 查询统计账务表中,一共有多少条数据 SELECT COUNT(*)AS'count' FROM zhangwu -- sum求和,对一列中数据进行求和计算 sum(列名) -- 对账务表查询,对所有的金额求和计算 SELECT SUM(zmoney) FROM zhangwu -- 求和,统计所有支出的总金额 SELECT SUM(zname) FROM zhangwu WHERE zname LIKE'%收入%' INSERT INTO zhangwu (zname) VALUES ('彩票收入') -- max 函数,对某列数据,获取最大值 SELECT MAX(zmoney) FROM zhangwu -- avg 函数,计算一个列所有数据的平均数 SELECT AVG(zmoney)FROM zhangwu 31分组查询12345678910111213141516171819202122232425262728293031323334353637383940* A: 分组查询 * a: 使用格式 * "分组查询是指使用group by字句对查询信息进行分组",例如：我们要统计出zhanguw表中所有分类账务的总数量,这时就需要使用group by 来对zhangwu表中的账务信息根据parent进行分组操作。 * "* SELECT 字段1,字段2… FROM 表名 GROUP BY 字段 HAVING 条件;" * "分组操作中的having子语句"，"是用于在分组后对数据进行过滤的，作用类似于where条件"。 * b: having与where的区别 *" having是在"【分组后】"对数据进行过滤". * "where是在"【分组前】"对数据进行过滤" * having后面可以使用分组函数(统计函数) * where后面不可以使用分组函数。 * B: 案例代码 /* 查询所有的数据 吃饭支出 共计多少 工资收入 共计多少 服装支出 共计多少 股票收入 共计多少 打麻将支出 共计多少钱 分组查询: group by 被分组的列名 必须跟随聚合函数 select 查询的时候,被分组的列,要出现在select 选择列的后面 */ SELECT SUM(zmoney),zname FROM zhangwu GROUP BY zname -- 对zname内容进行分组查询求和,但是只要支出 SELECT SUM(zmoney)AS 'getsum',zname FROM zhangwu WHERE zname LIKE'%支出%' GROUP BY zname ORDER BY getsum DESC -- 对zname内容进行分组查询求和,但是只要支出, 显示金额大于5000 -- 结果集是分组查询后,再次进行筛选,不能使用where, 分组后再次过滤,关键字 having SELECT SUM(zmoney)AS 'getsum',zname FROM zhangwu WHERE zname LIKE'%支出%' GROUP BY zname HAVING getsum&gt;5000 32总结]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础25(多线程安全问题(同步、死锁)、等待唤醒机制)]]></title>
    <url>%2F2016%2F11%2F26%2Fday27%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、多线程安全问题2、等待唤醒机制 01线程操作共享数据的安全问题*A:线程操作共享数据的安全问题如果有多个线程在同时运行，而这些线程可能会同时运行这段代码。程序每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。 02售票的案例1234567891011121314151617181920212223242526272829303132333435363738394041424344*A:售票的案例 /* * 多线程并发访问同一个数据资源 * 3个线程,对一个票资源,出售 */public class ThreadDemo &#123; public static void main(String[] args) &#123; //创建Runnable接口实现类对象 Tickets t = new Tickets(); //创建3个Thread类对象,传递Runnable接口实现类 Thread t0 = new Thread(t); Thread t1 = new Thread(t); Thread t2 = new Thread(t); t0.start(); t1.start(); t2.start(); &#125; &#125;public class Tickets implements Runnable&#123; //定义出售的票源 private int ticket = 100; private Object obj = new Object(); public void run()&#123; while(true)&#123; if( ticket &gt; 0)&#123; //模拟产生安全问题 try &#123; Thread.sleep(1); &#125; catch (Exception ex)&#123; ex.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+" 出售第 "+ticket--); &#125; &#125; &#125; &#125; 03线程安全问题引发123456789101112131415161718192021222324252627282930313233343536373839404142*A:线程安全问题引发/* * 多线程并发访问同一个数据资源 * 3个线程,对一个票资源,出售 */public class ThreadDemo &#123; public static void main(String[] args) &#123; //创建Runnable接口实现类对象 Tickets t = new Tickets(); //创建3个Thread类对象,传递Runnable接口实现类 Thread t0 = new Thread(t); Thread t1 = new Thread(t); Thread t2 = new Thread(t); t0.start(); t1.start(); t2.start(); &#125;&#125;/* * 通过线程休眠,出现安全问题 */public class Tickets implements Runnable&#123; //定义出售的票源 private int ticket = 100; private Object obj = new Object(); public void run()&#123; while(true)&#123; //对票数判断,大于0,可以出售,变量--操作 if( ticket &gt; 0)&#123; try&#123; Thread.sleep(10); //加了休眠让其他线程有执行机会 &#125;catch(Exception ex)&#123;&#125; System.out.println(Thread.currentThread().getName()+" 出售第 "+ticket--); &#125; &#125; &#125;&#125; 04同步代码块解决线程安全问题线程同步的方式有两种： 方式1：同步代码块 方式2：同步方法 同步代码块中的锁对象可以是任意的对象；但多个线程时，要使用同一个锁对象才能够保证线程安全。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051*A:同步代码块解决线程安全问题 *A:售票的案例 /* * 多线程并发访问同一个数据资源 * 3个线程,对一个票资源,出售 */public class ThreadDemo &#123; public static void main(String[] args) &#123; //创建Runnable接口实现类对象 Tickets t = new Tickets(); //创建3个Thread类对象,传递Runnable接口实现类 Thread t0 = new Thread(t); Thread t1 = new Thread(t); Thread t2 = new Thread(t); t0.start(); t1.start(); t2.start(); &#125; &#125; "/* * 通过线程休眠,出现安全问题 * 解决安全问题,Java程序,提供技术,同步技术 * 公式: * synchronized(任意对象)&#123; * 线程要操作的共享数据 * &#125; * 同步代码块 */"public class Tickets implements Runnable&#123; //定义出售的票源 private int ticket = 100; private Object obj = new Object(); public void run()&#123; while(true)&#123; //线程共享数据,保证安全,加入同步代码块 synchronized(obj)&#123; //对票数判断,大于0,可以出售,变量--操作 if( ticket &gt; 0)&#123; try&#123; Thread.sleep(10); &#125;catch(Exception ex)&#123;&#125; System.out.println(Thread.currentThread().getName()+" 出售第 "+ticket--); &#125; &#125; &#125; &#125; &#125; 05同步代码块的执行原理A:同步代码块的执行原理同步代码块: 在代码块声明上 加上synchronizedsynchronized (锁对象) {可能会产生线程安全问题的代码} 同步代码块中的锁对象可以是任意的对象；但多个线程时，要使用同一个锁对象才能够保证线程安全。 06同步的上厕所原理*A:同步的上厕所原理a:不使用同步:线程在执行的过程中会被打扰线程比喻成人线程执行代码就是上一个厕所第一个人正在上厕所,上到一半,被另外一个人拉出来b:使用同步:线程比喻成人线程执行代码就是上一个厕所锁比喻成厕所门第一个人上厕所,会锁门第二个人上厕所,看到门锁上了,等待第一个人上完再去上厕所 07同步方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455*A:同步方法:/** 多线程并发访问同一个数据资源* 3个线程,对一个票资源,出售*/public class ThreadDemo &#123; public static void main(String[] args) &#123; //创建Runnable接口实现类对象 Tickets t = new Tickets(); //创建3个Thread类对象,传递Runnable接口实现类 Thread t0 = new Thread(t); Thread t1 = new Thread(t); Thread t2 = new Thread(t); t0.start(); t1.start(); t2.start(); &#125;&#125;*A:同步方法 "/* * 采用同步方法形式,解决线程的安全问题 * 好处: 代码简洁 * 将线程共享数据,和同步,抽取到一个方法中 * 在方法的声明上,加入同步关键字 * * 问题: * 同步方法有锁吗,肯定有,同步方法中的对象锁,是本类对象引用 this * 如果方法是静态的呢,同步有锁吗,绝对不是this * 锁是本类自己.class 属性 * 静态方法,同步锁,是本类类名.class属性 */"public class Tickets implements Runnable&#123; //定义出售的票源 private int ticket = 100; public void run()&#123; while(true)&#123; payTicket(); &#125; &#125; public synchronized void payTicket()&#123; if( ticket &gt; 0)&#123; try&#123; Thread.sleep(10); &#125;catch(Exception ex)&#123;&#125; System.out.println(Thread.currentThread().getName()+" 出售第 "+ticket--); &#125; &#125; &#125; 08JDK1.5新特性Lock接口,实现类ReentrantLockLock 实现提供了比使用 synchronized 方法和语句可获得的更广泛的锁定操作。此实现允许更灵活的结构，可以具有差别很大的属性，可以支持多个相关的 Condition 对象。 锁是控制多个线程对共享资源进行访问的工具。通常，锁提供了对共享资源的独占访问。一次只能有一个线程获得锁，对共享资源的所有访问都需要首先获得锁。不过，某些锁可能允许对共享资源并发访问，如 ReadWriteLock 的读取锁。 synchronized 方法或语句的使用提供了对与每个对象相关的隐式监视器锁的访问，但却强制所有锁获取和释放均要出现在一个块结构中：当获取了多个锁时，它们必须以相反的顺序释放，且必须在与所有锁被获取时相同的词法范围内释放所有锁。 虽然 synchronized 方法和语句的范围机制使得使用监视器锁编程方便了很多，而且还帮助避免了很多涉及到锁的常见编程错误，但有时也需要以更为灵活的方式使用锁。例如，某些遍历并发访问的数据结果的算法要求使用 “hand-over-hand” 或 “chain locking”：获取节点 A 的锁，然后再获取节点 B 的锁，然后释放 A 并获取 C，然后释放 B 并获取 D，依此类推。Lock 接口的实现允许锁在不同的作用范围内获取和释放，并允许以任何顺序获取和释放多个锁，从而支持使用这种技术。 随着灵活性的增加，也带来了更多的责任。不使用块结构锁就失去了使用 synchronized 方法和语句时会出现的锁自动释放功能。在大多数情况下，应该使用以下语句： 1234567Lock l = ...; l.lock(); try &#123; // access the resource protected by this lock &#125; finally &#123; l.unlock();//最后必须释放锁 &#125; 1234567*A:JDK1.5新特性Lock接口 查阅API，查阅Lock接口描述，Lock 实现提供了比使用 synchronized 方法和语句可获得的更广泛的锁定操作。  Lock接口中的常用方法 void lock() void unlock() Lock提供了一个更加面对对象的锁，在该锁中提供了更多的操作锁的功能。 我们使用Lock接口,以及其中的lock()方法和unlock()方法替代同步，对电影院卖票案例中Ticket 09利用Lock接口实现类ReentrantLock改进售票案例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253*A:Lock接口改进售票案例 /* * 多线程并发访问同一个数据资源 * 3个线程,对一个票资源,出售 */public class ThreadDemo &#123; public static void main(String[] args) &#123; //创建Runnable接口实现类对象 Tickets t = new Tickets(); //创建3个Thread类对象,传递Runnable接口实现类 Thread t0 = new Thread(t); Thread t1 = new Thread(t); Thread t2 = new Thread(t); t0.start(); t1.start(); t2.start(); &#125; &#125; "/* * 使用JDK1.5 的接口Lock,替换同步代码块,实现线程的安全性 * Lock接口方法: * lock() 获取锁 * unlock()释放锁 * 实现类ReentrantLock */" public class Tickets implements Runnable&#123; //定义出售的票源 private int ticket = 100; //在类的成员位置,创建Lock接口的实现类对象 private Lock lock = new ReentrantLock(); public void run()&#123; while(true)&#123; //调用Lock接口方法lock获取锁 lock.lock(); //对票数判断,大于0,可以出售,变量--操作 if( ticket &gt; 0)&#123; try&#123; Thread.sleep(10); System.out.println(Thread.currentThread().getName()+" 出售第 "+ticket--); &#125;catch(Exception ex)&#123; &#125;finally&#123; ////最后必须释放锁,调用Lock接口方法unlock lock.unlock(); &#125; &#125; &#125; &#125; &#125; 10线程的死锁原理*A:线程的死锁原理当线程任务中出现了多个同步(多个锁) 时，如果同步中嵌套了其他的同步。这时容易引发一种现象：程序出现无限等待，这种现象我们称为死锁。这种情况能避免就避免掉。 12345synchronzied(A锁)&#123; synchronized(B锁)&#123; &#125;&#125; 11线程的死锁代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051*A:线程的死锁代码实现 public class LockA &#123; private LockA()&#123;&#125; public static final LockA locka = new LockA(); &#125; public class LockB &#123; private LockB()&#123;&#125; public static final LockB lockb = new LockB(); &#125; public class DeadLockDemo &#123; public static void main(String[] args) &#123; DeadLock dead = new DeadLock(); Thread t0 = new Thread(dead); Thread t1 = new Thread(dead); t0.start(); t1.start(); &#125; &#125;public class DeadLock implements Runnable&#123; private int i = 0; public void run()&#123; while(true)&#123; if(i%2==0)&#123; //先进入A同步,再进入B同步 synchronized(LockA.locka)&#123; System.out.println("if...locka"); synchronized(LockB.lockb)&#123; System.out.println("if...lockb"); &#125; &#125; &#125;else&#123; //先进入B同步,再进入A同步 synchronized(LockB.lockb)&#123; System.out.println("else...lockb"); synchronized(LockA.locka)&#123; System.out.println("else...locka"); &#125; &#125; &#125; i++; &#125; &#125; &#125; 打印效果之一：if … lockaif … lockbelse … lockbif … locka这是因为：Thread t0 = new Thread(dead);Thread t1 = new Thread(dead);2个线程都执行了DeadLock程序的内容，即2个线程可以共享DeadLock中同一锁对象LockA.locka，和LockB.lockb 在线程1执行完if语句后，进入else语句执行完B同步，正准备执行A同步时，这时线程2突然抢占了资源，执行了if语句中的A同步，准备执行B同步; 即这时线程1获得了B同步的锁对象LockB.lockb；而线程2获得了A同步的锁对象LockA.locka，导致线程1没有A同步的锁对象，无法执行A同步；线程2没有B同步的锁对象，无法执行B同步,陷入死锁 12线程等待与唤醒案例介绍线程之间的通信：多个线程在处理同一个资源，但是处理的动作（线程的任务）却不相同通过一定的手段使各个线程能有效的利用资源。而这种手段即—— 等待唤醒机制。*A:线程等待与唤醒案例介绍 等待唤醒机制所涉及到的方法：  wait（） :等待，将正在执行的线程释放其执行资格 和 执行权，并存储到线程池中。  notify（）：唤醒，唤醒线程池中被wait（）的线程，一次唤醒一个，而且是任意的。  notifyAll（）： 唤醒全部：可以将线程池中的所有wait() 线程都唤醒。 其实，所谓唤醒的意思就是让 线程池中的线程具备执行资格。必须注意的是，这些方法都是在 同步中才有效。同时这些方法在使用时必须标明所属锁，这样才可以明确出这些方法操作的到底是哪个锁上的线程。 13线程等待与唤醒案例资源类编写123456789101112*A:线程等待与唤醒案例资源类编写/* * 定义资源类,有2个成员变量 * name,sex * 同时有2个线程,对资源中的变量操作 * 1个对name,age赋值 * 2个对name,age做变量的输出打印 */public class Resource &#123; public String name; public String sex;&#125; 14线程等待与唤醒案例输入和输出线程123456789101112131415161718192021222324252627282930313233343536A:线程等待与唤醒案例输入和输出线程 /* * 输入的线程,对资源对象Resource中成员变量赋值 * 一次赋值 张三,男 * 下一次赋值 lisi,nv */ public class Input implements Runnable &#123; private Resource r=new Resource(); public void run() &#123; int i=0; while(true)&#123; if(i%2==0)&#123; r.name="张三"; r.sex="男"; &#125;else&#123; r.name="lisi"; r.sex="女"; &#125; i++; &#125; &#125; &#125; /* * 输出线程,对资源对象Resource中成员变量,输出值 */ public class Output implements Runnable &#123; private Resource r=new Resource() ; public void run() &#123; while(true)&#123; System.out.println(r.name+"..."+r.sex); &#125; &#125; &#125; 15线程等待与唤醒案例测试类12345678910111213141516171819A:线程等待与唤醒案例测试类 /* * 开启输入线程和输出线程,实现赋值和打印值 */ public class ThreadDemo&#123; public static void main(String[] args) &#123; Resource r = new Resource(); Input in = new Input(); Output out = new Output(); Thread tin = new Thread(in); Thread tout = new Thread(out); tin.start(); tout.start(); &#125; &#125; 16线程等待与唤醒案例null值解决12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061A:线程等待与唤醒案例null值解决/** 输入的线程,对资源对象Resource中成员变量赋值* 一次赋值 张三,男* 下一次赋值 lisi,nv*/public class Input implements Runnable &#123; private Resource r; public Input(Resource r)&#123; this.r=r; &#125; public void run() &#123; int i=0; while(true)&#123; if(i%2==0)&#123; r.name="张三"; r.sex="男"; &#125;else&#123; r.name="lisi" r.sex="女" &#125; i++; &#125; &#125;&#125;/** 输出线程,对资源对象Resource中成员变量,输出值*/ public class Output implements Runnable &#123; private Resource r; public Output(Resource r)&#123; this.r=r; &#125; public void run() &#123; while(true)&#123; System.out.println(r.name+"..."+r.sex); &#125; &#125; &#125;&#125;/** 开启输入线程和输出线程,实现赋值和打印值*/public class ThreadDemo&#123; public static void main(String[] args) &#123; Resource r = new Resource(); Input in = new Input(r); Output out = new Output(r); Thread tin = new Thread(in); Thread tout = new Thread(out); tin.start(); tout.start(); &#125;&#125; 17线程等待与唤醒案例数据安全解决1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465A:线程等待与唤醒案例数据安全解决/* * 输入的线程,对资源对象Resource中成员变量赋值 * 一次赋值 张三,男 * 下一次赋值 lisi,nv*/public class Input implements Runnable &#123; private Resource r; public Input(Resource r)&#123; this.r=r; &#125; public void run() &#123; int i=0; while(true)&#123; synchronized(r)&#123; if(i%2==0)&#123; r.name="张三"; r.sex="男"; &#125;else&#123; r.name="lisi" r.sex="女" &#125; i++; &#125; &#125; &#125; /* * 输出线程,对资源对象Resource中成员变量,输出值 */ public class Output implements Runnable &#123; private Resource r; public Output(Resource r)&#123; this.r=r; &#125; public void run() &#123; while(true)&#123; synchronized(r)&#123; System.out.println(r.name+"..."+r.sex); &#125; &#125; &#125; &#125; &#125; /* * 开启输入线程和输出线程,实现赋值和打印值 */public class ThreadDemo&#123; public static void main(String[] args) &#123; Resource r = new Resource(); Input in = new Input(r); Output out = new Output(r); Thread tin = new Thread(in); Thread tout = new Thread(out); tin.start(); tout.start(); &#125; &#125; 18线程等待与唤醒案例通信的分析*A:线程等待与唤醒案例通信的分析输入: 赋值后,执行方法wait()永远等待输出: 变量值打印输出,在输出等待之前,唤醒【输入】的notify(),自己在wait()永远等待输入: 被唤醒后,重新对变量赋值,赋值后,必须唤醒【输出】的线程notify(),自己的wait() 19线程等待与唤醒案例的实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697*A 线程等待与唤醒案例的实现 /* * 定义资源类,有2个成员变量 * name,sex * 同时有2个线程,对资源中的变量操作 * 1个对name,age赋值 * 2个对name,age做变量的输出打印 */public class Resource &#123; public String name; public String sex; public boolean flag = false; &#125; /* * 输入的线程,对资源对象Resource中成员变量赋值 * 一次赋值 张三,男 * 下一次赋值 lisi,nv */public class Input implements Runnable &#123; private Resource r ; public Input(Resource r)&#123; this.r = r; &#125; public void run() &#123; int i = 0 ; while(true)&#123; synchronized(r)&#123; //标记是true,等待 if(r.flag)&#123; try&#123;r.wait();&#125;catch(Exception ex)&#123;&#125; &#125; if(i%2==0)&#123; r.name = "张三"; r.sex = "男"; &#125;else&#123; r.name = "lisi"; r.sex = "nv"; &#125; //将对方线程唤醒,标记改为true r.flag = true; r.notify(); &#125; i++; &#125; &#125; &#125; /* * 输出线程,对资源对象Resource中成员变量,输出值 */public class Output implements Runnable &#123; private Resource r ; public Output(Resource r)&#123; this.r = r; &#125; public void run() &#123; while(true)&#123; synchronized(r)&#123; //判断标记,是false,等待 if(!r.flag)&#123; try&#123;r.wait();&#125;catch(Exception ex)&#123;&#125; &#125; System.out.println(r.name+".."+r.sex); //标记改成false,唤醒对方线程 r.flag = false; r.notify(); &#125; &#125; &#125; &#125; /* * 开启输入线程和输出线程,实现赋值和打印值 */public class ThreadDemo&#123; public static void main(String[] args) &#123; Resource r = new Resource(); Input in = new Input(r); Output out = new Output(r); Thread tin = new Thread(in); Thread tout = new Thread(out); tin.start(); tout.start(); &#125; &#125; 20总结1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 同步锁"多个线程"想保证线程安全，必须要使用"同一个锁对象" 同步代码块 synchronized (锁对象)&#123; 可能产生线程安全问题的代码&#125;同步代码块的"锁对象"可以是"任意(Object)的对象" 同步方法 public synchronized void method()&#123; 可能产生线程安全问题的代码 &#125; 同步方法中的锁对象是 this 静态同步方法public synchronized void method()&#123; 可能产生线程安全问题的代码&#125;"静态同步方法中的锁对象"是 类名.class 多线程有几种实现方案，分别是哪几种?" a, 继承Thread类 b, 实现Runnable接口 c, 通过线程池，实现Callable接口" 同步有几种方式，分别是什么?" a,同步代码块 b,同步方法 静态同步方法" 启动一个线程是run()还是start()?它们的区别?" 启动一个线程是start() 区别： start： 启动线程，并调用线程中的run()方法 run : 执行该线程对象要执行的任务" void test()  sleep()和wait()方法的区别 sleep: 不释放锁对象, 释放CPU使用权 在休眠的时间内，不能唤醒 wait(): 释放锁对象, 释放CPU使用权 在等待的时间内，能唤醒 为什么wait(),notify(),notifyAll()等方法都定义在Object类中 锁对象可以是任意类型的对象]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础24(多线程及其创建方式、线程池)]]></title>
    <url>%2F2016%2F11%2F20%2Fday26%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、多线程(Thread线程类、Runnable接口)2、线程池(ExecutorService：线程池类) 01进程概念*A:进程概念 a:进程：进程指正在运行的程序。确切的来说，当一个程序进入内存运行，即变成一个进程，进程是处于运行过程中的程序，并且具有一定独立功能。 02线程的概念 *A:线程的概念 a:线程：线程是进程中的一个执行单元(执行路径)，负责当前进程中程序的执行， 一个进程中至少有一个线程。一个进程中是可以有多个线程的， 这个应用程序也可以称之为多线程程序。 简而言之：一个程序运行后至少有一个进程，一个进程中可以包含多个线程 03深入线程的概念A:深入线程的概念什么是多线程呢？ 即就是一个程序中有多个线程在同时执行。 一个核心的CPU在多个线程之间进行着随即切换动作,由于切换时间很短(毫秒甚至是纳秒级别),导致我们感觉不出来 单线程程序：即，若有多个任务只能依次执行。当上一个任务执行结束后，下一个任务开始执行。如去网吧上网，网吧只能让一个人上网，当这个人下机后，下一个人才能上网。多线程程序：即，若有多个任务可以同时执行。如，去网吧上网，网吧能够让多个人同时上网。 04迅雷的多线程下载 A:迅雷的多线程下载 多线程,每个线程都读一个文件 05线程的运行模式A:线程的运行模式a:分时调度 所有线程轮流使用 CPU 的使用权，平均分配每个线程占用 CPU 的时间。 b:抢占式调度 优先让优先级高的线程使用 CPU，如果线程的优先级相同，那么会随机选择一个(线程随机性)，Java使用的为抢占式调度。 大部分操作系统都支持多进程并发运行，现在的操作系统几乎都支持同时运行多个程序。 比如：现在我们上课一边使用编辑器，一边使用录屏软件，同时还开着画图板，dos窗口等软件。 此时，这些程序是在同时运行，”感觉这些软件好像在同一时刻运行着“。 实际上，CPU(中央处理器)使用抢占式调度模式在多个线程间进行着高速的切换。 对于CPU的一个核而言，某个时刻，只能执行一个线程， 而 CPU的在多个线程间切换速度相对我们的感觉要快，看上去就是在同一时刻运行。 其实，多线程程序并不能提高程序的运行速度，但能够提高程序运行效率，让CPU的使用率更高。 06main的主线程jvm启动后，必然有一个执行路径(线程)从main方法开始的，一直执行到main方法结束，这个线程在java中称之为主线程 : thread “main”。当程序的主线程执行时，如果遇到了循环而导致程序在指定位置停留时间过长，则无法马上执行下面的程序，需要等待循环结束后能够执行。1234567891011121314151617*A:main的主线程 /* * 程序中的主线程 */ public class Demo &#123; public static void main(String[] args) &#123; System.out.println(0/0); function(); System.out.println(Math.abs(-9)); &#125; public static void function()&#123; for(int i = 0 ; i &lt; 10000;i++)&#123; System.out.println(i); &#125; &#125; &#125; 07 Thread 类和Runnable 接口介绍A:Thread类介绍:Thread是程序中的执行线程。Java 虚拟机允许应用程序并发地运行多个执行线程。 发现创建新执行线程有两种方法。 a:一种方法是将类声明为 Thread 的子类。 该子类应重写 Thread 类的 run 方法。创建对象，开启线程。run方法相当于其他线程的main方法。 b:另一种方法是声明一个实现 Runnable 接口的类。该类然后实现 run 方法。 然后创建Runnable的子类对象，传入到某个线程的构造方法中，开启线程。 创建新执行线程有两种方法。一种方法是将类声明为 Thread 的子类。该子类应重写 Thread 类的 run 方法。接下来可以分配并启动该子类的实例。例如，计算大于某一规定值的质数的线程可以写成： 1234567891011class PrimeThread extends Thread &#123; long minPrime; PrimeThread(long minPrime) &#123; this.minPrime = minPrime; &#125; public void run() &#123; // compute primes larger than minPrime . . . &#125; &#125; 然后，下列代码会创建并启动一个线程,必须用start()方法： 12PrimeThread p = new PrimeThread(143);p.start(); 创建线程的另一种方法是声明实现 Runnable 接口的类。该类然后实现 run 方法。然后可以分配该类的实例，在创建 Thread 时作为一个参数来传递并启动。采用这种风格的同一个例子如下所示： 1234567891011class PrimeRun implements Runnable &#123; long minPrime; PrimeRun(long minPrime) &#123; this.minPrime = minPrime; &#125; public void run() &#123; // compute primes larger than minPrime . . . &#125;&#125; 然后，下列代码会创建并启动一个线程： 12PrimeRun p = new PrimeRun(143);new Thread(p).start(); 08实现线程程序继承Thread线程对象调用 run方法和调用start方法区别？线程对象调用run方法不开启线程。仅是对象调用方法。线程对象调用start开启线程，并让jvm调用run方法在开启的线程中执行。 1234567891011121314151617181920212223242526272829*A:实现线程程序继承Thread /* * 创建和启动一个线程 * 创建Thread子类对象 * 子类对象调用方法start() * 让线程程序执行,JVM调用线程中的run */ public class ThreadDemo &#123; public static void main(String[] args) &#123; SubThread st = new SubThread(); SubThread st1 = new SubThread(); st.start(); st1.start(); for(int i = 0; i &lt; 50;i++)&#123; System.out.println("main..."+i); &#125; &#125; &#125; /* * 定义子类,继承Thread * 重写方法run */ public class SubThread extends Thread&#123; public void run()&#123; for(int i = 0; i &lt; 50;i++)&#123; System.out.println("run..."+i); &#125; &#125; &#125; 09线程执行的随机性12345678910111213141516171819202122232425262728293031323334353637383940*A:线程执行的随机性 * 代码分析: 整个程序就只有三个线程, 一个是主线程 启动另外两个线程 st.start(); st1.start(); for(int i = 0; i &lt; 50;i++)&#123; System.out.println("main..."+i); &#125; 一个是st(Thread-0)线程 for(int i = 0; i &lt; 50;i++)&#123; System.out.println("run..."+i); &#125; 一个是st1(Thread-1)线程下 * public class ThreadDemo &#123; public static void main(String[] args) &#123; SubThread st = new SubThread(); SubThread st1 = new SubThread(); st.start(); st1.start(); for(int i = 0; i &lt; 50;i++)&#123; System.out.println("main..."+i); &#125; &#125; &#125; /* * 定义子类,继承Thread * 重写方法run */ public class SubThread extends Thread&#123; public void run()&#123; for(int i = 0; i &lt; 50;i++)&#123; System.out.println("run..."+i); &#125; &#125; &#125; 10为什么要继承Thread*A:什么要继承Threada:我们为什么要继承Thread类，并调用其的start方法才能开启线程呢？ 继承Thread类：因为Thread类用来描述线程，具备线程应该有功能。那为什么不直接创建Thread类的对象呢？ 如下代码： Thread t1 = new Thread(); t1.start();//这样做没有错，但是该start调用的是Thread类中的run方法 //而这个run方法没有做什么事情，更重要的是这个run方法中并没有定义我们需要让线程执行的代码。Thread类run方法中的任务并不是我们所需要的，只有重写这个run方法。既然Thread类已经定义了线程任务的编写位置（run方法），那么只要在编写位置（run方法）中定义任务代码即可。所以进行了重写run方法动作 b:创建线程的目的是什么？ 是为了建立程序单独的执行路径，让多部分代码实现同时执行。也就是说线程创建并执行需要给定线程要执行的任务。 对于之前所讲的主线程，它的任务定义在main函数中。自定义线程需要执行的任务都定义在run方法中。 11多线程内存图解*A:多线程内存图解 多线程执行时，到底在内存中是如何运行的呢？多线程执行时，在栈内存中，其实每一个执行线程都有一片自己所属的栈内存空间。进行方法的压栈和弹栈。当执行线程的任务结束了，线程自动在栈内存中释放了。但是当所有的执行线程都结束了，那么进程就结束了。 12获取线程名字Thread类方法getName123456789101112131415161718192021222324252627282930313233*A:获取线程名字Thread类方法getName /* * 获取线程名字,父类Thread方法 * String getName() */ public class NameThread extends Thread&#123; public NameThread()&#123; super("小强"); &#125; public void run()&#123; System.out.println(getName()); &#125; &#125; "/* * 每个线程,都有自己的名字 * 运行方法main线程,名字就是"main" * 其他新键的线程也有名字,默认 "Thread-0","Thread-1" * * JVM开启主线程,运行方法main,主线程也是线程,是线程必然就是 * Thread类对象 */" public class ThreadDemo &#123; public static void main(String[] args) &#123; NameThread nt = new NameThread(); nt.start(); &#125; &#125; 13获取线程名字Thread类方法currentThread12345678910111213141516171819202122232425262728293031323334*A:获取线程名字Thread类方法currentThread /* * 获取线程名字,父类Thread方法 * String getName() */ public class NameThread extends Thread&#123; public void run()&#123; System.out.println(getName()); &#125; &#125; * * 每个线程,都有自己的名字 * 运行方法main线程,名字就是"main" * 其他新键的线程也有名字,默认 "Thread-0","Thread-1" * * JVM开启主线程,运行方法main,主线程也是线程,是线程必然就是 * Thread类对象 * Thread类中,静态方法 * static Thread currentThread()返回正在执行的线程对象 * public class ThreadDemo &#123; public static void main(String[] args) &#123; NameThread nt = new NameThread(); nt.start(); /*Thread t =Thread.currentThread(); System.out.println(t.getName());*/ System.out.println(Thread.currentThread().getName()); &#125; &#125; 14线程名字设置12345678910111213141516171819202122232425262728293031323334A:线程名字设置 "/* * 获取线程名字,父类Thread方法 * String getName() */" public class NameThread extends Thread&#123; public NameThread()&#123; super("小强"); &#125; public void run()&#123; System.out.println(getName()); &#125; &#125; "/* * 每个线程,都有自己的名字 * 运行方法main线程,名字就是"main" * 其他新键的线程也有名字,默认 "Thread-0","Thread-1" * * JVM开启主线程,运行方法main,主线程也是线程,是线程必然就是 * Thread类对象 * Thread类中,静态方法 * static Thread currentThread()返回正在执行的线程对象 */" public class ThreadDemo &#123; public static void main(String[] args) &#123; NameThread nt = new NameThread(); nt.setName("旺财"); nt.start(); &#125; &#125; 15Thread类方法sleep123456789101112131415161718192021222324A:Thread类方法sleep public class ThreadDemo &#123; public static void main(String[] args) throws Exception&#123; /*for(int i = 0 ; i &lt; 5 ;i++)&#123; Thread.sleep(50); System.out.println(i); &#125;*/ new SleepThread().start(); &#125; &#125; public class SleepThread extends Thread&#123; public void run()&#123; for(int i = 0 ; i &lt; 5 ;i++)&#123; try&#123; Thread.sleep(500);//睡眠500ms,500ms已到并且cpu切换到该线程继续向下执行 &#125;catch(Exception ex)&#123; &#125; System.out.println(i); &#125; &#125; &#125; 16实现线程的另一种方式实现Runnable接口12345678910111213141516171819202122232425262728A:实现线程的另一种方式实现Runnable接口 "/* * 实现接口方式的线程 * 创建Thread类对象,构造方法中,传递Runnable接口实现类 * 调用Thread类方法start() */" public class ThreadDemo &#123; public static void main(String[] args) &#123; SubRunnable sr = new SubRunnable(); Thread t = new Thread(sr); t.start(); for(int i = 0 ; i &lt; 50; i++)&#123; System.out.println("main..."+i); &#125; &#125; &#125; "/* * 实现线程成功的另一个方式,接口实现 * 实现接口Runnable,重写run方法 */" public class SubRunnable implements Runnable&#123; public void run()&#123; for(int i = 0 ; i &lt; 50; i++)&#123; System.out.println("run..."+i); &#125; &#125; &#125; 17实现Runnable接口方式的原理和好处A:实现接口方式的原理为什么需要定一个类去实现Runnable接口呢？继承Thread类和实现Runnable接口有啥区别呢？实现Runnable接口，避免了继承Thread类的单继承局限性。覆盖Runnable接口中的run方法，将线程任务代码定义到run方法中。创建Thread类的对象，只有创建Thread类的对象才可以创建线程。线程任务已被封装到Runnable接口的run方法中，而这个run方法所属于Runnable接口的子类对象，所以将这个子类对象作为参数传递给Thread的构造函数，这样，线程对象创建时就可以明确要运行的线程的任务。 B:实现接口方式的好处 第二种方式实现Runnable接口避免了单继承的局限性，所以较为常用。 实现Runnable接口的方式，更加的符合面向对象，线程分为两部分，一部分线程对象，一部分线程任务。 继承Thread类，线程对象和线程任务耦合在一起。 一旦创建Thread类的子类对象，既是线程对象，有又有线程任务。 实现runnable接口，将线程任务单独分离出来封装成对象，类型就是Runnable接口类型。Runnable接口对线程对象和线程任务进行解耦。 (降低紧密性或者依赖性,创建线程和执行任务不绑定) 18匿名内部类实现线程程序1234567891011121314151617181920212223242526272829303132333435*A:匿名内部类实现线程程序 /* * 使用匿名内部类,实现多线程程序 * 前提: 继承或者接口实现 * new 父类或者接口()&#123; * 重写抽象方法 * &#125; */public class ThreadDemo &#123; public static void main(String[] args) &#123; //继承方式 XXX extends Thread&#123; public void run()&#123;&#125;&#125; new Thread()&#123; public void run()&#123; System.out.println("!!!"); &#125; &#125;.start(); //实现接口方式 XXX implements Runnable&#123; public void run()&#123;&#125;&#125; Runnable r = new Runnable()&#123; public void run()&#123; System.out.println("###"); &#125; &#125;; new Thread(r).start(); new Thread(new Runnable()&#123; public void run()&#123; System.out.println("@@@"); &#125; &#125;).start(); &#125;&#125; 19线程的状态图 A:线程的状态图 20线程池的原理线程池，其实就是一个容纳多个线程的容器，其中的线程可以反复使用，省去了频繁创建线程对象的操作，无需反复创建线程而消耗过多资源。 A:线程池的原理 1.在java中，如果每个请求到达就创建一个新线程，开销是相当大的。 2.在实际使用中，创建和销毁线程花费的时间和消耗的系统资源都相当大， 甚至可能要比在处理实际的用户请求的时间和资源要多的多。 3.除了创建和销毁线程的开销之外，活动的线程也需要消耗系统资源。 如果在一个jvm里创建太多的线程，可能会使系统由于过度消耗内存或“切换过度”而导致系统资源不足。 为了防止资源不足，需要采取一些办法来限制任何给定时刻处理的请求数目， 尽可能减少创建和销毁线程的次数，特别是一些资源耗费比较大的线程的创建和销毁，尽量利用已有对象来进行服务。 线程池主要用来解决线程生命周期开销问题和资源不足问题。 通过对多个任务重复使用线程，线程创建的开销就被分摊到了多个任务上了，而且由于在请求到达时线程已经存在， 所以消除了线程创建所带来的延迟。这样，就可以立即为请求服务，使用应用程序响应更快。 另外，通过适当的调整线程中的线程数目可以防止出现资源不足的情况。 21JDK5实现线程池1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859通常，线程池都是通过线程池工厂创建，再调用线程池中的方法获取线程，再通过线程去执行任务方法。  Executors：线程池创建"工厂类" public static ExecutorService newFixedThreadPool(int nThreads)：返回线程池对象 ExecutorService：线程池类 Future&lt;?&gt; submit(Runnable task)：获取线程池中的某一个线程对象，并执行 Future接口：用来记录线程任务执行完毕后产生的结果。线程池创建与使用 使用线程池中线程对象的步骤： 创建线程池对象 创建Runnable接口子类对象 提交Runnable接口子类对象 关闭线程池 A:JDK5实现线程池public static ExecutorService newFixedThreadPool(int nThreads)创建一个可重用固定线程数的线程池，以共享的(无界队列方式)来运行这些线程。在任意点，在(大多数) nThreads 线程会处于(处理任务的活动状态)。如果在所有线程处于活动状态时提交附加任务，(则在有可用线程之前），（附加任务将在队列中等待）。如果在关闭前的执行期间由于失败而导致任何线程终止，那么一个新线程将代替它执行后续的任务（如果需要）。（在某个线程被显式地关闭之前），（池中的线程将一直存在）。 参数：nThreads - （池中的线程数） 返回：新创建的线程池 * * JDK1.5新特性,实现线程池程序 * 使用工厂类 Executors中的静态方法创建线程对象,指定线程的个数 * static ExecutorService newFixedThreadPool(int 个数) 返回线程池对象 * 返回的是ExecutorService接口的实现类 (线程池对象) * * 接口实现类对象,调用方法submit (Ruunable r) 提交线程执行任务 * * public class ThreadPoolDemo &#123; public static void main(String[] args) &#123; "//调用工厂类的静态方法,创建线程池对象" "//返回线程池对象,是返回的接口" ExecutorService es = Executors.newFixedThreadPool(2); "//调用接口实现类对象es中的方法submit提交线程任务" "//将Runnable接口实现类对象,传递" es.submit(new ThreadPoolRunnable()); es.submit(new ThreadPoolRunnable()); "//如果线程池大小为2，第3个线程则会等待在前2个线程结束之后才运行" es.submit(new ThreadPoolRunnable()); "注意：submit方法调用结束后，程序并不终止，是因为线程池控制了线程的关闭。将使用完的线程又归还到了线程池中" //关闭线程池 //es.shutdown(); &#125; &#125; public class ThreadPoolRunnable implements Runnable &#123; public void run()&#123; System.out.println(Thread.currentThread().getName()+" 线程提交任务"); &#125; &#125; 22实现线程的Callable接口方式12345678910111213141516171819202122232425262728293031323334353637383940414243Callable接口：与Runnable接口功能相似，用来指定线程的任务。其中的call()方法，用来返回线程任务执行完毕后的结果，call方法可抛出异常。ExecutorService：线程池类&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task)：获取线程池中的某一个线程对象，并执行线程中的call()方法Future接口：用来记录线程任务执行完毕后产生的结果。线程池创建与使用使用线程池中线程对象的步骤：创建线程池对象创建Callable接口子类对象提交Callable接口子类对象关闭线程池 A:实现线程的Callable接口方式 * * 实现线程程序的第三个方式,实现Callable接口方式 * 实现步骤 * 工厂类 Executors静态方法public static ExecutorService newFixedThreadPool(int nThreads)： * 利用newFixedThreadPool方法,创建线程池对象 * 线程池对象ExecutorService接口实现类,调用方法submit提交线程任务 * Future&lt;?&gt; submit(Callable c) * public class ThreadPoolDemo1 &#123; public static void main(String[] args)throws Exception &#123; ExecutorService es = Executors.newFixedThreadPool(2); "//提交线程任务的方法submit方法返回 Future接口的实现类" Future&lt;String&gt; f = es.submit(new ThreadPoolCallable()); String s = f.get(); System.out.println(s); &#125; &#125; /* * Callable 接口的实现类,作为线程提交任务出现 * 使用方法返回值 */ import java.util.concurrent.Callable; public class ThreadPoolCallable implements Callable&lt;String&gt;&#123; public String call()&#123; return "abc"; &#125; &#125; 23线程实现异步计算123456789101112131415161718192021222324252627282930313233A:线程实现异步计算 /* * 使用多线程技术,求和 * 两个线程,1个线程计算1+100,另一个线程计算1+200的和 * 多线程的异步计算 */ public class ThreadPoolDemo &#123; public static void main(String[] args)throws Exception &#123; ExecutorService es = Executors.newFixedThreadPool(2); Future&lt;Integer&gt; f1 =es.submit(new GetSumCallable(100)); Future&lt;Integer&gt; f2 =es.submit(new GetSumCallable(200)); System.out.println(f1.get()); System.out.println(f2.get()); es.shutdown(); &#125; &#125; public class GetSumCallable implements Callable&lt;Integer&gt;&#123; private int a; public GetSumCallable(int a)&#123; this.a=a; &#125; public Integer call()&#123; int sum = 0 ; for(int i = 1 ; i &lt;=a ; i++)&#123; sum = sum + i ; &#125; return sum; &#125; &#125; 总结1234567891011121314151617181920212223242526272829303132333435363738394041创建线程的方式方式1，继承Thread线程类步骤 1， 自定义类继承Thread类 2， 在自定义类中重写Thread类的run方法 3， 创建自定义类对象(线程对象) 4， 调用start方法，启动线程，通过JVM，调用线程中的run方法方式2，实现Runnable接口步骤 1， 创建线程任务类 实现Runnable接口 2， 在线程任务类中 重写接口中的run方法 3， 创建线程任务类对象 4， 创建线程对象，把线程任务类对象作为Thread类构造方法的参数使用 5， 调用start方法，启动线程，通过JVM，调用线程任务类中的run方法方式3和4 线程池：&gt;&gt;&gt;&gt;1、通过Runnable接口，run()方法没有返回值通常，线程池都是通过线程池工厂创建，再调用线程池中的方法获取线程，再通过线程去执行任务方法。  Executors：线程池创建"工厂类" public static ExecutorService newFixedThreadPool(int nThreads)：返回线程池对象 ExecutorService：线程池类 Future&lt;?&gt; submit(Runnable task)：获取线程池中的某一个线程对象，并执行 Future接口：用来记录线程任务执行完毕后产生的结果。线程池创建与使用 使用线程池中线程对象的步骤： 创建线程池对象 创建Runnable接口子类对象 提交Runnable接口子类对象 关闭线程池&gt;&gt;&gt;&gt;2、通过Callable接口，call()方法有返回值ExecutorService：线程池类&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task)：获取线程池中的某一个线程对象，并执行线程中的call()方法Future接口：用来记录线程任务执行完毕后产生的结果。线程池创建与使用使用线程池中线程对象的步骤：创建线程池对象创建Callable接口子类对象提交Callable接口子类对象关闭线程池]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础23(Properties集合,序列化流与反序列化流,打印流)]]></title>
    <url>%2F2016%2F11%2F19%2Fday25%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、Properties集合2、序列化流与反序列化流3、打印流4、commons-IO 01Properties集合的特点 A: Properties集合的特点 a: Properties类介绍 Properties 类表示了一个持久的属性集。Properties 可保存在流中或从流中加载。属性列表中每个键及其对应值都是一个字符串 b: 特点 Hashtable的子类，map集合中的方法都可以用。 该集合没有泛型。键值都是字符串。 它是一个可以持久化的属性集。键值可以存储到集合中，也可以存储到持久化的设备(硬盘、U盘、光盘)上。键值的来源也可以是持久化的设备。 有和流技术相结合的方法。 c: 方法介绍 123456789101112 void test()* load(InputStream inputStream) * 把指定流所对应的文件中的数据，读取出来，保存到Propertie集合中* load(Reader reader) * 按简单的面向行的格式从输入字符流中读取属性列表（键和元素对）* store(OutputStream outputStream,String commonts) * 把集合中的数据，保存到指定的流所对应的文件中，参数commonts代表对描述信息* stroe(Writer writer,String comments) * 以适合使用 load(Reader) 方法的格式，将此 Properties 表中的属性列表（键和元素对）写入输出字符 02Properties集合存储键值对123456789101112131415161718192021222324252627282930313233343536* A: Properties集合存储键值对 * a: 方法介绍 void test() * 集合对象Properties类,继承Hashtable,实现Map接口 * 可以和IO对象结合使用,实现数据的持久存储 * 使用Properties集合,存储键值对 * setProperty等同与Map接口中的put * setProperty(String key, String value) * 通过键获取值, getProperty(String key)* b: 案例代码public class PropertiesDemo &#123; public static void main(String[] args)throws IOException &#123; function_2(); &#125; /* * 使用Properties集合,存储键值对 * setProperty等同与Map接口中的put * setProperty(String key, String value) * 通过键获取值, getProperty(String key) */ public static void function()&#123; Properties pro = new Properties(); pro.setProperty("a", "1"); pro.setProperty("b", "2"); pro.setProperty("c", "3"); System.out.println(pro); String value = pro.getProperty("c"); System.out.println(value); //方法stringPropertyNames,将集合中的键存储到Set集合,类似于Map接口的方法keySet Set&lt;String&gt; set = pro.stringPropertyNames(); for(String key : set)&#123; System.out.println(key+"..."+pro.getProperty(key)); &#125; &#125;&#125; 03Properties集合的方法load123456789101112131415161718192021222324252627282930* A: Properties集合的方法load* a: 方法介绍 void test() * Properties集合特有方法 load * load(InputStream in)) * load(Reader r) * 传递任意的字节或者字符输入流 * 流对象读取文件中的键值对,保存到集合 * b: 案例代码 public class PropertiesDemo &#123; public static void main(String[] args)throws IOException &#123; function_1(); &#125; /* * Properties集合特有方法 load * load(InputStream in) * load(Reader r) * 传递任意的字节或者字符输入流 * 流对象读取文件中的键值对,保存到集合 */ public static void function_1()throws IOException&#123; Properties pro = new Properties(); FileReader fr = new FileReader("c:\\pro.properties"); //调用集合的方法load,传递字符输入流 pro.load(fr); fr.close(); System.out.println(pro); &#125; &#125; 04Properties集合的方法store12345678910111213141516171819202122232425262728* A: Properties集合的方法store* a: 方法介绍 void test() * Properties集合的特有方法store * store(OutputStream out,String comments) * store(Writer w,String comments) * 接收所有的字节或者字符的输出流,将集合中的键值对,写回文件中保存* b: 案例代码 public class PropertiesDemo &#123; public static void main(String[] args)throws IOException &#123; function_2(); &#125; /* * Properties集合的特有方法store * store(OutputStream out) * store(Writer w) * 接收所有的字节或者字符的输出流,将集合中的键值对,写回文件中保存 */ public static void function_2()throws IOException&#123; Properties pro = new Properties(); pro.setProperty("name", "zhangsan"); pro.setProperty("age", "31"); pro.setProperty("email", "123456789@163.com"); FileWriter fw = new FileWriter("c:\\pro.properties"); //键值对,存回文件,使用集合的方法store传递字符输出流 pro.store(fw, ""); fw.close(); &#125; &#125; 05对象的序列化与反序列化 A: 对象的序列化与反序列化 a: 基本概念 对象的序列化 对象中的数据，以流的形式，写入到文件中保存过程称为写出对象，对象的序列化 ObjectOutputStream将对象写道文件中，实现序列化 对象的反序列化 在文件中，以流的形式，将对象读出来，读取对象，对象的反序列化 ObjectInputStream 将文件对象读取出来，对象的反序列化 06ObjectOutputStream流写对象12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061* A: ObjectOutputStream流写对象* a: 简单介绍 void test() * IO流对象,实现对象Person序列化,和反序列化 * ObjectOutputStream 写对象,实现序列化 * ObjectInputStream 读取对象,实现反序列化 ObjectOutputStream流构造方法: ObjectOutputStream(OutputStream out) * final void writeObject(Object obj) 将指定的对象写入 ObjectOutputStream。* b: 案例代码 public class Person implements Serializable&#123; public String name; public int age; public Person(String name, int age) &#123; super(); this.name = name; this.age = age; &#125; public Person()&#123;&#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Person [name=" + name + ", age=" + age + "]"; &#125; &#125; public class ObjectStreamDemo &#123; public static void main(String[] args)throws IOException, ClassNotFoundException &#123; // writeObject(); readObject(); &#125; /* * ObjectOutputStream * 构造方法: ObjectOutputStream(OutputSteam out) * 传递任意的字节输出流 * void writeObject(Object obj)写出对象的方法 */ public static void writeObject() throws IOException&#123; //创建字节输出流,封装文件 FileOutputStream fos = new FileOutputStream("c:\\person.txt"); //创建写出对象的序列化流的对象,构造方法传递字节输出流 ObjectOutputStream oos = new ObjectOutputStream(fos); Person p = new Person("lisi",25); //调用序列化流的方法writeObject,写出对象 oos.writeObject(p); oos.close(); &#125; &#125; 07ObjectInputStream流读取对象1234567891011121314151617181920212223242526272829303132* A: ObjectInputStream流读取对象* a: 简单介绍 void test() * ObjectInputStream * 构造方法:ObjectInputStream(InputStream in) * 传递任意的字节输入流,输入流封装文件,必须是序列化的文件 * Object readObject() 读取对象* b: 案例代码 /* * IO流对象,实现对象Person序列化,和反序列化 * ObjectOutputStream 写对象,实现序列化 * ObjectInputStream 读取对象,实现反序列化 */ public class ObjectStreamDemo &#123; public static void main(String[] args)throws IOException, ClassNotFoundException &#123; readObject(); &#125; /* * ObjectInputStream * 构造方法:ObjectInputStream(InputStream in) * 传递任意的字节输入流,输入流封装文件,必须是序列化的文件 * Object readObject() 读取对象 */ public static void readObject() throws IOException, ClassNotFoundException&#123; FileInputStream fis = new FileInputStream("c:\\person.txt"); //创建反序列化流,构造方法中,传递字节输入流 ObjectInputStream ois = new ObjectInputStream(fis); //调用反序列化流的方法 readObject()读取对象 Object obj =ois.readObject(); System.out.println(obj); ois.close(); &#125; &#125; 08静态不能序列化 A: 静态不能序列化 a: 原因 序列化是把对象数据进行持久化存储 静态不属于对象，而属于类 09transient 瞬态关键字 A: transient关键字 a: 作用 被transient修饰的属性不会被序列化 transient关键字只能修饰成员变量 10Serializable接口的含义 A：Serializable接口的含义 a: 作用 给需要序列化的类上加标记。该标记中没有任何抽象方法 只有实现了 Serializable接口的类的对象才能被序列化 11序列化中的序列号冲突问题 A: 序列化中的序列号冲突问题 a: 问题产生原因 当一个类实现Serializable接口后，创建对象并将对象写入文件，之后更改了源代码(比如：将成员变量的修饰符有private改成public)， 再次从文件中读取对象时会报异常 12序列化中自定义的序列号 A: 序列化中自定义的序列号 a: 定义方式 private static final long serialVersionUID = 1478652478456L; 这样每次编译类时生成的serialVersionUID值都是固定的 b: 案例代码 123456789101112131415161718192021222324252627282930public class Person implements Serializable&#123; public String name; public /*transient阻止成员变量序列化*/ int age; //类,自定义了序列号,编译器不会计算序列号 private static final long serialVersionUID = 1478652478456L; public Person(String name, int age) &#123; super(); this.name = name; this.age = age; &#125; public Person()&#123;&#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Person [name=" + name + ", age=" + age + "]"; &#125; &#125; 13打印流和特性123456789101112131415161718192021* A: 打印流和特性* a: 概述 void test() * 打印流添加输出数据的功能，使它们能够方便地打印各种数据值表示形式. * 打印流根据流的分类： * 字节打印流 PrintStream * 字符打印流 PrintWriter * 方法： * void print(String str): 输出任意类型的数据， * void println(String str): 输出任意类型的数据，自动写入换行操作* b: 特点 * 此流不负责数据源,只负责数据目的 * 为其他输出流,添加功能 * 永远不会抛出IOException，但是可能抛出别的异常 * 两个打印流的方法,完全一致 * 构造方法,就是打印流的输出目的端——————————————————————————————————————————————————————————————————————————————————————————————— * PrintStream() 构造方法 * 接收File类型,接收字符串文件名,接收字节输出流OutputStream * PrintWriter() 构造方法 * (接收File类型,接收字符串文件名,接收字节输出流OutputStream, 接收字符输出流Writer)——————————————————————————————————————————————————————————————————————————————————————————————— 14打印流输出目的是File对象12345678910111213141516171819202122* A: 打印流输出目的是File对象* a: 案例代码 public class PrintWriterDemo &#123; public static void main(String[] args) throws IOException &#123; function_3(); &#125; * * 打印流,向File对象的数据目的写入数据 * "方法print println 原样输出" * "write方法走码表" * public static void function() throws FileNotFoundException&#123; File file = new File("c:\\1.txt"); PrintWriter pw = new PrintWriter(file); pw.println(true);// true pw.println(100);// 100 pw.write(100);// d pw.close(); &#125; &#125; 15输出语句是char数组123456789101112131415161718* A: 输出语句是char数组* a: 案例代码 public class Demo &#123; public static void main(String[] args) &#123; int[] arr = &#123;1&#125;; System.out.println(arr); char[] ch = &#123;'a','b'&#125;; System.out.println(ch);//打印 ab byte[] b = &#123;&#125;; System.out.println(b); &#125; &#125;* b: 结果分析* println数组，只有打印字符数组时只有容，其余均打印数组的地址 * 因为api中"定义了打印字符数组"的方法，其底层是在"遍历数组中的元素" * 而其他打印数组的方法，都是将数组对象编程Object，其底层再将对象编程String，调用了String s = String.valueOf(x);方法 16打印流输出目的是String和流对象123456789101112131415161718192021222324252627282930* A: 打印流输出目的是String和流对象* a: 案例代码 public class PrintWriterDemo &#123; public static void main(String[] args) throws IOException &#123; function_2(); &#125; /* * 打印流,输出目的,是流对象 * 可以是字节输出流,可以是字符的输出流 * OutputStream Writer */ public static void function_2() throws IOException&#123; // FileOutputStream fos = new FileOutputStream("c:\\3.txt"); FileWriter fw = new FileWriter("c:\\4.txt"); PrintWriter pw = new PrintWriter(fw); pw.println("打印流"); pw.close(); &#125; /* * 打印流,输出目的,String文件名 */ public static void function_1() throws FileNotFoundException&#123; PrintWriter pw = new PrintWriter("c:\\2.txt"); pw.println(3.5); pw.close(); &#125; &#125; 17打印流开启自动刷新123456789101112131415161718192021222324* A: 打印流开启自动刷新* 案例代码 public class PrintWriterDemo &#123; public static void main(String[] args) throws IOException &#123; function_3(); &#125; "/* * 打印流,可以开启自动刷新功能 * 满足2个条件: * 1. 输出的数据目的必须是流对象 * OutputStream Writer * 2. 必须调用println,printf,format三个方法中的一个,启用自动刷新 */" public static void function_3()throws IOException&#123; //File f = new File("XXX.txt"); FileOutputStream fos = new FileOutputStream("c:\\5.txt"); PrintWriter pw = new PrintWriter(fos,true); pw.println("i"); pw.println("love"); pw.println("java"); pw.close(); &#125; &#125; 18打印流复制文本文件12345678910111213141516171819* A: 打印流复制文本文件* a: 案例代码 "/* * 打印流实现文本复制 * 读取数据源 BufferedReader+File 读取文本行 * 写入数据目的 PrintWriter+println 自动刷新 */" public class PrintWriterDemo1 &#123; public static void main(String[] args) throws IOException&#123; BufferedReader bfr = new BufferedReader(new FileReader("c:\\a.txt")); PrintWriter pw = new PrintWriter(new FileWriter("d:\\a.txt"),true); String line = null; while((line = bfr.readLine())!=null)&#123; pw.println(line); &#125; pw.close(); bfr.close(); &#125; &#125; 19commons-io工具类介绍 A: commons-io工具类介绍 a: 工具类介绍 解压缩commons-io-2.4.zip文件 commons-io-2.4.jar需要导入到项目中的jar包，里面存放的是class文件 commons-io-2.4-sources.jar工具类中原代码 docs是帮助文档 20使用工具类commons_io A: 使用工具类commons_io a: 导入jar包 加入classpath的第三方jar包内的class文件才能在项目中使用 创建lib文件夹 将commons-io.jar拷贝到lib文件夹 右键点击commons-io.jar，Build Path→Add to Build Pathidea 是 Add as Libirary b: 学会如何看源代码,需要添加source文件：commons-io-2.4-sources.jar 21IO工具类FilenameUtils123456789101112131415161718192021222324252627282930313233343536373839404142* A: IO工具类FilenameUtils* a: 方法介绍 void test() * getExtension(String path)：获取文件的扩展名； * getName()：获取文件名； * isExtension(String fileName,String ext)：判断fileName是否是ext后缀名；* b: 案例代码* public class Commons_IODemo &#123; public static void main(String[] args) &#123; function_2(); &#125; /* * FilenameUtils类的方法 * static boolean isExtension(String filename,String extension) * 判断文件名的后缀是不是extension */ public static void function_2()&#123; boolean b = FilenameUtils.isExtension("Demo.java", "java"); System.out.println(b); &#125; /* * FilenameUtils类的方法 * static String getName(String filename) * 获取文件名 */ public static void function_1()&#123; String name = FilenameUtils.getName("c:\\windows\\"); System.out.println(name); &#125; /* * FilenameUtils类的方法 * static String getExtension(String filename) * 获取文件名的扩展名 */ public static void function()&#123; String name = FilenameUtils.getExtension("c:\\windows"); System.out.println(name); &#125; &#125; 22IO工具类FileUtils123456789101112131415161718192021222324252627282930313233343536373839404142434445464748* A: IO工具类FileUtils* a: 方法介绍 void test() * readFileToString(File file)：读取文件内容，并返回一个String； * writeStringToFile(File file，String content)：将内容content写入到file中； * copyDirectoryToDirectory(File srcDir,File destDir);文件夹复制 * copyFile(File srcFile,File destFile);文件复制 * b: 案例代码public class Commons_IODemo1 &#123; public static void main(String[] args)throws IOException &#123; function_3(); &#125; /* * FileUtils工具类方法 * static void copyDirectoryToDirectory(File src,File desc) * 复制文件夹 */ public static void function_3() throws IOException&#123; FileUtils.copyDirectoryToDirectory(new File("d:\\demo"), new File("c:\\")); &#125; /* * FileUtils工具类的方法 * static void copyFile(File src,File desc) * 复制文件 */ public static void function_2() throws IOException&#123; FileUtils.copyFile(new File("c:\\k.jpg"),new File("d:\\k.jpg")); &#125; /* * FileUtils工具类的方法 * static void writeStringToFile(File src,String date) * 将字符串直接写到文件中 */ public static void function_1() throws IOException&#123; FileUtils.writeStringToFile(new File("c:\\b.txt"),"我爱Java编程"); &#125; /* * FileUtils工具类的方法 * static String readFileToString(File src)读取文本,返回字符串 */ public static void function() throws IOException&#123; String s = FileUtils.readFileToString(new File("c:\\a.txt")); System.out.println(s); &#125;&#125; 23总结123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101 void test() 字节流  字节输入流 InputStream  FileInputStream() 操作文件的字节输入流  BufferedInputStream()高效的字节输入流  ObjectInputStream() 反序列化流  字节输出流 OutputStram  FileOutputStream() 操作文件的字节输出流  BufferedOutputStream() 高效的字节输出流  ObjectOuputStream() 序列化流  PrintStream() 字节打印流 字符流  字符输入流 Reader  FileReader()操作文件的字符输入流  BufferedReader() 高效的字符输入流  InputStreamReader() 输入操作的转换流(把字节流封装成字符流)  字符输出流 Writer  FileWriter()操作文件的字符输出流  BufferedWriter() 高效的字符输出流  OutputStreamWriter() 输出操作的转换流(把字节流封装成字符流)  PrintWriter() 字符打印流 方法： 读数据方法：  read() 一次读一个字节或字符的方法  read(byte[] char[]) 一次读一个数组数据的方法  readLine() 一次读一行字符串的方法(BufferedReader类特有方法)  readObject() 从流中读取对象(ObjectInputStream特有方法) 写数据方法：  write(int) 一次写一个字节或字符到文件中  write(byte[] char[]) 一次写一个数组数据到文件中  write(String) 一次写一个字符串内容到文件中  writeObject(Object ) 写对象到流中(ObjectOutputStream类特有方法)  newLine() 写一个换行符号(BufferedWriter类特有方法) 向文件中写入数据的过程 1，创建输出流对象 2，写数据到文件 3，关闭输出流 从文件中读数据的过程 1， 创建输入流对象 2， 从文件中读数据 3， 关闭输入流 文件复制的过程 1， 创建输入流（数据源） 2， 创建输出流（目的地） 3， 从输入流中读数据 4， 通过输出流，把数据写入目的地 5， 关闭流 File类 方法  获取文件名称 getName()  获取文件绝对路径 getAbsolutePath()  获取文件大小 length()  获取当前文件夹中所有File对象 File[] listFiles()  判断是否为文件 isFile()  判断是否为文件夹 isDirectory()  创建文件夹 mkdir() mkdirs()  创建文件 createNewFile() 异常  try..catch…finally捕获处理异常  throws 声明异常  throw 抛出异常对象 异常的分类  编译期异常 Exception |- 运行期异常 RuntimeException 注意： 编译期异常，必须处理，不然无法编译通过 运行期异常，程序运行过程中，产生的异常信息 Properties：Map集合的一种，它是Hashtable集合的子集合, 它键与值都是String类型,它是唯一能与IO流结合使用的集合 方法  load( InputStream in ) 从流所对应的文件中，读数据到集合中  load( Reader in ) 从流所对应的文件中，读数据到集合中  store( OutputStream out , String message ) 把集合中的数据，写入到流所对应的文件中  store( Writer out , String message) 把集合中的数据，写入到流所对应的文件中 实现文件内容的自动追加  构造方法  FileOutputStream(File file, boolean append)  FileOutputStream(String fileName, boolean append)  FileWriter(File, boolean append)  FileWriter(String fileName, boolean append) 实现文件内容的自动刷新  构造方法  PrintStream(OutputStream out, boolean autoFlush)  PrintWriter(OutputStream out, boolean autoFlush)  PrintWriter(Writer out, boolean autoFlush) Commons-IO 方法  readFileToString(File file)：读取文件内容，并返回一个String；  writeStringToFile(File file，String content)：将内容content写入到file中；  copyDirectoryToDirectory(File srcDir,File destDir);文件夹复制  copyFileToDirectory (File srcFile,File destFile);文件复制]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础22(转换流,缓冲流)]]></title>
    <url>%2F2016%2F11%2F18%2Fday24%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、转换流2、缓冲流 01转换流概述 A: 转换流概述 a: 转换流概述 FileReader、FileWriter是在默认字符编码和默认字节缓冲区大小的情况下进行的，对于需要编码转换的情况不太方便。 OutputStreamWriter 是字符流通向字节流的桥梁：可使用指定的字符编码表，将要写入流中的字符编码成字节 将字符串按照指定的编码表转成字节，再使用字节流将这些字节写出去 02转换流_字符转字节的过程 OutputStreamWriter A: 转换流_字符转字节的过程 OutputStreamWriter 是字符流通向字节流的桥梁：可使用指定的字符编码表，将要写入流中的字符编码成字节。它的作用的就是，将字符串按照指定的编码表转成字节，在使用字节流将这些字节写出去。 03OutputStreamWriter写文本文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849* A: OutputStreamWriter写文本文件* a: OutputStreamWriter * java.io.OutputStreamWriter 继承Writer类 * 就是一个字符输出流，写文本文件 * write()字符，字符数组，字符串 * 字符通向字节的桥梁，将字符流转字节流 * OutputStreamWriter 使用方式 * void test() * 构造方法： * OutputStreamWriter(OuputStream out)接收所有的字节输出流 * 字节输出流： FileOutputStream * OutputStreamWriter(OutputStream out, String charsetName) * String charsetName 传递编码表名字 GBK UTF-8 * OutputStreamWriter 有个子类， FileWriter* b: 案例代码public class OutputStreamWriterDemo &#123; public static void main(String[] args)throws IOException &#123;// writeGBK(); writeUTF(); &#125; /* * 转换流对象OutputStreamWriter写文本 * 采用UTF-8编码表写入 */ public static void writeUTF()throws IOException&#123; //创建字节输出流，绑定文件 FileOutputStream fos = new FileOutputStream("c:\\utf.txt"); //创建转换流对象，构造方法保证字节输出流，并指定编码表是UTF-8 OutputStreamWriter osw = new OutputStreamWriter(fos,"UTF-8"); osw.write("你好"); osw.close(); &#125; /* * 转换流对象 OutputStreamWriter写文本 * 文本采用GBK的形式写入 */ public static void writeGBK()throws IOException&#123; //创建字节输出流，绑定数据文件 FileOutputStream fos = new FileOutputStream("c:\\gbk.txt"); //创建转换流对象，构造方法，绑定字节输出流，使用GBK编码表 OutputStreamWriter osw = new OutputStreamWriter(fos); //转换流写数据 osw.write("你好"); osw.close(); &#125;&#125; 04转换流_字节转字符流过程 InputSteamReader1234567891011121314* A: 转换流_字节转字符流过程* a: InputStreamReader * java.io.InputStreamReader 继承 Reader * 字符输入流，读取文本文件 * 字节流向字符的敲了，将字节流转字符流 * 读取的方法: * read() 读取1个字符，读取字符数组 * 技巧 void test() * OuputStreamWriter写了文件 * InputStreamReader读取文件 * OutputStreamWriter(OutputStream out)所有字节输出流 * InputStreamReader(InputStream in) 接收所有的字节输入流 * 可以传递的字节输入流： FileInputStream * InputStreamReader(InputStream in,String charsetName) 传递编码表的名字 b: 图解 05InputSteamReader读取文本文件12345678910111213141516171819202122232425262728293031323334353637* A: InputSteamReader读取文本文件* a: 案例代码 public class InputStreamReaderDemo &#123; public static void main(String[] args) throws IOException &#123; // readGBK(); readUTF(); &#125; /* * 转换流,InputSteamReader读取文本 * 采用UTF-8编码表,读取文件utf */ public static void readUTF()throws IOException&#123; //创建自己输入流,传递文本文件 FileInputStream fis = new FileInputStream("c:\\utf.txt"); //创建转换流对象,构造方法中,包装字节输入流,同时写编码表名 InputStreamReader isr = new InputStreamReader(fis,"UTF-8"); char[] ch = new char[1024]; int len = isr.read(ch); System.out.println(new String(ch,0,len)); isr.close(); &#125; /* * 转换流,InputSteamReader读取文本 * 采用系统默认编码表,读取GBK文件 */ public static void readGBK()throws IOException&#123; //创建自己输入流,传递文本文件 FileInputStream fis = new FileInputStream("c:\\gbk.txt"); //创建转换流对象,构造方法,包装字节输入流 InputStreamReader isr = new InputStreamReader(fis); char[] ch = new char[1024]; int len = isr.read(ch); System.out.println(new String(ch,0,len)); isr.close(); &#125; &#125; 06转换流子类父类的区别123456789101112131415* A: 转换流子类父类的区别* a: 继承关系 OutputStreamWriter: |--FileWriter: InputStreamReader: |--FileReader;* b: 区别* OutputStreamWriter和InputStreamReader是"字符和字节"的桥梁：也可以称之为"字符转换流"。* "字符转换流原理：字节流+编码表"。* FileWriter和FileReader：作为子类，仅作为操作字符文件的便捷类存在。 "当操作的字符文件，使用的是默认编码表时可以不用父类"，而直接用子类就完成操作了，简化了代码。* 以下三句话功能相同 * InputStreamReader isr = new InputStreamReader(new FileInputStream("a.txt"));//默认字符集。 * InputStreamReader isr = new InputStreamReader(new FileInputStream("a.txt"),"GBK");//指定GBK字符集。 * FileReader fr = new FileReader("a.txt"); 07缓冲流概述 A: 缓冲流概述 a: 概述 可提高IO流的读写速度 分为字节缓冲流与字符缓冲流 08字节输出流缓冲流BufferedOutputStream123456789101112131415161718192021222324252627282930* A: 字节输出流缓冲流BufferedOutputStream* a: BufferedOutputStream * 字节输出流的缓冲流 void test() * java.io.BufferedOuputStream 作用: 提高原有输出流的写入效率 * BufferedOuputStream 继承 OutputStream * 方法,写入 write 字节,字节数组 * 构造方法: * BufferedOuputStream(OuputStream out) * 可以传递任意的字节输出流, 传递的是哪个字节流,就对哪个字节流提高效率 * b: 案例代码public class BufferedOutputStreamDemo &#123; public static void main(String[] args)throws IOException &#123; //创建字节输出流,绑定文件 //FileOutputStream fos = new FileOutputStream("c:\\buffer.txt"); //创建字节输出流缓冲流的对象,构造方法中,传递字节输出流 BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream("c:\\buffer.txt")); bos.write(55); byte[] bytes = "HelloWorld".getBytes(); bos.write(bytes); bos.write(bytes, 3, 2); bos.close(); &#125;&#125; 09字节输入流缓冲流BufferedInputStream1234567891011121314151617181920212223* A: 字节输入流缓冲流BufferedInputStream* a: BufferedInputStream * 字节输入流的缓冲流 void test() * 继承InputStream,标准的字节输入流 * 读取方法 read() 单个字节,字节数组 * 构造方法: * BufferedInputStream(InputStream in) * 可以传递任意的字节输入流,传递是谁,就提高谁的效率 * 可以传递的字节输入流 FileInputStream* b: 案例代码public class BufferedInputStreamDemo &#123; public static void main(String[] args) throws IOException&#123; //创建字节输入流的缓冲流对象,构造方法中包装字节输入流,包装文件 BufferedInputStream bis = new BufferedInputStream(new FileInputStream("c:\\buffer.txt")); byte[] bytes = new byte[10]; int len = 0 ; while((len = bis.read(bytes))!=-1)&#123; System.out.print(new String(bytes,0,len)); &#125; bis.close(); &#125;&#125; 10四种文件复制方式的效率比较 A：四种文件复制方式的效率比较 a: 四中复制方式 字节流读写单个字节 125250 毫秒 字节流读写字节数组 193 毫秒 OK 字节流缓冲区流读写单个字节 1210 毫秒 字节流缓冲区流读写字节数组 73 毫秒 OK b: 案例代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class Copy &#123; public static void main(String[] args)throws IOException &#123; long s = System.currentTimeMillis(); copy_4(new File("c:\\q.exe"), new File("d:\\q.exe")); long e = System.currentTimeMillis(); System.out.println(e-s); &#125; "/* * 方法,实现文件复制 * 4. 字节流缓冲区流读写字节数组 */" public static void copy_4(File src,File desc)throws IOException&#123; BufferedInputStream bis = new BufferedInputStream(new FileInputStream(src)); BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(desc)); int len = 0 ; byte[] bytes = new byte[1024]; while((len = bis.read(bytes))!=-1)&#123; bos.write(bytes,0,len); &#125; bos.close(); bis.close(); &#125; /* * 方法,实现文件复制 * 3. 字节流缓冲区流读写单个字节 */ public static void copy_3(File src,File desc)throws IOException&#123; BufferedInputStream bis = new BufferedInputStream(new FileInputStream(src)); BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(desc)); int len = 0 ; while((len = bis.read())!=-1)&#123; bos.write(len); &#125; bos.close(); bis.close(); &#125; /* * 方法,实现文件复制 * 2. 字节流读写字节数组 */ public static void copy_2(File src,File desc)throws IOException&#123; FileInputStream fis = new FileInputStream(src); FileOutputStream fos = new FileOutputStream(desc); int len = 0 ; byte[] bytes = new byte[1024]; while((len = fis.read(bytes))!=-1)&#123; fos.write(bytes,0,len); &#125; fos.close(); fis.close(); &#125; /* * 方法,实现文件复制 * 1. 字节流读写单个字节 */ public static void copy_1(File src,File desc)throws IOException&#123; FileInputStream fis = new FileInputStream(src); FileOutputStream fos = new FileOutputStream(desc); int len = 0 ; while((len = fis.read())!=-1)&#123; fos.write(len); &#125; fos.close(); fis.close(); &#125;&#125; 11字符输出流缓冲流BufferedWriter123456789101112131415161718192021222324252627282930313233343536373839* A: 字符输出流缓冲流BufferedWriter* a: BufferedWriter * 字符输出流缓冲区流 * java.io.BufferedWriter 继承 Writer * 写入方法 write () 单个字符,字符数组,字符串 * 构造方法: * BufferedWriter(Writer w)传递任意字符输出流 * 传递谁,就高效谁 * 能传递的字符输出流 FileWriter, OutputStreamWriter* b: 案例代码 public class BufferedWrierDemo &#123; public static void main(String[] args) throws IOException&#123; //创建字符输出流,封装文件 FileWriter fw = new FileWriter("c:\\buffer.txt"); BufferedWriter bfw = new BufferedWriter(fw); bfw.write(100); bfw.flush(); bfw.write("你好".toCharArray()); bfw.flush(); bfw.write("你好"); bfw.flush(); bfw.write("我好好"); bfw.flush(); bfw.write("大家都好"); bfw.flush(); bfw.close(); &#125; &#125; 12字符输出流缓冲流BufferedWriter特有方法newLine12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849* A: 字符输出流缓冲流BufferedWriter特有方法newLine* a: 方法介绍 * void newLine() 写换行 * newLine()文本中换行, \r\n也是文本换行 * 方法具有平台无关性 * Windows \r\n * Linux \n * newLine()运行结果,和操作系统是相互关系 * JVM: 安装的是Windows版本,newLine()写的就是\r\n * 安装的是Linux版本,newLine()写的就是\n /* * 将数据源 c:\\a.txt * 复制到 d:\\a.txt 数据目的 * 字节输入流,绑定数据源 * 字节输出流,绑定数据目的 * * 输入,读取1个字节 * 输出,写1个字节 */* b: 案例代码 public class BufferedWrierDemo &#123; public static void main(String[] args) throws IOException&#123; //创建字符输出流,封装文件 FileWriter fw = new FileWriter("c:\\buffer.txt"); BufferedWriter bfw = new BufferedWriter(fw); bfw.write(100); bfw.flush(); bfw.write("你好".toCharArray()); bfw.flush(); bfw.write("你好"); bfw.newLine(); bfw.flush(); bfw.write("我好好"); bfw.newLine(); bfw.flush(); bfw.write("大家都好"); bfw.flush(); bfw.close(); &#125; &#125; 13字符输入流缓冲流BufferedReader A: 字符输入流缓冲流BufferedReader a: 概述 从字符输入流中读取文本，缓冲各个字符，从而实现字符、数组和行的高效读取 public String readLine() 读取一个文本行，包含该行内容的字符串，不包含任何行终止符，如果已到达流末尾，则返回 null 14字符输入流缓冲流BufferedReader读取文本行123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051* A: 字符输入流缓冲流BufferedReader读取文本行* a: BufferedReader * 字符输入流缓冲流 * java.io.BufferedReader 继承 Reader * 读取功能 read() 单个字符,字符数组 * 构造方法: * BufferedReader(Reader r) * 可以任意的字符输入流 FileReader InputStreamReader * BufferedReader自己的功能 * String readLine() 读取文本行 \r\n * 方法读取到流末尾,返回null* b: 小特点 * 获取内容的方法一般都有返回值 * int 没有返回的都是负数 * 引用类型 找不到返回null * boolean 找不到返回false * c: 案例代码 public class BufferedReaderDemo &#123; public static void main(String[] args) throws IOException &#123; int lineNumber = 0; //创建字符输入流缓冲流对象,构造方法传递字符输入流,包装数据源文件 BufferedReader bfr = new BufferedReader(new FileReader("c:\\a.txt")); //调用缓冲流的方法 readLine()读取文本行 //循环读取文本行, 结束条件 readLine()返回null String line = null; while((line = bfr.readLine())!=null)&#123; lineNumber++; System.out.println(lineNumber+" "+line); &#125; bfr.close(); &#125; &#125; /* * String line = bfr.readLine(); System.out.println(line); line = bfr.readLine(); System.out.println(line); line = bfr.readLine(); System.out.println(line); line = bfr.readLine(); System.out.println(line); line = bfr.readLine(); System.out.println(line); */ 15字符流缓冲区流复制文本文件1234567891011121314151617181920212223* A: 字符流缓冲区流复制文本文件* a: 案例代码 /* * 使用缓冲区流对象,复制文本文件 * 数据源 BufferedReader+FileReader 读取 * 数据目的 BufferedWriter+FileWriter 写入 * 读取文本行, 读一行,写一行,写换行 */ public class Copy_1 &#123; public static void main(String[] args) throws IOException&#123; BufferedReader bfr = new BufferedReader(new FileReader("c:\\w.log")); BufferedWriter bfw = new BufferedWriter(new FileWriter("d:\\w.log")); //读取文本行, 读一行,写一行,写换行 String line = null; while((line = bfr.readLine())!=null)&#123; bfw.write(line); bfw.newLine(); bfw.flush(); &#125; bfw.close(); bfr.close(); &#125; &#125; 16IO流对象的操作规律123456789101112131415161718192021222324252627282930* A: IO流对象的操作规律* a: 明确一：要操作的数据是数据源还是数据目的。 * 源：InputStream Reader * 目的：OutputStream Writer * 先根据需求明确要读，还是要写。* b: 明确二：要操作的数据是字节还是文本呢？ * 源： * 字节：InputStream * 文本：Reader * 目的： * 字节：OutputStream * 文本：Writer* c: 明确三：明确数据所在的具体设备。 * 源设备： * 硬盘：文件 File开头。 * 内存：数组，字符串。 * 键盘：System.in; * 网络：Socket * 目的设备： * 硬盘：文件 File开头。 * 内存：数组，字符串。 * 屏幕：System.out * 网络：Socket * 完全可以明确具体要使用哪个流对象。* d: 明确四：是否需要额外功能呢？ * 额外功能： * 转换吗？转换流。InputStreamReader OutputStreamWriter * 高效吗？缓冲区对象。BufferedXXX * 已经明确到了具体的体系上。 17总结12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364InputStream FileInputStream BufferedInputStream OuputStream FileOutputStream BufferedOuputStreamWriter OutputStreamWriter FileWriter BufferedWriterReader InputStreamReader FileReader BufferedReader void test()字节流 字节输入流 InputStream FileInputStream() 操作文件的字节输入流 BufferedInputStream() 高效的字节输入流 字节输出流 OutputStream FileOutputStream() 操作文件的字节输出流 BufferedOutputStream() 高效的字节输出流字符流 字符输入流 Reader FileReader() 操作文件的字符输入流 BufferedReader() 高效的字符输入流 InputStreamReader() 输入操作的转换流(把字节流封装成字符流) 字符输出流 Writer FileWriter() 操作文件的字符输出流 BufferedWriter() 高效的字符输出流 OutputStreamWriter() 输出操作的转换流(把字节流封装成字符流)方法： 读数据方法： read() 一次读一个字节或字符的方法 read(byte[] char[]) 一次读一个数组数据的方法 readLine() 一次读一行字符串的方法(BufferedReader类特有方法) readObject() 从流中读取对象(ObjectInputStream特有方法)写数据方法： write(int) 一次写一个字节或字符到文件中 write(byte[] char[]) 一次写一个数组数据到文件中 write(String) 一次写一个字符串内容到文件中 writeObject(Object ) 写对象到流中(ObjectOutputStream类特有方法) newLine() 写一个换行符号(BufferedWriter类特有方法)向文件中写入数据的过程 1，创建输出流对象 2，写数据到文件 3，关闭输出流  从文件中读数据的过程 1， 创建输入流对象 2， 从文件中读数据 3， 关闭输入流 文件复制的过程 1， 创建输入流（数据源） 2， 创建输出流（目的地） 3， 从输入流中读数据 4， 通过输出流，把数据写入目的地 5， 关闭流]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java基础：编译时和运行时的区别]]></title>
    <url>%2F2016%2F11%2F18%2F%E7%BC%96%E8%AF%91%E6%97%B6%E5%92%8C%E8%BF%90%E8%A1%8C%E6%97%B6%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[在java开发设计过程中，了解java运行时和编译时的区别是非常有必要的。如下从几个问题来描述两者的区别 Q1: 如下代码片段中，A行和B行的区别是什么 A行是在编译时计算值，B行是在运行时计算值，当该类编译后，如果使用一些反编译器(如jd-gui)反编译后可以看到，实际代码如下： java编译时会做一些优化操作，比如替换一些final的不可变更的参数，在这里，由于number1和number2都是final的，那么product1肯定是确定的，这里就会在编译时计算出product1的值。 除了如上的一些代码优化话，再什么其他的情况下查看编译后的class文件是非常有用的？ java中的泛型。泛型是编译时会做优化，通过编译文件可以非常方便的看到其对应的实际类型，如下例子： 实际编码如下： 反编译后的代码如下： 可以，在编译后的文件中，Parent类会显示的被实际类型取代。 重写，重载，泛型，分别是在运行时还是编译时执行的? 方法重载是在编译时执行的，因为，在编译的时候，如果调用了一个重载的方法，那么编译时必须确定他调用的方法是哪个。如： 当调用evaluate(“hello”)时候，我们在编译时就可以确定他调用的method #1. 方法的重写是在运行时进行的。这个也常被称为运行时多态的体现。编译器是没有办法知道它调用的到底是那个方法，相反的，只有在jvm执行过程中，才知晓到底是父子类中的哪个方法被调用了。如下： 试想，当有如下一个接口的时候，我们是无法确定到底是调用父类还是子类的方法 泛型(类型检测)，这个发生在编译时。编译器会在编译时对泛型类型进行检测，并吧他重写成实际的对象类型(非泛型代码)，这样就可以被JVM执行了。这个过程被称为”类型擦除”。 类型擦除的关键在于从泛型类型中清除类型参数的相关信息，并且再必要的时候添加类型检查和类型转换的方法。 类型擦除可以简单的理解为将泛型java代码转换为普通java代码，只不过编译器更直接点，将泛型java代码直接转换成普通java字节码。类型擦除的主要过程如下： 1). 将所有的泛型参数用其最左边界（最顶级的父类型）类型替换。 2). 移除所有的类型参数。 在编译后变成： 注解。注解即有可能是运行时也有可能是编译时。 如java中的@Override注解就是典型的编译时注解，他会在编译时会检查一些简单的如拼写的错误(与父类方法不相同)等 同样的@Test注解是junit框架的注解，他是一个运行时注解，他可以在运行时动态的配置相关信息如timeout等。 异常。异常即有可能是运行时异常，也有可能是编译时异常。 RuntimeException是一个用于指示编译器不需要检查的异常。RuntimeException 是在jvm运行过程中抛出异常的父类。对于运行时异常是不需要再方法中显示的捕获或者处理的，如NullPointerException,ArrayIndexOutOfBoundsException 已检查的异常是被编译器在编译时候已经检查过的异常，这些异常需要在try/catch块中处理的异常。 AOP. Aspects能够在编译时，预编译时以及运行时使用。 1). 编译时：当你拥有源码的时候，AOP编译器(AspectJ编译器)能够编译源码并生成编织后的class。这些编织进入的额外功能是在编译时放进去的。 2). 预编译时：织入过程有时候也叫二进制织入，它是用来织入到哪些已经存在的class文件或者jar中的。 3). 运行时：当被织入的对象已经被加载如jvm中后，可以动态的织入到这些类中一些信息。 继承：继承是编译时执行的，它是静态的。这个过程编译后就已经确定 代理(delegate)：也称动态代理，是在运行时执行。 你如何理解”组合优于继承”这句话 继承是一个多态的工具，而非重用工具。在没有多态关联关系的对象间，一些程序员倾向于使用继承来保持重用。但事实是，只有当子类和父类的关系为”is a”的关系时候，继承才会使用。 不要使用继承来实现代码的重用。如果两者之间没有”is a”的关系，那么使用组合来实现重用。当父类的某个方法修改后，子类的相关实现也有可能会被更改。 不要为了多态而使用继承。如果你只是为了实现多态而采用继承模式，那么实际上组合模式更加适合你，而且更加简洁和灵活。 这也就是为什么GoF设计模式中常说”组合优于继承”的原因。 你能区分编译时继承和运行时继承的区别吗？请列举例子说明 实际上在java中只支持编译时继承。java语言原生是不支持运行时时继承的。一般情况下所谓编译时继承如下： 如上有两个类，其中Child为Parent的子类。当我们创建一个Parent实例的时候(无论实际对象为Parent还是Child)，编译器在编译期间会将其替换成实际类型。所以继承实际上在编译时就已经确定了。 而在java中，可以设计通过组合模式来尝试模拟下所谓的运行时继承。 在Child类中，其中有一个Parent实例。通过这种方式，我们动态的child类中代理了parent的相关功能]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础21(字节流,字符流)]]></title>
    <url>%2F2016%2F11%2F16%2Fday23%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、字节流2、字符流 01输入和输出 A:输入和输出 a: 参照物 到底是输入还是输出，都是以Java程序为参照 b: Output 把内存中的数据存储到持久化设备上这个动作称为输出（写）Output操作 程序到文件称为输出 c: Input 把持久设备上的数据读取到内存中的这个动作称为输入（读）Input操作 文件到程序称为输入 d: IO操作 把上面的这种输入和输出动作称为IO操作 02字节输出流OutputStream A: 字节输出流OutputStream a.概念 IO流用来处理设备之间的数据传输 Java对数据的操作是通过流的方式 Java用于操作流的类都在IO包中 流按流向分为两种：输入流，输出流。 流按操作类型分为两种： 字节流 : 字节流可以操作任何数据,因为在计算机中任何数据都是以字节的形式存储的 字符流 : 字符流只能操作纯字符数据，比较方便。 b.IO流常用父类 字节流的抽象父类： InputStream OutputStream 字符流的抽象父类： Reader Writer c.IO程序书写 使用前，导入IO包中的类 使用时，进行IO异常处理 使用后，释放资源 d: 方法介绍 1234* void close(): 关闭此输出流并释放与此流有关的所有系统资源。* void write(byte[] b)： 将 b.length 个字节从指定的 byte 数组写入此输出流* void write(byte[] b, int off, int len) ：将指定 byte 数组中从偏移量 off 开始的 len 个字节写入此输出流。* abstract void write(int b) ： 将指定的字节写入此输出流。 03字节输出流FileOutputStream写字节1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950* A: 字节输出流FileOutputStream写字节* a: FileOutputStream * 写入数据文件,学习父类方法,使用子类对象 * void test() * b: FileOutputStream构造方法 * 作用：绑定输出的输出目的 * FileOutputStream(File file) * 创建一个向指定 File 对象表示的文件中写入数据的文件输出流。 * FileOutputStream(File file, boolean append) * 创建一个向指定 File 对象表示的文件中写入数据的文件输出流，以追加的方式写入。 * FileOutputStream(String name) * 创建一个向具有指定名称的文件中写入数据的输出文件流。 * FileOutputStream(String name, boolean append) * 创建一个向具有指定 name 的文件中写入数据的输出文件流，以追加的方式写入。* c: 流对象使用步骤 * 1. 创建流子类的对象,绑定数据目的 * 2. 调用流对象的方法write写 * 3. close释放资源* d: 注意事项 * 流对象的构造方法,可以创建文件,如果文件存在,直接覆盖 * e: 案例代码 * * FileOutputStream * 写入数据文件,学习父类方法,使用子类对象 * * 子类中的构造方法: 作用:绑定输出的输出目的 * 参数: * File 封装文件 * String 字符串的文件名 * * 流对象使用步骤 * 1. 创建流子类的对象,绑定数据目的 * 2. 调用流对象的方法write写 * 3. close释放资源 * * 流对象的构造方法,可以创建文件,如果文件存在,直接覆盖 * public class FileOutputStreamDemo &#123; public static void main(String[] args)throws IOException &#123; FileOutputStream fos = new FileOutputStream("c:\\a.txt"); //流对象的方法write写数据 //写1个字节 fos.write(97); //关闭资源 fos.close(); &#125; &#125; 04字节输出流FileOutputStream写字节数组1234567891011121314151617181920212223242526272829303132333435363738394041* A: 字节输出流FileOutputStream写字节数组* a: 方法介绍 * void write(byte[] b)： 将 b.length 个字节从指定的 byte 数组写入此输出流 * void write(byte[] b, int off, int len) ：将指定 byte 数组中从偏移量 off 开始的 len 个字节写入此输出流。* b: 案例代码 /* * FileOutputStream * 写入数据文件,学习父类方法,使用子类对象 * * 子类中的构造方法: 作用:绑定输出的输出目的 * 参数: * File 封装文件 * String 字符串的文件名 * * 流对象使用步骤 * 1. 创建流子类的对象,绑定数据目的 * 2. 调用流对象的方法write写 * 3. close释放资源 * * 流对象的构造方法,可以创建文件,如果文件存在,直接覆盖 */ public class FileOutputStreamDemo &#123; public static void main(String[] args)throws IOException &#123; FileOutputStream fos = new FileOutputStream("c:\\a.txt"); //流对象的方法write写数据 //写字节数组 byte[] bytes = &#123;65,66,67,68&#125;; fos.write(bytes); //写字节数组的一部分,开始索引,写几个 fos.write(bytes, 1, 2); //写入字节数组的简便方式 //写字符串 fos.write("hello".getBytes()); //关闭资源 fos.close(); &#125; &#125; 05文件的续写和换行符号12345678910111213141516171819202122* A: 文件的续写和换行符号* a: 文件的续写 * FileOutputStream构造方法, 的第二个参数中,加入true* b: 换行符号 * 在文件中,写入换行,符号换行 \r\n * \r\n 可以写在上一行的末尾, 也可以写在下一行的开头* c: 案例代码 /* * FileOutputStream 文件的续写和换行问题 * 续写: FileOutputStream构造方法, 的第二个参数中,加入true * 在文件中,写入换行,符号换行 \r\n * \r\n 可以写在上一行的末尾, 也可以写在下一行的开头 */ public class FileOutputStreamDemo1 &#123; public static void main(String[] args)throws IOException &#123; File file = new File("c:\\b.txt"); FileOutputStream fos = new FileOutputStream(file,true); fos.write("hello\r\n".getBytes()); fos.write("world".getBytes()); fos.close(); &#125; &#125; 06IO中的异常处理1234567891011121314151617181920212223242526272829303132333435* A: IO中的异常处理* a:IO流的异常处理 * try catch finally * b: 细节 * 1. 保证流对象变量,作用域足够 * 2. catch里面,怎么处理异常 * 输出异常的信息,目的看到哪里出现了问题 * 停下程序,从新尝试 * 3. 如果流对象建立失败了,需要关闭资源吗 * new 对象的时候,失败了,没有占用系统资源 * 释放资源的时候,对流对象判断null * 变量不是null,对象建立成功,需要关闭资源* c: 案例代码 public class FileOutputStreamDemo3 &#123; public static void main(String[] args) &#123; //try 外面声明变量,try 里面建立对象 FileOutputStream fos = null; try&#123; fos = new FileOutputStream("s:\\a.txt"); fos.write(100); &#125;catch(IOException ex)&#123; System.out.println(ex); throw new RuntimeException("文件写入失败,重试"); &#125;finally&#123; try&#123; if(fos!=null) fos.close(); &#125;catch(IOException ex)&#123; throw new RuntimeException("关闭资源失败"); &#125; &#125; &#125; &#125; 07字节输入流InputStream12345678910111213141516171819202122232425* A: 字节输入流InputStream* a: 方法介绍 * abstract int read() ： * 从输入流中读取数据的下一个字节。 * 下一个数据字节；如果已到达文件末尾，则返回 -1。 * int read(byte[] b) * 从输入流中读取一定数量的字节，并将其存储在缓冲区数组 b 中。 * int read(byte[] b, int off, int len) * 将输入流中最多 len 个数据字节读入 byte 数组。 * void close() * 关闭此输入流并释放与该流关联的所有系统资源。 * b: 案例代码 /* * 字节输入流 * java.io.InputStream 所有字节输入流的超类 * 作用: 读取任意文件,每次只读取1个字节 * 读取的方法 read * int read() 读取1个字节 * int read(byte[] b) 读取一定量的字节,存储到数组中 */ public class InputStreamDemo &#123; &#125; 08字节输入流FileInputStream读取字节12345678910111213141516171819202122232425262728293031323334353637383940414243* A: 字节输入流FileInputStream读取字节* a: 方法介绍 * abstract int read() ： * 从输入流中读取数据的下一个字节，返回-1表示文件结束 * int read(byte[] b) * 从输入流中读取一定数量的字节，并将其存储在缓冲区数组 b 中。 * 读入缓冲区的字节总数，如果因为已经到达文件末尾而没有更多的数据，则返回 -1。 * int read(byte[] b, int off, int len) * 将输入流中最多 len 个数据字节读入 byte 数组。 * void close() * 关闭此输入流并释放与该流关联的所有系统资源。* b: 案例代码 /* * FileInputStream读取文件 * * 构造方法: 为这个流对象绑定数据源 * * 参数: * File 类型对象 * String 对象 * 输入流读取文件的步骤 * 1. 创建字节输入流的子类对象 * 2. 调用读取方法read读取 * 3. 关闭资源 * * read()方法, * read()执行一次,就会自动读取下一个字节 * 返回值,返回的是读取到的字节, 读取到结尾返回-1 */ public class FileInputStreamDemo &#123; public static void main(String[] args) throws IOException&#123; FileInputStream fis = new FileInputStream("c:\\a.txt"); //读取一个字节,调用方法read 返回int //使用循环方式,读取文件, 循环结束的条件 read()方法返回-1 int len = 0;//接受read方法的返回值 while( (len = fis.read()) != -1)&#123; System.out.print((char)len); &#125; //关闭资源 fis.close(); &#125; &#125; 09字节输入流FileInputStream读取字节数组123456789101112131415161718192021222324252627282930313233343536373839* A: 字节输入流FileInputStream读取字节数组* a: 方法介绍 * int read(byte[] b) * 从输入流中读取一定数量的字节，并将其存储在缓冲区数组 b 中。 * 读入缓冲区的字节总数，如果因为已经到达文件末尾而没有更多的数据，则返回 -1。 * int read(byte[] b, int off, int len) * 将输入流中最多 len 个数据字节读入 byte 数组。* b: 案例代码 /* * FileInputStream读取文件 * 读取方法 int read(byte[] b) 读取字节数组 * 数组作用: 缓冲的作用, 提高效率 * read返回的int,表示什么含义 读取到多少个有效的字节数 */ public class FileInputStreamDemo1 &#123; public static void main(String[] args) throws IOException &#123; FileInputStream fis = new FileInputStream("c:\\a.txt"); // 创建字节数组 byte[] b = new byte[2]; int len = fis.read(b); System.out.println(new String(b));// ab System.out.println(len);// 2 len = fis.read(b); System.out.println(new String(b));// cd System.out.println(len);// 2 len = fis.read(b); System.out.println(new String(b));// ed System.out.println(len);// 1 len = fis.read(b); System.out.println(new String(b));// ed System.out.println(len);// -1 fis.close(); &#125; &#125; 10字节输入流FileInputStream读取字节数组的实现原理 A：字节输入流FileInputStream读取字节数组的实现原理 a: 原理 123456789101112131415161718192021222324252627282930* b: 案例代码public class FileInputStreamDemo1 &#123; public static void main(String[] args) throws IOException &#123; FileInputStream fis = null; try &#123; fis = new FileInputStream("aa.txt"); byte[] b = new byte[1024 * 10]; int value;//每次 fis.read(b) 读取字节的个数 while ((value = fis.read(b)) != -1) &#123; System.out.print(new String(b, 0, value, "GBK")); //每次只把value长度的byte类型数据 创建为字符串,"GBK"是国标编码 &#125; &#125; catch (IOException ex)&#123; ex.printStackTrace(); System.out.println("文件有误"); &#125; finally &#123; try &#123; if (fis != null) fis.close(); &#125; catch (IOException ex)&#123; ex.printStackTrace(); &#125; &#125; &#125;&#125; 11文件复制原理 A: 文件复制原理 12字节流复制文件读取单个字节123456789101112131415161718192021222324252627282930313233343536373839404142434445* A: 字节流复制文件读取单个字节* a: 案例代码/* * 将数据源 c:\\a.txt * 复制到 d:\\a.txt 数据目的 * 字节输入流,绑定数据源 * 字节输出流,绑定数据目的 * * 输入,读取1个字节 * 输出,写1个字节 */public class Copy &#123; public static void main(String[] args) &#123; //定义两个流的对象变量 FileInputStream fis = null; FileOutputStream fos = null; try&#123; //建立两个流的对象,绑定数据源和数据目的 fis = new FileInputStream("c:\\t.zip"); fos = new FileOutputStream("d:\\t.zip"); //字节输入流,读取1个字节,输出流写1个字节 int len = 0 ; while((len = fis.read())!=-1)&#123; fos.write(len); &#125; &#125;catch(IOException ex)&#123; System.out.println(ex); throw new RuntimeException("文件复制失败"); &#125;finally&#123; try&#123; if(fos!=null) fos.close(); &#125;catch(IOException ex)&#123; throw new RuntimeException("释放资源失败"); &#125;finally&#123; try&#123; if(fis!=null) fis.close(); &#125;catch(IOException ex)&#123; throw new RuntimeException("释放资源失败"); &#125; &#125; &#125; &#125;&#125; 13字节流复制文件读取字节数组12345678910111213141516171819202122232425262728293031323334353637383940414243444546* A: 字节流复制文件读取字节数组* a: 案例代码/* * 字节流复制文件 * 采用数组缓冲提高效率 * 字节数组 * FileInputStream 读取字节数组 * FileOutputStream 写字节数组 */public class Copy_1 &#123; public static void main(String[] args) &#123; long s = System.currentTimeMillis(); FileInputStream fis = null; FileOutputStream fos = null; try&#123; fis = new FileInputStream("c:\\t.zip"); fos = new FileOutputStream("d:\\t.zip"); //定义字节数组,缓冲 byte[] bytes = new byte[1024*10]; //读取数组,写入数组 int len = 0 ; while((len = fis.read(bytes))!=-1)&#123; fos.write(bytes, 0, len); &#125; &#125;catch(IOException ex)&#123; System.out.println(ex); throw new RuntimeException("文件复制失败"); &#125;finally&#123; try&#123; if(fos!=null) fos.close(); &#125;catch(IOException ex)&#123; throw new RuntimeException("释放资源失败"); &#125;finally&#123; try&#123; if(fis!=null) fis.close(); &#125;catch(IOException ex)&#123; throw new RuntimeException("释放资源失败"); &#125; &#125; &#125; long e = System.currentTimeMillis(); System.out.println(e-s); &#125;&#125; 14编码表1234567891011121314151617* A: 编码表* a: 定义： * 生活中字符和计算机二进制的对应关系表,就是编码表* b: 分类* 1、ascii： 一个字节中的7位就可以表示。对应的字节都是正数。0-xxxxxxx* 2、"iso-8859-1:拉丁码表" latin，用了一个字节用的8位。1-xxxxxxx 负数。* 3、GB2312:简体中文码表。包含6000-7000中文和符号。用两个字节表示。两个字节第一个字节是负数,第二个字节可能是正数 * "GBK:目前最常用的中文码表"，2万的中文和符号。用两个字节表示，其中的一部分文字，第一个字节开头是1，第二字节开头是0 * GB18030：最新的中文码表，目前还没有正式使用。* 4、unicode：国际标准码表:无论是什么文字，都用两个字节存储。 * Java中的char类型用的就是这个码表。char c = 'a';占两个字节。 * Java中的字符串是按照系统默认码表来解析的。简体中文版 字符串默认的码表是GBK。* 5、UTF-8:基于unicode，一个字节就可以存储数据，不要用两个字节存储，而且这个码表更加的标准化，在每一个字节头加入了编码信息(后期到api中查找)。* 6、"能识别中文的码表：GBK、UTF-8 "；正因为识别中文码表不唯一，涉及到了编码解码问题。 * 对于我们开发而言；常见的编码 GBK UTF-8 ISO-8859-1 * 文字---&gt;(数字) ：编码。 “abc”.getBytes() byte[] * (数字)---&gt;文字 : 解码。 byte[] b=&#123;97,98,99&#125; new String(b) 15字符输出流写文本FileWriter类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657* A: 字符输出流写文本FileWriter类,只能写"文本文件"* a: 方法介绍 * void write(int c) * 写入单个字符 * void write(String str) * 写入字符串 * void write(String str, int off, int len) * 写入字符串的某一部分 * void write(char[] cbuf) * 写入字符数组 * abstract void write(char[] cbuf, int off, int len) * 写入字符数组的某一部分* b: 案例代码 * * 字符输出流 * java.io.Writer 所有字符输出流的超类 * 写文件,写文本文件 * * 写的方法 write * write(int c) 写1个字符 * write(char[] c)写字符数组 * write(char[] c,int,int)字符数组一部分,开始索引,写几个 * write(String s) 写入字符串 * * Writer类的子类对象 FileWriter * * 构造方法: 写入的数据目的 * File 类型对象 * String 文件名 * * 字符输出流写数据的时候,必须要运行一个功能,刷新功能 * flush() */ public class WriterDemo &#123; public static void main(String[] args) throws IOException&#123; FileWriter fw = new FileWriter("c:\\1.txt"); //写1个字符 fw.write(100); fw.flush(); //写1个字符数组 char[] c = &#123;'a','b','c','d','e'&#125;; fw.write(c); fw.flush(); //写字符数组一部分 fw.write(c, 2, 2); fw.flush(); //写如字符串 fw.write("hello"); fw.flush(); fw.close(); &#125; &#125; 16字符输入流读取文本FileReader类123456789101112131415161718192021222324252627282930313233343536373839404142* A: 字符输入流读取文本FileReader类* a: 方法介绍 * int read() * 读取单个字符 * int read(char[] cbuf) * 将字符读入数组 * abstract int read(char[] cbuf, int off, int len) * 将字符读入数组的某一部分。* b: 案例代码 * * 字符输入流读取文本文件,所有字符输入流的超类 * java.io.Reader * 专门读取文本文件 * * 读取的方法 : read() * int read() 读取1个字符 * int read(char[] c) 读取字符数组 * * Reader类是抽象类,找到子类对象 FileReader * * 构造方法: 绑定数据源 * 参数: * File 类型对象 * String文件名 */ public class ReaderDemo &#123; public static void main(String[] args) throws IOException&#123; ** 要求文件的默认编码为GBK或者UTF-8，不然会有中文乱码 ** FileReader fr = new FileReader("c:\\1.txt"); /*int len = 0 ; while((len = fr.read())!=-1)&#123; System.out.print((char)len); &#125;*/ char[] ch = new char[1024]; int len = 0 ; while((len = fr.read(ch))!=-1)&#123; System.out.print(new String(ch,0,len)); &#125; fr.close(); &#125; &#125; 17flush方法和close方法区别 A: flush方法和close方法区别*a: flush()方法 用来刷新缓冲区的,刷新后可以再次写出,流还可以继续使用,只有字符流FileWriter类才需要刷新*b: close()方法 用来关闭流释放资源的,如果是带缓冲区的流对象的close()方法,不但会关闭流,还会再关闭流之前刷新缓冲区,关闭后不能再写出 18字符流复制文本文件123456789101112131415161718192021222324252627282930313233343536373839404142* A: 字符流复制文本文件* a: 案例代码 /* * 字符流复制文本文件,必须文本文件 * 字符流查询本机默认的编码表,简体中文GBK * FileReader读取数据源 * FileWriter写入到数据目的 */ public class Copy_2 &#123; public static void main(String[] args) &#123; FileReader fr = null; FileWriter fw = null; try&#123; fr = new FileReader("c:\\1.txt"); fw = new FileWriter("d:\\1.txt"); char[] cbuf = new char[1024]; int len = 0 ; while(( len = fr.read(cbuf))!=-1)&#123; fw.write(cbuf, 0, len); fw.flush(); &#125; &#125;catch(IOException ex)&#123; System.out.println(ex); throw new RuntimeException("复制失败"); &#125;finally&#123; try&#123; if(fw!=null) fw.close(); &#125;catch(IOException ex)&#123; throw new RuntimeException("释放资源失败"); &#125;finally&#123; try&#123; if(fr!=null) fr.close(); &#125;catch(IOException ex)&#123; throw new RuntimeException("释放资源失败"); &#125; &#125; &#125; &#125; &#125; 19总结 IO流的分类123456789101112*- 字节流 *- 字节输入流 InputStream 抽象类 *- FileInputStream 操作文件的字节输入流 *- 字节输出流 OuputStream抽象类 *- FileOutputStream 操作文件的字节输出流*- 字符流 *- 字符输入流 Reader抽象类 *- InputStreamReader 输入操作的转换流 *- FileReader 用来操作文件的字符输入流（简便的流） *- 字符输出流 Writer抽象类 *- OutputStreamWriter 输出操作的转换流 *- FileWriter 用来操作文件的字符输出流（简便的流）]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础20(IO,File类,递归)]]></title>
    <url>%2F2016%2F11%2F16%2Fday22%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、File2、递归 01IO技术概述 A:IO技术概述 a: Output 把内存中的数据存储到持久化设备上这个动作称为输出（写）Output操作 b: Input 把持久设备上的数据读取到内存中的这个动作称为输入（读）Input操作 c: IO操作 把上面的这种输入和输出动作称为IO操作 02File类的概述和作用 A:File类的概述和作用 a: File的概念 File类是文件和目录路径名的抽象表示形式 Java中把文件或者目录（文件夹）都封装成File对象 我们要去操作硬盘上的文件，或者文件夹只要找到File这个类即可 03File类静态的成员变量 A:File类静态的成员变量 a: pathSeparator 与系统有关的路径分隔符，为了方便，它被表示为一个字符串 windows中是一个分号； Linux中是冒号 : b: separator 与系统有关的默认名称分隔符，为了方便，它被表示为一个字符串 windows中向右 \ Linux / c: 案例代码 1234567891011121314151617181920212223/** java.io.File* 将操作系统中的,文件,目录(文件夹),路径,封装成File对象* 提供方法,操作系统中的内容* File与系统无关的类* 文件 file* 目录 directory* 路径 path*/&gt;public class FileDemo &#123;public static void main(String[] args) &#123;//File类静态成员变量//与系统有关的路径分隔符String separator = File.pathSeparator;System.out.println(separator);// windows中是一个分号,//目录的分割(window中环境变量配置各个路径用分号分割，表示一个完整的路径结束) Linux中是冒号 ://与系统有关的默认名称分隔符separator = File.separator;System.out.println(separator);// windows中向右 \ 目录名称分割 Linux / &#125;&#125; 04File类构造方法_11234567891011121314151617181920* A: File类构造方法_1* a: File(String pathname) * 通过将给定路径名字符串转换为一个File对象,之后可以使用File中的方法 * "windows中的路径或文件名不区分大小写"* d: 案例代码 public class FileDemo1 &#123; public static void main(String[] args) &#123; function(); &#125; /* * File(String pathname) * 传递路径名: 可以写到文件夹,可以写到一个文件 * c:\\abc c:\\abc\\Demo.java * 将路径封装File类型对象 */ public static void function()&#123; File file = new File("d:\\eclipse"); System.out.println(file); &#125; &#125; 05相对路径和绝对路径123456789101112131415161718* A: 相对路径和绝对路径* a: 绝对路径 * 绝对路径是一个固定的路径,从盘符开始* b: 相对路径 * 相对路径相对于某个位置,在eclipse下是指当前项目下 * c: 路径 绝对路径 在系统中具有唯一性 c:\\windows\\system32 相对路径 表示路径之间的关系 D:\\develop\\Java\\jdk1.7.0_72\\bin D:\\develop\\Java\\jre7 路径之间关系 Java 父目录是D:\\develop Java 子目录是：jdk1.7.0_72 父路径是 唯一性 子目录是可以多个 06File类的构造方法_21234567891011121314151617181920212223242526272829303132* A: File类的构造方法_2* a:File(String parent, String child) * 根据 parent 路径名字符串和 child 路径名字符串创建一个新 File 对象 * b: File(File parent, String child)* c: 案例代码public class FileDemo1 &#123; public static void main(String[] args) &#123; function_2(); &#125; * * File(File parent,String child) * "传递路径,传递File类型父路径,字符串子路径" * "好处: 父路径是File类型,父路径可以直接调用File类方法" */ public static void function_2()&#123; File parent = new File("d:"); File file = new File(parent,"eclipse"); System.out.println(file); &#125; * * File(String parent,String child) * "传递路径,传递字符串父路径,字符串子路径 * 好处: 单独操作父路径和子路径" */ public static void function_1()&#123; File file = new File("d:","eclipse"); System.out.println(file); &#125;&#125; 07File类创建文件功能123456789101112131415161718192021* A: File类创建文件功能* a: public boolean createNewFile() * 创建文件 如果存在这样的文件，就不创建了 * b: 案例代码 public class FileDemo2 &#123; public static void main(String[] args)throws IOException &#123; function(); &#125; "/* * File创建文件的功能 * boolean createNewFile() * 创建的文件路径和文件名,在File构造方法中给出 * 文件已经存在了,不再创建 */" public static void function()throws IOException&#123; File file = new File("c:\\a.txt"); boolean b = file.createNewFile(); System.out.println(b); &#125; &#125; 08File类创建目录功能123456789101112131415161718192021* A: File类创建目录功能* a: 创建目录 * public boolean mkdir():创建单层文件夹 如果存在这样的文件夹，就不创建了 * public boolean mkdirs():创建文件夹,如果父文件夹不存在，会帮你创建出来* b: 案例代码 public class FileDemo2 &#123; public static void main(String[] args)throws IOException &#123; function_1(); &#125; "/* * File创建文件夹功能 * boolean mkdirs() 创建多层文件夹 * 创建的路径也在File构造方法中给出 * 文件夹已经存在了,不在创建 */" public static void function_1()&#123; File file = new File("c:\\abc"); boolean b = file.mkdirs(); System.out.println(b); &#125; &#125; 09File类删除功能12345678910111213141516171819202122* A: File类删除功能* a: 删除功能 * public boolean delete():删除文件或者文件夹* B: 案例代码public class FileDemo2 &#123; public static void main(String[] args)throws IOException &#123; function_2(); &#125; "/* * File类的删除功能 * boolean delete() * 删除的文件或者是文件夹,在File构造方法中给出 * 删除成功返回true,删除失败返回false * 删除方法,不走回收站,直接从硬盘中删除 * 删除有风险,运行需谨慎 */" public static void function_2()&#123; File file = new File("c:\\a.txt"); boolean b = file.delete(); System.out.println(b); &#125; &#125; 10File类获取功能123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869* A：File类获取功能* a: 方法介绍* String getName(): 返回路径中表示的文件或者文件夹名 * 获取路径中的最后部分的名字* long length(): 返回路径中表示的文件的字节数* String getAbsolutePath(): 获取绝对路径,返回String对象* File getAbsoluteFile() : 获取绝对路径,返回File对象 * eclipse环境中,写一个相对路径,绝对位置工程根目录* String getParent(): 获取父路径,返回String对象* File getParentFile(): 获取父路径,返回File对象 * b: 案例代码public class FileDemo3 &#123; public static void main(String[] args) &#123; function_3(); &#125; /* * File类的获取功能 * String getParent() 返回String对象 * File getParentFile()返回File对象 * 获取父路径 */ public static void function_3()&#123; File file = new File("d:\\eclipse\\eclipse.exe"); File parent = file.getParentFile(); System.out.println(parent); &#125; /* * File类获取功能 * String getAbsolutePath() 返回String对象 * File getAbsoluteFile() 返回File对象 * 获取绝对路径 * eclipse环境中,写的是一个相对路径,绝对位置工程根目录 */ public static void function_2()&#123; File file = new File("src"); File absolute = file.getAbsoluteFile(); System.out.println(absolute); &#125; /* * File类获取功能 * long length() * 返回路径中表示的文件的字节数 */ public static void function_1()&#123; File file = new File("d:\\eclipse\\eclipse.exe"); long length = file.length(); System.out.println(length); &#125; /* * File类的获取功能 * String getName() * 返回路径中表示的文件或者文件夹名 * 获取路径中的最后部分的名字 */ public static void function()&#123; File file = new File("d:\\eclipse\\eclipse.exe"); String name = file.getName(); System.out.println(name); /*String path = file.getPath(); System.out.println(path);*/// System.out.println(file); &#125;&#125; 11File类判断功能12345678910111213141516171819202122232425262728293031323334353637383940414243* A: File类判断功能* a: 方法介绍 * boolean exists(): 判断File构造方法中封装路径是否存在 * 存在返回true,不存在返回false * boolean isDirectory(): 判断File构造方法中封装的路径是不是文件夹 * 如果是文件夹,返回true,不是文件返回false * boolean isFile(): 判断File构造方法中封装的路径是不是文件 * 如果是文件,返回true,不是文件返回false* b: 案例代码 public class FileDemo4 &#123; public static void main(String[] args) &#123; function_1(); &#125; /* * File判断功能 * boolean isDirectory() * 判断File构造方法中封装的路径是不是文件夹 * 如果是文件夹,返回true,不是文件返回false * * boolean isFile() * 判断File构造方法中封装的路径是不是文件 */ public static void function_1()&#123; File file = new File("d:\\eclipse\\eclipse.exe"); if(file.exists())&#123; boolean b = file.isDirectory(); System.out.println(b); &#125; &#125; /* * File判断功能 * boolean exists() * 判断File构造方法中封装路径是否存在 * 存在返回true,不存在返回false */ public static void function()&#123; File file = new File("src"); boolean b = file.exists(); System.out.println(b); &#125; &#125; 12File类list获取功能1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950* A: File类list获取功能* a: 方法介绍 * String[] list()：获取到File构造方法中封装的路径中的文件和文件夹名 (遍历一个目录) * "返回只有名字" * File[] listFiles()：获取到,File构造方法中封装的路径中的文件和文件夹名 (遍历一个目录) * 返回的是目录或者文件的"全路径" * static File[] listRoots(): 列出可用的文件系统根 * b: 案例代码 public class FileDemo &#123; public static void main(String[] args) &#123; function_2(); &#125; public static void function_2()&#123; //获取系统中的所有根目录 File[] fileArr = File.listRoots(); for(File f : fileArr)&#123; System.out.println(f); &#125; &#125; /* * File类的获取功能 * File[] listFiles() * 获取到,File构造方法中封装的路径中的文件和文件夹名 (遍历一个目录) * 返回的是目录或者文件的全路径 */ public static void function_1()&#123; File file = new File("d:\\eclipse"); File[] fileArr = file.listFiles(); for(File f : fileArr)&#123; System.out.println(f); &#125; &#125; /* * File类的获取功能 * String[] list() * 获取到,File构造方法中封装的路径中的文件和文件夹名 (遍历一个目录) * 返回只有名字 */ public static void function()&#123; File file = new File("c:"); String[] strArr = file.list(); System.out.println(strArr.length); for(String str : strArr)&#123; System.out.println(str); &#125; &#125; &#125; 13文件过滤器123456789101112131415161718192021222324252627282930313233343536373839404142434445* A: 文件过滤器* a: 作用 * "过滤一个目录下的指定扩展名的文件，或者包含某些关键字的文件夹" * b: 方法介绍 * public String[] list(FilenameFilter filter) * public File[] listFiles(FileFilter filter) * C: 案例代码 /* * 自定义过滤器 * 实现FileFilter接口,重写抽象方法 */ public class MyFilter implements FileFilter&#123; public boolean accept(File pathname) &#123; /* * pathname 接受到的也是文件的全路径 * c:\\demo\\1.txt * 对路径进行判断,如果是java文件,返回true,不是java文件,返回false * 文件的后缀结尾是.java */ //String name = pathname.getName(); return pathname.getName().endsWith(".java"); &#125; &#125; "/* * File类的获取,文件获取过滤器 * 遍历目录的时候,可以根据需要,只获取满足条件的文件 * 遍历目录方法 listFiles()重载形式 * listFiles(FileFilter filter)接口类型 * 传递FileFilter接口的实现类 * 自定义FileFilter接口实现类,重写抽象方法, * 接口实现类对象传递到遍历方法listFiles */" public class FileDemo1 &#123; public static void main(String[] args) &#123; File file = new File("c:\\demo"); File[] fileArr = file.listFiles(new MyFilter()); for(File f : fileArr)&#123; System.out.println(f); &#125; &#125; &#125; 14文件过滤器_原理分析1234567* A:文件过滤器_原理分析* "listFiles()遍历目录的同时，获取到了文件名全路径，调用过滤器的方法accept， 将获取到的路径传递给accept方法的参数pathname"* accept方法接收了参数pathname，参数是listFiles传递来的* 在accept方法中，进行判断，如果这个路径是Java文件，返回true，走着返回false* 一旦方法返回了true* listFiles将路径保存到File数组中 15递归遍历全目录12345678910111213141516171819202122232425262728293031* A: 递归遍历全目录* a: 案例代码 /* * 对一个目录的下的所有内容,进行完全的遍历 * 编程技巧,方法的递归调用,自己调用自己 */ public class FileDemo &#123; public static void main(String[] args) &#123; File dir = new File("d:\\eclipse"); getAllDir(dir); &#125; /* * 定义方法,实现目录的全遍历 */ public static void getAllDir(File dir)&#123; System.out.println(dir); //调用方法listFiles()对目录,dir进行遍历 File[] fileArr = dir.listFiles(); for(File f : fileArr)&#123; //判断变量f表示的路径是不是文件夹 if(f.isDirectory())&#123; //是一个目录,就要去遍历这个目录 //本方法,getAllDir,就是给个目录去遍历 //继续调用getAllDir,传递他目录 getAllDir(f); &#125;else&#123; System.out.println(f); &#125; &#125; &#125; &#125; 16递归概念和注意事项123456789* A:递归概念和注意事项* a: 递归概念 * 递归，指在当前方法内调用自己的这种现象 * 递归分为两种，直接递归和间接递归 * 直接递归称为方法自身调用自己。间接递归可以A方法调用B方法，B方法调用C方法，C方法调用A方法* b: 注意事项 * 递归一定要有出口, 必须可以让程序停下 * 递归次数不能过多 * 构造方法,禁止递归 17递归求和计算12345678910111213141516171819202122232425262728293031323334353637* A: 递归求和计算* a: 题目分析 * 1+2+3+...+(n-1)+n:求1到n的和 * 总结规律：1到n的和等于1到(n-1)的和再加n * getSum(n-1)+ n * 递归出口：getSum(1) return 1;* b: 案例代码 /* * 方法的递归调用 * 方法自己调用自己 * 适合于,方法中运算的主体不变,但是运行的时候,参与运行的方法参数会变化 * 注意: * 递归一定要有出口, 必须可以让程序停下 * 递归次数不能过多 * 构造方法,禁止递归 */ public class DiGuiDemo &#123; public static void main(String[] args) &#123; int sum = getSum(3); System.out.println(sum); &#125; /* * 计算 1+2+3+100和 = 5050 * 计算规律: * n+(n-1)+(n-2) * 100+(100-1)+(99-1)+...1 */ public static int getSum(int n)&#123; if( n == 1) return 1; return n + getSum(n-1); &#125; &#125; 18递归求阶乘123456789101112131415161718192021222324252627282930313233343536* A: 递归求和计算* a: 题目分析 * 5!=5*4*3*2*1 * =5*4! * 4!=4*3! * 3!=3*2! * 2!=2*1! * 1!=1 * n!=n*(n-1)! * 递归出口：n*getJieCheng(n-1): getJieCheng(1) return 1;* b: 案例代码 /* * 方法的递归调用 * 方法自己调用自己 * 适合于,方法中运算的主体不变,但是运行的时候,参与运行的方法参数会变化 * 注意: * 递归一定要有出口, 必须可以让程序停下 * 递归次数不能过多 * 构造方法,禁止递归 */ public class DiGuiDemo &#123; public static void main(String[] args) &#123; System.out.println(getJieCheng(5)); &#125; /* * 计算阶乘 5! * 5*4*3*2*1 */ public static int getJieCheng(int n)&#123; if ( n == 1) return 1; return n * getJieCheng(n-1); &#125; &#125; 19递归计算斐波那契数列123456789101112131415161718192021222324252627282930* A: 递归计算斐波那契数列* a：题目分析 * 1 1 2 3 5 8 13 21 * 从第三项开始，后面的每一项都等于前面两项的和，第一项和第二项的值为1，作为程序的出口* b: 案例代码 /* * 方法的递归调用 * 方法自己调用自己 * 适合于,方法中运算的主体不变,但是运行的时候,参与运行的方法参数会变化 * 注意: * 递归一定要有出口, 必须可以让程序停下 * 递归次数不能过多 * 构造方法,禁止递归 */ public class DiGuiDemo &#123; public static void main(String[] args) &#123; System.out.println(getFBNQ(12)); &#125; /* * 方法递归,计算斐波那契数列 * */ public static int getFBNQ(int month)&#123; if( month == 1) return 1; if( month == 2) return 1; return getFBNQ(month-1)+getFBNQ(month-2); &#125; &#125; 20遍历目录下的所有java文件123456789101112131415161718192021222324252627282930313233343536373839* A: 遍历目录下的所有java文件* a: 案例代码 public class MyJavaFilter implements FileFilter &#123; public boolean accept(File pathname) &#123; //判断获取的是目录,直接返回true if(pathname.isDirectory()) return true; return pathname.getName().toLowerCase().endsWith(".java"); &#125; &#125; /* * 遍历目录,获取目录下的所有.java文件 * 遍历多级目录,方法递归实现 * 遍历的过程中,使用过滤器 */ public class FileDemo1 &#123; public static void main(String[] args) &#123; getAllJava(new File("c:\\demo")); // new File("c:\\demo").delete(); &#125; /* * 定义方法,实现遍历指定目录 * 获取目录中所有的.java文件 */ public static void getAllJava(File dir)&#123; //调用File对象方法listFiles()获取,加入过滤器 File[] fileArr = dir.listFiles(new MyJavaFilter()); for(File f : fileArr)&#123; //对f路径,判断是不是文件夹 if(f.isDirectory())&#123; //递归进入文件夹遍历 getAllJava(f); &#125;else&#123; System.out.println(f); &#125; &#125; &#125; &#125; 21总结123456789101112131415161718192021222324252627282930313233343536373839404142434445 递归： 方法定义中调用方法本身的现象 直接递归 public void methodA()&#123; methodA(); &#125; 间接递归 public void metohdB()&#123; methodC(); &#125; public void methodC()&#123; methodB(); &#125; 递归注意实现 要有出口，否则就是死递归 次数不能太多，否则就内存溢出 File: 文件和目录路径名的抽象表示形式 构造方法：public File(String pathname) 通过给定的文件或文件夹的路径，来创建对应的File对象public File(String parent, String child) 通过给定的父文件夹路径，与给定的文件名称或目录名称来创建对应的File对象public File(File parent, String child)通过给定的File对象的目录路径，与给定的文件夹名称或文件名称来创建对应的File对象 路径的分类： 绝对路径, 带盘盘符 E:\Workspace\day20_File\abc.txt 相对路径， 不带盘符 day20_File\abc.txt 注意： 当指定一个文件路径的时候，如果采用的是相对路径，默认的目录为 项目的根目录 方法public boolean createNewFile()创建文件 返回值为true， 说明创建文件成功 返回值为false，说明文件已存在，创建文件失败public boolean mkdir() 创建单层文件夹 创建文件夹成功，返回 true 创建文件夹失败，返回 falsepublic boolean mkdirs() 创建多层文件夹public boolean delete() 删除此抽象路径名表示的文件或目录。 如果此路径名表示一个目录，则该目录必须为空才能删除public boolean isDirectory() 判断是否为文件夹public boolean isFile() 判断是否为文件public boolean exists() 判断File对象对应的文件或文件夹是否存在public String getAbsolutePath() 获取当前File的绝对路径public String getName() 获取当前File对象的文件或文件夹名称public long length() 获取当前File对象的文件或文件夹的大小（字节）public File[] listFiles() 获取File所代表目录中所有文件或文件夹的绝对路径]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础19(异常、throw、try...catch、finally、Throwable类))]]></title>
    <url>%2F2016%2F11%2F01%2Fday21%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、异常概述和继承体系2、异常原因以及处理方式3、运行时期异常4、方法重写的异常处理5、Throwable类常见方法6、自定义异常 01异常的概述1234567* A: 异常的概述* a:什么是异常 * Java代码在运行时期发生的问题就是异常。* b:异常类 * 在Java中，把异常信息封装成了一个类。 * 当出现了问题时，就会创建异常类对象并抛出异常相关的信息（如异常出现的位置、原因等）。* c：我们见过的异常：数组角标越界异常ArrayIndexOutOfBoundsException,空指针异常NullPointerException 02异常的继续体系和错误的区别1234567891011121314151617181920212223242526272829* A: 异常的继承体系 Throwable: 它是所有错误与异常的超类（祖宗类） |- Error 错误 |- Exception 编译期异常,进行编译JAVA程序时出现的问题 |- RuntimeException 运行期异常, JAVA程序运行过程中出现的问题* B：异常与错误的区别* a："异常Exception" * 指程序在"编译、运行期间"发生了某种"异常(XxxException)"，我们可以对异常进行具体的处理。 * 若不处理异常，程序将会结束运行。 * 案例演示： public static void main(String[] args) &#123; int[] arr = new int[3]; System.out.println(arr[0]); System.out.println(arr[3]); // 该句运行时发生了数组索引越界异常ArrayIndexOutOfBoundsException， // 由于没有处理异常，导致程序无法继续执行，程序结束。 System.out.println("over"); // 由于上面代码发生了异常，此句代码不会执行 &#125; * b："错误Error" * 指程序在"运行期间"发生了某种"错误(XxxError)"，Error错误通常"没有具体的处理方式"，程序将会结束运行。 * Error错误的发生往往都是"系统级别"的问题，都是"jvm所在系统"发生的，并反馈给jvm的。 * 我们无法针对处理，"只能修正代码"。 * 案例演示： public static void main(String[] args) &#123; int[] arr = new int[1024*1024*100]; //该句运行时发生了内存溢出错误OutOfMemoryError，开辟了过大的数组空间， //导致JVM在分配数组空间时超出了JVM内存空间，直接发生错误。 &#125; 03异常对象的产生原因和处理方式1234567891011121314151617181920212223242526272829303132333435* A: 异常对象的产生原因* 案例代码： * 工具类 class ArrayTools&#123; //对给定的数组通过给定的角标获取元素。 public static int getElement(int[] arr,int index) &#123; int element = arr[index]; return element; &#125; &#125; * 测试类 class ExceptionDemo2 &#123; public static void main(String[] args) &#123; int[] arr = &#123;34,12,67&#125;; int num = ArrayTools.getElement(arr,4) System.out.println("num="+num); System.out.println("over"); &#125; &#125;* 原因分析： * a: 由于没找到4索引，导致运行时发生了异常。这个异常JVM认识：ArrayIndexOutOfBoundsException。 这个异常Java本身有描述：异常的名称、异常的内容、异常的产生位置。 java将这些信息直接封装到异常对象中。new ArrayIndexOutOfBoundsException(4); * b：throw new ArrayIndexOutOfBoundsException(4);产生异常对象。JVM将产生的异常抛给调用者main()方法。 * c：main()方法接收到了数组索引越界异常对象。 由于main()方法并没有进行处理异常，main()方法就会继续把异常抛给调用者JVM。 当JVM收到异常后，将异常对象中的名称、异常内容、位置都显示在就控制台上。同时让程序立刻终止。* B：异常的处理方式* a：JVM的默认处理方式 * 把异常的名称,原因,位置等信息输出在控制台，同时会结束程序。 * 一旦有异常发生，其后来的代码不能继续执行。* b：解决程序中异常的手动方式 * a)：编写处理代码 try...catch...finally * b)：抛出 throws * 04方法内部抛出对象throw关键字1234567891011121314151617在java中，提供了一个throw关键字，它用来抛出一个指定的异常对象。* A: 什么时候使用throw关键字？ * 当调用方法使用接受到的参数时，首先需要先对参数数据进行合法的判断， 数据若不合法，就应该告诉调用者，传递合法的数据进来。 这时需要使用抛出异常的方式来告诉调用者。* B: 使用throw关键字具体操作 * a: 创建一个异常对象。封装一些提示信息(信息可以自己编写)。 * b: 通过关键字throw将这个异常对象告知给调用者。throw 异常对象； throw 用在方法内，用来抛出一个异常对象，将这个异常对象传递到调用者处，并结束当前方法的执行。* C: throw关键字使用格式 * throw new 异常类名(参数); * 例如： throw new NullPointerException("要访问的arr数组不存在"); throw new ArrayIndexOutOfBoundsException("该索引在数组中不存在，已超出范围");* D：案例演示 * throw的使用 * 05方法声明异常关键字throws123456789101112131415161718192021222324252627282930313233* A: 声明 * 将问题标识出来，报告给调用者。如果方法内通过throw抛出了编译时异常， 而"没有捕获处理"（稍后讲解该方式），那么"必须通过"throws进行声明，让"调用者去处理"。* B: 声明异常格式 * 修饰符 返回值类型 方法名(参数) throws 异常类名1,异常类名2… &#123; &#125;* C：注意事项： * throws用于进行异常类的声明，若该方法可能有多种异常情况产生，那么在throws后面可以写多个异常类，用逗号隔开。* D：代码演示： * 多个异常的处理"//方法声明异常关键字" throwspublic class ExceptionDemoTest &#123; public static void main(String[] args) throws Exception &#123; int [] arr = &#123;&#125;; int [] trt = null; int [] ere = &#123;1,2&#125;;// func(arr); func(trt); &#125; private static int func(int [] arr) throws Exception&#123; if(arr == null)&#123; throw new NullPointerException("数组对象是空指针"); &#125; if(arr.length ==0)&#123; throw new ArrayIndexOutOfBoundsException("数组元素为空"); &#125; int result = arr[arr.length-1]; return result*2; &#125;&#125; 06try…catch异常处理1234567891011121314151617181920212223242526272829303132333435363738394041424344* A: 捕获 * Java中对异常有针对性的语句进行捕获，可以对出现的异常进行指定方式的处理* B: 捕获异常格式 try &#123; "//需要被检测的语句。" &#125; catch(异常类 变量) &#123; //参数。 "//异常的处理语句。" &#125; finally &#123; "//一定会被执行的语句。" &#125;* C: 格式说明 * a: try * 该代码块中编写可能产生异常的代码。 * b: catch * 用来进行某种异常的捕获，实现对捕获到的异常进行处理。 * c: finally： * "有一些特定的代码无论异常是否发生，都需要执行"。 * 另外，因为"异常会引发程序【跳转】到"catch语句处，"导致有些语句执行不到"。 * 而finally就是解决这个问题的，在finally代码块中存放的"代码都是【一定】会被执行"的。 * d：try...catch..."处理掉异常后，程序可以继续执行"* D：案例演示 * 捕获异常格式"//try…catch异常处理"public class TryCatchDemo &#123; public static void main(String[] args) &#123; int [] arr = &#123;&#125;; int [] trt = null; int [] ere = &#123;1,2&#125;; try&#123; int ano = func(ere); int result = func(arr);"//异常发生后后，程序将发生跳转到catch处执行" System.out.println("ano: "+ ano);"//try异常后面的语句不会执行" System.out.println("result: "+ result); &#125;catch(Exception ex)&#123; System.out.println(ex); &#125; System.out.println("程序继续执行..."); &#125; 07多catch处理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354* A：一个try 多个catch组合 * 对代码进行异常检测，并对检测的异常传递给catch处理。对每种异常信息进行不同的捕获处理。* B：多catch处理的格式 void show()&#123; //不用throws try&#123; throw new Exception();//产生异常，直接捕获处理 &#125;catch(XxxException e)&#123; //处理方式 &#125;catch(YyyException e)&#123; //处理方式 &#125;catch(ZzzException e)&#123; //处理方式 &#125; &#125; 注意事项：在捕获异常处理中，变量也是有作用域的，如可以定义多个catch中异常变量名为e。"//多catch处理"public class TryCatchDemo_1 &#123; public static void main(String[] args) &#123; int [] arr = &#123;&#125;; int [] trt = null; int [] ere = &#123;1,2&#125;; try&#123; int ano = func(ere); int result = func(arr);//异常发生后后，程序将发生跳转到catch出执行 System.out.println("ano: "+ ano);//try异常后面的语句不会执行// System.out.println("result: "+ result); &#125; catch(NullPointerException nullex)&#123; System.out.println(nullex); &#125; catch(ArrayIndexOutOfBoundsException outboundex)&#123; System.out.println(outboundex); &#125; System.out.println("程序继续执行..."); &#125; private static int func(int [] arr) throws NullPointerException,ArrayIndexOutOfBoundsException &#123; if(arr == null)&#123; throw new NullPointerException("数组对象是空指针"); &#125; if(arr.length ==0)&#123; throw new ArrayIndexOutOfBoundsException("数组元素为空"); &#125; int result = arr[arr.length-1]; return result*2; &#125;&#125; 08多catch处理细节12345678910* A：细节：多个catch小括号中，写的是异常类的类名，有没有顺序的概念？ * 有顺序关系。* B："平级异常"： * 抛出的"异常类之间","没有""继承关系","没有顺序" NullPointerException extends RuntimeException NoSuchElementException extends RuntimeException ArrayIndexOutOfBoundsException extends IndexOutOfBoundsException extends RuntimeException* C："上下级关系(继承关系)的异常" * 越高级的"父类",越"写在下面"，《考虑多态的影响》 NullPointerException extends RuntimeException extends Exception 09finally代码块123456789101112131415161718192021222324252627282930313233343536373839404142* A: finally的特点 * "无论"try...catch语句"有没有异常出现"，被finally控制的"语句体"一定"会执行"， * "除非"发生"异常时"在catch语句中 有 "System.exit(0)" 或者 try语句外部"前面""有异常"出现;* B：finally的作用 * finally,无论程序是否有异常出现,程序必须执行释放资源在 如：IO流操作和数据库操作中会见到public class FinallyDemo &#123; public static void main(String[] args) &#123; int [] arr = &#123;&#125;; int [] trt = null; int [] ere = &#123;1,2&#125;; try&#123; int ano = func(ere);// int result = func(arr);//异常发生后后，程序将发生跳转到catch处执行 System.out.println("ano: "+ ano);//try异常后面的语句不会执行 &#125;catch(Exception ex)&#123; System.out.println(ex); &#125; finally&#123; System.out.println("无论有无异常，这里的代码均会执行..."); &#125; &#125; private static int func(int [] arr) throws Exception&#123; if(arr == null)&#123; throw new NullPointerException("数组对象是空指针"); &#125; if(arr.length ==0)&#123; throw new ArrayIndexOutOfBoundsException("数组元素为空"); &#125; int result = arr[arr.length-1]; return result*2; &#125;&#125; 09finally代码块中有return语句123456789101112131415161718192021警告： 当 finally 子句包含 return 语句时， 将会出现一种意想不到的结果。假设利用 return语句从 try语句块中退出。在"方法返回前"，finally 子句的内容"将【先被】执行"。如果 finally 子句中也有一个 return 语句， 这个"返回值"将会"【覆盖】""原始的返回值"。例子： public static int f(int n) &#123; try &#123; int r = n * n; return r; &#125; finally &#123; if (n == 2) return 0; &#125; &#125;如果调用 f(2), 那么 try 语句块的计算结果为 r = 4, 并执行 return 语句然而，在方法真正返回前，还要执行 finally 子句。finally 子句将使得方法返回 0, 这个返回值覆盖了原始的返回值 4 10try…catch…finally代码块详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class TryCatchFinallyDemo &#123; public static void main(String[] args) &#123; InputStream in = new FileInputStream(. . .); try &#123; "//1" "code that might throw exceptions" "//2" &#125; catch (IOException e) &#123; "// 3" "show error message" "// 4" &#125; finally &#123; "// 5" in.close()； &#125; "//6" &#125;&#125;在上面这段代码中，有下列 3 种情况会执行 finally 子句：1 ) "代码【没有】抛出异常"。 在这种情况下， 程序首先执行 try 语句块中的"全部代码"，然后执行 finally 子句中的代码 。随后， 继续执行 try...finally 语句块之"后的"第一条"语句"。也就是说，执行标注的 1、 2、 5、 6 处。2 ) "抛出"一个在 catch 子句中"捕获的异常"。在上面的示例中就是 IOException 异常。在这种情况下，程序将执行 try语句块中的所有代码，"直到发生异常为止"。此时，将"跳过" try语句块中的"剩余代码"， 转去"执行与该异常匹配"的 catch 子句中的代码， 最后执行 finally 子句中的代码。【分为以下2种情况】： A:如果 catch 子句"没有抛出异常"， 程序将执行 try 语句块之后的第一条语句。 在这里，执行标注 1、 3、 4、5、 6 处的语句。 B:如果 catch 子句"抛出了一个异常"， "异常"将被"抛回"这个方法的"调用者"。 在这里， 执行标注1、 3、 5 处的语句，"注意"语句6"将不再执行"。3 ) 代码"抛出了一个异常"， "但这个异常【不是】"由 catch 子句"捕获"的。在这种情况下， 程序将执行 try 语句块中的所有语句，"直到有异常被抛出为止"。此时， 将"跳过" try 语句块中的"剩余代码"， 然后执行 finally子句中的语句， 并将异常抛给这个方法的调用者。在这里， 执行标注 1、5 处的语句。"注意"语句6"将不再执行"。即：try语句"抛出异常"，但是catch"没有捕获"的"异常"或者 catch语句"自身出现异常"，6处的代码"不会执行"try 语句"可以只有" finally 子句，而"没有"catch 子句。例如，下面这条 try 语句： InputStream in = ...； try &#123; code that might throw exceptions &#125; finally &#123; in.close()； &#125; 10调用抛出异常方法try和throws处理方式123456789101112131415161718192021222324* A: 在实际开发中使用哪种异常处理方式呢，* 继续向上throws Exception 还是用 try...catch...finally处理异常 ？ * 能自己处理的尽量自己处理。(建议用try...catch)例如：public Date parse(String source) throws ParseException从给定字符串的开始解析文本，以生成一个日期。该方法不使用给定字符串的整个文本。 该方法本身会 throws ParseException (声明可能抛出的异常)public class TryCatch_ThowsDemo &#123; public static void main(String[] args) &#123; try&#123; func(); &#125; catch(ParseException ex)&#123; System.out.println(ex); &#125; &#125; public static void func() throws ParseException &#123; SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd"); Date dd = sdf.parse("2088-8-8"); System.out.println(dd); &#125;&#125; 11运行时期异常RuntimeException的特点1234567891011121314151617* A: 运行时期异常的概述: * RuntimeException和"他的所有子类异常",都属于"运行时期异常"。 如常见的 NullPointerException,ArrayIndexOutOfBoundsException 等都属于运行时期异常.* B：运行时期异常的特点 * a：方法中"抛出运行时期异常",方法定义中"无需"throws"声明",调用者也"无需处理此异常"。 * b："运行时期异常一旦发生,【一定】是源代码发生了错误，需要程序人员【修改】【源代码】"。 设计原因: 运行异常,不能发生,但是如果发生了,程序人员停止程序修改源代码 运行异常: 一旦发生,不要处理,请你修改源代码,运行异常一旦发生,后面的代码没有执行的意义(1) 抛出"Exception"，"必须要"throws"声明"，一声明就"告知""调用者"进行"捕获"，一旦"问题处理了"调用者的"程序会继续执行"。(2) 抛出"RuntimeExcpetion","不需要"throws"声明"的，这时调用是"不需要编写捕获代码"的，因为调用者根本就不知道有问题。一旦发生RuntimeException，"调用者程序会停掉"，并有jvm将信息显示到屏幕，让调用者看到问题，"修正代码"。 12运行异常的案例12345678910111213141516171819202122232425262728293031323334353637* A: 计算圆的面积案例 定义方法,计算圆形的面积 传递参数0,或者负数,计算的时候没有问题 但是,违反了真实情况 参数小于=0, 停止程序,不要在计算了* B：数组索引越界案例 使用数组中不存在的索引public class RuntimeExceptionDemo &#123; public static void main(String[] args) &#123; double d = getArea(1); System.out.println(d); &#125; /* * 定义方法,计算圆形的面积 * 传递参数0,或者负数,计算的时候没有问题 * 但是,违反了真实情况 * 参数小于=0, 停止程序,不要在计算了 * */ 方法中"抛出运行时期异常",方法定义中"无需"throws"声明",调用者也"无需处理此异常" public static double getArea(double r)&#123; if(r &lt;= 0) throw new RuntimeException("圆形不存在"); return r*r*Math.PI; &#125; public static void function()&#123; int[] arr = &#123;1,2,3&#125;; //对数组的5索引进行判断,如果5索引大于100,请将3索引上的数据/2,否则除以3 //索引根本就没有 if(arr[3] &gt; 100)&#123; arr[3] = arr[3]/2; &#125;else&#123; arr[3] = arr[3]/3; &#125;&#125; 13方法重写时候异常的处理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657* A：方法重写时候异常的处理* a："子类"覆盖"父类"方法时，* 如果"父类"的"方法""声明异常"，"子类""只能"声明"父类异常"或者"父类异常的子类"，或者"不声明"。 例如： class Fu &#123; public void method () throws RuntimeException &#123; &#125; &#125; class Zi extends Fu &#123; public void method() throws RuntimeException &#123; &#125; "//抛出父类一样的异常" public void method() throws NullPointerException&#123; &#125; "//抛出父类异常的子类" public void method()&#123;&#125; "//不声明异常" &#125;* b：当"父类方法"声明"多个异常"时，"子类""覆盖"时"只能"声明"多个异常"的"子集"(注意是"子集")。 例如： class Fu &#123; public void method () throws NullPointerException, ClassCastException&#123; &#125; &#125; class Zi extends Fu &#123; public void method()throws NullPointerException, ClassCastException &#123; &#125; public void method() throws NullPointerException&#123; &#125; "//抛出父类异常中的一部分" public void method() throws ClassCastException &#123; &#125; "//抛出父类异常中的一部分" &#125;* c：当"父类"被覆盖的"方法""没有""异常声明"时，"子类"覆盖时"不能""声明异常"。 例如： class Fu &#123; public void method ()&#123; &#125; &#125; class Zi extends Fu &#123; public void method() throws Exception &#123; &#125; ！！！error /"错误的方式" &#125;* B：问题：父类中会存在下列这种情况，接口也有这种情况。 接口中没有声明异常，而实现的子类覆盖方法时发生了异常，怎么办？回答：无法进行throws声明，只能catch的捕获。 万一问题处理不了呢？catch中继续throw抛出，但是只能将异常转换成RuntimeException子类抛出。interface Inter &#123; public abstract void method();&#125;class Zi implements Inter &#123; public void method()&#123; //无法声明 throws Exception int[] arr = null; if (arr == null) &#123; //只能捕获处理 try&#123; throw new Exception("哥们，你定义的数组arr是空的!"); &#125; catch(Exception e)&#123; System.out.println("父方法中没有异常抛出，子类中不能抛出Exception异常"); //我们把异常对象e，采用RuntimeException异常方式抛出 throw new RuntimeException(e); &#125; &#125; &#125;&#125; 14Throwable类方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556* A: 常见方法 * a："getMessage()方法" 返回该异常的详细信息字符串，即"异常提示信息" * b："toString()方法" 返回该"异常的名称"与"详细信息字符串" * c："printStackTrace()方法" 在控制台输出"该异常的名称"与"详细信息字符串"、"异常出现的代码【位置】"* B：案例演示 异常的常用方法代码演示 try &#123; Person p= null; if (p==null) &#123; throw new NullPointerException(“出现空指针异常了，请检查对象是否为null”); &#125; &#125; catch (NullPointerException e) &#123; String message = e.getMesage(); System.out.println(message ); String result = e.toString(); System.out.println(result); e.printStackTrace(); &#125;public class ThrowableDemo &#123; public static void main(String[] args) &#123; try&#123; func(); &#125; catch(Exception ex)&#123; System.out.println(ex); System.out.println("--------------------------------------------1"); System.out.println(ex.getMessage()); System.out.println("--------------------------------------------2"); System.out.println(ex.toString()); System.out.println("---------------------------------------------3"); ex.printStackTrace(); &#125; &#125; private static void func() throws Exception&#123; int[] arr =&#123;1,2,3&#125;; for(int i=0;i&lt;5;i++)&#123; if(i&gt;=arr.length)&#123; throw new ArrayIndexOutOfBoundsException("数组长度是"+ arr.length +", 数组越界了..."); &#125; System.out.println(arr[i]); &#125; &#125;&#125; 15自定义异常类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113* A: 自定义异常的定义例如NullPointerException异常类源代码：public class NullPointerException extends RuntimeException &#123; public NullPointerException() &#123; super();"//调用父类构造方法" &#125; public NullPointerException(String s) &#123; super(s);"//调用父类具有异常信息的构造方法" &#125;&#125;* a：通过阅读源码，发现规律： 每个异常中都"调用了父类的构造方法"，把"异常描述信息""传递"给了"父类"， 让"父类"帮我们"进行异常信息的封装"。* b："格式"： Class 异常名 extends Exception&#123; "//或继承RuntimeException" public 异常名()&#123; &#125; public 异常名(String s)&#123; super(s); &#125; &#125; * c：自定义异常"继承Exception"演示class MyException extends Exception&#123; /* 为什么要定义构造函数，因为看到Java中的异常描述类中有提供对异常对象的初始化方法。 */ public MyException()&#123; super(); &#125; public MyException(String message) &#123; // 如果自定义异常需要异常信息， //可以通过调用父类的带有字符串参数的构造函数即可。 super(message); &#125;&#125;* d：自定义异常"继承RuntimeException"演示* class MyException extends RuntimeException&#123; /* 为什么要定义构造函数，因为看到Java中的异常描述类中有提供对异常对象的初始化方法。 */ MyException()&#123; super(); &#125; MyException(String message) &#123; // 如果自定义异常需要异常信息， //可以通过调用父类的带有字符串参数的构造函数即可。 super(message); &#125;&#125;——————————————————————————————————————————————————————————————————————————————————————————* B：自定义异常的练习 在Person类的有参数构造方法中，进行年龄范围的判断， 若年龄为负数或大于200岁，则抛出NoAgeException异常，异常提示信息“年龄数值非法”。 要求：在测试类中，调用有参数构造方法，完成Person对象创建，并进行异常的处理。"//自定义异常类"public class AgeException extends Exception &#123; public AgeException()&#123; &#125; public AgeException(String message)&#123; super(message); &#125;&#125;"//Person类"public class Person &#123; private String name; private int age; public Person()&#123;&#125; public Person(String name, int age) throws AgeException&#123; if(age &lt;0 || age&gt;200)&#123; throw new AgeException("年龄输入有误:" + age); &#125; this.name =name; this.age =age; &#125; @Override public String toString()&#123; return "姓名： "+ name + " |年龄: "+ age; &#125;&#125;"//测试类"public class ExceptionTestDemo &#123; public static void main(String[] args) &#123; try &#123; Person p= new Person("张楠", 209); System.out.println(p.toString()); &#125; catch(AgeException aex)&#123; aex.printStackTrace(); &#125; &#125;&#125;——————————————————————————————————————————————————————————————————————————————————————————* C：关于构造方法"抛出异常总结"(1) 抛出"Exception"，"必须要"throws"声明"，一声明就"告知""调用者"进行"捕获"，一旦"问题处理了"调用者的"程序会继续执行"。(2) 抛出"RuntimeExcpetion","不需要"throws"声明"的，这时调用是"不需要编写捕获代码"的，因为调用者根本就不知道有问题。一旦发生RuntimeException，"调用者程序会停掉"，并有jvm将信息显示到屏幕，让调用者看到问题，"修正代码"。 16总结12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667 异常：就是程序中出现的不正常的现象(错误与异常) 异常的继承体系: Throwable: 它是所有错误与异常的超类（祖宗类） |- Error 错误，修改java源代码 |- Exception 编译期异常, javac.exe进行编译的时候报错 |- RuntimeException 运行期异常, java出现运行过程中出现的问题 异常处理的两种方式： 1，出现问题，自己解决 try…catch…finally try&#123; 可能出现异常的代码 &#125; catch(异常类名 对象名)&#123; 异常处理代码 &#125; finally &#123; 异常操作中一定要执行的代码 &#125; 2，出现问题，别人解决 throws 格式： 修饰符 返回值类型 方法名(参数) throws 异常类名1,异常类名2,...&#123;&#125; public void method() throws Exception&#123;&#125;—————————————————————————————————————————————————————————————————————————————————————————— 异常分类异常的根类是Throwable，其下有两个子类：Error与Exception，平常所说的异常指Exception。 严重错误Error，无法通过处理的错误 编译时异常Exception，编译时无法编译通过。如日期格式化异常 运行时异常RuntimeException，是Exception的子类，运行时可能会报错，可以不处理。如空指针异常 异常基本操作 创建异常对象 抛出异常 处理异常： 捕获处理，将异常获取，使用try/catch做分支处理 try&#123; 需要检测的异常；&#125; catch(异常对象) &#123; 通常我们只使用一个方法：printStackTrace打印异常信息&#125; "声明抛出处理"，"出现异常后不处理"，"声明抛出给调用者处理"。 方法声明上加throws 异常类名 "注意"：异常的处理，指处理"异常"的"一种可能性"，即有了异常处理的代码，"不一定"会"产生异常"。如果没有产生异常，则代码正常执行，如果产生了异常，则中断当前执行代码，执行异常处理代码。—————————————————————————————————————————————————————————————————————————————————————————— 异常注意事项 多异常处理捕获处理： 1多个异常可以分别处理 2多个异常一次捕获多次处理 3多个异常一次捕获，采用同一种方式处理声明抛出异常： 声明上使用,一次声明多个异常 —————————————————————————————————————————————————————————————————————————————————————————— "运行时异常"被抛出可以"不处理"。"即不捕获""也不声明抛出" 如果"父类"抛出了"多个异常","子类覆盖父类方法"时,"只能"抛出相同的异常或者是他的"子集" "父类"方法"没有"抛出异常，"子类覆盖父类该方法"时也"不可抛出异常"。 此时子类产生该异常，只能捕获处理，不能声明抛出 当"多"catch异常处理时，捕获处理，"前边的类""不能"是"后边类"的"父类" 自定义异常如果Java没有提供你需要的异常，则可以自定义异常类。定义方法：编译时异常继承Exception，运行时异常继承RuntimeException。]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础18(Map接口、HashMap集合、LinkedHashMap集合、集合嵌套))]]></title>
    <url>%2F2016%2F10%2F29%2Fday20%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、Map接口2、HashMap集合、LinkedHashMap集合3、集合的嵌套4、集合应用举例 01Map集合概述12345678910111213A:Map集合概述:我们通过查看Map接口描述,发现Map接口下的集合与Collection接口下的集合，它们存储数据的形式不同 a:Collection中的集合，元素是孤立存在的（理解为单身），向集合中存储元素采用一个个元素的方式存储。 b:Map中的集合，元素是成对存在的(理解为夫妻)。每个元素由键与值两部分组成，通过键可以找对所对应的值。 "Collection中的集合称为【单列集合】，Map中的集合称为【双列集合】"。需要注意的是，"Map中的集合【不能】包含【重复的键】"，【"值】可以重复"；"每个【键】只能对应一个【值】"。"如果添加【重复的键】，会把之前的【键值】【覆盖】掉"Map |--HashMap |--LinkedHashMap 02Map接口中的常用方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687A:Map接口中的常用方法 /* * Map接口中的常用方法 * 使用Map接口的实现类 HashMap */ public class MapDemo &#123; public static void main(String[] args) &#123; function_2(); &#125; "/* * 移除集合中的键值对,【返回】被【移除】之前的【值】 * V remove(K) * 如果集合中【没有】这个【键】,【返回null】，不移除任何元素 */" public static void function_2()&#123; Map&lt;Integer,String&gt; map = new HashMap&lt;Integer, String&gt;(); map.put(1, "a"); map.put(2, "b"); map.put(3, "c"); System.out.println(map); String value = map.remove(33);//null System.out.println(value); System.out.println(map); &#125; "/* * 通过键对象,获取值对象 * V get(K) * 如果集合中【没有】这个【键】,【返回null】 */" public static void function_1()&#123; //创建集合对象,作为键的对象整数,值的对象存储字符串 Map&lt;Integer,String&gt; map = new HashMap&lt;Integer, String&gt;(); map.put(1, "a"); map.put(2, "b"); map.put(3, "c"); System.out.println(map); String value = map.get(4);//null System.out.println(value); &#125; "/* * 将键值对存储到集合中 * V put(K,V) K 作为键的对象, V作为值的对象 * 返回值：以前与 key 关联的值，如果没有针对 key 的映射关系，则返回 null。 * 存储的是重复的键,将原有的值,覆盖 * 返回值一般情况下返回null, * 存储重复键的时候,返回被覆盖之前的值 */" public static void function()&#123; //创建集合对象,HashMap,存储对象,键是字符串,值是整数 Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;(); map.put("a", 1); map.put("b", 2); map.put("c", 3); System.out.println(map); &#125; &#125;————————————————————————————————————————————————————————————————————————————————————————Java 8 为 Map 新增的方法&gt; void forEach(BiConsumer action): 该方法是 Java 8 为 Map 新增的 一个遍历 key-value 对的方法 ，通过该方法可以更简洁地遍历 Map 的 key-value 对 。&gt; Object replace(Object key, Object value) : 将 Map 中指定 key 对应的 value 替换成新value。与传统put()方法不同的是，该方法【不可能添加新的 key-value 对】 。 如果尝试替换的 key 在原 Map 中不存在，该方法不会添加 key-value 对 ， 而是返回 null 。&gt; Object computelfAbsent(Object key, Function mappingFunction): 如 果传给该方法的 key 参数在Map 中对应的 value 为 null ，则使用 mappingFunction 根据 key 计算一个新的结果，如果计算结果不为 null ，则用计算结果覆盖原有的 value。如果原 Map 原来不包括该 key，那么该方法可能会添加一组 key-value 对。&gt; Object computelfPresent(Object key, BiFunction remappingFunction): 如果传给该方法的 key 参数在 Map 中对应的 value 不为 null ， 该方法将使用 remappingFunction 根据原 key、 value 计算一个新的结果 ，如果计算结果不为 null ，则使用该结果覆盖原来的 value; 如果计算结果为 null ，则删除原 key-value 对 。 03Map集合遍历方式keySet方法1234567891011121314151617181920212223242526272829303132333435363738394041424344A:Map集合遍历方式"keySet方法" 1.获取Map集合中所有的键，由于键是唯一的，所以返回一个Set集合存储所有的键 2.遍历键的Set集合，得到每一个键 3.根据键利用get(key)去Map找所对应的值 "/* * Map集合的遍历 * 利用键获取值 * Map接口中定义方法keySet * 所有的键,存储到Set集合 */" public class MapDemo1 &#123; public static void main(String[] args) &#123; "/* * 1. 调用map集合的方法keySet,所有的键存储到Set集合中 * 2. 遍历Set集合,获取出Set集合中的所有元素 (Map中的键) * 3. 调用map集合方法get,通过键获取到值 */" Map&lt;String,Integer&gt; map = new HashMap&lt;String,Integer&gt;(); map.put("a", 11); map.put("b", 12); map.put("c", 13); map.put("d", 14); "//1. 调用map集合的方法keySet,所有的键存储到Set集合中" Set&lt;String&gt; set = map.keySet(); "//2. 遍历Set集合,获取出Set集合中的所有元素 (Map中的键)" Iterator&lt;String&gt; it = set.iterator(); while(it.hasNext())&#123; "//it.next返回是Set集合元素,也就是Map中的键 //3. 调用map集合方法get,通过键获取到值" String key = it.next(); Integer value = map.get(key); System.out.println(key+"...."+value); &#125; System.out.println("======================="); // for Each方法更简便 for(String key : map.keySet())&#123; Integer value = map.get(key); System.out.println(key+"...."+value); &#125; &#125; &#125; 04Map集合Entry对象12345678910111213141516171819202122232425在Map类设计时，提供了一个"嵌套接口"："Entry"。Entry将"【键值对】的【对应关系】""封装成了对象"，即"键值对对象"。这样我们在遍历Map集合时，就可以从每一个"键值对（Entry）对象"中获取对应的"键"与对应的"值"。"entrySet()方法"：用于"返回"Map集合中所有的"键值对(Entry)对象"，以"Set集合"形式返回。A:Map集合Entry对象 interface Map&#123; interface Entry&#123;"//Entry是Map的一个【内部接口】，是static的" //由Map的子类的内部类实现 &#125; &#125; class HashMap&#123; static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;//Entry对象指的就是该类的对象 final K key; V value; &#125; &#125; 在Map类设计时，提供了一个"嵌套接口：Entry"。 Entry将键值对的对应关系封装成了对象。 即"键值对对象"，这样我们在遍历Map集合时，就可以"从每一个键值对（Entry）对象中获取对应的键与对应的值"。 a:Entry是Map接口中提供的一个"静态内部嵌套接口"。 b:相关方法  "getKey()方法"：获取Entry对象中的"键"  "getValue()方法"：获取Entry对象中的"值"  "entrySet()方法"：用于"返回"Map集合中所有的"键值对(Entry)对象"，以"Set集合形式返回"。 05Map集合遍历方式entrySet方法123456789101112131415161718192021222324252627282930313233343536A:Map集合遍历方式"entrySet方法"* * Map集合获取方式 * entrySet方法,"键值对映射关系"获取 * 实现步骤: * 1. 调用map集合方法entrySet()将集合中的"映射关系对象","存储"到"Set集合" *" Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet(); *" 2." 迭代Set集合" * 3. 获取出的"Set集合的元素",是"映射关系对象Map.Entry&lt;K, V&gt;" * 4. 通过映射关系对象的方法" getKet(), getValue()"获取"键值对" * * 创建内部类对象 外部类.内部类 = new */public class MapDemo2 &#123; public static void main(String[] args) &#123; Map&lt;Integer,String&gt; map = new HashMap&lt;Integer, String&gt;(); map.put(1, "abc"); map.put(2, "bcd"); map.put(3, "cde"); "//1. 调用map集合方法entrySet()将集合中的映射关系对象,存储到Set集合" Set&lt;Map.Entry &lt;Integer,String&gt; &gt; set = map.entrySet(); "//2. 迭代Set集合" Iterator&lt;Map.Entry &lt;Integer,String&gt; &gt; it = set.iterator(); while(it.hasNext())&#123; "// 3. 获取出的Set集合的元素,是映射关系对象 // it.next 获取的是Map.Entry对象" Map.Entry&lt;Integer, String&gt; entry = it.next(); "//4. 通过映射关系对象方法 getKet, getValue获取键值对" Integer key = entry.getKey(); String value = entry.getValue(); System.out.println(key+"...."+value); &#125; &#125;&#125; 06Map集合遍历方式增强for循环123456789101112131415161718192021222324252627282930313233343536373839404142434445464748A:Map集合遍历方式"增强for循环" A:Map集合遍历方式"entrySet方法"* * Map集合获取方式 * entrySet方法,"键值对映射关系"获取 * 实现步骤: * 1. 调用map集合方法entrySet()将集合中的"映射关系对象","存储"到"Set集合" *" Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet(); *" 2." 迭代Set集合" * 3. 获取出的"Set集合的元素",是"映射关系对象Map.Entry&lt;K, V&gt;" * 4. 通过映射关系对象的方法" getKet(), getValue()"获取"键值对" * * 创建内部类对象 外部类.内部类 = new */—————————————————————————————————————————————————————————————————————————————————————— "注意"：Map接口"没有"继承自"Iterable&lt;E&gt;接口"， "【不能】"直接使用"迭代器或者foreach"进行遍历。"转成Set之后"才可以使用。—————————————————————————————————————————————————————————————————————————————————————— public class MapDemo2 &#123; public static void main(String[] args) &#123; Map&lt;Integer,String&gt; map = new HashMap&lt;Integer, String&gt;(); map.put(1, "abc"); map.put(2, "bcd"); map.put(3, "cde"); //1. 调用map集合方法entrySet()将集合中的映射关系对象,存储到Set集合 Set&lt;Map.Entry &lt;Integer,String&gt; &gt; set = map.entrySet(); //2. 迭代Set集合 Iterator&lt;Map.Entry &lt;Integer,String&gt; &gt; it = set.iterator(); while(it.hasNext())&#123; // 3. 获取出的Set集合的元素,是映射关系对象 // it.next 获取的是什么对象,也是Map.Entry对象 Map.Entry&lt;Integer, String&gt; entry = it.next(); //4. 通过映射关系对象方法 getKet, getValue获取键值对 Integer key = entry.getKey(); String value = entry.getValue(); System.out.println(key+"...."+value); &#125; System.out.println("========================="); for(Map.Entry&lt;Integer, String&gt; entry : map.entrySet())&#123; System.out.println(entry.getKey()+"..."+entry.getValue()); &#125; &#125; &#125;—————————————————————————————————————————————————————————————————————————————————————— "注意：Map集合不能直接使用迭代器或者foreach进行遍历。但是转成Set之后就可以使用了。"—————————————————————————————————————————————————————————————————————————————————————— 07HashMap集合存储和遍历123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110A:HashMap集合存储和遍历 "/* * 使用HashMap集合,存储自定义的对象 * 自定义对象,作为键,出现,作为值出现 */" public class HashMapDemo &#123; public static void main(String[] args) &#123; function_1(); &#125; "/* * HashMap 存储自定义对象Person,作为键出现 * 键的对象,是Person类型,值是字符串 * 保证键的唯一性,存储到键的对象,【【重写hashCode equals】】，见下面的Person类 */" public static void function_1()&#123; HashMap&lt;Person, String&gt; map = new HashMap&lt;Person, String&gt;(); map.put(new Person("a",20), "里约热内卢"); map.put(new Person("b",18), "索马里"); map.put(new Person("b",18), "索马里"); map.put(new Person("c",19), "百慕大"); for(Person key : map.keySet())&#123; String value = map.get(key); System.out.println(key+"..."+value); &#125; System.out.println("==================="); for(Map.Entry&lt;Person, String&gt; entry : map.entrySet())&#123; System.out.println(entry.getKey()+"..."+entry.getValue()); &#125; &#125; "/* * HashMap 存储自定义的对象Person,作为值出现 * 【【键的对象,是字符串,可以保证唯一性】】 */" public static void function()&#123; HashMap&lt;String, Person&gt; map = new HashMap&lt;String, Person&gt;(); map.put("beijing", new Person("a",20)); map.put("tianjin", new Person("b",18)); map.put("shanghai", new Person("c",19)); for(String key : map.keySet())&#123; Person value = map.get(key); System.out.println(key+"..."+value); &#125; System.out.println("================="); for(Map.Entry&lt;String, Person&gt; entry : map.entrySet())&#123; String key = entry.getKey(); Person value = entry.getValue(); System.out.println(key+"..."+value); &#125; &#125; &#125;public class Person &#123; private String name; private int age; public Person() &#123; &#125; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Person&#123;" + "name='" + name + '\'' + ", age=" + age + '&#125;'; &#125; //重写方法hashCode和equals @Override public int hashCode()&#123; return this.name.hashCode()+this.age*31; &#125; @Override public boolean equals(Object obj)&#123; if(this == obj)&#123; return true; &#125; if(obj == null)&#123; return false; &#125; if(obj instanceof Person)&#123; Person p = (Person) obj; return Objects.equals(this.name,p.name) &amp;&amp; this.age==p.age;// return this.name.equals(p.name) &amp;&amp; this.age==p.age; &#125; return false; &#125;&#125; 08LinkedHashMap的特点12345678910111213141516*A:LinkedHashMap的特点 "/* * LinkedHashMap继承HashMap * 保证迭代的顺序,有序的HashMap */" public class LinkedHashMapDemo &#123; public static void main(String[] args) &#123; LinkedHashMap&lt;String, String&gt; link = new LinkedHashMap&lt;String, String&gt;(); link.put("1", "a"); link.put("13", "a"); link.put("15", "a"); link.put("17", "a"); System.out.println(link); &#125; &#125; 09Hashtable的特点123456789101112131415161718192021*A:Hashtable的特点 * * "Map接口实现类 Hashtable" * 底层数据结果哈希表,特点和HashMap是一样的 * "Hashtable" "线程安全"集合,运行"速度慢" * "HashMap" "线程不安全"的集合,运行"速度快" * * Hashtable命运和Vector是一样的,从JDK1.2开始,被更先进的HashMap取代 * * "HashMap" "允许存储""null值,null键" * "Hashtable" "不允许存储""null值,null键" * * Hashtable他的孩子,"子类 Properties 依然活跃"在开发舞台 * public class HashtableDemo &#123; public static void main(String[] args) &#123; Map&lt;String,String&gt; map = new Hashtable&lt;String,String&gt;(); map.put(null, null); System.out.println(map); &#125; &#125; 10静态导入1234567891011121314151617181920212223242526272829303132333435363738394041*A:静态导入:如果"本类"中有和"静态导入"的"同名方法"会"优先使用""本类"的 如果还想使用静态导入的,依然需要类名来调用 "/* * JDK1.5新特性,静态导入 * 减少开发的代码量 * 标准的写法,【导入包】的时候才能使用 * * import static java.lang.System.out;【最末尾】,【必须】是一个【静态成员】 */" import static java.lang.System.out; import static java.util.Arrays.sort; public class StaticImportDemo &#123; public static void main(String[] args) &#123; out.println("hello"); int[] arr = &#123;1,4,2&#125;; sort(arr); &#125; &#125;例如：Map.Entry的访问，简化后为Entryimport static java.util.Map.Entry;public class HashMapTest &#123; public static void main(String[] args) &#123; "//1,创建hashmap集合对象。" Map&lt;Student,String&gt; map = new HashMap&lt;Student,String&gt;(); "//取出元素。键值对方式" //Set&lt;Map.Entry&lt;Student, String&gt;&gt; entrySet = map.entrySet(); Set&lt;Entry&lt;Student, String&gt;&gt; entrySet = map.entrySet();//静态导入后，直接用Entry //for (Map.Entry&lt;Student, String&gt; entry : entrySet) &#123; for (Entry&lt;Student, String&gt; entry : entrySet) &#123; Student key = entry.getKey(); String value = entry.getValue(); System.out.println(key.toString()+"....."+value); &#125; &#125;&#125; 11方法的可变参数12345678910111213141516171819202122232425262728293031323334353637*A:方法的可变参数 * * JDK1.5新的特性,"方法的可变参数" * 前提: 方法参数数据类型确定,"参数的个数""任意" * 可变参数语法: "数据类型...变量名" * "可变参数","本质"就是一个"数组" */ public class VarArgumentsDemo &#123; public static void main(String[] args) &#123; //调用一个带有可变参数的方法,传递参数,可以任意 // getSum(); int sum = getSum(5,34,3,56,7,8,0); System.out.println(sum); &#125; /* * 定义方法,计算10个整数和 * 方法的可变参数实现 */ public static int getSum(int...a)&#123; int sum = 0 ; for(int i : a)&#123; sum = sum + i; &#125; return sum; &#125; "可变参数","本质"就是一个"数组" private static void func(int ... arr)&#123; for(int i=0;i&lt;arr.length;i++)&#123; arr[i] *= 2; System.out.println(arr[i]); &#125; &#125; &#125; 12可变参数的注意事项123456789*A:可变参数的注意事项 * * 可变参数的注意事项 * 1. "一个方法中,【可变参数】"只能"有【一个】" * 2. 方法的"参数列表"中"可变参数"和"普通参数""都有"时,"必须"写在参数列表的"末尾位置（最后）" */ private static void funb(int a,int b,int ... arr)&#123; &#125; 13Collections工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132A:Collections工具类 * * 集合操作的工具类 * "Collections" * 均为"静态方法"，通过"Collections.方法名"进行调用 */public static &lt;T&gt; boolean addAll(Collection&lt;? super T&gt; c,T...elements)将所有指定的元素添加到指定的集合。 要添加的元素【可以单独指定】或【作为数组指定】。 这种方便方法的行为与c.addAll(Arrays.asList(elements)) 相同 ，但是在大多数实现中，【这种方法可能会显着加快】。【单独指定元素】时，此方法为现有集合添加一些元素提供了一种便捷的方法：Collections.addAll(flavors, "Peaches 'n Plutonium", "Rocky Racoon"); 参数类型T - 要添加和收集的元素的类参数c - 要插入 elements的集合elements - 要插入到 c的元素结果true如果集合由于调用而更改—————————————————————————————————————————————————————————————————————————————————————————Element[] array = &#123;new Element(1),new Element(2),new Element(3)&#125;;"将数组转化成List":(1)"利用ArrayList的构造方法"ArrayList&lt;Element&gt; arrayList = new ArrayList&lt;Element&gt;(Arrays.asList(array));ArrayList(Collection &lt; ? extends E &gt; c) : 构造一个包含特定容器的元素的列表ArrayList，并且根据容器迭代器的顺序返回。 所以"构造方法"所做的事情如下： 1.将"容器c转换为一个数组" 2.将"数组拷贝到ArrayList中称为”elementData”的数组"中 ArrayList的构造方法的源码如下：public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125;—————————————————————————————————————————————————————————————————————————————————————————(2)"Arrays.asList(array)方法"List&lt;Element&gt; list1 = Arrays.asList(array);"asList()返回的列表的大小是固定的"。事实上，返回的列表"不是java.util.ArrayList"，而是定义在java.util.Arrays中一个"私有静态类"。我们知道ArrayList的实现本质上是一个数组，而asList()返回的列表是由原始数组支持的固定大小的列表。这种情况下，如果"添加或删除列表中的元素，程序会抛出异常"UnsupportedOperationException。—————————————————————————————————————————————————————————————————————————————————————————(3)(java.util.Collections包),"Collections.addAll(list2, array)方法"；List&lt;element&gt; list2 = new ArrayList&lt;element&gt;();Collections.addAll(list2, array);"这种方便方法的行为与c.addAll(Arrays.asList(elements)) 相同 ，但是在大多数实现中，这种方法可能会显着加快"。————————————————————————————————————————————————————————————————————————————————————————— public class CollectionsDemo &#123; public static void main(String[] args) &#123; function_2(); &#125; "/* * Collections.shuffle方法 * 对List集合中的元素,进行随机排列 */" public static void function_2()&#123; List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(1); list.add(5); list.add(9); list.add(11); list.add(8); list.add(10); list.add(15); list.add(20); System.out.println(list); //调用工具类方法shuffle对集合随机排列 Collections.shuffle(list); System.out.println(list); &#125; "/* * Collections.binarySearch静态方法 * 对List集合进行二分搜索,方法参数,传递List集合,传递被查找的元素 * ！！！注意：使用该方法前，"必须"先进行"排序" */" public static void function_1()&#123; List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(1); list.add(5); list.add(8); list.add(10); list.add(15); list.add(20); //调用工具类静态方法binarySearch int index = Collections.binarySearch(list, 16); System.out.println(index); &#125; "/* * Collections.sort静态方法 * 对于List集合,进行"升序排列" */" public static void function()&#123; //创建List集合 List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add("ewrew"); list.add("qwesd"); list.add("Qwesd"); list.add("bv"); list.add("wer"); System.out.println(list); //调用集合工具类的方法sort Collections.sort(list); System.out.println(list); &#125; &#125; 14集合的嵌套123456789101112131415161718192021222324252627282930313233343536373839404142A:集合的嵌套/* * Map集合的嵌套,Map中存储的还是Map集合 * 要求: * 传智播客 * Java基础班 * 001 张三 * 002 李四 * * Java就业班 * 001 王五 * 002 赵六 * 对以上数据进行对象的存储 * 001 张三 键值对 * Java基础班: 存储学号和姓名的键值对 * Java就业班: * 传智播客: 存储的是班级 * * 基础班Map &lt;学号,姓名&gt; * 传智播客Map &lt;班级名字, 基础班Map&gt; */public class MapMapDemo &#123; public static void main(String[] args) &#123; //定义基础班集合 HashMap&lt;String, String&gt; javase = new HashMap&lt;String, String&gt;(); //定义就业班集合 HashMap&lt;String, String&gt; javaee = new HashMap&lt;String, String&gt;(); //向班级集合中,存储学生信息 javase.put("001", "张三"); javase.put("002", "李四"); javaee.put("001", "王五"); javaee.put("002", "赵六"); //定义传智播客集合容器,键是班级名字,值是两个班级容器 HashMap&lt;String, HashMap&lt;String,String&gt;&gt; czbk = new HashMap&lt;String, HashMap&lt;String,String&gt;&gt;(); czbk.put("基础班", javase); czbk.put("就业班", javaee); keySet(czbk); &#125; 15集合的嵌套keySet遍历1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980A:集合的嵌套keySet遍历 /* * Map集合的嵌套,Map中存储的还是Map集合 * 要求: * 传智播客 * Java基础班 * 001 张三 * 002 李四 * * Java就业班 * 001 王五 * 002 赵六 * 对以上数据进行对象的存储 * 001 张三 键值对 * Java基础班: 存储学号和姓名的键值对 * Java就业班: * 传智播客: 存储的是班级 * * 基础班Map &lt;学号,姓名&gt; * 传智播客Map &lt;班级名字, 基础班Map&gt; */public class MapMapDemo &#123; public static void main(String[] args) &#123; //定义基础班集合 HashMap&lt;String, String&gt; javase = new HashMap&lt;String, String&gt;(); //定义就业班集合 HashMap&lt;String, String&gt; javaee = new HashMap&lt;String, String&gt;(); //向班级集合中,存储学生信息 javase.put("001", "张三"); javase.put("002", "李四"); javaee.put("001", "王五"); javaee.put("002", "赵六"); //定义传智播客集合容器,键是班级名字,值是两个班级容器 HashMap&lt;String, HashMap&lt;String,String&gt;&gt; czbk = new HashMap&lt;String, HashMap&lt;String,String&gt;&gt;(); czbk.put("基础班", javase); czbk.put("就业班", javaee); keySet(czbk); &#125; "//keySet() Iterator 遍历"public static void keySet(HashMap&lt;String,HashMap&lt;String,String&gt;&gt; czbk)&#123;"//调用czbk集合方法keySet将键存储到Set集合"Set&lt;String&gt; classNameSet = czbk.keySet();"//迭代Set集合"Iterator&lt;String&gt; classNameIt = classNameSet.iterator();while(classNameIt.hasNext())&#123; "//classNameIt.next获取出来的是Set集合元素,czbk集合的键" String classNameKey = classNameIt.next(); "//czbk集合的方法get获取值,值是一个HashMap集合" HashMap&lt;String,String&gt; classMap = czbk.get(classNameKey); "//调用classMap集合方法keySet,键存储到Set集合" Set&lt;String&gt; studentNum = classMap.keySet(); Iterator&lt;String&gt; studentIt = studentNum.iterator(); while(studentIt.hasNext())&#123; "//studentIt.next获取出来的是classMap的键,学号" String numKey = studentIt.next(); "//调用classMap集合中的get方法获取值" String nameValue = classMap.get(numKey); System.out.println(classNameKey+".."+numKey+".."+nameValue); &#125;&#125;System.out.println("==================================");"//keySet() forEach 遍历"for(String className: czbk.keySet())&#123; HashMap&lt;String, String&gt; hashMap = czbk.get(className); for(String numKey : hashMap.keySet())&#123; String nameValue = hashMap.get(numKey); System.out.println(className+".."+numKey+".."+nameValue); &#125;&#125;&#125;&#125; 16集合的嵌套entrySet遍历123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384A:集合的嵌套entrySet遍历/* * Map集合的嵌套,Map中存储的还是Map集合 * 要求: * 传智播客 * Java基础班 * 001 张三 * 002 李四 * * Java就业班 * 001 王五 * 002 赵六 * 对以上数据进行对象的存储 * 001 张三 键值对 * Java基础班: 存储学号和姓名的键值对 * Java就业班: * 传智播客: 存储的是班级 * * 基础班Map &lt;学号,姓名&gt; * 传智播客Map &lt;班级名字, 基础班Map&gt; */public class MapMapDemo &#123; public static void main(String[] args) &#123; //定义基础班集合 HashMap&lt;String, String&gt; javase = new HashMap&lt;String, String&gt;(); //定义就业班集合 HashMap&lt;String, String&gt; javaee = new HashMap&lt;String, String&gt;(); //向班级集合中,存储学生信息 javase.put("001", "张三"); javase.put("002", "李四"); javaee.put("001", "王五"); javaee.put("002", "赵六"); //定义传智播客集合容器,键是班级名字,值是两个班级容器 HashMap&lt;String, HashMap&lt;String,String&gt;&gt; czbk = new HashMap&lt;String, HashMap&lt;String,String&gt;&gt;(); czbk.put("基础班", javase); czbk.put("就业班", javaee); entrySet(czbk);&#125;"//entrySet() Iterator 遍历"public static void entrySet(HashMap&lt;String,HashMap&lt;String,String&gt;&gt; czbk)&#123;"//调用czbk集合方法entrySet方法,将czbk集合的键值对关系对象,存储到Set集合"Set&lt;Map.Entry&lt;String, HashMap&lt;String,String&gt;&gt;&gt; classNameSet = czbk.entrySet();"//迭代器迭代Set集合"Iterator&lt;Map.Entry&lt;String, HashMap&lt;String,String&gt;&gt;&gt; classNameIt = classNameSet.iterator();while(classNameIt.hasNext())&#123; "//classNameIt.next方法,取出的是czbk集合的键值对关系对象" Map.Entry&lt;String, HashMap&lt;String,String&gt;&gt; classNameEntry = classNameIt.next(); //classNameEntry方法 getKey,getValue String classNameKey = classNameEntry.getKey(); "//获取值,值是一个Map集合" HashMap&lt;String,String&gt; classMap = classNameEntry.getValue(); "//调用班级集合classMap方法entrySet,键值对关系对象存储Set集合" Set&lt;Map.Entry&lt;String, String&gt;&gt; studentSet = classMap.entrySet(); "//迭代Set集合" Iterator&lt;Map.Entry&lt;String, String&gt;&gt; studentIt = studentSet.iterator(); while(studentIt.hasNext())&#123; "//studentIt方法next获取出的是班级集合的键值对关系对象" Map.Entry&lt;String, String&gt; studentEntry = studentIt.next(); //studentEntry方法 getKey getValue String numKey = studentEntry.getKey(); String nameValue = studentEntry.getValue(); System.out.println(classNameKey+".."+numKey+".."+nameValue); &#125;&#125; System.out.println("==================================");"//entrySet() Iterator 遍历"for (Map.Entry&lt;String, HashMap&lt;String, String&gt;&gt; me : czbk.entrySet()) &#123; String classNameKey = me.getKey(); HashMap&lt;String, String&gt; numNameMapValue = me.getValue(); for (Map.Entry&lt;String, String&gt; nameMapEntry : numNameMapValue.entrySet()) &#123; String numKey = nameMapEntry.getKey(); String nameValue = nameMapEntry.getValue(); System.out.println(classNameKey + ".." + numKey + ".." + nameValue); &#125;&#125;&#125;&#125; 17集合应用举例：斗地主的功能分析12345678910111213141516171819A:斗地主的功能分析 a:具体规则： 1. 组装54张扑克牌 2. 将54张牌顺序打乱 3. 三个玩家参与游戏，三人交替摸牌，每人17张牌，最后三张留作底牌。 4. 查看三人各自手中的牌（按照牌的大小排序）、底牌 b:分析: 1.准备牌： 完成数字与纸牌的映射关系： 使用双列Map(HashMap)集合，完成一个数字与字符串纸牌的对应关系(相当于一个字典)。 2.洗牌： 通过数字完成洗牌发牌 3.发牌： 将每个人以及底牌设计为ArrayList&lt;String&gt;,将最后3张牌直接存放于底牌，剩余牌通过对3取模依次发牌。 存放的过程中要求数字大小与斗地主规则的大小对应。 将代表不同纸牌的数字分配给不同的玩家与底牌。 4.看牌： 通过Map集合找到对应字符展示。 通过查询纸牌与数字的对应关系，由数字转成纸牌字符串再进行展示。 18斗地主的准备牌123456789101112131415161718192021222324252627282930313233343536A:斗地主的准备牌 /* * 实现模拟斗地主的功能 * 1. 组合牌 * 2. 洗牌 * 3. 发牌 * 4. 看牌 */ public class DouDiZhu &#123; public static void main(String[] args) &#123; //1. 组合牌 //创建Map集合,键是编号,值是牌 HashMap&lt;Integer,String&gt; pooker = new HashMap&lt;Integer, String&gt;(); //创建List集合,存储编号 ArrayList&lt;Integer&gt; pookerNumber = new ArrayList&lt;Integer&gt;(); //定义出13个点数的数组 String[] numbers = &#123;"2","A","K","Q","J","10","9","8","7","6","5","4","3"&#125;; //定义4个花色数组 String[] colors = &#123;"♠","♥","♣","♦"&#125;; //定义整数变量,作为键出现 int index = 2; //遍历数组,花色+点数的组合,存储到Map集合 for(String number : numbers)&#123; for(String color : colors)&#123; pooker.put(index, color+number); pookerNumber.add(index); index++; &#125; &#125; //存储大王,和小王,索引是从0~54,对应大王,小王,...3(牌的顺序从大到小) pooker.put(0, "大王"); pookerNumber.add(0); pooker.put(1, "小王"); pookerNumber.add(1); &#125; 19斗地主的洗牌123456789101112131415161718192021222324252627282930313233343536373839404142A:斗地主的洗牌 /* * 实现模拟斗地主的功能 * 1. 组合牌 * 2. 洗牌 * 3. 发牌 * 4. 看牌 */ public class DouDiZhu &#123; public static void main(String[] args) &#123; //1. 组合牌 //创建Map集合,键是编号,值是牌 HashMap&lt;Integer,String&gt; pooker = new HashMap&lt;Integer, String&gt;(); //创建List集合,存储编号 ArrayList&lt;Integer&gt; pookerNumber = new ArrayList&lt;Integer&gt;(); //定义出13个点数的数组 String[] numbers = &#123;"2","A","K","Q","J","10","9","8","7","6","5","4","3"&#125;; //定义4个花色数组 String[] colors = &#123;"♠","♥","♣","♦"&#125;; //定义整数变量,作为键出现 int index = 2; //遍历数组,花色+点数的组合,存储到Map集合 for(String number : numbers)&#123; for(String color : colors)&#123; pooker.put(index, color+number); pookerNumber.add(index); index++; &#125; &#125; //存储大王,和小王 pooker.put(0, "大王"); pookerNumber.add(0); pooker.put(1, "小王"); pookerNumber.add(1); //洗牌,将牌的编号打乱 Collections.shuffle(pookerNumber); &#125; &#125; 20斗地主的发牌123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566A:斗地主的发牌/* * 实现模拟斗地主的功能 * 1. 组合牌 * 2. 洗牌 * 3. 发牌 * 4. 看牌 */public class DouDiZhu &#123; public static void main(String[] args) &#123; //1. 组合牌 //创建Map集合,键是编号,值是牌 HashMap&lt;Integer,String&gt; pooker = new HashMap&lt;Integer, String&gt;(); //创建List集合,存储编号 ArrayList&lt;Integer&gt; pookerNumber = new ArrayList&lt;Integer&gt;(); //定义出13个点数的数组 String[] numbers = &#123;"2","A","K","Q","J","10","9","8","7","6","5","4","3"&#125;; //定义4个花色数组 String[] colors = &#123;"♠","♥","♣","♦"&#125;; //定义整数变量,作为键出现 int index = 2; //遍历数组,花色+点数的组合,存储到Map集合 for(String number : numbers)&#123; for(String color : colors)&#123; pooker.put(index, color+number); pookerNumber.add(index); index++; &#125; &#125; //存储大王,和小王 pooker.put(0, "大王"); pookerNumber.add(0); pooker.put(1, "小王"); pookerNumber.add(1); //洗牌,将牌的编号打乱 Collections.shuffle(pookerNumber); //发牌功能,将牌编号,发给玩家集合,底牌集合 ArrayList&lt;Integer&gt; player1 = new ArrayList&lt;Integer&gt;(); ArrayList&lt;Integer&gt; player2 = new ArrayList&lt;Integer&gt;(); ArrayList&lt;Integer&gt; player3 = new ArrayList&lt;Integer&gt;(); ArrayList&lt;Integer&gt; bottom = new ArrayList&lt;Integer&gt;(); //发牌采用的是集合索引%3 for(int i = 0 ; i &lt; pookerNumber.size() ; i++)&#123; //先将底牌做好 if(i &lt; 3)&#123; //存到底牌去 bottom.add( pookerNumber.get(i)); //对索引%3判断 &#125;else if(i % 3 == 0)&#123; //索引上的编号,发给玩家1 player1.add( pookerNumber.get(i) ); &#125;else if( i % 3 == 1)&#123; //索引上的编号,发给玩家2 player2.add( pookerNumber.get(i) ); &#125;else if( i % 3 == 2)&#123; //索引上的编号,发给玩家3 player3.add( pookerNumber.get(i) ); &#125; &#125; &#125; &#125; 21斗地主的看牌1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283A:斗地主的看牌 /* * 实现模拟斗地主的功能 * 1. 组合牌 * 2. 洗牌 * 3. 发牌 * 4. 看牌 */public class DouDiZhu &#123; public static void main(String[] args) &#123; //1. 组合牌 //创建Map集合,键是编号,值是牌 HashMap&lt;Integer,String&gt; pooker = new HashMap&lt;Integer, String&gt;(); //创建List集合,存储编号 ArrayList&lt;Integer&gt; pookerNumber = new ArrayList&lt;Integer&gt;(); //定义出13个点数的数组 String[] numbers = &#123;"2","A","K","Q","J","10","9","8","7","6","5","4","3"&#125;; //定义4个花色数组 String[] colors = &#123;"♠","♥","♣","♦"&#125;; //定义整数变量,作为键出现 int index = 2; //遍历数组,花色+点数的组合,存储到Map集合 for(String number : numbers)&#123; for(String color : colors)&#123; pooker.put(index, color+number); pookerNumber.add(index); index++; &#125; &#125; //存储大王,和小王 pooker.put(0, "大王"); pookerNumber.add(0); pooker.put(1, "小王"); pookerNumber.add(1); //洗牌,将牌的编号打乱 Collections.shuffle(pookerNumber); //发牌功能,将牌编号,发给玩家集合,底牌集合 ArrayList&lt;Integer&gt; player1 = new ArrayList&lt;Integer&gt;(); ArrayList&lt;Integer&gt; player2 = new ArrayList&lt;Integer&gt;(); ArrayList&lt;Integer&gt; player3 = new ArrayList&lt;Integer&gt;(); ArrayList&lt;Integer&gt; bottom = new ArrayList&lt;Integer&gt;(); //发牌采用的是集合索引%3 for(int i = 0 ; i &lt; pookerNumber.size() ; i++)&#123; //先将底牌做好 if(i &lt; 3)&#123; //存到底牌去 bottom.add( pookerNumber.get(i)); //对索引%3判断 &#125;else if(i % 3 == 0)&#123; //索引上的编号,发给玩家1 player1.add( pookerNumber.get(i) ); &#125;else if( i % 3 == 1)&#123; //索引上的编号,发给玩家2 player2.add( pookerNumber.get(i) ); &#125;else if( i % 3 == 2)&#123; //索引上的编号,发给玩家3 player3.add( pookerNumber.get(i) ); &#125; &#125; //对玩家手中的编号排序 Collections.sort(player1); Collections.sort(player2); Collections.sort(player3); //看牌,将玩家手中的编号,到Map集合中查找,根据键找值 //定义方法实现 look("刘德华",player1,pooker); look("张曼玉",player2,pooker); look("林青霞",player3,pooker); look("底牌",bottom,pooker);&#125; public static void look(String name,ArrayList&lt;Integer&gt; player,HashMap&lt;Integer,String&gt; pooker)&#123; //遍历ArrayList集合,获取元素,作为键,到集合Map中找值 System.out.print(name+" "); for(Integer key : player)&#123; String value = pooker.get(key); System.out.print(value+" "); &#125; System.out.println();&#125;&#125; 小结1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465 Map集合: map集合中的元素都是成对出现，成对存储的 map集合中的元素都是以一对键和值的形式组成存在的，称为键值对 map集合中的键不能重复存储，值可以重复 map集合中的每一个键 对应着一个值 方法：V put(K key, V value) 把指定的键与指定的值添加到Map集合中V remove(Object key) 把指定的键 所对应的键值对元素 在Map集合中删除，返回被删除元素的值Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() 获取到Map集合中所有的键值对对象的集合(Set集合)V get(Object key) 根据指定的键，在Map集合中获取对应的值Set&lt;K&gt; keySet() 获取Map集合中所有的键，存储到Set集合中——————————————————————————————————————————————————————————————————————————————————————  Map集合遍历的两种方式 方式1：根据键找值的方式 //a, 获取到Map集合中所有的键，返回对应的Set集合 //b, 遍历键的集合，获取到每一个键 //c, 通过键，找到对应的值 //获取到Map集合中所有的键，返回对应的Set集合 Set&lt;String&gt; keys = map.keySet(); //遍历键的集合，获取到每一个键 for (String key : keys) &#123; //通过键，找到对应的值 Student s = map.get(key); System.out.println( key + "..." + s.getName() + "..." + s.getAge() ); &#125;—————————————————————————————————————————————————————————— 方式2：根据键值对对象找键和值的方式 //a, 获取Map集合中所有的键值对元素,返回对应的Set集合 //b, 遍历键值对元素集合，获取到每一个键值对元素对象 //c, 通过键值对元素对象，获取对应的键，和对应的值 //获取Map集合中所有的键值对元素,返回对应的Set集合 Set&lt; Map.Entry&lt;String, Student&gt;&gt; entrySet = map.entrySet(); //遍历键值对元素集合，获取到每一个键值对元素对象 for (Map.Entry&lt;String, Student&gt; entry : entrySet) &#123; //通过键值对元素对象，获取对应的键，和对应的值 //找键 String key = entry.getKey(); //找值 Student s = entry.getValue(); //打印 System.out.println( key+"..."+s.getName()+"..."+s.getAge() ); &#125;——————————————————————————————————————————————————————————————————————————————————————  HashMap: 特点： "是Map集合的子集合 底层采用【哈希表】结构 HashMap集合中的key不能重复，通过【重写】hashCode() 与 equals()方法来保证【键的唯一】。 【不能保证】元素存与取的【顺序】完全一致"——————————————————————————————————————————————————————————————————————————————————————  LinkedHashMap: 特点： "是HashMap集合的子集合 底层采用【哈希表+链表】结构 LinkedHashMap集合中的key【不能重复】，通过【重写】hashCode() 与 equals()方法来保证【键的唯一】"。——————————————————————————————————————————————————————————————————————————————————————  Collections中的方法： public static &lt;T&gt; void sort(List&lt;T&gt; list) 排序 public static void shuffle(List&lt;?&gt; list) 集合中的元素存储位置随机打乱]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础17(List接口、Set接口以及其实现的集合类，哈希表(Hash table)，Queue接口(队列),Deque 接口(双端队列))]]></title>
    <url>%2F2016%2F10%2F28%2Fday19%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、List接口2、ArrayList集合、LinkedList集合3、Set接口4、哈希表(Hash table)5、HashSet集合、LinkedHashSet集合、TreeSet集合6、判断集合唯一性原理7、Queue接口(队列)8、PrioritQueue 优先级队列9、Deque 接口(双端队列)、ArrayDeque 实现类 01List接口的特点12345678910A:List接口的特点:a:"它是一个元素【存取有序】的集合。" 例如，存元素的顺序是11、22、33。那么集合中，元素的存储就是按照11、22、33的顺序完成的）。b:"它是一个【带有索引】的集合"，通过索引就可以精确的操作集合中的元素（与数组的索引是一个道理）。 c:"集合中【可以有重复】的元素"，通过元素的equals方法，来比较是否为重复的元素。 d:List接口的常用子类有： ArrayList集合 LinkedList集合 02List接口的特有方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576A:List接口的特有方法(带索引的方法)a:增加元素方法 add(Object e)："向集合末尾处，添加指定的元素"  add(int index, Object e) "向集合指定索引处，添加指定的元素，原有元素依次后移" /* * add(int index, E) * 将元素插入到列表的指定索引上 * 带有索引的操作,防止越界问题 * java.lang.IndexOutOfBoundsException * ArrayIndexOutOfBoundsException * StringIndexOutOfBoundsException */ public static void function()&#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add("abc1"); list.add("abc2"); list.add("abc3"); list.add("abc4"); System.out.println(list); list.add(1, "itcast"); System.out.println(list); &#125;——————————————————————————————————————————————————————————————————————————————————————————b:删除元素删除 remove(Object e)："将指定元素对象，从集合中删除，返回值为被删除的元素" remove(int index)："将指定索引处的元素，从集合中删除，返回值为被删除的元素" /* * E remove(int index) * 移除指定索引上的元素 * 返回被删除之前的元素 */ public static void function_1()&#123; List&lt;Double&gt; list = new ArrayList&lt;Double&gt;(); list.add(1.1); list.add(1.2); list.add(1.3); list.add(1.4); Double d = list.remove(0); System.out.println(d); System.out.println(list); &#125;——————————————————————————————————————————————————————————————————————————————————————————c:替换元素方法 set(int index, Object e)："将指定索引处的元素，替换成指定的元素，返回值为替换前的元素"注意："指定的索引【必须】是List集合的有效索引"、例如集合长度是4，就不能指定替换索引为4处的元素。也就是说，set(int index, Object element)方法"【不会改变】List集合的【长度】" " /* * E set(int index, E) * 修改指定索引上的元素 * 返回【被修改之前】的元素 */" public static void function_2()&#123; List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(1); list.add(2); list.add(3); list.add(4); Integer i = list.set(0, 5); System.out.println(i); System.out.println(list); &#125;d:查询元素方法 get(int index)：获取指定索引处的元素，并返回该元素——————————————————————————————————————————————————————————————————————————————————————————e:指定元素的索引 indexOf int indexOf(Object o)"返回此列表中第一次出现的【指定元素的索引】；如果此列表不包含该元素，则返回 -1。"更确切地讲，返回满足 (o==null ? get(i)==null : o.equals(get(i))) 的"最低索引 i"；如果没有这样的索引，则返回 -1。 03迭代器的并发修改异常123456789101112131415161718192021222324252627282930313233343536373839A:迭代器的并发修改异常 "/* * 迭代器的并发修改异常 java.util.ConcurrentModificationException (并发修改异常) * 就是在遍历的过程中,使用了集合方法【修改】了【集合的长度】,不允许的 */" public class ListDemo1 &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add("abc1"); list.add("abc2"); list.add("abc3"); list.add("abc4"); //对集合使用迭代器进行获取,获取时候判断集合中是否存在 "abc3"对象 //如果有,添加一个元素 "ABC3" Iterator&lt;String&gt; it = list.iterator(); while(it.hasNext())&#123; String s = it.next(); //对获取出的元素s,进行判断,是不是有"abc3" if(s.equals("abc3"))&#123; "添加一个元素 "ABC3",造成集合长度变化，抛出异常" list.add("ABC3");//error "修改指定索引的元素为"ABC3",【没有】造成集合长度变化，正常运行" list.set(list.indexOf("abc3"),"ABC3");//正常运行 &#125; System.out.println(s); &#125; &#125; &#125;运行上述代码发生了错误 java.util.ConcurrentModificationException这是什么原因呢？在迭代过程中，使用了集合的方法对元素进行操作。"导致迭代器并不知道集合中的变化，容易引发数据的不确定性"。"并发修改异常解决办法"："在迭代时，【不要使用】集合的方法操作元素"。或者"通过ListIterator迭代器操作元素是可以"的，ListIterator的出现，解决了使用Iterator迭代过程中可能会发生的错误情况。 04数据的存储结构12345678910A:数据的存储结构 a:栈结构:"后进先出/先进后出"(手枪弹夹) FILO (first in last out) b:队列结构:"先进先出/后进后出"(银行排队) FIFO(first in first out) c:数组结构: "【查询快】:通过索引快速找到元素" "【增删慢】:每次增删都需要开辟新的数组,将老数组中的元素拷贝到新数组中" " 开辟新数组耗费资源" d:链表结构 " 【查询慢】:每次都需要从链头或者链尾找起" "【增删快】:只需要修改元素记录的下个元素的地址值即可不需要移动大量元素" 05ArrayList集合的自身特点1234567891011A:ArrayList集合的自身特点 底层采用的是数组结构 ArrayList al=new ArrayList();//创建了一个长度为0的Object类型数组 al.add("abc");"//底层会创建一个长度为10的Object数组 "Object[] obj=new Object[10] //obj[0]="abc" "//如果添加的元素的超过10个,底层会开辟一个1.5*10的长度的新数组" "//把原数组中的元素【拷贝】(Arrays.copyOf)到新数组,再把最后一个元素添加到新数组中"原数组: a b c d e f g h k l添加m: a b c d e f g h k l m null null null null 06LinkedList集合的自身特点123456789101112131415161718A:LinkedList集合的自身特点LinkedList 类是 "List 接口 "的 实现类,LinkedList 还实现了 "Deque 接口",可以被当成"双端队列"来使用 ， 因此既可以被当成"栈"来使用，也可以 当成"队列"使用 。"底层采用链表结构,每次查询都要从【链头】或【链尾】找起,【查询】相对数组【较慢】""但是【删除元素】直接【修改元素记录的地址值】即可,不需要大量移动元素，【增删】相对数组【较快】"LinkedList的"索引"决定是从"链头"开始找还是从"链尾"开始找"如果该元素【小于】元素长度一半,从【链头】开始找起；如果【大于】元素长度的一半,则从【链尾】找起"实现所有可选的列表操作，并且允许所有元素（包括 null）。除了实现 List 接口外，LinkedList 类还为在"列表的开头及结尾" get、remove 和 insert 元素提供了统一的命名方法。这些操作允许将"链接列表"用作"堆栈、队列"或双端队列。LinkedList集合数据存储的结构是链表结构。"方便元素添加、删除的集合"。实际开发中对一个集合元素的添加与删除经常涉及到"首尾操作"，而LinkedList提供了大量"首尾操作"的方法 07LinkedList特有方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132具体查看 ："25 Deque 接口(双端队列)与 ArrayDeque 实现类、LinkedList 实现类"public class LinkedListDemo &#123; public static void main(String[] args) &#123; LinkedList&lt;Integer&gt; lds = new LinkedList&lt;&gt;(); "//将元素加入队列的尾部" lds.offer(23); "//将一个元素加入【栈】的顶部" lds.push(111); "//将元素加入【队列】的尾部" lds.offer(407); "//将元素添加到【队列】的头部(相当于【栈】的顶部〉" lds.addFirst(56); "//输出：[56, 111, 23, 407]" System.out.println(lds); "//以 List 的方式(按【索引访问】的方式〉来遍历集合元素" for(int ee:lds)&#123; System.out.println(ee); &#125; //访问并不删除顶的元素:56 System.out.println(lds.peekFirst()) ; //访问并不删除队列的最后一个元素:407 System.out.println(lds.peekLast()) ; "//将【栈】顶的元素弹出 ,输出 56" System.out.println(lds.pop()); //输出：[111, 23, 407] System.out.println(lds); //访问并删除【队列】的最后一个元素: 407 System.out.println(lds.pollLast()); //输出：[111, 23] System.out.println(lds); &#125;&#125;———————————————————————————————————————————————————————————————————————————————————— *A:LinkedList特有方法:获取,添加,删除 * * LinkedList 链表集合的特有功能 * "自身特点: 链表底层实现,查询慢,增删快" * "* 子类的特有功能,不能多态调用，只能向下强制转换" * public class LinkedListDemo &#123; public static void main(String[] args) &#123; function_3(); &#125;———————————————————————————————————————————————————————————————————————————————————— /* * E removeFirst() 移除并返回链表的开头 * E removeLast() 移除并返回链表的结尾 */ public static void function_3()&#123; LinkedList&lt;String&gt; link = new LinkedList&lt;String&gt;(); link.add("1"); link.add("2"); link.add("3"); link.add("4"); String first = link.removeFirst(); String last = link.removeLast(); System.out.println(first); System.out.println(last); System.out.println(link); &#125;———————————————————————————————————————————————————————————————————————————————————— /* * E getFirst() 获取链表的开头 * E getLast() 获取链表的结尾 */ public static void function_2()&#123; LinkedList&lt;String&gt; link = new LinkedList&lt;String&gt;(); link.add("1"); link.add("2"); link.add("3"); link.add("4"); if(!link.isEmpty())&#123; String first = link.getFirst(); String last = link.getLast(); System.out.println(first); System.out.println(last); &#125; &#125; public static void function_1()&#123; LinkedList&lt;String&gt; link = new LinkedList&lt;String&gt;(); link.addLast("a"); link.addLast("b"); link.addLast("c"); link.addLast("d"); link.addFirst("1"); link.addFirst("2"); link.addFirst("3"); System.out.println(link); &#125;———————————————————————————————————————————————————————————————————————————————————— /* * addFirst(E) 添加到链表的开头 * addLast(E) 添加到链表的结尾 */ public static void function()&#123; LinkedList&lt;String&gt; link = new LinkedList&lt;String&gt;(); link.addLast("heima"); link.add("abc"); link.add("bcd"); link.addFirst("itcast"); System.out.println(link); &#125; &#125; 08 各List实现类的性能分析，集合Vector类的特点,1234567891011121314151617181920212223242526272829303132Java 提供的 List 就是一个线性表接口，而ArrayList 、 LinkedList 又是线性表的两种典型实现 : "ArrayList是基于数组的线性表"，"LinkedList是基于链的线性表"。 "Queue 代表了队列"，" Deque 代表了双端队列(既可作为【队列】使用，也可作为【栈】使用)" ，"LinkedList 集合"不仅提供了 "List 的功能"，还提供了"双端队列"、"栈"的功能。接下来对各种实现类的性能进行分析。"总体来说"， "ArrayList "的性能"比" "LinkedList" 的性能要"好""数组"在"随机访问"时"性能""最好" ，所有的内部以数组作为底层实现的集合在随机访问时性能都比较好 ;而内部以"链表"作为底层实现的集合在"执行插入、删除操作"时有"较好"的性能 。》如果需要"遍历 List 集合元素" ： 对于 ArrayList、 Vector 集合 ， 应该使用"随机访问方法 (get) "来"遍历"集合元素，这样性能更好 ; 对于" LinkedList 集合"，则应该采用"迭代器 （Iterator) "来"遍历"集合元素 。》如果需要经常"执行插入、删除操作"来改变包含大量数据的 List 集合的大小：可考虑"使用LinkedList 集合"。使用 "ArrayList 、 Vector 集合"可能需要经常"重新分配内部数组的大小"，效果可能"较差"。》如果有"多个线程"需要"同时访问" List 集合中的元素，开发者可考虑使用 "Collections "将集合"包装"成"线程安全"的集合。————————————————————————————————————————————————————————————————————————————————————*B:Vector类的特点 Vector集合数据存储的结构是数组结构，为JDK中"最早"提供的"集合",它是"线程同步"的 Vector中提供了一个独特的取出方式，就是枚举Enumeration，它其实就是早期的迭代器。 此接口Enumeration的功能与 Iterator 接口的功能是类似的。 " Vector集合已被 ArrayList【替代】。枚举Enumeration 已被 迭代器Iterator【替代】"。 09Set接口的特点12345678910Set接口类似于个"罐子"，"程序可以依次把多个对象“丢进”Set集合"，集合通常"不能"记住"元索的添加顺序"。"Set集合与Collection基本相同"，"【没有】提供【任何】【额外的方法】"。实际上Set就是Collection，只是行为略有不同("Set不允许包含重复元素")。A:Set接口的特点 a:它是个"【不包含】重复元素"的集合。 b:Set集合取出元素的方式可以采用："【迭代器】、【增强for】"。"不能通过索引进行取值"。 HashSet"没有提供get()方法"，同HashMap一样，"Set内部是无序的"，只能通过迭代的方式获得 c:Set集合有多个子类，这里我们介绍其中的"HashSet、LinkedHashSet"这两个集合。 10Set集合存储和迭代(以HashSet为例)12345678910111213141516171819202122232425262728293031A:Set集合存储和迭代"HashSet类(散列集) 实现 Set 接口，由哈希表Hash table（实际上是一个 HashMap 实例）支持"。它"【不保证】 set 的迭代顺序"；"特别是它【不保证】该顺序恒久不变"。此类允许"使用 null 元素" "/* * Set接口,特点不重复元素,没索引 * * Set接口的实现类,HashSet * 特点: 无序集合,存储和取出的顺序不同,没有索引,不存储重复元素 * 代码的编写上,和ArrayList完全一致 */" public class HashSetDemo &#123; public static void main(String[] args) &#123; Set&lt;String&gt; set = new HashSet&lt;String&gt;(); set.add("cn"); set.add("heima"); set.add("java"); set.add("java"); set.add("itcast"); Iterator&lt;String&gt; it = set.iterator(); while(it.hasNext())&#123; System.out.println(it.next()); &#125; System.out.println("=============="); for(String s : set)&#123; System.out.println(s); &#125; &#125; &#125; 11哈希表的数据结构1234567891011A:哈希表的数据结构:(参见图解)"加载因子:表中填入的记录数 / 哈希表的长度"例如:加载因子是0.75 代表: 数组中的16个位置,其中存入16*0.75=12个元素如果在存入第13个(&gt;12)元素,导致存储链子过长,会降低哈希表的性能,那么此时会"扩充哈希表(再哈希 Rehash)",底层会"开辟一个长度为原长度2倍的数组",把老元素拷贝到新数组中,再把新元素添加数组中 当存入"元素数量" &gt; "哈希表长度*加载因子",就要"扩容",因此"加载因子决定扩容时机" 12字符串对象的哈希值(HashCode)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354A:字符串对象的哈希值"/** 对象的哈希值,普通的十进制整数* 父类Object,方法 public int hashCode() 计算结果int整数*/"举例：StringBuilder sb = new StringBuilder("abc");StringBuilder tb = new StringBuilder("abc");int s = sb.hashCode();int t = tb.hashCode();System.out.println("s: " + s);"//StringBuilder没有重写HashCode方法，返回对象的内存地址值"System.out.println("t: " + t);//StringBuilder没有重写HashCode方法，返回对象的内存地址值System.out.println(sb.equals(tb));"//比较的是对象的内存地址值"System.out.println("————————————————————————————————————————1");String ss= new String("abc");"//String重写HashCode方法，根据内容的值进行计算"String st = "abc";System.out.println("ss.hashCode(): " + ss.hashCode());System.out.println("st.hashCode(): " + st.hashCode());System.out.println(ss.equals(st));"//比较的是对象的内容是否完全相同"——————————————————————————————————————————————————————————————————————————————————————————public class HashDemo &#123; public static void main(String[] args) &#123; Person p = new Person(); int i = p.hashCode(); System.out.println(i); String s1 = new String("abc"); String s2 = new String("abc"); System.out.println(s1.hashCode());//96354 System.out.println(s2.hashCode());//96354 "两个【不同】字符串的hashCode值完全可能【相同】" System.out.println("重地".hashCode());//1179395 System.out.println("通话".hashCode());//1179395 &#125;&#125;//String类重写hashCode()方法//字符串都会存储在底层的value数组中&#123;'a','b','c'&#125;public int hashCode() &#123; int h = hash;//hash初值为0 if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h; &#125; 13哈希表的存储过程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657A:哈希表的存储原理当向哈希表中"存放元素"时，需要根据元素的"特有数据结合相应的算法"，这个算法其实就是"Object类中的【hashCode方法】"。由于任何对象都是Object类的子类，所以"任何对象都拥有这个方法"。即就是"在给哈希表中【存放对象】时，会【调用】对象的【hashCode方法】"，这里需要注意：算出对象在表中的存放位置，如果"两个对象hashCode方法算出【结果一样】"，这样现象称为"哈希冲突"，这时会调用对象的"equals方法"，比较这"两个对象【是不是】同一个对象"，(1)如果"equals方法返回的是true"，那么就"不会"把第二个对象存放在哈希表中，(2)如果"返回的是false"，就会"把这个值存放在哈希表中"。总结："保证HashSet集合元素的唯一"，其实就是根据"对象的 hashCode和 equals 方法"来决定的。！！！如果我们往集合中存放"自定义的对象"，那么保证其唯一，就"必须""重写hashCode和equals方法"建立属于当前对象的比较方式。——————————————————————————————————————————————————————————————————————————————————————————B:哈希表的存储过程 public static void main(String[] args) &#123; HashSet&lt;String&gt; set = new HashSet&lt;String&gt;(); set.add(new String("abc")); set.add(new String("abc")); set.add(new String("bbc")); set.add(new String("bbc")); System.out.println(set); &#125;存取原理:每存入一个新的元素都要走以下三步:1.首先调用"本类的hashCode()方法"算出哈希值2."在容器中找是否与【新元素】【哈希值相同】的【老元素】", "如果没有直接存入" 如果有转到第三步3."新元素会与该索引位置下的老元素利用equals方法"一一对比 一旦"新元素.equals(老元素)"返回true,停止对比,"说明重复","不再存入" 如果与该索引位置下的老元素都通过equals方法对比返回false,说明"没有重复","存入"——————————————————————————————————————————————————————————————————————————————————————————举例：HashSet&lt;String&gt; hset = new HashSet&lt;&gt;(); hset.add("abc");"//hashCode: 96354" hset.add("abc"); hset.add("ad%");"//hashCode: 96354" hset.add("yut"); System.out.println(hset);上述代码：第1行： "abc"的hashCode 为 96354第2行： "abc"的hashCode 为 96354，调用新元素.equals(老元素)，即"abc".equals("abc")结果为true,说明"元素重复，不添加到HashSet中";第3行： "ad%"的hashCode 也为 96354，调用新元素.equals(老元素)，即"ad%".equals("abc")结果为false，"没有元素重复，添加到HashSet中"; —————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————— 14HashSet存储自定义的对象12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152A:HashSet存储自定义的对象 "/* * HashSet集合的自身特点: * 底层数据结构,哈希表 * 存储,取出都比较快 * 线程不安全,运行速度快 */" public class HashSetDemo1 &#123; public static void main(String[] args) &#123; //将Person对象中的姓名,年龄,相同数据,看作同一个对象 "//判断对象是否重复,依赖对象自己的方法 hashCode(),equals()" HashSet&lt;Person&gt; setPerson = new HashSet&lt;Person&gt;(); setPerson.add(new Person("a",11)); setPerson.add(new Person("b",10));"hashCode方法返回对象的地址值，地址值不同，会存入HashSet" setPerson.add(new Person("b",10));"hashCode方法返回对象的地址值，地址值不同，会存入HashSet" setPerson.add(new Person("c",25)); setPerson.add(new Person("d",19)); setPerson.add(new Person("e",17));"//每个对象的【地址值都不同】,调用【Obejct类】的hashCode方法返回【不同】【哈希值】,【直接存入】" System.out.println(setPerson); &#125; &#125;public class Person &#123; private String name; private int age; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public Person(String name, int age) &#123; super(); this.name = name; this.age = age; &#125; public Person()&#123;&#125; public String toString()&#123; return name+".."+age; &#125; &#125; 15自定义对象重写hashCode和equals方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687 A:自定义对象重写hashCode和equals方法"给HashSet中存放【自定义类型元素】时，需要【重写】对象中的hashCode和equals方法，建立【自己的比较方式】，才能【保证】HashSet集合中的【对象唯一】"也就是说，HashSet集合"判断两个元素相等的标准"是：两个对象通过"equals()方法"比较"相等"，返回true，"并且"两个对象的"hashCode()方法"返回值"也相等"。"则 HashSet集合中的 两个元素【相同】，【不予添加】" "/* * HashSet集合的自身特点: * 底层数据结构,哈希表 * 存储,取出都比较快 * 线程不安全,运行速度快 */" public class HashSetDemo1 &#123; public static void main(String[] args) &#123; //将Person对象中的姓名,年龄,相同数据,看作同一个对象 "//判断对象是否重复,依赖【对象自己】的方法 hashCode,equals" HashSet&lt;Person&gt; setPerson = new HashSet&lt;Person&gt;(); setPerson.add(new Person("a",11)); setPerson.add(new Person("b",10)); setPerson.add(new Person("b",10)); setPerson.add(new Person("c",25)); setPerson.add(new Person("d",19)); setPerson.add(new Person("e",17)); System.out.println(setPerson); &#125; &#125; public class Person &#123; private String name; private int age;"/** 没有做重写父类(Obejct类)的hashCode和equals方法,每次运行结果都是不同整数， 因为每个对象的【地址值都不同】,调用【Obejct类】的hashCode方法返回【不同】【哈希值】* 如果子类重写父类hashCode和equals方法,将会得到自定义的哈希值* 存储到HashSet集合的依据：用hashCode和equals方法进行判断* * 尽可能让不同的属性值产生不同的哈希值(优化hashCode的产生方法),这样就不用再调用equals方法去比较属性**/" public int hashCode()&#123; return name.hashCode()+age*55; &#125; //方法equals重写父类,保证和父类相同 //public boolean equals(Object obj)&#123;&#125; public boolean equals(Object obj)&#123; if(this == obj) return true; if(obj == null) return false; if(obj instanceof Person)&#123; Person p = (Person)obj; return name.equals(p.name) &amp;&amp; age==p.age; &#125; return false; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public Person(String name, int age) &#123; super(); this.name = name; this.age = age; &#125; public Person()&#123;&#125; public String toString()&#123; return name+".."+age; &#125; &#125; 16LinkedHashSet集合123456789101112131415161718192021A:LinkedHashSet集合 " /* * LinkedHashSet 基于【链表】的【哈希表】实现 * 继承自HashSet："有序"的hashSet * * LinkedHashSet 自身特性,"具有顺序",存储和取出的顺序相同 * 线程不安全的集合,"运行速度块" */" public class LinkedHashSetDemo &#123; public static void main(String[] args) &#123; LinkedHashSet&lt;Integer&gt; link = new LinkedHashSet&lt;Integer&gt;(); link.add(123); link.add(44); link.add(33); link.add(33); link.add(66); link.add(11); System.out.println(link); &#125; &#125; 17ArrayList,HashSet判断对象是否重复的原理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115ArrayList,HashSet判断对象是否重复的原理1： "ArrayList的【contains方法】判断元素是否重复"a:"ArrayList的【contains方法】原理:【底层依赖于】【equals方法】"ArrayList的【contains方法】会使用调用方法时， "传入的元素的equals方法依次与集合中的旧元素所比较"， 从而根据返回的布尔值判断是否有重复元素。b:"当ArrayList存放【自定义类型】时"，由于自定义类型在"未重写equals方法"之前， "判断是否重复的依据是内存地址值"，"所以如果想根据【内容】判断是否为重复元素，需要【重写】元素的equals方法"。——————————————————————————————————————————————————————————————————————————————————————————2: "HashSet的add/contains等方法判断元素是否重复""HashSet的【add()方法和contains方法()】【底层】都【依赖】 hashCode()方法与equals方法()"HashSet集合"判断两个元素相等的标准"是：两个对象通过"equals()方法"比较"相等"，返回true，"并且"两个对象的"hashCode()方法"返回值"也相等"。"则 HashSet集合中的 两个元素【相同】，【不予添加】"Set集合"不能"存放重复元素，"其add()方法在添加时会判断是否有重复元素，"有重复【不】添加"，"没重复则添加""。HashSet集合由于是"无序"的，其判断唯一的依据是元素类型的"hashCode与equals方法的返回结果"。规则如下：先判断新元素与集合内已经有的旧元素的"HashCode值"1): 如果"不同"，说明是"不同元"素，"添加到集合"。2): 如果"相同"，再"判断equals比较结果"。返回true则"相同元素"，"不予添加"； 返回false则"不同元素"，"添加到集合"。即：两个对象通过"equals()方法"比较"相等"，并且两个对象的"hashCode()方法"返回值"也相等"。则"不予添加"。——————————————————————————————————————————————————————————————————————————————————————————总结：使用"HashSet""存储【自定义类型】"时，如果"没有重写"该类的hashCode与equals方法，则判断重复时，使用的是"内存地址值"，如果想通过"【内容】比较元素是否相同"，"需要重写"该元素类的hashcode与equals方法。——————————————————————————————————————————————————————————————————————————————————————————！！！！！！！！！！！！！！"注意"：如果向HashSet中添加一个"可变对象"后，后面程序修改了该"可变对象"的"实例变量"，则可能导致它与集合中"其他对象"的"元素相同"。(即两个对象通过equals()方法比较返回true，两个对象的 hashCode 值也相等)，这就可能导致HashSet 中包含"两个相同的对象"。public class Example &#123; int count; public Example(int count) &#123; this.count = count; &#125; public Example() &#123; &#125; @Override public int hashCode() &#123; return this.count; &#125; @Override public boolean equals(Object obj) &#123; if(this == obj)&#123; return true; &#125; if(obj != null &amp;&amp; obj.getClass()==Example.class)&#123; Example ex = (Example) obj; return this.count ==ex.count; &#125; return false; &#125; @Override public String toString()&#123; return "Example[count: "+ this.count + "]"; &#125;&#125;public class ExampleTest &#123; public static void main(String[] args) &#123; HashSet&lt;Example&gt; hs = new HashSet&lt;&gt;(); hs.add(new Example(5)); hs.add(new Example(-3)); hs.add(new Example(9)); hs.add(new Example(-2)); //打印HashSet集合，集合元素没有重复 System.out.println(hs); Iterator&lt;Example&gt; it = hs.iterator(); it.next().count = -3; //为第一个元素的count实例变量赋值 System.out.println(hs); //删除值为-3的Example对象 hs.remove(new Example(-3)); System.out.println(hs); System.out.println("hs是否包含count为-3的Example对象? "+ hs.contains(new Example(-3))); System.out.println("hs是否包含count为-2的Example对象? "+ hs.contains(new Example(-2))); &#125;&#125;结果：[Example[count: -2], Example[count: -3], Example[count: 5], Example[count: 9]][Example[count: -3], Example[count: -3], Example[count: 5], Example[count: 9]][Example[count: -3], Example[count: 5], Example[count: 9]]hs是否包含count为-3的Example对象? falsehs是否包含count为-2的Example对象? false分析：正如结果所见到的，HashSet集合的第1个元素和第2个元素"完全相同"，这表明两个元素"已经重复"。此时HashSet会比较混乱:当试图删除count为-3的Example对象时，HashSet会计算出该对象的hashCode值，从而找出该对象在集合中的保存位置，然后把此处的对象与count为-3的Example对象时通过equals()方法进行比较，如果相等则删除该对象：HashSet"只有"第2个元素才满足该条件(第1个元素"实际"上保存在count为-2的Example对象对应的位置)，所以"第2个元素被删除"。至于第一个count为-3的Example对象，它保存在count为-2的Example对象对应的位置，但使用equals()方法拿它和count为-2的R对象比较时又返回false—这将导致HashSet"不能""准确"访问该"元素"。 18hashCode和equals方法的面试题12345678910111213141516171819202122232425262728293031 A:hashCode和equals的面试题 两个对象 Person p1 p2 问题: (1)"如果两个对象的哈希值相同" p1.hashCode()==p2.hashCode() 两个对象的equals一定返回true吗 p1.equals(p2) 一定是true吗 正确答案:"p1.equals(p2)不一定"是true (2)"如果两个对象的equals方法返回true",p1.equals(p2)==true 两个对象的"哈希值一定相同"吗 正确答案: "哈希值一定相同"——————————————————————————————————————————————————————————————————————————————————————————在 Java 应用程序执行期间，"规定"：1."如果根据 equals(Object) 方法"，"两个对象是相等"的，那么对这两个对象中的每个对象调用 "hashCode 方法"都"必须生成相同的整数结果"。 2.如果根据 equals(java.lang.Object) 方法，"两个对象【不相等】"，那么对这两个对象中的任一对象上调用" hashCode 方法" "不要求"一定"生成不同的整数结果"。此时，hashCode值(可以"相同"也"可以不同") 2.1 两个对象不同(对象属性值不同) equals返回false=====&gt;两个对象调用hashCode()方法"哈希值""可相同"两个对象调用hashCode()方法哈希值不同=====&gt;equals返回true2.2 两个对象不同(对象属性值不同) equals返回false=====&gt;两个对象调用hashCode()方法"哈希值""可不同"两个对象调用hashCode()方法哈希值相同=====&gt;equals返回true"所以说两个对象【哈希值】无论【相同】还是【不同】,equals都可能返回"true 19TreeSet类123456789101112131415161718192021222324252627282930313233343536373839404142434445TreeSet 类与散列集HashSet十分类似， 不过， 它比HashSet有所改进。TreeSet是一个"有序集合"( sorted collection) 。可以以任意顺序将元素插入到集合中。在对集合进行遍历时， 每个值将"自动地按照排序后"的"顺序"呈现。TreeSet是SortedSet接口的实现类。与"HashSet集合"采用"hash算法"来决定元索的"存储位置"不同，"TreeSet"采用"红黑树"的数据结构来存储集合元素。TreeSet支持两种排序方法:"自然排序"和"定制排序"。public Comparator&lt;? super E&gt; comparator():如果TreeSet采用了"定制排序"，则该方法返回定制排序所使用的如果TreeSet采用了"自然排序"，则返回nullpublic E first(): 返回集合中的第一个元素。public E last(): 返回集合中的最后一个元素。public E lower(E e):返回集合中位于指定元素之前的元素(即小于指定元素的最大元素，参考元素不需要是TreeSet集合里的元素)。public E higher(E e):返回集合中位于指定元素之后的元素(即大于指定元素的最小元素，参考元素不需要是TreeSet集合里的元素)。public SortedSet&lt;E&gt; subSet(E fromElement,E toElement):返回此Set的子集合，范围从fromElement (包含)到toElement(不包含)。public SortedSet&lt;E&gt; headSet(E toElement):返回此Set的子集，由小于toElement的元素组成。public SortedSet&lt;E&gt; tailSet(E fromElement):返回此Set的子集，由大于或等于fromElement的元素组成。TreeSet并【不是】根据元素的【插入顺序】进行排序的，而是根据元素【实际值的大小】来进行排序的。public class TreeSetDemol &#123; public static void main(String[] args) &#123; TreeSet&lt;Integer&gt; tset = new TreeSet&lt;&gt;(); tset.add(12); tset.add(-9); tset.add(19); tset.add(78); tset.add(3); System.out.println(tset);//[-9, 3, 12, 19, 78] System.out.println(tset.first());//-9 System.out.println(tset.last());//78 System.out.println(tset.lower(5));//3 System.out.println(tset.higher(7));//12 System.out.println(tset.headSet(4));//[-9, 3] System.out.println(tset.tailSet(8));//[12, 19, 78] System.out.println(tset.subSet(2,13));//[3, 12] &#125;&#125; 20TreeSet类的自然排序和定制排序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778791. 自然排序TreeSet会调用集合元素的compareTo(Object obj)方法来比较元素之间的大小关系，然后将集合元素按升序排列，这种方式就是自然排序。如果试图把个对象添加到TreeSet时，则该对象的类必须实现Comparable接口，否则程序将会抛出异常。例如：class Err&#123;&#125;public class TreeSetErrorTest&#123; public static void main (String「1args) &#123; TreeSet ts=new TreeSet(); //向TreeSet集合中添加两个Err对象 ts.add(aew Err()); ts.add (nest Err());//(1) &#125;&#125;上面的程序试图向TreeSet集合中添加两个Err对象，添加第一个对象时，TreeSet里没有任何元素，所以不会出现任何问题;但是添加第二个Err对象时，TreeSet就会调用该对象的compareTo(Object obj)方法与集合中的其他元素进行比较：如果其对应的类没有实现Comparable接口，则会引发CIassCastException异常。因此，上面的程序会在(1)处引发该异常。此外："如果希望TreeSet能正常运作，TreeSet【只能】添加【同一种类型】的对象"。对于TreeSet集合，判断两个对象是否相等的唯一标准是：两个对象通过"compareTo(Object obj)方法"比较"是否返回0"：如果通过compareTo(Object obj)方法比较"返回0"，TreeSet则会认为它们"相等";否则就认为它们不相等—————————————————————————————————————————————————————————————————————————————————————————————2. 定制排序TreeSet 的 自然排序是根据集合元素的大小， TreeSet将它们以升序排列。 如果需要实现定制排序 ，例如以降序排列 ，则可以通过" Comparator 接口 "的帮助 。 该接 口 里包含一个 int compare(T 01, T 02)方法 ，该方法用于 比较 01 和 02 的大小:如果该方法返回正整数，则表 明 01 大于 02； 如果该方法返回 0，则表 明 0 1 等于 02；如果该方法返回负整数，则表 明 01 小于 02 ;如果需要实现"定制排序" ，则需要在创建 TreeSet 集合对象时，提供一个 "Comparator 对象"与该 "TreeSet集合""关联" ，由该" Comparator 对象""负责"集合元素的"排序逻辑" 。 由于 Comparator 是一个函数式接口 ， 因此可使用 Lambda 表达式来代替 Comparator 对象 。//TreeSet定制排序class M&#123; int age; public M(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "M&#123;" + "age=" + age + '&#125;'; &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; //此处 Lambda 表达式的目标类型是 Comparator TreeSet ts = new TreeSet((t1, t2) -&gt; &#123; M m1 = (M) t1; M m2 = (M) t2; //根据"对象的 a归属性来决定大小， ag. 越大， M 对象反而越小 return m1.age&gt; m2.age ? -1 : m1.age&lt;m2.age ? 1 : 0; &#125;); ts.add(new M(5)); ts.add(new M(-3)); ts.add(new M(9)); System.out.println(ts); &#125;&#125;结果：降序排列： [M&#123;age=9&#125;, M&#123;age=5&#125;, M&#123;age=-3&#125;] 21TreeSet类判断对象是否重复的原理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061对于TreeSet集合，判断"两个对象是否相等"的"唯一标准"是:两个对象通过"compareTo(Object obj)方法""比较"是否返回0：如果通过compareTo(Object obj)方法比较"返回0"，TreeSet则会认为它们"相等";"否则"就认为它们"不相等"。只和"compareTo(Object obj)方法""结果有关"举例：public class Exampale implements Comparable &#123; int age; public Exampale()&#123; &#125; public Exampale(int age)&#123; this.age =age; &#125; @Override public boolean equals(Object obj)&#123; return true; "equals()方法总是返回 true" &#125; public int compareTo(Object obj)&#123; return 1; "compareTo(Object obj)方法总是返回 1" &#125;&#125;public class TreeSetDemo &#123; public static void main(String[] args) &#123; TreeSet&lt;Exampale&gt; ts= new TreeSet&lt;&gt;(); Exampale e1 = new Exampale(10); ts.add(e1); (1) //第二次添加同一个对象 ， 输出 true ， 表明添加成功 boolean bb = ts.add(e1); (1) //下面输出 set 集合，将看到有两个元素 System.out.println(ts); //修改 set 集合的第一个元素的 age 变量 ts.first().age = 88; //输出 set 集合的最后一个元素的 age 变量，将看到也变成了88 System.out.println(ts.last().age);//88 &#125;&#125;结果：[demo10.Exampale@4554617c, demo10.Exampale@4554617c]88分析：程序中(1)代码行把同一个对象再次添加到 TreeSet 集合中 ，"因为 e1 对象的compareTo(Object obj)方法总是返回 1 "， "不返回0 "，虽然它的 equals()方法总是返回 true ，但 "TreeSet "会认为 " e1 对象 "和 "它自己 "也 "不相等 " ， 因此,TreeSet 可以添加两个e1对象。从图可以看到 TreeSet 对象保存的两个元素(集合里的元素总是"引用"，但习惯上把被引用的对象称为集合元素) ， 实际上是同一个元素("同一个引用") 。所以当"修改" TreeSet 集合里"第一个元素"的 age 变量后，该 TreeSet 集合里"最后一个元素"的 age 变量也"随之改变"。由此应该注意一个问题 :当需要把一个对象放入 TreeSet 中，重写该对象对应类的" equals方法"时 ，应保证该方法与 "compareTo(Object obj)方法"有"一致"的"结果".其规则是 : 如果两个对象通过" equals()方法"比较返回 true 时，这两个对象通过 "compareTo(Object obj)方法 "比较应"返回 0 "。 22各Set实现类的性能分析123456789HashSet 和 TreeSet 是 Set 的两个典型实现 ，到底如何选择HashSet 和 TreeSet 呢? "HashSet "的性能总是"比" "TreeSet" "好"(特别是最常用的"添加、查询元素等操作" ) ，因为 TreeSet 需要额外的"红黑树算法"来维护集合元素的"次序"。只有当需要一个保持"排序"的 Set 时，才应该使用 TreeSet ， "否则都应该使用 HashSet"。LinkedHashSet，对于普通的"插入、删除操作"， LinkedHashSet 比 HashSet要"略微慢一点" ，这是由"维护链表"所带来的额外开销造成的 ，但"由于有了链表"，"遍历" LinkedHashSet 会"比"HashSet"更快" 。 23 Queue(队列)集合12345678910111213Queue 用于模拟队列这种数据结构 ， 队列通常是指"先进先出" (FIFO ) 的容器 。 队列的头部保存在队列中存放时间最长的元素 ，队列的尾部保存在队列中存放时间最短的元素。新元素插入 (offer ) 到队列的尾部，访问元素 (poll) 操作会返回队列头部的元素 。通常 ，队列不允许随机访问队列中的元素。Queue 接口中定义了如下儿个方法。~ void add(Object e): 将指定元素加入此队列的【尾部】 。~ Object element(): 获取队列【头部】 的元素，但是不删除该元素 。~ boolean offer(Object e): 将指定元素加入此队列的【尾部】。当使用有容量 限制的队列时，此方法通常比 add(Object e)方法更好 。~ Object peek(): 获取队列【头部】的元素，但是【不删除】该元素。如果此队列为空，则返回 null 。~ Object poll(): 获取队列【头部】的元素 ， 并【删除】该元素 。如果此队列为 空 ，则返回 null 。~ Object remove(): 获取 队列【头部】的元素，并删除该元素 。 24 Priority Queue 优先级队列12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152"PriorityQueue" 是一个比较标准的队列实现类 ，但"不是绝对标准"的"队列"实现，是因为 PriorityQueue 保存队列元素的顺序并"不是"按"加入队列"的"顺序"，而是按"队列元素"的"大小"进行"重新排序"（堆结构）。因此当调用 "peek()方法或者 poll()方法"取出队列中的元素时，并"不是取出""最先进入队列的元素"，"而是"取出队列中"最小的元素" 。 从这个意义上来看 ， PriorityQueue 已经违反了队列的最基本规则 : 先进先出 (FIFO )优先级队列使用的是"堆（heap)数据结构"。堆是一个可以"自我调整的二叉树"，对树执行"添加（add) "和"删除（remore) "操作， 可以让"最小的元素（优先级最高）""移动到根"，都将"优先级最高"的任务从"队列"中"删除"（由于"习惯上将1设为最高优先级"，所以会将"最小的元素删除" )而不必花费时间对元素进行排序。优先级队列（priority queue) 中的元素可以"按照任意的顺序插人"，却总是"按照排序的顺序进行检索"。也就是说，无论何时调用 remove 方法，"总会获得"当前"优先级队列"中"最小的元素（优先级最高的元素）"。然而，优先级队列并没有对所有的元素进行排序public class QueueDemo &#123; public static void main(String[] args) &#123; Queue&lt;Integer&gt; pq =new PriorityQueue&lt;&gt;(); pq.offer(12); pq.offer(-10); pq.offer(118); pq.offer(5); pq.offer(120); System.out.println(pq);//[-10, 5, 118, 12, 120] System.out.println(pq.poll());//-10 System.out.println(pq);//[5, 12, 118, 120] System.out.println(pq.poll());//5 System.out.println(pq.poll());//12 System.out.println(pq.poll());//118 System.out.println(pq.poll());//120 &#125;&#125;运行上面程序"直接输出" PriorityQueue 集合时，可能看到该队列里的元素"并没有"很好地"按大小进行排序"，但这只是受到 PriorityQueue 的 toString()方法的返回值的影响 。实际上 ，程序"多次调用" PriorityQueue集合对象的" poll()方法"，即可看到元素"按从小到大"的顺序"移出队列"。PriorityQueue "不允许插入" null 元素，它还"需要"对"队列元素"进行"排序" ，PriorityQueue 的元素有两种排序方式。》"自然排序" : 采用自然顺序的 PriorityQueue 集合中的元素必须实现了 "Comparable 接口"，而且应该是"同一个类的多个实例"，否则可能导致 ClassCastException 异常 。》"定制排序":创建 PriorityQueue 队列时，传入一个 "Comparator 对象"，该对象负责对队列中的所有元素进行排序 。采用定制排序时不要求队列元素实现 Comparable 接口 。PriorityQueue 队列对元素的要求与 TreeSet 对元素的要求基本 一致 25 Deque 接口(双端队列)与 ArrayDeque 实现类、LinkedList 实现类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147~ void addFirst(Object e): 将指定元素插入该双端队列的开头。~ void addLast(Object e): 将指定元素插入该双端队列的末尾。~ Iterator descendingIterator(): 返回该双端队列对应的迭代器，该迭代器将以逆向顺序来法代队列中的元素。~ Object getFirst(): 获取但不删除双端队列的第一个元素。~ Object getLast() : 获取但不删除双端队列的最后 一个元素 。~ boolean offerFirst(Object e): 将指定元素插入该双端队列的开头 。~ boolean offerLast(Object e): 将指定元素插入该双端队列的末尾 。~ Object peekFirst(): 获取但不删除该双端队列的第一个元素;如果此双端队列为空，则返回 null 。~ Object peekLast(): 获取但不删除该双端队列的最后 一个元素;如果此双端队列为空，则返回 null 。~ Object pollFirst(): 获取并删除该双端队列的第一个元素 :如果此双端队列为 空 ，则返回 null o~ Object pollLast(): 获取并删除该双端队列的最后一个元素 ; 如果此双端队列为空，则返回 null 。~ Object pop() (栈方法) : pop 出该双端队列所表示的栈的栈顶元素 。 相当于 removeFirst() 。~ void push(Object e) (栈方法) : 将 一个元素 push 进该双端队列所表 示 的栈的栈顶 。 相当于addFirst(e) 。~ Object removeFirst(): 获取并删除该双端队列的第一个元素 。~ Object removeFirstOccurrence(Object 0): 删 除该双端队列的第一次出现的元素 。 。~ Object removeLast(): 获取并删除该双端队列的最后一个元素 。~ boolean removeLastOccurrence(Object 0): 删除该双端队列的最后一次出现的元素。;从上面方法中可以看出，" Deque" 不仅可以 当成"双端队列"使用，而且可以被当成"栈"来使用 ， 因为 该类里还包含了 pop (出栈〉、 push (入栈)两个方法。————————————————————————————————————————————————————————————————————————————————————Deque 接口提供了 一个典型的实现类: "ArrayDeque" ，从该名称就可以看出，它是一个"基于数组实现的双端队列"，创建 Deque 时同样可指定一个 numElements 参数 ，该参数用于指定 Object[]数组的长度:如果不指定 numElements 参数， Deque 底层数组的长度为 16 。"————————————————————————————————————————————————————————————————————————————————————Queue 方法 等效 Deque 方法 add(e) addLast(e) offer(e) offerLast(e) remove() removeFirst() poll() pollFirst() element() getFirst() peek() peekFirst() ————————————————————————————————————————————————————————————————————————————————————堆栈方法 等效 Deque 方法 push(e) addFirst(e) pop() removeFirst() peek() peekFirst() ————————————————————————————————————————————————————————————————————————————————————"当然 "ArrayDeque" 也可以 当成"队列使用"，此处 ArrayDeque 将按"先进先出"的方式操作集合元素public class ArrayDequeDemo1 &#123; public static void main(String[] args) &#123; ArrayDeque&lt;Integer&gt; ad = new ArrayDeque&lt;&gt;(); ad.offer(23); ad.offer(1); ad.offer(56); ad.offer(-70); ad.offer(8); "//输出 :[23, 1, 56, -70, 8]" System.out.println(ad); ////访问队列头部的元素，但并不将其 poll 出队列"钱 "， 输出 : 23 System.out.println(ad.peek()); // poll 出第一个元素，输出 23 System.out.println(ad.poll()); //输出 :[1, 56, -70, 8] System.out.println(ad); &#125;&#125;展示 "ArrayDeque" 作为"栈"的行为 ，"后进先出",因此当程序中需要使用"栈" 这种数据结构时，推荐使用 ArrayDequepublic class ArrayDequeDemo &#123; public static void main(String[] args) &#123; ArrayDeque&lt;Integer&gt; ad = new ArrayDeque&lt;&gt;(); ad.push(42); ad.push(205); ad.push(-30); ad.push(78); ad.push(3); ad.push(11); "//输出 :[11, 3, 78, -30, 205, 42]" System.out.println(ad); //访问第一个元素，但并不将其 pop 出"栈,输出 :11 System.out.println(ad.peek()); //输出 :[11, 3, 78, -30, 205, 42] System.out.println(ad); //第一个元素将其 pop 出"栈,输出 :11 System.out.println(ad.pop()); //输出 :[ 3, 78, -30, 205, 42] System.out.println(ad); System.out.println(ad.peekLast()); &#125;&#125;————————————————————————————————————————————————————————————————————————————————————LinkedList 类是 "List 接口 "的 实现类,LinkedList 还实现了 "Deque 接口",可以被当成"双端队列"来使用 ， 因此既可以被当成"栈"来使用，也可以 当成"队列"使用 。public class LinkedListDemo &#123; public static void main(String[] args) &#123; LinkedList&lt;Integer&gt; lds = new LinkedList&lt;&gt;(); "//将元素加入队列的尾部" lds.offer(23); "//将一个元素加入【栈】的顶部" lds.push(111); "//将元素加入【队列】的尾部" lds.offer(407); "//将元素添加到【队列】的头部(相当于【栈】的顶部〉" lds.addFirst(56); "//输出：[56, 111, 23, 407]" System.out.println(lds); "//以 List 的方式(按【索引访问】的方式〉来遍历集合元素" for(int ee:lds)&#123; System.out.println(ee); &#125; //访问并不删除顶的元素:56 System.out.println(lds.peekFirst()) ; //访问并不删除队列的最后一个元素:407 System.out.println(lds.peekLast()) ; "//将【栈】顶的元素弹出 ,输出 56" System.out.println(lds.pop()); //输出：[111, 23, 407] System.out.println(lds); //访问并删除【队列】的最后一个元素: 407 System.out.println(lds.pollLast()); //输出：[111, 23] System.out.println(lds); &#125;&#125; 小结123456789101112131415161718192021222324252627282930 List与Set集合的区别？List: 它是一个有序的集合(元素存与取的顺序相同) 它可以存储重复的元素 Set: 它是一个无序的集合(元素存与取的顺序可能不同) 它不能存储重复的元素 List集合中的特有方法 void add(int index, Object element) 将指定的元素，添加到该集合中的指定位置上 Object get(int index)返回集合中指定位置的元素。 Object remove(int index) 移除列表中指定位置的元素, 返回的是被移除的元素 Object set(int index, Object element)用指定元素替换集合中指定位置的元素,返回值的更新前的元素 ArrayList: 底层数据结构是数组，查询快，增删慢 LinkedList: 底层数据结构是链表，查询慢，增删快 HashSet: 元素唯一，不能重复 底层结构是 哈希表结构 元素的存与取的顺序不能保证一致 如何保证元素的唯一的？ 重写hashCode() 与 equals()方法 LinkedHashSet: 元素唯一不能重复 底层结构是 哈希表结构 + 链表结构 元素的存与取的顺序一致]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础16(集合Collecton,Iterator迭代器,增强for循环,泛型)]]></title>
    <url>%2F2016%2F10%2F26%2Fday18%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、集合2、Iterator迭代器3、增强for循环4、泛型 01集合使用的回顾1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465 *A:集合使用的回顾 *a.ArrayList集合存储5个int类型元素 public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(111); list.add(222); list.add(333); list.add(444); list.add(555); for(int i=0; i&lt;list.size(); i++)&#123; System.out.println(list.get(i)); &#125; &#125; *b.ArrayList集合存储5个Person类型元素public class Person &#123; private String name; private int age; public Person()&#123; super(); &#125; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; //重写toString()方法 @Override public String toString() &#123; return "Person&#123;" + "name='" + name + '\'' + ", age=" + age + '&#125;'; &#125;public class ArraryListDemo &#123; public static void main(String[] args) &#123; ArrayList &lt;Person&gt; aa = new ArrayList&lt;Person&gt;(); aa.add(new Person("a",23)); aa.add(new Person("b",52)); aa.add(new Person("c",36)); for(Person p : aa)&#123; System.out.println(p);//默认调用toString()方法 &#125; &#125;&#125; 02集合的学习目标12345 集合，集合是java中提供的一种容器，可以用来存储多个数据。 在前面的学习中，我们知道数据多了，可以使用数组存放或者使用ArrayList集合进行存放数据。那么，集合和数组既然都是容器，它们有啥区别呢？  "数组的长度是固定的。【集合】的【长度】是【可变】的。"  " 集合中存储的元素【必须】是【引用类型数据】" 03集合继承关系图123456789101112131415161718192021222324252627A:集合继承关系图 a:ArrayList的继承关系: 查看ArrayList类发现它继承了抽象类AbstractList同时实现接口List，而List接口又继承了Collection接口 "Collection接口为【最顶层】【集合接口】了"。 源代码： interface List extends Collection &#123; &#125; public class ArrayList extends AbstractList implements List&#123; &#125;b:集合继承体系 "这说明我们在使用ArrayList类时，该类已经把所有抽象方法进行了重写。那么，实现Collection接口的所有子类都会进行方法重写。  Collecton接口常用的子接口有：List接口、Set接口  List接口常用的子类有：ArrayList类、LinkedList类  Set接口常用的子类有：HashSet类、LinkedHashSet类 Collection 接口 | ---------------------------------------------------------------- | | List接口 Set接口 | | ---------------- ------------- | | | |ArrayList类 LinkedList类 HashSet类 LinkedHashSet类" 04集合Collection的方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879A:集合Collection的方法 "/* * Collection接口中的方法 * 是集合中所有实现类必须拥有的方法 * 使用Collection接口的实现类,程序的演示 * ArrayList implements List * List extends Collection * 方法的执行,都是实现的重写 */" public class CollectionDemo &#123; public static void main(String[] args) &#123; function_2(); &#125; "/* Collection接口方法 * Object[] toArray() 集合中的元素,转成一个数组中的元素, 集合转成数组 * 返回是一个存储对象的数组, 数组存储的数据类型是Object */" private static void function_2() &#123; Collection&lt;String&gt; coll = new ArrayList&lt;String&gt;(); coll.add("abc"); coll.add("itcast"); coll.add("itheima"); coll.add("money"); coll.add("123"); Object[] objs = coll.toArray(); for(int i = 0 ; i &lt; objs.length ; i++)&#123; System.out.println(objs[i]); &#125; &#125; "/* * 学习Java中三种长度表现形式 * —————————————————————————————————— * 数组.length 属性 返回值 int * —————————————————————————————————— * 字符串.length() 方法,返回值int * —————————————————————————————————— * 集合.size()方法, 返回值int */" "/* * Collection接口方法 * boolean contains(Object o) 判断对象是否存在于集合中,对象存在返回true * 如果此 collection 包含【指定的元素】，则返回 true * 方法参数是Object类型 */" private static void function_1() &#123; Collection&lt;String&gt; coll = new ArrayList&lt;String&gt;(); coll.add("abc"); coll.add("itcast"); coll.add("itheima"); coll.add("money"); coll.add("123"); boolean b = coll.contains("itcast"); System.out.println(b); &#125; "/* * Collection接口的方法 * void clear() 清空集合中的所有元素 * 集合容器本身依然存在 */" public static void function()&#123; //接口多态的方式调用 Collection&lt;String&gt; coll = new ArrayList&lt;String&gt;(); coll.add("abc"); coll.add("bcd"); System.out.println(coll); coll.clear(); System.out.println(coll); &#125; &#125; 05集合Collection的remove方法1234567891011121314151617181920212223242526A:05集合Collection的remove方法 "/* * Collection接口方法 * boolean remove(Object o)移除集合中指定的元素 * 如果集合中包含多个相同的元素，remove方法只删除出现的第一个元素。 * * * 另外： * boolean removeAll(Collection&lt;?&gt; c) * 移除此 collection 中那些也包含在【指定 collection 】中的【所有元素】（可选操作）。 * 此调用返回后，collection 中将不包含任何与指定 collection 相同的元素。 */" private static void function_3()&#123; Collection&lt;String&gt; coll = new ArrayList&lt;String&gt;(); coll.add("abc"); coll.add("money"); coll.add("itcast"); coll.add("itheima"); coll.add("money"); coll.add("123"); System.out.println(coll); boolean b = coll.remove("money"); System.out.println(b); System.out.println(coll); &#125; 06迭代器的概述1234567891011A:迭代器概述:a:java中提供了很多个集合，它们在存储元素时，采用的存储方式不同。我们要取出这些集合中的元素，可通过一种"通用的获取方式"来完成。b:"Collection集合元素的通用获取方式：在取元素之前先要判断集合中有没有元素，如果有，就把这个元素取出来，继续在判断，如果还有就再取出出来。一直把集合中的所有元素全部取出。这种取出方式专业术语称为【迭代】。"c:"每种集合的底层的数据结构不同,例如ArrayList是数组,LinkedList底层是链表,但是无论使用那种集合,我们都会有判断是否有元素以及取出里面的元素的动作,那么Java为我们提供一个【迭代器】定义了【统一的判断元素和取元素的方法】" 07迭代器的实现原理123456789101112131415161718 *A:迭代器的实现原理" /* * 集合中的迭代器: * 获取集合中元素方式 * 接口 Iterator : 两个抽象方法 * boolean hasNext() 判断集合中还有没有可以被取出的元素,如果有返回true * next() 取出集合中的下一个元素 * ———————————————————————————————————————————————————————————————————— * Iterator接口,找实现类. * Collection接口定义了iterator方法： * Iterator&lt;E&gt; iterator() * 返回在此 collection 的元素上进行迭代的迭代器 *———————————————————————————————————————————————————————————————————— * ArrayList类 重写方法 iterator(),返回了Iterator接口的实现类的对象 * 使用ArrayList集合的对象 * Iterator it =array.iterator(),运行结果就是Iterator接口的实现类ArrayList的对象 * it是接口的实现类对象,调用方法 hasNext 和 next 集合元素迭代 */" 08迭代器的代码实现1234567891011121314151617181920212223242526*A:迭代器的代码实现 public class IteratorDemo &#123; public static void main(String[] args) &#123; Collection&lt;String&gt; coll = new ArrayList&lt;String&gt;(); coll.add("abc1"); coll.add("abc2"); coll.add("abc3"); coll.add("abc4"); //迭代器,对集合ArrayList中的元素进行取出 //调用集合的方法iterator()获取出,Iterator接口的实现类的对象 Iterator&lt;String&gt; it = coll.iterator(); //接口实现类对象,调用方法hasNext()判断集合中是否有元素 //boolean b = it.hasNext(); //System.out.println(b); //接口的实现类对象,调用方法next()取出集合中的元素 //String s = it.next(); //System.out.println(s); //迭代是反复内容,使用循环实现,循环的条件,集合中没元素, hasNext()返回了false while(it.hasNext())&#123; String s = it.next(); System.out.println(s); &#125; &#125; &#125; 09迭代器的执行过程12345678910111213141516171819202122232425A:迭代器的执行过程 a:迭代器的原理: while(it.hasNext()) &#123; System.out.println(it.next()); &#125; //cursor记录的索引值不等于集合的长度返回true,否则返回false public boolean hasNext() &#123; return cursor != size; //cursor初值为0 &#125; //next()方法作用: //①返回cursor指向的当前元素 //②cursor++ public Object next() &#123; int i = cursor; cursor = i + 1; return elementData[lastRet = i]; &#125; b:for循环迭代写法: for (Iterator&lt;String&gt; it2 = coll.iterator(); it2.hasNext(); ) &#123; System.out.println(it2.next()); &#125; 10集合迭代中的转型12345678910111213141516171819202122232425262728293031323334A:集合迭代中的转型 a:在使用集合时，我们需要注意以下几点：  "集合中存储其实都是【对象的地址】"。  "集合中可以存储基本数值"：jdk1.5版本以后可以存储了。 "因为出现了【基本类型】的【包装类】，它提供了【自动装箱】操作（基本类型对象）"， 这样，"集合中的元素就是【基本数值】的【包装类】对象"。b:"存储时提升了Object。取出时要使用元素的【特有内容】，必须【向下转型】"。 "可以【不指定】【集合的存储类型】，即可以添加 Object 对象(任意对象)"，如下所示： Collection coll = new ArrayList(); coll.add("abc"); coll.add("aabbcc"); coll.add("shitcast"); Iterator it = coll.iterator(); while (it.hasNext()) &#123; //由于元素被存放进集合后全部被提升为Object类型 //当需要使用子类对象特有方法时，需要向下转型 String str = (String) it.next(); System.out.println(str.length()); &#125;" 注意：如果集合中存放的是多个对象，这时进行向下转型会发生类型转换异常。"c:Iterator接口也可以使用&lt;&gt;来控制迭代元素的类型的。代码演示如下： Collection&lt;String&gt; coll = new ArrayList&lt;String&gt;(); coll.add("abc"); coll.add("aabbcc"); coll.add("shitcast"); Iterator&lt;String&gt; it = coll.iterator(); while (it.hasNext()) &#123; String str = it.next(); //当使用Iterator&lt;String&gt;控制元素类型后，就不需要强转了。获取到的元素直接就是String类型 System.out.println(str.length()); &#125; 11增强for循环遍历数组123456789101112131415161718192021222324252627282930313233*A:增强for循环遍历数组 a:格式: "/* * JDK1.5新特性,增强for循环 * JDK1.5版本后,出现新的接口 java.lang.Iterable * Collection开是继承Iterable * Iterable作用,实现增强for循环 * * 格式: * for( 数据类型 变量名 : 数组或者集合 )&#123; * sop(变量); * &#125; */" public static void function_1()&#123; "for each对于对象数组遍历的时候,可以【调用】【对象的方法】" String[] str = &#123;"abc","itcast","cn"&#125;; for(String s : str)&#123; System.out.println(s.length()); &#125; &#125; "/* * 实现for循环,遍历数组 * 好处: 代码少了,方便对容器遍历 * 弊端: 没有索引,不能操作容器里面的元素 */" public static void function()&#123; int[] arr = &#123;3,1,9,0&#125;; for(int i : arr)&#123; System.out.println(i+1); &#125; System.out.println(arr[0]); &#125; 12增强for循环遍历集合12345678910111213A:增强for循环遍历集合 " /* * 增强for循环遍历集合 * 存储自定义Person类型 */" public static void function_2()&#123; ArrayList&lt;Person&gt; array = new ArrayList&lt;Person&gt;(); array.add(new Person("a",20)); array.add(new Person("b",10)); for(Person p : array)&#123; System.out.println(p);// System.out.println(p.toString()); &#125; &#125; 13泛型的引入12345678910111213141516171819202122232425A:泛型的引入"在前面学习集合时，我们都知道集合中是可以【存放任意对象】的，只要把对象存储集合后，那么这时他们都会被提升成Object类型。当我们在取出每一个对象，并且进行相应的操作，这时必须采用【类型转换】。"比如下面程序：public class GenericDemo &#123; public static void main(String[] args) &#123; List list = new ArrayList(); list.add("abc"); list.add("itcast"); list.add(5);"//由于集合没有做任何限定，任何类型都可以存放" "//自动装箱:Object obj=new Integer(5);" Iterator it = list.iterator(); while(it.hasNext())&#123; //需要打印每个字符串的长度,就要把迭代出来的对象转成String类型 String str = (String) it.next();//String str=(String)obj; "//编译时期仅检查语法错误,String是Object的子类可以向下转型 //运行时期String str=(String)(new Integer(5)) //String与Integer没有父子关系所以转换失败 //程序在运行时发生了问题java.lang.ClassCastException" System.out.println(str.length()); &#125; &#125;&#125; 14泛型的定义和使用12345678910111213141516171819202122232425A:泛型的定义和使用"/* * JDK1.5 出现新的安全机制,保证程序的安全性 * 泛型: 指明了【集合】中【存储数据的类型】 &lt;类型变量&gt; */"public class GenericDemo &#123; public static void main(String[] args) &#123; function(); &#125; public static void function()&#123; Collection&lt;String&gt; coll = new ArrayList&lt;String&gt;(); coll.add("abc"); coll.add("rtyg"); coll.add("43rt5yhju");// coll.add(1); Iterator&lt;String&gt; it = coll.iterator(); while(it.hasNext())&#123; String s = it.next(); System.out.println(s.length()); &#125; &#125;&#125; 15Java中的伪泛型1234567891011121314151617181920212223242526272829303132333435363738A:Java中的【伪泛型】："泛型【只在】【编译时】存在,【编译后】就被【擦除】,在编译之前我们就可以限制集合的类型,起到安全作用""编译后得到的Class文件是【没有】【泛型】的，实际并不存在泛型类，【系统】【不会】生成泛型类"例如: ArrayList&lt;String&gt; al=new ArrayList&lt;String&gt;();"编译后": ArrayList al=new ArrayList();————————————————————————————————————————————————————————————————————————————————————————B："运行时类查询(getClass方法)【只适用】于【原始类型】"。可以理解为ArrayList&lt;String&gt;类是ArrayList的子类，事实上，ArrayList&lt;String&gt;类也确实像一种特殊的ArrayList类:"该ArrayList&lt;String&gt;对象【只能】添加【String对象】作为【集合元素】"。但实际上，"系统【并没有】为ArrayList&lt;String&gt;生成【新的class文件】， 而且也【不会】把ArrayList&lt;String&gt;当成【新类】来处理"例如:List&lt;String&gt; l1 =new ArrayList&lt;&gt;();List&lt;Integer&gt; ii = new ArrayList&lt;&gt;();System.out.println(l1.getClass());"//class java.util.ArrayList"System.out.println(ii.getClass());"//class java.util.ArrayList"System.out.println(l1.getClass() == ii.getClass());"true"————————————————————————————————————————————————————————————————————————————————————————C： "不管为泛型的【类型形参】传入哪一种一【类型实参】，对于Java来说，它们依然被当成【同一个类处理】，在内存中也【只占用一块内存空间】"，"因此在【静态方法】、【静态初始化块】或者【静态变量】的【声明和初始化】中【不允许】使用【类型形参】"。下面程序演示了这种"【错误】"。public class Apple&lt;T&gt; &#123; private static T age; "【error】" public static void bar(T mm)&#123; "【error】" &#125;————————————————————————————————————————————————————————————————————————————————————————D："由于系统中并不会真正生成泛型类，所以【instanceof运算符】后【不能】使用【泛型类】"List&lt;Integer&gt; ii = new ArrayList&lt;Integer&gt;();if(ii instanceof ArrayList)&#123;//true &#125;if(ii instanceof ArrayList&lt;Integer&gt;)&#123;"【error】" &#125; 16泛型类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697A:泛型类:a:定义格式： 修饰符 class 类名&lt;代表泛型的变量&gt; &#123; &#125; 例如，API中的ArrayList集合： class ArrayList&lt;E&gt;&#123; public boolean add(E e)&#123; &#125; public E get(int index)&#123; &#125; &#125;注意："泛型类的【静态方法】、【静态初始化块】或者【静态变量】的 【声明和初始化】中【不允许】使用【类型形参】T"private static T age;"【error】"public static void bar(T mm)&#123;"【error】"&#125;static&#123; T gr = 1;"【error】"&#125;————————————————————————————————————————————————————————————————————————————————————————b:使用格式： "创建对象时，确定泛型的类型" 例如，ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); 此时，变量E的值就是String类型 class ArrayList&lt;String&gt;&#123; public boolean add(String e)&#123; &#125; public String get(int index)&#123; &#125; &#125; 例如，ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); 此时，变量E的值就是Integer类型 class ArrayList&lt;Integer&gt;&#123; public boolean add(Integer e)&#123; &#125; public Integer get(int index)&#123; &#125; &#125;————————————————————————————————————————————————————————————————————————————————————————c:"可以为【任何类，接口】【增加泛型声明】(【井不是】【只有】集合类才可以使用泛型声明，虽然集合类是泛型的重要使用场所)"例如：public class Apple&lt;T&gt; &#123; private T info; private String id; public Apple()&#123; super(); &#125; public Apple(T info)&#123; this.info = info; &#125; public Apple(T info, String id)&#123; this.info = info; this.id =id; &#125; public void setInfo(T info)&#123; this.info =info; &#125; public T getInfo()&#123; return this.info; &#125; public void setId(String id)&#123; this.id =id; &#125; public String getId()&#123; return this.id; &#125; @Override public String toString()&#123; return "&#123;"+ "id=: " +this.id+ "|"+" info=: "+ this.info +"&#125;"; &#125;&#125;public class AppleTest &#123; public static void main(String[] args) &#123; new Apple&lt;Double&gt;(); Apple&lt;Double&gt; a1= new Apple&lt;&gt;(25008.8,"刘鹏001"); Apple&lt;Integer&gt; b2 = new Apple&lt;&gt;(26000,"周莉002"); System.out.println(a1); System.out.println(b2); &#125;&#125;————————————————————————————————————————————————————————————————————————————————————————d: "当创建带泛型声明的自定义类，为该类定义【构造器】时， 【构造器名】还是【原来的类名】，【不能】【增加泛型声明】。例如，为Apple&lt;T&gt;类定义构造器，其【构造器名依然是Apple】，而【不是】Apple&lt;T&gt;!【调用】（new对象时）该构造器时却可以使用Apple&lt;T&gt;的形式，当然应该为T形参传入实际的类型参数"。如：public Apple(T info)&#123; this.info = info; &#125;public Apple(T info, String id)&#123; this.info = info; this.id =id; &#125; 17 泛型类派生子类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849A:当创建了带泛型声明的接口、父类之后，可以为该接创建实现类，或从该父类派生子类，"需要指出的是，当使用这些接口、父类时【不能】再【包含】【类型形参】。例如，下而代码就是【错误】的"public class SubApple extends Apple&lt;T&gt;&#123;&#125;"//error""除非：子类也是泛型类"，即：SubApple&lt;T&gt;public class SubApple&lt;T&gt; extends Apple&lt;T&gt;&#123;&#125;————————————————————————————————————————————————————————————————————————————————————————B:定义方法时可以声明数据形参，调用方法(使用方法)时必须为这些数据形参传入实际的数据:与此类似的是，"定义类、接口、方法时可以声明类型形参，使用类、接口、方法时应该为【类型形参】传入【实际的类型】"。public class SubApple11 extends Apple&lt;Integer&gt;&#123;&#125;public class SubApple11 extends Apple&lt;Integer&gt;&#123; public SubApple11()&#123; super(); &#125; public SubApple11(Integer d,String s)&#123; super(d,s); &#125; @Override public Integer getInfo()&#123; "//父类是Apple&lt;Integer&gt;" "返回值类型必须与Apple&lt;Integer&gt;的返回值类型完全相同" return super.getInfo() +5000; &#125;&#125;————————————————————————————————————————————————————————————————————————————————————————C: 调用方法时必须为所有的数据形参传入参数值，"与调用方法不同的是"，"使用类、接口时【可以】【不为】类型形参传入【实际的类型参数】，即下面代码也是【正确】的"。"此时，系统会把Apple&lt;T&gt;类里的T形参当成【Object类型】处理"。public class SubApple extends Apple&#123;&#125;举例：public class SubApple extends Apple&#123;//系统会把Apple&lt;T&gt;类里的T形参当成【Object类型】处理public SubApple()&#123; super();&#125;public SubApple(Double d,String s)&#123; super(d,s);&#125;@Overridepublic Double getInfo()&#123; "//super.getInfo()是Object类型" return (Double) super.getInfo() +1000;&#125;&#125; 18泛型的方法123456789101112131415161718192021222324A:泛型的方法a:"定义格式：修饰符 &lt;代表泛型的变量&gt; 返回值类型 方法名(参数)&#123; &#125;"b:泛型方法的使用: 1:例如，API中的ArrayList集合中的方法： public &lt;T&gt; T[] toArray(T[] a)&#123; &#125; //该方法，用来把集合元素存储到指定数据类型的数组中，返回已存储集合元素的数组"使用格式：调用方法时，确定泛型的类型"例如: ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); String[] arr = new String[100]; String[] result = list.toArray(arr); "此时，变量T的值就是String类型。变量T，可以与定义集合的泛型不同" public &lt;String&gt; String[] toArray(String[] a)&#123; &#125;  例如: ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); Integer[] arr = new Integer[100]; Integer [] result = list.toArray(arr); "此时，变量T的值就是Integer类型。变量T，可以与定义集合的泛型不同" public &lt;Integer&gt; Integer[] toArray(Integer[] a)&#123; &#125; 19泛型的接口12345678910111213141516171819202122A:泛型的接口: "/* * 带有泛型的接口 * * public interface List &lt;E&gt;&#123; * abstract boolean add(E e); * &#125; * ———————————————————————————————————————————————————————————————————— *A: 实现类,先实现接口,不理会泛型 * public class ArrayList&lt;E&gt; implements List&lt;E&gt;&#123; * &#125; * 调用者 : new ArrayList&lt;String&gt;() 后期创建集合对象的时候,指定数据类型 * * ———————————————————————————————————————————————————————————————————— *B: 实现类,实现接口的同时,也指定了数据类型 * public class XXX implements List&lt;String&gt;&#123; * &#125; * new XXX() */" public class GenericDemo2 &#123; &#125; 20泛型的好处1234567891011121314151617181920A:泛型的好处a:将运行时期的ClassCastException，转移到了编译时期变成了编译失败。b:避免了类型强转的麻烦。演示下列代码：public class GenericDemo &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add("abc"); list.add("itcast"); //list.add(5);//当集合明确类型后，存放类型不一致就会编译报错 //集合已经明确具体存放的元素类型，那么在使用迭代器的时候，迭代器也同样会知道具体遍历元素类型 Iterator&lt;String&gt; it = list.iterator(); while(it.hasNext())&#123; String str = it.next(); System.out.println(str.length()); //当使用Iterator&lt;String&gt; //控制元素类型后，就不需要强转了。获取到的元素直接就是String类型 &#125; &#125; &#125; 21泛型的继承规则12345678910111213A："Manager类 是 Employee类 的【子类】。 但 Pair&lt;Manager&gt; 【不是】Pair&lt;Employee&gt; 的【子类】" ，"即 Pair&lt;Manager&gt; 与 Pair&lt;Employee&gt; 【没有】【继承关系】""无论 S 与 T 有什么联系，通常， Pair&lt;S&gt; 与 Pair&lt;T&gt; 没有联系"如：Integer是Number的子类List&lt;Integer&gt; ss = new ArrayList&lt;&gt;();List&lt;Number&gt; nn= ss; "// Error"B："数组和泛型有所不同：，假设Foo是Bar的一个子类型(子类或者子接口)，那么 Foo[]【依然是】Bar[] 的子类型;但 G&lt;Foo&gt; 【不是】 G&lt;Bar&gt; 的子类型"。Manager[] managerBuddies = &#123; ceo, cfo &#125;;Employee[] employeeBuddies = managerBuddies; // OK 22泛型的通配符123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179A:泛型的通配符"为了表示各种泛型List的父类，可以使用类型通配符，类型通配符是一个问号(?)，将一个问号作为类型实参传给List集合，写作:List&lt;?&gt; 意思是元素类型未知的List 。这个问号(?)被称为【通配符】，它的元素类型可以【匹配任何类型】(Object 类型)"注意："这种带通配符的List仅表示它是【各种泛型List】的【父类】， 【不能】把【元素】加入到其中，因为其类型是无法确定的" 但是程序【可以调用】get() 方法来返回List&lt;?&gt;集合指定索引处的元素， 其返回值是一个未知类型，但可以肯定的是，它总是一个【Object类型】如：List&lt;?&gt; c = new ArrayList&lt;&gt;();"//下面程序引起编译错误"c.add(new Object());"//error"—————————————————————————————————————————————————————————————————————————————————————————— /** 泛型的通配符*/public class GenericDemo &#123;public static void main(String[] args) &#123; ArrayList&lt;String&gt; array = new ArrayList&lt;String&gt;(); HashSet&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); array.add("123"); array.add("456"); set.add(789); set.add(890); iterator(array); iterator(set);&#125;"/* * 定义方法,可以同时迭代2个集合 * 参数: 怎么实现 , 不能写ArrayList,也不能写HashSet * 参数: 或者共同实现的接口 * 泛型的通配,匹配所有的数据类型 ? */"public static void iterator(Collection&lt;?&gt; coll)&#123; Iterator&lt;?&gt; it = coll.iterator(); while(it.hasNext())&#123; //it.next()获取的对象是什么类型,就得到什么类型 System.out.println(it.next()); &#125;&#125;&#125;——————————————————————————————————————————————————————————————————————————————————————————B：设定类型通配符的上限" List&lt;? extends Shape&gt; 是受限制通配符的例子，此处的问号(?)代表一个未知的类型，就像前面看到的通配符一样。但是此处的这个未知类型【必须】是【Shape的子类型(也可以是Shape本身)】，因此可以把Shape称为这个【通配符的上限】（upper bound）"类似地，"由于程序【无法确定】这个受限制的通配符的【具体类型】，所以【不能】把【Employee对象或其子类的对象】加入这个泛型集合中。例如，下面代码就是【错误】的。"public static void iterator_func(ArrayList&lt;? extends Employee&gt; list)&#123; list.add(new Manager());"//error"&#125;"————————————————————————————————extends通配符的缺陷————————————————————————————————""当使用 extends 通配符时，我们【无法】向其中【添加】【任何对象】。【只能】从中【取出】对象"例如：Apple 类 和 Orange 类 继承自 Fruit类，Fruit类继承自 Food类Plate&lt;? extends Fruit&gt; plate = new Plate&lt;Apple&gt;();plate.add(new Apple()); "//Compile Error"plate.get(); // Compile Success因为编译时只看父类，运行时看子类，在我们还【未具体运行】时，1）进行"添加操作"时："JVM 并不知道我们要往plate里【添加】什么对象，只知道添加的是Fruit的【子类】，【无法确定】"。2）而执行"取出操作"时，JVM 知道结果"一定是父类Fruit的子类，可以做自动【向上转型】，用【父类的变量】接收【子类对象】"即：Fruit apple = plate.get();//多态的向上转型当然：如果考虑" Fruit类继承自 Food类"，还可以"继续向上转型"：即:Food food = plate.get();//多态的向上转型同样：Object food = plate.get(); 上述3种 赋值 都是"正确"的。举例："方法参数: 控制,可以传递Employee对象,也可以传递Employee的子类的对象" public static void iterator_func(ArrayList&lt;? extends Employee&gt; list)&#123; Iterator&lt;? extends Employee&gt; it = list.iterator(); while(it.hasNext())&#123; Employee e = it.next(); e.work(); &#125; &#125;&#125;——————————————————————————————————————————————————————————————————————————————————————————C：设定类型形参的上限Java泛型不仅允许在使用通配符形参时设定上限，"而且可以在定义类型形参时设定上限，用于表示传给该类型形参的实际类型要么是该上限类型，要么是该上限类型的子类。"下面程序示范了这种用法。public class GenericDemo2&lt;T extends Number&gt; &#123; T nn; public static void main(String[] args) &#123; GenericDemo2&lt;Integer&gt; ii= new GenericDemo2&lt;&gt;(); GenericDemo2&lt;Double&gt; dd = new GenericDemo2&lt;&gt;(); "//下面代码将引发编译异常，下面代码试图把String类型传给T形参 //但String不是Number的子类型，所以引起编译错误" GenericDemo2&lt;String&gt; ss = new GenericDemo2&lt;&gt;();//error &#125;&#125;——————————————————————————————————————————————————————————————————————————————————————————D：设定类型形参的下限" List&lt;? super Type&gt;表示传入的未知类型【必须】是【Type本身，或者Type的父类型】"例如：Apple 类 和 Orange 类 继承自 Fruit类，Plate&lt;? super Apple&gt; plate = new Plate&lt;Fruit&gt;();Plate&lt;? super Apple&gt; plate = new Plate&lt;Object&gt;();上面的声明都是对的，因为 Object 是任何一个类的父类，而 Fruit类 是 Apple类 的父类。"————————————————————————————————super通配符的缺陷————————————————————————————————"&lt;? super T&gt;对于使用了 super 通配符的情况，我们"只能【存入】【 T 类型】及【 T 类型的子类】对象"。"【取出】的时候【必须】用【 Object 类型】的属性指向取出的对象"。例如：Apple 类 和 Orange 类 继承自 Fruit类，Fruit类继承自 Food类Plate&lt;? super Fruit&gt; plate = new Plate&lt;&gt;();plate.add(new Fruit());plate.add(new Apple());plate.add(new Food()); "//Compile Error"plate 指向的具体类型可以是任何 "Fruit类及其父类"，JVM 在编译的时候肯定"无法判断具体是哪个类型"。但 JVM 能确定的是，"任何 Fruit 的子类【都可以】自动【向上转型】为 Fruit 类型"，"但任何 Fruit 的父类都【无法直接】转为 Fruit 类型，【只能】【向下强转】"。所以 "只能存入 T 类型及 T 类型的【子类】对象"，"T 类型的子类对象 能自动 【向上转型】为T 类型"Object object = plate.get();Fruit fruit = plate.get(); "//Error"Food food = plate.get(); "//Error"plate 指向的具体类型可以是任何 "Fruit类及其父类",接收类型是不确定的，"只能用Object 类型才能正确接收"。——————————————————————————————————————————————————————————————————————————————————————————总结：PECS(Producer Extends, Consumer Super)原则extends 和 super 通配符的使用和限制：对于 "extends 通配符"，我们"【无法】向其中【加入】任何对象"，但是"我们可以进行正常的取出"。对于 super 通配符，我们"可以存入 【T 类型】对象或 【T 类型的子类】对象"，但是我们取出的时候"【只能】用【 Object 类】变量指向取出的对象"。从上面的总结可以看出，"extends 通配符""偏向于内容的获取"，而 super 通配符更"偏向于内容的存入"。我们有一个 PECS 原则（Producer Extends Consumer Super）很好的解释了这两个通配符的使用场景。Producer Extends 说的是当你的情景是"生产者类型"，需要"获取资源"以供生产时，我们建议使用" extends 通配符"，因为使用了 extends 通配符的类型更适合获取资源。Consumer Super 说的是当你的场景是"消费者类型"，需要"存入资源"以供消费时，我们建议使用 "super 通配符"，因为使用 super 通配符的类型更适合存入资源。但如果你"既想存入，又想取出"，那么你最好还是不要使用 extends 或 super 通配符。 23泛型的限定123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051A:泛型的限定" /** 将的酒店员工,厨师,服务员,经理,分别存储到3个集合中* 定义方法,可以同时遍历3集合,遍历三个集合的同时,可以调用工作方法*/"import java.util.ArrayList;import java.util.Iterator;public class GenericTest &#123;public static void main(String[] args) &#123; //创建3个集合对象 ArrayList&lt;ChuShi&gt; cs = new ArrayList&lt;ChuShi&gt;(); ArrayList&lt;FuWuYuan&gt; fwy = new ArrayList&lt;FuWuYuan&gt;(); ArrayList&lt;JingLi&gt; jl = new ArrayList&lt;JingLi&gt;(); //每个集合存储自己的元素 cs.add(new ChuShi("张三", "后厨001")); cs.add(new ChuShi("李四", "后厨002")); fwy.add(new FuWuYuan("翠花", "服务部001")); fwy.add(new FuWuYuan("酸菜", "服务部002")); jl.add(new JingLi("小名", "董事会001", 123456789.32)); jl.add(new JingLi("小强", "董事会002", 123456789.33)); // ArrayList&lt;String&gt; arrayString = new ArrayList&lt;String&gt;(); iterator(jl); iterator(fwy); iterator(cs);&#125;"/* * 定义方法,可以同时遍历3集合,遍历三个集合的同时,可以调用工作方法 work * ? 通配符,迭代器it.next()方法取出来的是Object类型,怎么调用work方法 * 强制转换: it.next()=Object o ==&gt; Employee * 方法参数: 控制,可以传递Employee对象,也可以传递Employee的子类的对象 * 【泛型的限定】 本案例,父类固定Employee,但是子类可以无限? * ———————————————————————————————————————————————————————————————————— * ? extends Employee 限制的是【父类】, 【上限限定】, 可以传递Employee,传递他的【子类】对象 * ———————————————————————————————————————————————————————————————————— * ? super Employee 限制的是【子类】, 【下限限定】, 可以传递Employee,传递他的【父类】对象 */"public static void iterator(ArrayList&lt;? extends Employee&gt; array)&#123; Iterator&lt;? extends Employee&gt; it = array.iterator(); while(it.hasNext())&#123; //获取出的next() 数据类型,是什么Employee Employee e = it.next(); e.work(); &#125;&#125;&#125;]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础15(包装类,System类,Math类,Arrays类)]]></title>
    <url>%2F2016%2F10%2F25%2Fday17%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、基本类型包装类2、System类3、Math类4、Arrays类5、大数据运算 01基本数据类型对象包装类概述123456789101112*A:基本数据类型对象包装类概述 *a.基本类型包装类的产生 在实际程序使用中，程序界面上用户输入的数据都是以字符串类型进行存储的。而程序开发中，我们需要把字符串数据，根据需求转换成指定的基本数据类型，如年龄需要转换成int类型，考试成绩需要转换成double类型等 *b.八种基本类型对应的包装类 char Character int Integer byte Byte short Short long Long float Float double Double boolean Boolean 02Integer类parseInt方法123456789101112131415161718 *A:Integer类parseInt方法: *a:parseInt() int i = Integer.parseInt("12"); System.out.println(i/2);//6 *b:parseInt(String s, int radix) /* * Integer类静态方法parseInt(String s, int radix) * radix基数,进制 * "110",2 含义 前面的数字是二进制的,但是方法parseInt运行结果都是十进制 * 指定进制的字符串转换为十进制的整数 */ public static void function_1()&#123; int i = Integer.parseInt("110", 2); System.out.println(i); int a = Integer.parseInt("f",16); System.out.println(a); &#125; 03Integer类int转成字符串123456789*A:Integer类int转成字符串: *a:使用+与字符串拼接 int i = 3; String s = i+""; System.out.println(s+1);//"31" *b:toString(int ,int 进制),任意进制整数转成任意进制的字符串 (了解) String s1 = Integer.toString(5,2); System.out.println(s1); 04Integer类构造方法12345678910111213*A:Integer类构造方法 "/* * Integer类构造方法 * Integer (String s) * 将数字格式的字符串,传递到Integer类的构造方法中 * 创建Integer对象,包装的是一个字符串 * 将构造方法中的字符串,转成基本数据类型,调用方法,非静态的, intValue() */" public static void function_3()&#123; Integer in = new Integer("100"); int i = in.intValue(); System.out.println(--i);//99 &#125; 05Integer类其他方法12345678910111213141516171819202122232425*A:Integer类其他方法 "/** Integer类的3个静态方法* 做进制的转换* 十进制转成二进制 toBinarString(int)* 十进制转成八进制 toOctalString(int)* 十进制转成十六进制 toHexString(int)* 三个方法,返回值都是以String形式出现*/" a:十进制转二,八,十六进制 public static void function_1()&#123; System.out.println(Integer.toBinaryString(99)); System.out.println(Integer.toOctalString(99)); System.out.println(Integer.toHexString(999)); &#125; b:获取int的最大值和最小值 /* * Integer类的静态成员变量 * MAX_VALUE * MIN_VALUE */ public static void function()&#123; System.out.println(Integer.MAX_VALUE); System.out.println(Integer.MIN_VALUE); &#125; 06自动装箱和自动拆箱,valueOf12345678910111213141516171819 *A:自动装箱与自动拆箱: "//JDK1.5新特性//自动装箱,拆箱的 好处: 基本类型和引用类直接运算 //自动装箱:使用Integer.valueOf(整数值)返回一个封装了该整数值的Integer对象 //自动拆箱:使用Integer对象.intValue()返回Integer对象中封装的整数值"public static void function()&#123; //引用类型 , 引用变量一定指向对象 //自动装箱, 基本数据类型1, 直接变成了对象 Integer in = 1; // Integer in = new Integer(1) //in 是引用类型,不能和基本类型运算, 自动拆箱,引用类型in,转换基本类型 //in+1 ==&gt; in.inValue()+1 = 2 //in = 2 自动装箱 in = in + 1; System.out.println(in); &#125; valueOf() 方法继承自Java Number类 valueOf() 方法用于返回给定参数的原生 Number 对象值，参数可以是原生数据类型, String等。 该方法是静态方法。该方法可以接收两个参数一个是字符串，一个是基数。 语法该方法有以下几种语法格式：123static Integer valueOf(int i)static Integer valueOf(String s)static Integer valueOf(String s, int radix) 参数i – Integer 对象的整数。 s – Integer 对象的字符串。 radix –在解析字符串 s 时使用的基数，用于指定使用的进制数。 返回值Integer valueOf(int i)：返回一个表示指定的 int 值的 Integer 实例。 Integer valueOf(String s):返回保存指定的 String 的值的 Integer 对象。 Integer valueOf(String s, int radix): 返回一个 Integer 对象，该对象中保存了用第二个参数提供的基数进行解析时从指定的 String 中提取的值。 实例1234567891011121314public class Test&#123; public static void main(String args[])&#123; Integer x =Integer.valueOf(9); Double c = Double.valueOf(5); Float a = Float.valueOf("80"); Integer b = Integer.valueOf("789",16); // 使用 16 进制 System.out.println(x); System.out.println(c); System.out.println(a); System.out.println(b); &#125;&#125; 编译以上程序，输出结果为： 95.080.01929 前言今天在做题时，碰到了一道选择题，就是关于Integer.valueOf()的知识，题目如下：Integer i01=59int i02=59Integer i03 =Integer.valueOf(59)Integer i04 = new Integer(59) 判断对错：A.System.out.println(i01== i02);B.System.out.println(i01== i03);C.System.out.println(i03== i04);D.System.out.println(i02== i04); 分析 选项A 选项A中比较的是i01和i02，Integer i01=59这里涉及到自动装箱过程，59是整型常量，经包装使其产生一个引用并存在栈中指向这个整型常量所占的内存，这时i01就是Integer 的引用。 而int i02=59由于int是基本类型，所以不存在引用问题，直接由编译器将其存放在栈中，换一句话说，i02本身就是59。那么System.out.println(i01== i02)结果任何呢？这里涉及到了拆箱的过程，因为等号一边存在基本类型所以编译器后会把另一边的Integer对象拆箱成int型，这时等号两边比较的就是数值大小，所以是true。 好了，到了这里，你有没有想到这样一个问题：如果是Integer i01=59；Integer i02=59；然后System.out.println(i01== i02)的结果是？可能你会说比较数值大小所以相等啊，也有可能说等号两边对象引用，所以比较的是引用，又因为开辟了不同的内存空间，所以引用不同所以返回false。可是正确答案是：true.再来看这个问题：：如果是Integer i01=300；Integer i02=300；然后System.out.println(i01== i02)的结果是？ 这次的答案是false。 解析：当靠想象无法解决问题的时候，这是就要看源代码了！！很重要！我们可以在Integer类中找到这样的嵌套内部类IntegerCache：12345678910111213141516171819202122232425private static class IntegerCache &#123;//静态缓存类 static final int low = -128; static final int high; static final Integer cache[]; static &#123; //静态代码块 // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty("java.lang.Integer.IntegerCache.high"); if (integerCacheHighPropValue != null) &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); &#125; private IntegerCache() &#123;&#125; &#125; 这个类就是在Integer类装入内存中时，会执行其内部类中静态代码块进行其初始化工作，做的主要工作就是把一字节的整型数据（-128-127）包装成Integer类并把其对应的引用存入到cache数组中，这样在方法区中开辟空间存放这些静态Integer变量，同时静态cache数组也存放在这里，供线程享用，这也称静态缓存。 所以当用Integer 声明初始化变量时，会先判断所赋值的大小是否在-128到127之间，若在，则利用静态缓存中的空间并且返回对应cache数组中对应引用，存放到运行栈中，而不再重新开辟内存。 所以对于Integer i01=59；Integer i02=59；i01 和 i02是引用并且相等都指向缓存中的数据，所以返回true。而对于Integer i01=300；Integer i02=300；因为其数据大于127，所以虚拟机会在堆中重新new （开辟新空间）一个 Integer 对象存放300，创建2个对象就会产生2个这样的空间，空间的地址肯定不同导致返回到栈中的引用的只不同。所以System.out.println打印出false。 补充：为什么1个字节的数据范围是-128到127呢，因为Java中数据的表示都是带符号数，所以最高位是用来表示数据的正负，0表示正数，1表示负数，所以正数最大的情况对应的二进制数为：01111111，负数最小对应的二进制数为：10000000. B选项 从上面的分析，我们已经知道Integer i01=59返回的是指向缓存数据的引用。那么Integer.valueOf(59)返回的是什么或者操作是什么呢？ 这个函数的功能就是把int 型转换成Integer，简单说就是装包，那他是新创建一个对象吗？还是像之前利用缓存的呢？有了之前的经验，肯定想到的是利用缓存，这样做既提高程序速度，又节约内存，何乐而不为？来看一下源代码：123456public static Integer valueOf(int i) &#123; assert IntegerCache.high &gt;= 127; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125; 很明显跟之前的思想一致，若在-128到127范围，直接返回该对象的引用，否则在堆中重新new 一个。 到这，System.out.println(i01== i03)的结果毋庸置疑就是true. 选项C Integer.valueOf(59)返回的是已缓存的对象的引用，而Integer i04 = new Integer(59)是在堆中新开辟的空间，所以二者的引用的值必然不同，返回false,这道题呢就选C 选项D System.out.println(i02== i04) i02是整型变量，i04是引用，这里又用到了解包，虚拟机会把i04指向的数据拆箱为整型变量再与之比较，所以比较的是数值，59==59，返回true. 思考 不得不服，Java这的设计真是巧妙，以后应多注意看看源码，其思想使我受益匪浅。出一道题：12345System.out.println(Integer.valueOf("127")==Integer.valueOf("127"));//trueSystem.out.println(Integer.valueOf("128")==Integer.valueOf("128"));//falseSystem.out.println(Integer.parseInt("128")==Integer.valueOf("128"));//true"//parseInt返回的是10进制整数，Integer.valueOf("128")的Integer对象拆箱成int型， 这时等号两边比较的就是数值大小，所以是true" 07自动装箱和自动拆箱练习题12345678910111213141516171819202122*A:自动装箱与自动拆箱: Integer i = new Integer(1);Integer j = new Integer(1);System.out.println(i==j);// false 对象地址System.out.println(i.equals(j));// true 继承Object重写equals,比较的对象数据System.out.println("===================");Integer a = 500;//Integer integer=Integer.valueOf(500) //integer=new Integer(500);Integer b = 500;System.out.println(a==b);//falseSystem.out.println(a.equals(b));//trueSystem.out.println("===================");"数据在byte(-128~127)范围内,JVM不会从新new对象"Integer aa = 127; // Integer aa = new Integer(127)Integer bb = 127; // Integer bb = aa;System.out.println(aa==bb); //trueSystem.out.println(aa.equals(bb));//true 08System类方法currentTimeMillis123456789101112131415161718192021在API中System类介绍的比较简单，我们给出定义，System中代表程序所在系统，提供了对应的一些系统属性信息，和系统操作。System类"不能手动创建对象"，因为"构造方法"被private修饰，"阻止外界创建对象"。System类中的"都是"static方法，"类名访问即可"。在JDK中，有许多这样的类。*A:System类方法currentTimeMillis():用于计算程序的执行时间 /* * 获取系统当前毫秒值 * static long currentTimeMillis() * 对程序执行时间测试 */ public static void function()&#123; long start = System.currentTimeMillis();//当前时间x-1970年1月1日零时零分零秒 for(int i = 0 ; i &lt; 10000; i++)&#123; System.out.println(i); &#125; long end = System.currentTimeMillis();//当前时间y-1970年1月1日零时零分零秒 System.out.println(end - start);//当前时间y-当前时间x &#125; 09System类方法exit1234567891011 *A:System类方法exit()方法 /* * 退出虚拟机,所有程序全停止 * static void exit(0) */public static void function_1()&#123; while(true)&#123; System.out.println("hello"); System.exit(0);//该方法会在以后的finally代码块中使用(讲到再说) &#125;&#125; 10System类方法gc123456789101112131415161718192021222324A:System类方法gc public class Person &#123; public void finalize()&#123; System.out.println("垃圾收取了"); &#125; &#125; "* * JVM在内存中,收取对象的垃圾 * 当没有更多引用指向该对象时,会自动调用垃圾回收机制回收堆中的对象 * 同时调用回收对象所属类的 【finalize方法() * static void gc() *" public static void function_2()&#123; new Person(); new Person(); new Person(); new Person(); new Person(); new Person(); new Person(); new Person(); System.gc(); &#125; 11System类方法getProperties12345678A:System类方法getProperties(了解) /* * 获取当前操作系统的属性:例如操作系统名称, * static Properties getProperties() */ public static void function_3()&#123; System.out.println( System.getProperties() ); &#125; 12System类方法arraycopy1234567891011121314151617181920212223242526272829303132333435 " /* * System类方法,复制数组,这是一个本地方法 * arraycopy(Object src, int srcPos, Object dest, int destPos, int length) * Object src, 要复制的源数组 * int srcPos, 数组源的起始索引 * Object dest,复制后的目标数组 * int destPos,目标数组起始索引 * int length, 复制几个 */""从指定源数组中复制一个数组，复制从指定的位置开始，到目标数组的指定位置结束。从 src 引用的【源数组】到 dest 引用的【目标数组】，数组组件的一个【子序列】被复制下来。被复制的组件的编号等于 length 参数。【源数组】中位置在【 srcPos 】到【 srcPos+length-1 】之间的组件被分别复制到【目标数组】中的【 destPos 】到【 destPos+length-1 】位置。" A:System类方法arraycopy： /* * System类方法,复制数组 * arraycopy(Object src, int srcPos, Object dest, int destPos, int length) * Object src, 要复制的源数组 * int srcPos, 数组源的起始索引 * Object dest,复制后的目标数组 * int destPos,目标数组起始索引 * int length, 复制几个 */ public static void function_4()&#123; int[] src = &#123;11,22,33,44,55,66&#125;; int[] desc = &#123;77,88,99,0&#125;; System.arraycopy(src, 1, desc, 1, 2);//将src数组的1位置开始(包含1位置)的两个元素,拷贝到desc的1,2位置上 for(int i = 0 ; i &lt; desc.length ; i++)&#123; System.out.println(desc[i]); &#125; &#125; 13Math类的方法_1123456789101112131415161718192021222324252627282930313233343536373839404142434445A:Math类中的方法/* * static double sqrt(double d) * 返回参数的平方根 */ public static void function_4()&#123; double d = Math.sqrt(-2); System.out.println(d); &#125; /*0 * static double pow(double a, double b) * a的b次方 */ public static void function_3()&#123; double d = Math.pow(2, 3); System.out.println(d); &#125; /* * static double floor(double d) * 返回小于或者等于参数d的最大整数 */ public static void function_2()&#123; double d = Math.floor(1.5); System.out.println(d); &#125; /* * static double ceil(double d) * 返回大于或者等于参数d的最小整数 */ public static void function_1()&#123; double d = Math.ceil(5.1); System.out.println(d); &#125; /* * static int abs(int i) * 获取参数的绝对值 */ public static void function()&#123; int i = Math.abs(0); System.out.println(i); &#125; 14Math类的方法_21234567891011121314151617181920A:Math类的方法_2 /* * static double round(doubl d) * 获取参数的四舍五入,取整数 */ public static void function_6()&#123; double d = Math.round(5.4195); System.out.println(d); &#125; /* * static double random() 返回随机数 0.0-1.0之间 * 来源,也是Random类 */ public static void function_5()&#123; for(int i = 0 ; i &lt; 10 ;i++)&#123; double d = Math.random(); System.out.println(d); &#125; &#125; 15Arrays工具类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859A:Arrays工具类: public class ArraysDemo &#123; public static void main(String[] args) &#123; function_2(); int[] arr = &#123;56,65,11,98,57,43,16,18,100,200&#125;; int[] newArray = test(arr); System.out.println(Arrays.toString(newArray)); &#125; "/* * 定义方法,接收输入,存储的是10个人考试成绩 * 将最后三个人的成绩,存储到新的数组中,返回新的数组 */" public static int[] test(int[] arr)&#123; //对数组排序 Arrays.sort(arr); //将最后三个成绩存储到新的数组中 int[] result = new int[3]; //成绩数组的最后三个元素,复制到新数组中 // System.arraycopy(arr, 0, result, 0, 3); for(int i = 0 ; i &lt; 3 ;i++)&#123; result[i] = arr[i]; &#125; return result; &#125; "/* * static String toString(数组) * 将数组变成字符串 */" public static void function_2()&#123; int[] arr = &#123;5,1,4,6,8,9,0&#125;; String s = Arrays.toString(arr); System.out.println(s); &#125; "/* * static int binarySearch(数组, 被查找的元素) * 数组的二分搜索法 * 返回元素在数组中出现的索引 * 元素不存在, 返回的是 (-插入点-1) */" public static void function_1()&#123; int[] arr = &#123;1,4,7,9,11,15,18&#125;; int index = Arrays.binarySearch(arr, 10); System.out.println(index); &#125; "/* * static void sort(数组) * 对数组升序排列 */" public static void function()&#123; int[] arr = &#123;5,1,4,6,8,9,0&#125;; Arrays.sort(arr); for (int i = 0; i &lt; arr.length; i++) &#123; System.out.println(arr[i]); &#125; &#125; &#125; 16数组复制练习12345678910111213141516171819202122*A:数组复制练习: public static void main(String[] args) &#123; int[] arr = &#123;56,65,11,98,57,43,16,18,100,200&#125;; int[] newArray = test(arr); System.out.println(Arrays.toString(newArray)); &#125; /* * 定义方法,接收输入,存储的是10个人考试成绩 * 将最后三个人的成绩,存储到新的数组中,返回新的数组 */ public static int[] test(int[] arr)&#123; //对数组排序 Arrays.sort(arr); //将最后三个成绩存储到新的数组中 int[] result = new int[3]; //成绩数组的最后三个元素,复制到新数组中 //System.arraycopy(arr, 0, result, 0, 3); for(int i = 0 ; i &lt; 3 ;i++)&#123; result[i] = arr[i]; &#125; return result; &#125; 17BigInteger类概述和构造方法1234567891011121314A:BigInteger类概述和构造方法public static void main(String[] args) &#123; function(); &#125;/* * BigInteger类的构造方法 * 传递字符串,要求数字格式,没有长度限制 */ public static void function()&#123; BigInteger b = new BigInteger("8465846668464684562385634168451684568645684564564"); System.out.println(b); BigInteger b1 = new BigInteger("5861694569514568465846668464684562385634168451684568645684564564"); System.out.println(b1); &#125; 18BigInteger类四则运算12345678910111213141516171819202122232425262728A:BigInteger类四则运算 public static void main(String[] args) &#123; function_1(); &#125;/* * BigInteger对象的四则运算 * 调用方法计算,计算结果也只能是BigInteger对象 */ public static void function_1()&#123; BigInteger b1 = new BigInteger("5665464516451051581613661405146"); BigInteger b2 = new BigInteger("965855861461465516451051581613661405146"); //计算 b1+b2对象的和,调用方法 add BigInteger bigAdd = b1.add(b2);//965855867126930032902103163227322810292 System.out.println(bigAdd); //计算b1-b2对象的差,调用方法subtract BigInteger bigSub = b1.subtract(b2); System.out.println(bigSub); //计算b1*b2对象的乘积,调用方法multiply BigInteger bigMul = b1.multiply(b2); System.out.println(bigMul); //计算b2/b1对象商,调用方法divied BigInteger bigDiv = b2.divide(b1); System.out.println(bigDiv); &#125; 19员工案例的子类的编写1234567891011A:BigDecimal类概述 " /* * 计算结果,未知 * 原因: 计算机二进制中,表示浮点数不精确造成 * 超级大型的浮点数据,提供高精度的浮点运算, BigDecimal System.out.println(0.09 + 0.01);//0.09999999999999999 System.out.println(1.0 - 0.32);//0.6799999999999999 System.out.println(1.015 * 100);//101.49999999999999 System.out.println(1.301 / 100);//0.013009999999999999 */" 20BigDecimal类实现加法减法乘法123456789101112131415161718192021222324A:BigDecimal类实现加法减法乘法 /* * BigDecimal实现三则运算 * + - * */ public static void function()&#123; BigDecimal b1 = new BigDecimal("0.09"); BigDecimal b2 = new BigDecimal("0.01"); //计算b1+b2的和,调用方法add BigDecimal bigAdd = b1.add(b2); System.out.println(bigAdd); BigDecimal b3 = new BigDecimal("1"); BigDecimal b4 = new BigDecimal("0.32"); //计算b3-b2的差,调用方法subtract BigDecimal bigSub = b3.subtract(b4); System.out.println(bigSub); BigDecimal b5 = new BigDecimal("1.015"); BigDecimal b6 = new BigDecimal("100"); //计算b5*b6的成绩,调用方法 multiply BigDecimal bigMul = b5.multiply(b6); System.out.println(bigMul); &#125; 21BigDecimal类实现除法12345678910111213141516171819A:BigDecimal类实现除法/* * BigDecimal实现除法运算 * divide(BigDecimal divisor, int scale, int roundingMode) * int scale : 保留几位小数 * int roundingMode : 保留模式 * 保留模式 阅读API文档 * static int ROUND_UP 向上+1 * static int ROUND_DOWN 直接舍去 * static int ROUND_HALF_UP &gt;= 0.5 向上+1 * static int ROUND_HALF_DOWN &gt; 0.5 向上+1 ,否则直接舍去 */public static void function_1()&#123; BigDecimal b1 = new BigDecimal("1.0301"); BigDecimal b2 = new BigDecimal("100"); //计算b1/b2的商,调用方法divied BigDecimal bigDiv = b1.divide(b2,2,BigDecimal.ROUND_HALF_UP);//0.01301 System.out.println(bigDiv);&#125; 22小结12345678910111213141516171819202122232425262728293031323334353637383940 基本类型包装类 8种基本类型对应的包装类基本类型 包装类byte Byteshort Shortint " Integer "long Longfloat Floatdouble Doublechar " Character "boolean Boolean 自动装箱、自动拆箱 自动装箱：基本数值转成对象（int &gt;&gt; Integer） 自动拆箱：对象转成基本数值（Integer &gt;&gt; int） 常用方法public int parseInt(String str):把字符串转成基本类型intpublic static String toString(int x):把基本类型int转成字符串public static Integer valueOf(int x):返回一个表示指定的 int 值的 Integer 实例。如果不需要新的 Integer 实例，则通常应优先使用该方法。public int intValue():以 int类型返回该包装类对象的值 System类: 系统属性信息工具类 public static long currentTimeMillis()：获取当前系统时间与1970年01月01日00:00点之间的毫秒差值 public static void exit(int status)：用来结束正在运行的Java程序。参数传入一个数字即可。通常传入0记为正常状态，其他为异常状态 public static void gc()：用来运行JVM中的垃圾回收器，完成内存中垃圾的清除。 public static String getProperties()：用来获取指系统属性信息 Arrays类：数组操作工具类 public static void sort方法，用来对指定数组中的元素进行排序（元素值从小到大进行排序） public static String toString方法，用来返回指定数组元素内容的字符串形式 public static void binarySearch方法，在指定数组中，查找给定元素值出现的位置。若没有查询到，返回位置为-插入点-1。要求该数组必须是个有序的数组 Math类：数学运算工具类 abs方法,结果都为正数 ceil方法，结果为比参数值大的最小整数的double值 floor方法，结果为比参数值小的最大整数的double值 max方法，返回两个参数值中较大的值 min方法，返回两个参数值中较小的值 pow方法，返回第一个参数的第二个参数次幂的值 round方法，返回参数值四舍五入的结果 random方法，产生一个大于等于0.0且小于1.0的double小数]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础14(正则表达式,Date类,Calendar类)]]></title>
    <url>%2F2016%2F10%2F20%2Fday16%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、正则表达式的定义及使用2、Date类的用法3、Calendar类的用法 01正则表达式的概念和作用* A: 正则表达式的概念和作用 123456* a: 正则表达式的概述 * "正则表达式也是一个【字符串】，用来定义匹配规则，在Pattern类中有简单的规则定义"。 "可以结合【字符串类】的【方法】使用"。 * 简单记：正则表达式是具有特殊含义的字符串。* b: 正则表达式的作用* 比如注册邮箱,邮箱有用户名和密码,一般会对其限制长度,这个限制长度的事情就是正则表达式做的 02正则表达式语法规则* A: 正则表达式语法规则 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950* a: 字符 * x 代表的是字符x * \\ 代表的是反斜线字符'\' * \t 代表的是制表符 * \n 代表的是换行符 * \r 代表的是回车符——————————————————————————————————————————————————————————————————————————————————————* b: 字符类 * [abc] a、b 或 c（简单类） * [^abc] 任何字符，【除了】 a、b 或 c（否定） * [a-zA-Z] a到 z 或 A到 Z，【两头】的字母【包括在内（范围）】 * [0-9] 0到9的字符都包括 * [a-zA-Z_0-9] 代表的【字母】或者【数字】或者【下划线(即单词字符)】——————————————————————————————————————————————————————————————————————————————————————* c: 预定义字符类 * . : . 【任何字符】。 * \d ： [\\d] 数字：[0-9] ,相反地，[\\D]: 匹配字符不是数字 * \w ： [\\w] 单词字符：[a-zA-Z_0-9]如"com.itheima.tests"/finish——————————————————————————————————————————————————————————————————————————————————————* d: 边界匹配器 * ^ 代表的是行的开头 * $ 代表的是行的结尾 * \b 代表的是单词边界——————————————————————————————————————————————————————————————————————————————————————* e: 数量词 * X? X，一次或一次也没有 * X* X，零次或多次 * X+ X，一次或多次 * X&#123;n&#125; X，恰好 n 次 * X&#123;n,&#125; X，至少 n 次 * X&#123;n,m&#125; X，至少 n 次，但是不超过 m 次————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————举例：请写出满足如下匹配规则的字符串:规则："[0-9]&#123;6,12&#125;"该规则需要匹配的内容是：长度为6位到12位的数字。如：使用数据"123456789"进行匹配结果为true；使用数据"12345"进行匹配结果为false。规则："1[34578][0-9]&#123;9&#125;"该规则需要匹配的内容是：11位的手机号码，第1位为1，第2位为3、4、5、7、8中的一个，后面9位为0到9之间的任意数字。如：使用数据"12345678901"进行匹配结果为false；使用数据"13312345678"进行匹配结果为true。规则："a*b"该规则需要匹配的内容是：在多个a或零个a后面有个b；b必须为最后一个字符。如：使用数据"aaaaab"进行匹配结果为true；使用数据"abc"进行匹配结果为false。 03正则表达式练习和相关的String类方法* A: 正则表达式练习和相关的String类方法 12345678910111213* a: boolean matches(String 正则的规则) ：告知此字符串是否匹配给定的正则表达式。 * "abc".matches("[a]") ：根据给定正则表达式的匹配拆分此字符串。 * 匹配成功返回true* b: String[] split(String 正则的规则) * "abc".split("a") * 使用规则将字符串进行切割 * String [] rr = "abc".split(""); // 按每个字符切割，得到:[a,b,c] * 返回：String [] 字符串数组，它是根据给定正则表达式的匹配拆分此字符串确定的 * c: String replaceAll( String 正则规则,String 字符串)：* 使用给定的字符串替换此字符串所有匹配给定的正则表达式的子字符串。 * "abc0123".repalceAll("[\\d]","#") * 按照正则的规则,替换字符串 04正则表达式匹配练习* A: 正则表达式匹配练习 12345678910111213141516171819202122232425262728293031* a: 案例代码public class RegexDemo &#123; public static void main(String[] args) &#123; checkTel(); &#125; /* * 检查手机号码是否合法 * 1开头 可以是34578 0-9 位数固定11位 */ public static void checkTel()&#123; String telNumber = "1335128005"; //String类的方法matches boolean b = telNumber.matches("1[34857][\\d]&#123;9&#125;"); System.out.println(b); &#125; /* * 检查QQ号码是否合法 * 0不能开头,全数字, 位数5,10位 * 123456 * \\d \\D匹配不是数字 */ public static void checkQQ()&#123; String QQ = "123456"; //检查QQ号码和规则是否匹配,String类的方法matches boolean b = QQ.matches("[1-9][\\d]&#123;4,9&#125;"); System.out.println(b); &#125;&#125; 05正则表达式切割练习* A: 正则表达式切割练习 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051* a: 案例代码public class RegexDemo1 &#123; public static void main(String[] args) &#123; split_1(); split_2(); split_3(); &#125; /* * String类方法split对字符串进行切割 * 192.168.105.27 按照 点切割字符串 * 注意： * "\\."使用转义字符，因为"."表示【任何字符】 */ public static void split_3()&#123; String ip = "192.168.105.27"; String[] strArr = ip.split("\\."); System.out.println("数组的长度"+strArr.length); for(int i = 0 ; i &lt; strArr.length ; i++)&#123; System.out.println(strArr[i]); &#125; &#125; /* * String类方法split对字符串进行切割 * 18 22 40 65 按照空格切割字符串 */ public static void split_2()&#123; String str = "18 22 40 65"; String[] strArr = str.split(" +"); System.out.println("数组的长度"+strArr.length); for(int i = 0 ; i &lt; strArr.length ; i++)&#123; System.out.println(strArr[i]); &#125; &#125; /* * String类方法split对字符串进行切割 * 12-25-36-98 按照-对字符串进行切割 */ public static void split_1()&#123; String str = "12-25-36-98"; //按照-对字符串进行切割,String类方法split String[] strArr = str.split("-"); System.out.println("数组的长度"+strArr.length); for(int i = 0 ; i &lt; strArr.length ; i++)&#123; System.out.println(strArr[i]); &#125; &#125;&#125; 06正则表达式替换练习* A: 正则表达式替换练习 1234567891011121314151617 * a: 案例代码public class RegexDemo1 &#123; public static void main(String[] args) &#123; replaceAll_1(); &#125; /* * "Hello12345World6789012"将所有数字替换掉 * String类方法replaceAll(正则规则,替换后的新字符串) */ public static void replaceAll_1()&#123; String str = "Hello12345World6789012"; str = str.replaceAll("[\\d]+", "#"); System.out.println(str); &#125;&#125; 07正则表达式邮箱地址验证* A: 正则表达式邮箱地址验证 12345678910111213141516171819202122232425262728293031323334353637383940414243 匹配正确的数字匹配规则： 匹配正整数："\\d+" 匹配正小数："\\d+\\.\\d+" 匹配负整数："-\\d+" 匹配负小数："-\\d+\\.\\d+" 匹配保留两位小数的正数："\\d+\\.\\d&#123;2&#125;" 匹配保留1-3位小数的正数："\\d+\\.\\d&#123;1,3&#125;" 匹配合法的邮箱匹配规则： "[a-zA-Z_0-9]+@[a-zA-Z_0-9]+(\\.[a-zA-Z_0-9]+)+" "\\w+@\\w+(\\.\\w+)+" 注意；用() 表示多个相同的匹配规则 获取IP地址(192.168.1.100)中的每段数字匹配规则： "\\."* a: 案例代码public class RegexDemo2 &#123; public static void main(String[] args) &#123; checkMail(); &#125; /* * 检查邮件地址是否合法 * 规则: * 1234567@qq.com * mym_ail@sina.com * nimail@163.com * wodemail@yahoo.com.cn * * @: 前 数字字母_ 个数不能少于1个 * @: 后 数字字母 个数不能少于1个 * .: 后面 字母 * */ public static void checkMail()&#123; String email ="abc123@sina.com"; boolean b = email.matches("[a-zA-Z0-9_]+@[0-9a-z]+(\\.[a-z]+)+"); System.out.println(b); &#125;&#125; 08毫秒值概念* A: 毫秒值概念 12345678910* a: 时间和日期类 * java.util.Date* b: 毫秒概念 * 1000毫秒=1秒* c: 毫秒的0点 * System.currentTimeMillis() 返回值long类型参数 * 获取当前日期的毫秒值 3742769374405 * 时间原点; 公元1970年1月1日,午夜0:00:00 英国格林威治 毫秒值就是0 * 时间2088年8月8日 * 时间和日期的计算，必须依赖毫秒值 09Date类的构造方法* A: Date类的构造方法 1234* a: 空参构造 * public Date()* b: 带参构造 * public Date(long times) 10Date类的get和set方法* A：Date类的get和set方法 1234* public long getTime() * 将当前的日期对象，转为对应的毫秒值* public void setTime(long times); * 根据给定的毫秒值，生成对应的日期对象 11日期格式化SimpleDateFormat* A: 日期格式化SimpleDateFormat 12345678910111213141516* a: 对日期进行格式化(自定义) * 对日期格式化的类 java.text.DateFormat 抽象类, 普通方法,也有抽象的方法 * 实际使用是子类 java.text.SimpleDateFormat 可以使用父类普通方法,重写了抽象方法* b: 对日期进行格式化的步骤 * 1: 创建SimpleDateFormat对象 * 在类构造方法中,写入字符串的日期格式 (自己定义) * 2: SimpleDateFormat调用方法format对日期进行格式化 * public String format(Date date) 传递日期对象,返回字符串 * 日期模式: * yyyy 年份 * MM 月份 * dd 月中的天数 * HH 0-23小时 * mm 小时中的分钟 * ss 秒 * yyyy年MM月dd日 HH点mm分钟ss秒 汉字修改,: - 字母表示的每个字段不可以随便写 12字符串转成日期对象* A: 字符串转成日期对象 12345678* a: 使用步骤 * 1: 创建SimpleDateFormat的对象 * 构造方法中,指定日期模式 * 2: 子类对象,调用方法 parse 传递String,返回Date * 注意: 时间和日期的模式yyyy-MM-dd, 必须和字符串中的时间日期匹配 *西方星期的开始为周日，中国为周一。 在Calendar类中，"月份的表示是以0-11代表1-12月"。 日期是有大小关系的，时间靠后，时间越大。 13Calendar类_1* A: Calendar类_1 12345* a: 日历类(抽象类) * java.util.Calendar* b: 创建对象 * "Calendar类写了【静态方法】 getInstance() 【直接】返回了【子类的对象】" * "【不需要】直接new子类的对象,通过【静态方法】直接获取" 14Calendar类_2* A: Calendar类_2 123456789101112* a: 成员方法 * getTime() 把日历对象,转成Date日期对象 * get(日历字段) 获取指定日历字段的值* b: 代码演示 Calendar c = Calendar.getInstance(); // 获取年份 int year = c.get(Calendar.YEAR); // 获取月份 int month = c.get(Calendar.MONTH) + 1; // 获取天数 int day = c.get(Calendar.DAY_OF_MONTH); System.out.println(year + "年" + month + "月" + day + "日"); 15Calendar类_3* A: Calendar类_3 12345678910111213141516171819202122232425* a: 成员方法 * set(int field,int value) 设置指定的时间* b: 代码演示 /* * Calendar类的set方法 设置日历 set(int field,int value) field 设置的是哪个日历字段 value * 设置后的具体数值 * * set(int year,int month,int day) 传递3个整数的年,月,日 */ public static void function_1() &#123; Calendar c = Calendar.getInstance(); // 设置,月份,设置到10月分 // c.set(Calendar.MONTH, 9); // 设置年,月,日 c.set(2099, 4, 1); // 获取年份 int year = c.get(Calendar.YEAR); // 获取月份 int month = c.get(Calendar.MONTH) + 1; // 获取天数 int day = c.get(Calendar.DAY_OF_MONTH); System.out.println(year + "年" + month + "月" + day + "日"); &#125; 16Calendar类_4* A: Calendar类_4 12345678910111213141516171819202122* a: 成员方法 * add(int field, int value) 进行整数的偏移 * int get(int field) 获取指定字段的值* b: 案例演示 /* * Calendar类方法add 日历的偏移量, * 可以指定一个日历中的字段, * 进行整数的偏移 add(int field, int value) */ public static void function_2() &#123; Calendar c = Calendar.getInstance(); // 让日历中的天数,向后偏移280天 c.add(Calendar.DAY_OF_MONTH, -280); // 获取年份 int year = c.get(Calendar.YEAR); // 获取月份 int month = c.get(Calendar.MONTH) + 1; // 获取天数 int day = c.get(Calendar.DAY_OF_MONTH); System.out.println(year + "年" + month + "月" + day + "日"); &#125; 17日期练习_活了多少天* A: 日期练习_活了多少天 1234567891011121314151617181920212223242526272829303132* a: 案例代码 /* * 计算活了多少天 * 生日 今天的日期 * 两个日期变成毫秒值,减法 */ public static void function() throws Exception &#123; System.out.println("请输入出生日期 格式 YYYY-MM-dd"); //获取出生日期,键盘输入 String birthdayString = new Scanner(System.in).next(); //将字符串日期,转成Date对象 //创建SimpleDateFormat对象,写日期模式 SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd"); //调用方法parse,字符串转成日期对象 Date birthdayDate = sdf.parse(birthdayString); //获取今天的日期对象 Date todayDate = new Date(); //将两个日期转成毫秒值,Date类的方法getTime long birthdaySecond = birthdayDate.getTime(); long todaySecond = todayDate.getTime(); long secone = todaySecond-birthdaySecond; if(secone &lt; 0)&#123; System.out.println("还没出生呢"); &#125; else&#123; System.out.println(secone/1000/60/60/24); &#125; &#125; 18日期练习_闰年计算* A: 日期练习_闰年计算 12345678910111213141516* a: 案例代码 /* * 闰年计算 * 2000 3000 * 高级的算法: 日历设置到指定年份的3月1日,add向前偏移1天,获取天数,29闰年 */ public static void function_1()&#123; Calendar c = Calendar.getInstance(); //将日历,设置到指定年的3月1日 c.set(2088, 2, 1); //日历add方法,向前偏移1天 c.add(Calendar.DAY_OF_MONTH, -1); //get方法获取天数 int day = c.get(Calendar.DAY_OF_MONTH); System.out.println(day); &#125; 19总结12345678910111213141516171819202122232425262728293031323334353637383940 正则表达式：用来定义匹配规则，匹配一系列符合某个句法规则的字符串。正则表达式的匹配规则请参见1.2 正则表达式的匹配规则正则表达式的常用方法：public boolean matches(String regex) //判断字符串是否匹配给定的规则public String[] split(String regex) //根据给定正则表达式的匹配规则，拆分此字符串public String replaceAll(String regex,String replacement) //将符合规则的字符串内容，全部替换为新字符串———————————————————————————————————————————————————————————————————————————————————————— Date: 日期/时间类构造方法：public Date()// 系统当前日期时间public Date(long date) 得到一个1970年1月1日 0点这个时间基础上，加上参数date 毫秒值对应的日期时间方法： public long getTime() 获取日期所对应的毫秒值 public void setTime(long times); * 根据给定的毫秒值，生成对应的日期对象———————————————————————————————————————————————————————————————————————————————————————— DateFormat:是日期/时间格式化子类的抽象类, 使用其子类SimpleDateFormat 实例化构造方法：public SimpleDateFormat() 默认的格式化操作 public SimpleDateFormat(String pattern) 按照指定的格式，进行日期格式化 日期和时间模式 y 年 M 年中的月份 d 月份中的天数 H 一天中的小时数（0-23） m 小时中的分钟数 s 分钟中的秒数 S 毫秒数 方法： public final String format(Date date) 把日期 格式化成字符串 public Date parse(String source) 把日期字符串 转换成 日期对象———————————————————————————————————————————————————————————————————————————————————————— Calendar:日历类，可获取日期中指定字段的值方法：public static Calendar getInstance() //获取日期对象public int get(int field) //获取时间字段值public void add(int field,int amount) //指定字段增加某值public final void set(int field,int value)//设置指定字段的值public final Date getTime() //获取该日历对象转成的日期对象]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础13(Object,String,StringBuilder)]]></title>
    <url>%2F2016%2F10%2F18%2Fday15%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、Object2、String3、StringBuilder 01API概念123456* A:API(Application Programming Interface) * 应用程序编程接口* B:Java API * 就是Java提供给我们使用的类，这些类将底层的实现封装了起来， * 我们不需要关心这些类是如何实现的，只需要学习这些类如何使用。* C: 演示查看Object类中的相关方法 02Object类概述123456789* A:Object类概述 * "类层次结构的【根类】 * 【所有类】都【直接】或者【间接】的【继承】自该类 * Object中描述的【所有方法】【子类】【都可以使用】 * 所有类在创建对象的时候，最终找的父类就是Object"。* B:构造方法 * public Object() * 回想面向对象中为什么说： * 子类的构造方法默认访问的是父类的无参构造方法 03equals方法比较内存地址* A:equals方法比较内存地址 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152* a: Object类中的equals方法 * 用于比较两个对象是否相同，Object类中就是使用两个对象的内存地址在比较。 * Object类中的equals方法内部使用的就是==比较运算符。 * b: 案例代码 public class Person extends Object&#123; private String name; private int age; public Person()&#123;&#125; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; /* * 将父类的equals方法写过来,重写父类的方法 * 但是,不改变父类方法的源代码, 方法equals 比较两个对象的内存地址 * */ public boolean equals(Object obj)&#123; return this == obj; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; &#125; //测试代码 public class TestEquals &#123; public static void main(String[] args) &#123; //Person类继承Object类,继承下来了父类的方法equals Person p1 = new Person("李四",20); Person p2 = new Person("张三",20); //Person对象p1,调用父类的方法equals,进行对象的比较 boolean b = p1.equals(p1); System.out.println(b); &#125; &#125; 04重写equals方法* A: 重写equals方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788* a: 开发中要比较两个对象是否相同，经常会根据对象中的属性值进行比较 * b: 在开发经常需要子类重写equals方法根据对象的属性值进行比较。 * c: ==号和equals方法的区别* "==是一个比较运算符号,既可以比较基本数据类型,也可以比较引用数据类型,* 基本数据类型比较的是值,引用数据类型比较的是地址值"* "equals方法是一个方法,【只能】【比较】【引用数据类型】,所有的对象都会继承Object类中的方法,如果【没有】重写Object类中的equals方法,equals方法和==号比较引用数据类型无区别,重写后的equals方法比较的是对象中的属性"* d: 案例代码public class Person extends Object&#123; private String name; private int age; public Person()&#123;&#125; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; /* * 重写父类的方法toString() * 没有必要让调用者看到内存地址 * 要求: 方法中,返回类中所有成员变量的值 */ public String toString()&#123; return name + age; &#125; /* * 将父类的equals方法写过来,重写父类的方法 * 但是,不改变父类方法的源代码, 方法equals 比较两个对象的内存地址 * * 两个对象,比较地址,没有意义 * 比较两个对象的成员变量,age * 两个对象变量age相同,返回true,不同返回false * * 重写父类的equals,自己定义自己对象的比较方式 */ public boolean equals(Object obj)&#123; if( this == obj)&#123; return true; &#125; //对参数obj,非null判断 if( obj == null)&#123; return false; &#125; if( obj instanceof Person)&#123; // 参数obj接受到是Person对象,才能转型 "由于多态【编译】看父类，【父类】Object 没有成员变量age, 必须【向下转型】为 Person 类型，才能调用成员变量 age" // 对obj参数进行类型的向下转型,obj转成Person类型 Person p = (Person)obj; return this.age == p.age; &#125; return false; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; &#125;//测试代码public class TestEquals &#123; public static void main(String[] args) &#123; //Person类继承Object类,继承下来了父类的方法equals Person p1 = new Person("李四",20); Person p2 = new Person("张三",20); //Person对象p1,调用父类的方法equals,进行对象的比较 boolean b = p1.equals(p1); System.out.println(b); &#125;&#125; 05重写toString方法* A: 重写toString方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445* a: 为什么要重写toString方法 * "toString方法返回该对象的【字符串】表示"， * 其实该字符串内容就是"【对象的类型】+ @ + 【内存地址值】"。 * 由于toString方法返回的结果是内存地址， * 而在"开发"中，经常需要按照对象的属性得到相应的字符串表现形式，因此也需要"重写"它。 * "Object类中的toString的核心代码" " getClass().getName() + @ + Integer.toHexString(hashCode()) " * 由于默认情况下的数据对我们来说没有意义，一般建议重写该方法。* b: 案例核心代码(重写Person类中的toString方法) /* * 重写父类的方法toString() * 没有必要让调用者看到内存地址 * 要求: 方法中,返回类中所有成员变量的值 */ public String toString()&#123; return name + age; &#125; //Eclipse中自动生成的toString @Override public String toString() &#123; return "Person [name=" + name + ", age=" + age + "]"; &#125; //测试代码 public class TestToString &#123; public static void main(String[] args) &#123; //调用Person类的方法toString() //输出语句中,写的是一个对象,默认调用对象的toString方法 Person p = new Person("张三",20); String s = p.toString(); System.out.println(p); System.out.println(s); /* * System.out.println(p); * System.out.println(p.toString()); */ /*Random r = new Random(); System.out.println(r.toString()); Scanner sc = new Scanner(System.in); System.out.println(sc.toString());*/ &#125; &#125; 06String类的概念和不变性* A: String类的概念和不变性 12345678910111213141516171819202122232425262728293031323334353637383940* a:String类* API中的String类的描述，发现String 类代表字符串* Java 程序中的所有字符串字面值（如 "abc" ）都作为此类的实例实现。* ———————————————————————————————————————————————————————————————————————————————————————* "【字符串】是【常量】,在创建之后不能更改"* ———————————————————————————————————————————————————————————————————————————————————————* "其实就是说一旦这个字符串确定了，那么就会【在内存区域中】就【生成】了【这个字符串】。"* ———————————————————————————————————————————————————————————————————————————————————————*" 【字符串】【本身】【不能改变】，但str变量中记录的【地址值】是【可以改变】的。"* ———————————————————————————————————————————————————————————————————————————————————————* 源码分析,String类底层采用的是"【字符数组】": private final char value[] private 修饰说明"value只能在【String类内部】使用,而且又没有提供get方法, 所以【外部无法获取value数组】,就无法改变数组中元素的值" final修饰说明"value是常量,【一旦创建】,就【不能被改变】, value一旦被初始化成某个数组,将永远指向这个数组,不可能再指向其它的数组了" * b: 案例代码" /* * String类特点: * 一切都是对象,字符串事物 "" 也是对象 * 类是描述事物,String类,描述字符串对象的类 * 所有的 "" 都是String类的对象 * * 字符串是一个常量,一旦创建,不能改变 * 字符串本质是 【字符数组】 */" public class StringDemo &#123; public static void main(String[] args) &#123; //引用变量str指向内存变化 //定义好的字符串对象,不变 String str = "itcast"; System.out.println(str); str = "itheima"; System.out.println(str); &#125; &#125; 07String类创建方式和比较* A: String类创建方式和比较 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103* a: "创建对象的【数量】比较" * String s3 = "abc"; * "在内存中【只有一个对象】。这个对象在【字符串常量池】中"——————————————————————————————————————————————————————————————————————————————————————— * String s4 = new String("abc"); * "在内存中有【两个对象】。一个new的对象在【堆】中，另一个是字符串本身对象，在【字符串常量池】中"———————————————————————————————————————————————————————————————————————————————————————"String重写了equals方法，建立了字符串自己的判断相同的依据（通过【字符串对象】中的【字符】进行判断）"，"即【字符】相同" ，返回true；否则，返回false。———————————————————————————————————————————————————————————————————————————————————————"引用数据类型,比较对象的地址""如果String常量池内【存在】与其【指定值】【【相同】】的String对象，那么此时虚拟机将【不】为此创建【新】的String对象】，而直接返回【已存在】的String对象的【引用】。"String s1 = "java";String s2 = "java";System.out.println(s1==s2); //true"如果String常量池内【【不存在】】与其指定值相同的String对象，那么此时虚拟机将为此【【创建新】】的String对象，并存放在String常量池内。"———————————————————————————————————————————————————————————————————————————————————————* b: 案例代码public class StringDemo2 &#123; public static void main(String[] args) &#123; //字符串定义方式2个, 直接= 使用String类的构造方法 String str1 = new String("abc"); String str2 = "abc"; System.out.println(str1); System.out.println(str2); //str1==str2 "引用数据类型,比较对象的地址" System.out.println(str1==str2);//引用数据类型,比较对象的地址 false //str1.equals(str2) "因为String重写了equals方法， 建立了字符串自己的判断相同的依据（通过【字符串对象】中的【字符】进行判断）" System.out.println(str1.equals(str2));//true ///// String s1 = "java"; String s2 = "java"; "引用数据类型,比较对象的地址" "如果String常量池内存在与其【指定值】【相同】的String对象， 那么此时虚拟机将【不】为此创建【新】的String对象】， 而直接返回【已存在】的String对象的【引用】。" System.out.println(s1==s2); //true System.out.println(s1.equals(s2)); //true &#125;&#125;———————————————————————————————————————————————————————————————————————————————————————public class StringDemo2 &#123; public static void main(String[] args) &#123; String a = "hello2"; final String b ="hello"; String d = "hello"; String c =b+2; "//相当于：JVM会优化成 String c ="hello"+2 结果是变成编译期就是已知的， 指向常量池中的hello2字符串，也就是a;" String e =d+2; // System.out.println(a==c);"//true" System.out.println(a==e);"//false" "//b是final修饰，表示在编译成.class文件的时候，所有引用到b变量的地方都被直接编译成"hello"" "// c= "hello"+2,即c="hello2",指向常量池中的hello2字符串，也就是a" "// 当比较a==c的时候,是同一个地址，都指向常量池中的hello2字符串" "// d 是指向存在于堆内存中的地址，当比较a==e的时候，比较的是a和e指向堆内存的地址。" "// 编译的时候，由于d对象的值是未知的，从而c对象的值也是未知的， //JVM会为e对象在堆内存中开辟新的内存空间"， "//运行时，d 指向字符串常量池中创建的字符串"hello"，" &#125;&#125;———————————————————————————————————————————————————————————————————————————————————————public class StringDemo3 &#123; public static void main(String[] args) &#123; String a = "hello2"; final String b = getStr(); String c = b + 2; System.out.println((a == c));//false "/* 因为这里的b虽然是常量，但是在编译期是不能获得值的， 只有在运行的时候才会调用函数，初始化赋值， 所以这时的String c = b+2是运行期间计算出来的， 所以编译的时候，JVM会为c对象在堆内存中开辟新的内存空间 而加号连接运算符，内部则是调用的StringBuilder，然后toString， 所以c相当于是new出来的String，即c是指向堆内存的地址， c内部的char数组才指向常量池中的字符串，所以明显a ！= c */" &#125; public static String getStr() &#123; return "hello"; &#125;&#125; 08String类构造方法* A: String类构造方法 12345678910111213141516171819202122232425262728293031323334353637* a: 常见构造方法 * public String():空构造 * public String(byte[] bytes):把字节数组转成字符串 * public String(byte[] bytes,int index,int length):把字节数组的一部分转成字符串 * public String(String original):把字符串常量值转成字符串* b: 案例代码 public class StringDemo3 &#123; public static void main(String[] args) &#123; function_1(); &#125; /* * 定义方法,String类的构造方法 * String(byte[] bytes) 传递字节数组 * 字节数组转成字符串 * 通过使用平台的默认字符集解码指定的 byte 数组，构造一个新的 String。 * 平台 : 机器操作系统 * 默认字符集: 操作系统中的默认编码表, 默认编码表GBK * 将字节数组中的每个字节,查询了编码表,得到的结果 * 字节是负数,汉字的字节编码就是负数, 默认编码表 ,一个汉字采用2个字节表示 * * String(byte[] bytes, int offset, int length) 传递字节数组 * 字节数组的一部分转成字符串 * offset 数组的起始的索引 * length 个数,转几个 , 不是结束的索引 */ public static void function()&#123; byte[] bytes = &#123;97,98,99,100&#125;; //调用String类的构造方法,传递字节数组 String s = new String(bytes); System.out.println(s); byte[] bytes1 =&#123;65,66,67,68,69&#125;; //调用String构造方法,传递数组,传递2个int值 String s1 = new String(bytes1,1,3); System.out.println(s1); &#125; &#125; 09String类构造方法_2* A: String类构造方法 1234567891011121314151617181920212223242526272829303132* a: 常见构造方法 * public String(char[] value):把字符数组转成字符串 * public String(char[] value,int index,int count):把字符数组的一部分转成字符串* B: 案例代码 /* * String类构造方法 * String类的构造方法,重载形式 * */public class StringDemo3 &#123; public static void main(String[] args) &#123; function_1(); &#125; /* * String(char[] value) 传递字符数组 * 将字符数组,转成字符串, 字符数组的参数,不查询编码表 * * String(char[] value, int offset, int count) 传递字符数组 * 将字符数组的一部分转成字符串 * offset 数组开始索引 * count 个数 */ public static void function_1()&#123; char[] ch = &#123;'a','b','c','d','e','f'&#125;; //调用String构造方法,传递字符数组 String s = new String(ch); System.out.println(s); String s1 = new String(ch,1,4); System.out.println(s1); &#125;&#125; 10String类的其他方法* A：String类的其他方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143* a: 方法介绍* char charAt(int index):返回指定索引处的 char 值。索引范围为从 0 到 length() - 1。* int length(): 返回字符串的长度* String substring(int beginIndex,int endIndex): 获取字符串的一部分* String substring(int beginIndex): 获取字符串的一部分* boolean startsWith(String prefix): 判断一个字符串是不是另一个字符串的前缀,开头* boolean endsWith(String prefix): 判断一个字符串是不是另一个字符串的后缀,结尾* boolean contains (String s): 判断一个字符串中,是否包含另一个字符串* int indexOf(char ch): 查找一个字符,在字符串中第一次出现的索引,被查找的字符不存在,返回-1* byte[] getBytes(): 将字符串转成字节数组,此功能和String构造方法相反,byte数组相关的功能,查询编码表* char[] toCharArray(): 将字符串转成字符数组,功能和构造方法相反* boolean equals(Object obj): 方法传递字符串,判断字符串中的字符是否完全相同,如果完全相同返回true* boolean equalsIgnoreCase(String s): 传递字符串,判断字符串中的字符是否相同,忽略大小写 * b: 案例代码 public class StringDemo4 &#123; public static void main(String[] args) &#123; function_9(); &#125; /* * boolean equals(Object obj) * 方法传递字符串,判断字符串中的字符是否完全相同,如果完全相同返回true * * boolean equalsIgnoreCase(String s) * 传递字符串,判断字符串中的字符是否相同,忽略大小写 */ public static void function_9()&#123; String str1 = "Abc"; String str2 = "abc"; //分别调用equals和equalsIgnoreCase boolean b1 = str1.equals(str2); boolean b2 = str1.equalsIgnoreCase(str2); System.out.println(b1); System.out.println(b2); &#125; /* * char[] toCharArray() 将字符串转成字符数组 * 功能和构造方法相反 */ public static void function_8()&#123; String str = "itcast"; //调用String类的方法toCharArray() char[] ch = str.toCharArray(); for(int i = 0 ; i &lt; ch.length ; i++)&#123; System.out.println(ch[i]); &#125; &#125; /* * byte[] getBytes() 将字符串转成字节数组 * 此功能和String构造方法相反 * byte数组相关的功能,查询编码表 */ public static void function_7()&#123; String str = "abc"; //调用String类方法getBytes字符串转成字节数组 byte[] bytes = str.getBytes(); for(int i = 0 ; i &lt; bytes.length ; i++)&#123; System.out.println(bytes[i]); &#125; &#125; /* * int indexOf(char ch) * 查找一个字符,在字符串中第一次出现的索引 * 被查找的字符不存在,返回-1 */ public static void function_6()&#123; String str = "itcast.cn"; //调用String类的方法indexOf int index = str.indexOf('x'); System.out.println(index); &#125; /* * boolean contains (String s) * 判断一个字符串中,是否包含另一个字符串 */ public static void function_5()&#123; String str = "itcast.cn"; //调用String类的方法contains boolean b =str.contains("ac"); System.out.println(b); &#125; /* * boolean endsWith(String prefix) * 判断一个字符串是不是另一个字符串的后缀,结尾 * Demo.java * .java */ public static void function_4()&#123; String str = "Demo.java"; //调用String类方法endsWith boolean b = str.endsWith(".java"); System.out.println(b); &#125; /* * boolean startsWith(String prefix) * 判断一个字符串是不是另一个字符串的前缀,开头 * howareyou * hOw */ public static void function_3()&#123; String str = "howareyou"; //调用String类的方法startsWith boolean b = str.startsWith("hOw"); System.out.println(b); &#125; /* * String substring(int beginIndex,int endIndex) 获取字符串的一部分 * 返回新的字符串 * 包含头,不包含尾巴 * * String substring(int beginIndex)获取字符串的一部分 * 包含头,后面的字符全要 */ public static void function_2()&#123; String str = "howareyou"; //调用String类方法substring获取字符串一部分 str= str.substring(1, 5); System.out.println(str); String str2 = "HelloWorld"; str2 = str2.substring(1); System.out.println(str2); &#125; /* * int length() 返回字符串的长度 * 包含多少个字符 */ public static void function()&#123; String str = "cfxdf#$REFewfrt54GT"; //调用String类方法length,获取字符串长度 int length = str.length(); System.out.println(length); &#125; &#125; 11String类练习* A: 获取指定字符串中，大写字母、小写字母、数字的个数 123456789101112131415161718192021222324252627282930313233343536373839404142434445* a: 题目分析 * 为了统计大写字母、小写字母、数字的个数。创建3个计数的变量。 * 为了获取到字符串中的每个字符，进行字符串的遍历，得到每个字符。 * 对得到的字符进行判断，如果该字符为大写字母，则大写字母个数+1； * 如果该字符为小写字母，则小写字母个数+1；如果该字符为数字，则数字个数+1。 * 显示大写字母、小写字母、数字的个数* b: 解题步骤 * 略* 案例代码public class StringTest &#123; public static void main(String[] args) &#123; getCount("A%A3eBr1FFy"); &#125; /* * 获取指定字符串中，大写字母、小写字母、数字的个数。 * 思想: * 1. 计数器,就是int变量,满足一个条件 ++ * 2. 遍历字符串, 长度方法length() + charAt() 遍历 * 3. 字符判断是大写,是小写,还是数字 */ public static void getCount(String str)&#123; //定义三个变量,计数 int upper = 0; int lower = 0; int digit = 0; //对字符串遍历 for(int i = 0 ; i &lt; str.length() ; i++)&#123; //String方法charAt,索引,获取字符 char c = str.charAt(i); //利用编码表 65('A')-90('Z') 97('a')-122('z') 48('0')-57('9') if(c &gt;='A' &amp;&amp; c &lt;='Z')&#123; upper++; &#125;else if( c &gt;= 'a' &amp;&amp; c &lt;= 'z')&#123; lower++; &#125;else if( c &gt;= '0' &amp;&amp; c &lt;='9')&#123; digit++; &#125; &#125; System.out.println(upper); System.out.println(lower); System.out.println(digit); &#125;&#125; 12String类练习_2* A: 将字符串中，第一个字母转换成大写，其他字母转换成小写，并打印改变后的字符串。 12345678910111213141516171819202122232425262728293031323334* a: 题目分析* String toUpperCase(): 返回要转换为大写的 String。* String toLowerCase(): 返回要转换为小写的 String。 * 把字符串分为两个部分，第一部分为字符串中第一个字母，第二部分为剩下的字符串。 * 把第一部分字符串转换成大写字母，把第二部分字符串转换成小写字母 * 把两部分字符串连接在一起，得到一个完整的字符串* b: 解题步骤 * 略* C: 案例代码 public class StringTest &#123; public static void main(String[] args) &#123; System.out.println(toConvert("aBc5%4dEF")); &#125; /* * 将字符串的首字母转成大写,其他内容转成小写 * 思想: * 获取首字母, charAt(0) substring(0,1) * 转成大写 toUpperCase() * * 获取剩余字符串, substring(1) toLowerCase() */ public static String toConvert(String str)&#123; //定义变量,保存首字母,和剩余字符 String first = str.substring(0,1); String after = str.substring(1); //调用String类方法,大写,小写转换 first = first.toUpperCase(); after = after.toLowerCase(); return first+after; &#125; &#125; 13String类练习_3* A: 查询大字符串中，出现指定小字符串的次数 * 如&quot;hellojava,nihaojava,javazhenbang&quot;中查询出现&quot;java&quot;的次数。 12345678910111213141516171819202122232425262728293031323334353637*利用：* int indexOf(String str):返回指定子字符串在此字符串中第一次出现处的索引。* String substring(int beginIndex) :返回一个新的字符串，它是此字符串的一个子字符串。* a: 题目分析 * 在大串中，查找小串出现的位置，出现了就次数+1 * 在上次小串出现位置的后面继续查找，需要更改大串的内容为上次未查询到的字符串。 * 回到第一步，继续查找小串出现的位置，直到大串中查询不到小串为止* b: 解题步骤 * 略* C: 案例代码 package cn.itcast.demo02;public class StringTest &#123; public static void main(String[] args) &#123; System.out.println(getStringCount("hellojava,nijavahaojava,javazhenbang", "java")); &#125; /* * 获取一个字符串中,另一个字符串出现的次数 * 思想: * 1. indexOf到字符串中到第一次出现的索引 * 2. 找到的索引+被找字符串长度,截取字符串 * 3. 计数器++ */ public static int getStringCount(String str, String key)&#123; //定义计数器 int count = 0; //定义变量,保存indexOf查找后的索引的结果 int index = 0; "开始循环找,条件,indexOf==-1 字符串没有了" while(( index = str.indexOf(key) )!= -1)&#123; count++; //获取到的索引,和字符串长度求和,截取字符串 str = str.substring(index+key.length()); &#125; return count; &#125;&#125; 14StringBuffer特点可变字符数组* A:StringBuffer类概述 1234567 *"StringBuffe：可变字符数组" * 通过JDK提供的API，查看StringBuffer类的说明 * "【线程安全】的【可变字符序列】 " * "底层采用【字符数组】实现,初始容量为【16】"* B:StringBuffer和String的区别 * "String是一个【不可变】的字符序列" * "StringBuffer是一个【可变】的字符序列" 15StringBuffer类的方法* A: StringBuffer类的方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697* a: 方法介绍* StringBuffer append(), 将任意类型的数据,添加缓冲区 * append 返回值,写return this * 调用者是谁,返回值就是谁* delete(int start,int end): 删除缓冲区中字符 * 开始索引包含,结尾索引不包含* insert(int index, 任意类型): 将任意类型数据,插入到缓冲区的指定索引上* replace(int start,int end, String str): 将指定的索引范围内的所有字符,替换成新的字符串* reverse(): 将缓冲区中的字符反转* String toString(): 继承Object,重写toString() * 将缓冲区中的所有字符,变成字符串* b: 案例代码 public class StringBufferDemo &#123; public static void main(String[] args) &#123; function_5(); &#125; /* * StringBuffer类的方法 * String toString() 继承Object,重写toString() * 将缓冲区中的所有字符,变成字符串 */ public static void function_5()&#123; StringBuffer buffer = new StringBuffer(); buffer.append("abcdef"); buffer.append(12345); //将可变的字符串缓冲区对象,变成了不可变String对象 String s = buffer.toString(); System.out.println(s); &#125; /* * StringBuffer类的方法 * reverse() 将缓冲区中的字符反转 */ public static void function_4()&#123; StringBuffer buffer = new StringBuffer(); buffer.append("abcdef"); buffer.reverse(); System.out.println(buffer); &#125; /* * StringBuffer类方法 * replace(int start,int end, String str) * 将指定的索引范围内的所有字符,替换成新的字符串 */ public static void function_3()&#123; StringBuffer buffer = new StringBuffer(); buffer.append("abcdef"); buffer.replace(1, 4, "Q"); System.out.println(buffer); &#125; /* * StringBuffer类方法 insert * insert(int index, 任意类型) * 将任意类型数据,插入到缓冲区的指定索引上 */ public static void function_2()&#123; StringBuffer buffer = new StringBuffer(); buffer.append("abcdef"); buffer.insert(3, 9.5); System.out.println(buffer); &#125; /* * StringBuffer类方法 * delete(int start,int end) 删除缓冲区中字符 * 开始索引包含,结尾索引不包含 */ public static void function_1()&#123; StringBuffer buffer = new StringBuffer(); buffer.append("abcdef"); buffer.delete(1,5); System.out.println(buffer); &#125; /* * StringBuffer类方法 * StringBuffer append, 将任意类型的数据,添加缓冲区 * append 返回值,写return this * 调用者是谁,返回值就是谁 */ public static void function()&#123; StringBuffer buffer = new StringBuffer(); //调用StringBuffer方法append向缓冲区追加内容 buffer.append(6).append(false).append('a').append(1.5); System.out.println(buffer); &#125; &#125; 16StringBuilder类* A:StringBuilder的概述 1234567891011* 通过查看API了解一下StringBuilder类* B:面试题* "String,StringBuffer,StringBuilder的区别"——————————————————————————————————————————————————————————————————————————————————————* StringBuffer和StringBuilder的区别 * "【StringBuffer】是jdk1.0版本的,是【线程安全】的,【效率低】 " * "【StringBuilder】是jdk1.5版本的,【不保证同步】，是【线程不安全】的,【效率高】 "——————————————————————————————————————————————————————————————————————————————————————* String和StringBuffer,StringBuilder的区别 * "【String】是一个【不可变】的【字符序列】 " * "StringBuffer,StringBuilder是【可变】的【字符序列】 " 17StringBuffer类案例拼接数组* A: StringBuffer类案例拼接数组 12345678910111213141516171819202122232425262728293031323334353637* a: 题目分析 * 定义StringBuffer对象 * 遍历数组,按照格式要求拼接处新的字符串,追加到StringBuffer容器中 * 将StringBuffer中的内容以String的形式返回* b: 解题步骤 * 略* C: 案例代码 public class StringBufferTest &#123; public static void main(String[] args) &#123; int[] arr = &#123;4,1,4,56,7,8,76&#125;; System.out.println(toString(arr)); &#125; /* * int[] arr = &#123;34,12,89,68&#125;;将一个int[]中元素转成字符串 * 格式 [34,12,89,68] * String s = "[" * 数组遍历 * s+= arr[i]; * s+"]" * StringBuffer实现,节约内存空间, String + 在缓冲区中,append方法 */ public static String toString(int[] arr)&#123; //创建字符串缓冲区 StringBuffer buffer = new StringBuffer(); buffer.append("["); //数组遍历 for(int i = 0 ; i &lt; arr.length;i++)&#123; //判断是不是数组的最后一个元素 if(i == arr.length-1)&#123; buffer.append(arr[i]).append("]"); &#125;else&#123; buffer.append(arr[i]).append(","); &#125; &#125; return buffer.toString(); &#125; &#125; 18总结1234567891011121314151617181920212223242526272829303132333435363738394041424344 Object: 它是所有类的超类，祖宗类。java中所有的类都直接或间接的继承这个类 方法public String toString() 返回当前对象中的内容, 对于Object类默认操作来说，返回的对象的类型+@+内存地址值public boolean equals(Object obj) 比较两个对象内容是否相同，对于Object类默认操作来说,比较的是地址值—————————————————————————————————————————————————————————————————————————————————————— String: 字符串类，字符串是常量；它们的值在创建之后不能更改 方法boolean equals(Object obj) 判断两个字符串中的内容是否相同boolean equalsIgnoreCase(String str) 判断两个字符串中的内容是否相同, 忽略大小写boolean contains(String str) 判断该字符串中 是否包含给定的字符串boolean startsWith(String str) 判断该字符串 是否以给定的字符串开头boolean endsWith(String str) 判断该字符串 是否以给定的字符串结尾boolean isEmpty() 判断该字符串的内容是否为空的字符串 ""int length() 获取该字符串的长度char charAt(int index) 获取该字符串中指定位置上的字符 String substring(int start) 从指定位置开始，到末尾结束，截取该字符串，返回新字符串String substring(int start,int end) 从指定位置开始，到指定位置结束，截取该字符串，返回新字符串 int indexOf(int ch ) 获取给定的字符，在该字符串中第一次出现的位置int indexOf(String str) 获取给定的字符串，在该字符串中第一次出现的位置int indexOf(int ch,int fromIndex) 从指定位置开始，获取给定的字符，在该字符byte[] getBytes() 把该字符串 转换成 字节数组char[] toCharArray() 把该字符串 转换成 字符数组String replace(char old,char new) 在该字符串中，将给定的旧字符，用新字符替换String replace(String old,String new) 在该字符串中， 将给定的旧字符串，用新字符串替换String trim() 去除字符串两端空格，中间的不会去除，返回一个新字符串String toLowerCase() 把该字符串转换成 小写字符串 String toUpperCase() 把该字符串转换成 大写字符串int indexOf(String str,int fromIndex) 从指定位置开始，获取给定的字符串，在该字符串中第一次出现的位置—————————————————————————————————————————————————————————————————————————————————————— StringBuffer/StringBuilder: 方法public StringBuffer append(String str) 在原有字符串缓冲区内容基础上，在末尾追加新数据public StringBuffer insert(int offset,String str) 在原有字符串缓冲区内容基础上，在指定位置插入新数据public StringBuffer deleteCharAt(int index) 在原有字符串缓冲区内容基础上，删除指定位置上的字符public StringBuffer delete(int start,int end) 在原有字符串缓冲区内容基础上，删除指定范围内的多个字符public StringBuffer replace(int start,int end,String str)在原有字符串缓冲区内容基础上， 将指定范围内的多个字符 用给定的字符串替换public StringBuffer reverse() 将字符串缓冲区的内容 反转 "abc"----"cba"public String substring(int start) 从指定位置开始，到末尾结束，截取该字符串缓冲区，返回新字符串public String substring(int start,int end) 从指定位置开始，到指定位置结束，截取该字符串缓冲区，返回新字符串]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础12(修饰符,“变参”方法,Comparable、Comparator接口,lambda表达式)]]></title>
    <url>%2F2016%2F10%2F16%2Fday14%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、不同修饰符混合使用细节2、辨析何时定义变量为成员变量3、类、抽象类、接口作为方法参数4、类、抽象类、接口作为方法返回值5、参数数量可变的方法（“变参”方法）6、Comparable 接口 &amp;&amp; Comparator 接口7、lambda表达式 不同修饰符使用细节A: 常用来修饰类、方法、变量的修饰符如下：12345678910111213 public 权限修饰符，【公共访问】, "类,方法,成员变量"————————————————————————————————————————————————————————— protected 权限修饰符，【受保护访问】, "方法,成员变量"，"注意【不能】修饰类"————————————————————————————————————————————————————————— 【默认什么也不写】 也是一种权限修饰符，【默认访问】, "类,方法,成员变量"————————————————————————————————————————————————————————— private 权限修饰符，【私有访问】, "方法,成员变量"———————————————————————————————————————————————————————————————————————————————————————— static 静态修饰符 "方法,成员变量,静态内部类"————————————————————————————————————————————————————————— final 最终修饰符 "类,方法,成员变量,局部变量"————————————————————————————————————————————————————————— abstract 抽象修饰符 "类 ,方法" B: 不能同时使用的修饰符12345678910111213141516171819202122232425262728同时，abstract 与 private "不能"同时使用；(私有abstract不能继承，无意义)同时，abstract 与 static "不能"同时使用；(abstract没有方法体，静态通过类名调用，无意义)同时，abstract 与 final "不能"同时使用。(abstract没有方法体，final不能重写，无意义)————————————————————————————————————————————————————————————————————————————————————————小结：1.抽象方法只能定义在抽象类中，抽象方法和抽象类必须由abstract修饰，abstract关键字只能描述类和方法，不能描述变量。抽象方法只定义方法声明，不定义方法实现。抽象类不可以被实例化（创建对象），只有通过子类继承抽象类并覆盖抽象类中的所有抽象方法后，该子类才可以被实例化，否则该子类还是一个抽象类。抽象类中有构造函数用于给子类对象进行初始化，同时"抽象类中【可以】含有非抽象方法"。—————————————————————————————————————————————————————————abstract关键字"不可以"与final，private,static关键字共存，因为被final修饰的方法不可以被重写，意味着子类不可以重写该方法，如果abstract和final共同修饰父类中的方法，子类要实现抽象方法（abstract的作用），而final又不让该方法重写，这相互矛盾。如果private和abstract共同修饰父类中的方法，private修饰则该方法不可以被子类访问，但是abstract修饰需要子类去实现，两者产生矛盾。如果static和abstract共同修饰父类中的方法，static表示是"静态的方法，随着类的加载而加载，则该方法不需要在子类中去实现"，这与abstract关键字矛盾。————————————————————————————————————————————————————————————————————————————————————————2.static用于修饰成员变量和成员函数，想要"实现对象中的【共性数据】的【对象共享】"，可以将这个数据进行静态修饰，"被静态修饰的成员可以直接被类名调用，静态随着类的加载而加载，而且优先于对象存在"。"静态方法只能访问静态成员（静态方法和静态变量），不可以【直接】用【成员名】访问非静态成员，需要new（创建对象）访问。这是因为静态方法加载时，优先于对象存在，所以没有办法访问对象中的成员"。静态方法中"不能"使用this和super关键字，因为this代表本类对象，super代表父类对象，而静态时，有可能没有对象存在，所以this和super无法使用。————————————————————————————————————————————————————————————————————————————————————————3.final关键字可以修饰类，方法，变量（成员变量内，局部变量，静态变量），被final修饰的类是一个最终类，不可以被继承，被final修饰的方法是一个最终方法，不可以被覆盖，但是可以被继承。被final修饰的变量只能是一个常量，只能赋值一次。内部类被定义在类中的局部位置上时，只能访问局部被final修饰的局部变量。  C: 修饰类能够使用的修饰符：123456789修饰类【只能】使用public、默认的、final、abstract关键字静态内部类：static使用最多的是 public关键字a:代码案例 public class Demo &#123;&#125; //最常用的方式 class Demo2&#123;&#125; public final class Demo3&#123;&#125; public abstract class Demo4&#123;&#125; D:修饰成员变量能够使用的修饰符：1234567891011121314151617181920public : 公共的protected : 受保护的 : 默认的private ：私有的"【权限修饰符都可以】"————————————————————————————————————————————————————————————————————————————————————————final : 最终的static : 静态的使用最多的是 private修饰【成员变量】,【除了】 abstract 都可以————————————————————————————————————————————————————————————————————————————————————————a: 代码案例 public int count = 100; protected int count2 = 100; int count3 = 100; private int count4 = 100; //最常用的方式 public final int count5 = 100; public static int count6 = 100;  E:修饰构造方法能够使用的修饰符： 1234567891011121314public : 公共的protected : 受保护的 : 默认的private ：私有的"【权限修饰符都可以】"————————————————————————————————————————————————————————————————————————————————————————使用最多的是 publica:代码案例 public Demo()&#123;&#125; //最常用的方式 protected Demo()&#123;&#125; Demo()&#123;&#125; private Demo()&#123;&#125;  F:修饰成员方法能够使用的修饰符：123456789101112131415161718192021222324public : 公共的protected : 受保护的 : 默认的private ：私有的"【权限修饰符都可以】"————————————————————————————————————————————————————————————————————————————————————————final : 最终的static : 静态的abstract : 抽象的————————————————————————————————————————————————————————————————————————————————————————使用最多的是 publica:代码案例 public void method1()&#123;&#125;//最常用的方式 protected void method2()&#123;&#125; void method3()&#123;&#125; private void method4()&#123;&#125; public final void method5()&#123;&#125; public static void method6()&#123;&#125;//最常用的方式 public abstract void method7();//最常用的方式 局部变量和成员变量解析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 定义长方形类，包含求周长与求面积的方法 定义数学工具类，包含求两个数和的二倍与求两个数积的方法【思考】：这两个类的计算方法均需要两个数参与计算，请问两个数定义在【成员位置】还是【形参位置】更好，为什么？"如果变量是【该类的一部分】时，定义成【成员变量】。 ""如果变量【不应该是类的一部分】，而仅仅是【功能】当中需要【参与计算的数】，则定义为【形参变量】。"* A：程序编译 数学工具类public class MathTool &#123; //求两个数的和的二倍 public double sum2times(int number,int number2) &#123; return (number+number2)*2; &#125; //求两个数的积 public double area(int number,int number2) &#123; return number*number2; &#125;&#125; 长方形类public class CFX &#123; //因为长与宽，在现实事物中属于事物的一部分，所以定义成员变量 private int chang; private int kuan; public CFX(int chang, int kuan) &#123; this.chang = chang; this.kuan = kuan; &#125; //求长与宽的周长 public double zhouChang() &#123; return (chang+kuan)*2; &#125; //求长与宽的面积 public double mianJi() &#123; return chang*kuan; &#125; public int getChang() &#123; return chang; &#125; public void setChang(int chang) &#123; this.chang = chang; &#125; public int getKuan() &#123; return kuan; &#125; public void setKuan(int kuan) &#123; this.kuan = kuan; &#125;&#125; 类作为方法的参数与返回值* A： 类作为方法参数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647在编写程序中，会经常碰到调用的方法要接收的是一个类类型的情况，那么这时，要向方法中传入该类的对象。如下代码演示： class Person&#123; public void show()&#123; System.out.println("show方法执行了"); &#125; &#125; //测试类 public class Test &#123; public static void main(String[] args) &#123; //创建Person对象 Person p = new Person(); //调用method方法 method(p); &#125; //定义一个方法method，用来接收一个Person对象，在方法中调用Person对象的show方法 public static void method(Person p)&#123; p.show(); &#125;———————————————————————————————————————————————————————————————————————————————————————— B：类作为方法返回值写程序调用方法时，我们以后会经常碰到"【返回】一个【类】类型的【返回值】"，那么这时，该方法要"返回"（return）一个"【该类的对象】"。如下代码演示：class Person&#123; public void show()&#123; System.out.println("show方法执行了"); &#125;&#125;//测试类public class Test &#123; public static void main(String[] args) &#123; //调用method方法，获取返回的Person对象 Person p = method(); //调用p对象中的show方法 p.show(); &#125; //定义一个方法method，用来获取一个Person对象，在方法中完成Person对象的创建 public static Person method()&#123; Person p = new Person(); //返回的是 【类的对象】 return p; &#125;&#125; 抽象类作为方法参数与返回值* A: 抽象类作为方法参数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667今后开发中，【抽象类】作为【方法参数】的情况也很多见。"当遇到【方法参数】为【抽象类】类型时，要传入一个【实现】【抽象类】【所有抽象方法】的【子类对象】"。"抽象类【没有对象】，只能通过【多态】的方式，传递【抽象类】的【子类】的【对象】"如下代码演示：//抽象类abstract class Person&#123; public abstract void show();&#125;class Student extends Person&#123; @Override public void show() &#123; System.out.println("重写了show方法"); &#125;&#125;//测试类public class Test &#123; public static void main(String[] args) &#123; //通过多态的方式，创建一个Person类型的变量，而这个对象实际是Student Person p = new Student(); //调用method方法 method(p); &#125; //定义一个方法method，用来接收一个Person类型对象，在方法中调用Person对象的show方法 public static void method(Person p)&#123;//抽象类作为参数 //抽象类【没有对象】，只能通过【多态】的方式，传递【抽象类】的【子类】的【对象】 //通过p变量调用show方法,这时实际调用的是Student对象中的show方法 p.show(); &#125;&#125;————————————————————————————————————————————————————————————————————————————————————————* B: 抽象类作为方法返回值"【抽象类】作为【方法返回值】的情况，这时需要【返回】一个实现抽象类【所有抽象方法】的【子类对象】。""抽象类【没有对象】，只能通过【多态】的方式，返回的是【抽象类】的【子类】的【对象】"如下代码演示：//抽象类abstract class Person&#123; public abstract void show();&#125;class Student extends Person&#123; @Override public void show() &#123; System.out.println("重写了show方法"); &#125;&#125;//测试类public class Test &#123; public static void main(String[] args) &#123; //调用method方法，获取返回的Person对象 Person p = method(); //通过p变量调用show方法,这时实际调用的是Student对象中的show方法 p.show(); &#125; //定义一个方法method，用来获取一个Person对象，在方法中完成Person对象的创建 public static Person method()&#123; Person p = new Student(); //抽象类【没有对象】，只能通过【多态】的方式，返回的是【抽象类】的【子类】的【对象】 return p; &#125;&#125; 接口作为方法参数与返回值* A: 接口作为方法参数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465【接口】作为【方法参数】的情况是很常见的，经常会碰到。当遇到方法参数为【接口类型】时，那么该方法要传入一个"【接口实现类】【对象】"。"【接口】【没有对象】，只能通过【多态】的方式，【传入】的是【接口】的【实现类】的【对象】"如下代码演示。//接口interface Smoke&#123; public abstract void smoking();&#125;class Student implements Smoke&#123; @Override public void smoking() &#123; System.out.println("no smoking"); &#125;&#125;//测试类public class Test &#123; public static void main(String[] args) &#123; //通过多态的方式，创建一个Smoke类型的变量，而这个对象实际是Student Smoke s = new Student(); //调用method方法 method(s); &#125; //定义一个方法method，用来接收一个Smoke类型对象，在方法中调用Smoke对象的show方法 public static void method(Smoke sm)&#123;//接口作为参数 //通过sm变量调用smoking方法，这时实际调用的是Student对象中的smoking方法 sm.smoking(); &#125;&#125;————————————————————————————————————————————————————————————————————————————————————————* B: 接口作为方法返回值接口作为方法返回值的情况，在后面的学习中会碰到。当遇到方法返回值是接口类型时，那么该方法需要返回一个"【接口实现类对象】"。"【接口】【没有对象】，只能通过【多态】的方式，【返回】的是【接口】的【实现类】的【对象】"如下代码演示。//接口interface Smoke&#123; public abstract void smoking();&#125;class Student implements Smoke&#123; @Override public void smoking() &#123; System.out.println("no smoking"); &#125;&#125;//测试类public class Test &#123; public static void main(String[] args) &#123; //调用method方法，获取返回的会吸烟的对象 Smoke s = method(); //通过s变量调用smoking方法,这时实际调用的是Student对象中的smoking方法 s.smoking(); &#125; //定义一个方法method，用来获取一个具备吸烟功能的对象，并在方法中完成吸烟者的创建 public static Smoke method()&#123; Smoke sm = new Student(); return sm; &#125;&#125; 星级酒店案例* A:  根据“某五星级酒店，资金雄厚……都有自己的工作要做。”分析出，该题 目中包含酒店，可以把它封装成类，多名员工）。 1234567891011121314151617181920212223242526272829class 员工 &#123; 属性：姓名属性：工号方法：工作&#125;class 厨师 extends 员工&#123;&#125;class 服务员 extends 员工&#123;&#125;class 经理 extends 员工 &#123; 属性：奖金&#125;员工的类型有经理、厨师、服务员，它们有共同的属性（姓名、工号、），经理额外属性（奖金）。 根据“向酒店中，增加多名员工（其中包含1名经理，1名厨师、2名服务员）”。分析出，要创建一个酒店对象，并添加4名员工到酒店对象的员工集合中。酒店员工集合添加新员工： 经理对象酒店员工集合添加新员工： 厨师对象酒店员工集合添加新员工： 服务员对象酒店员工集合添加新员工： 服务员对象 根据“获取酒店幸运员工”。分析出，从酒店员工集合随机得到一名员工对象。1. 从酒店员工集合长度范围内，随机产生一个随机数2. 使用该随机数作为集合的索引，返回该索引处对应的员工对象 根据“酒店开设VIP服务，酒店的厨师与服务员可以提供VIP服务。（厨师做菜加量、服务员给顾客倒酒）”。分析出，这是要增加一个VIP的接口，接口中提供个VIP服务的方法。让厨师与服务员实现该接口。interface VIP服务&#123; 抽象方法：服务&#125;class 厨师 extends 员工 implements VIP服务&#123; 重写服务方法 &#125;class 服务员 extends 员工 implements VIP服务&#123; 重写服务方法 &#125; B:  VIP服务 public interface VIP { public abstract void server(); //服务 }  员工 1234567891011121314151617181920212223242526272829303132333435363738/** 员工：姓名 String工号 String*/public abstract class YuanGong &#123; // 成员变量 private String xingMing; private String gongHao; // 构造方法 public YuanGong() &#123; super(); &#125; public YuanGong(String xingMing, String gongHao) &#123; super(); this.xingMing = xingMing; this.gongHao = gongHao; &#125; // 抽象方法 public abstract void work(); // getters与setters public String getXingMing() &#123; return xingMing; &#125; public void setXingMing(String xingMing) &#123; this.xingMing = xingMing; &#125; public String getGongHao() &#123; return gongHao; &#125; public void setGongHao(String gongHao) &#123; this.gongHao = gongHao; &#125; &#125;  服务员 1234567891011121314151617181920/** 定义员工的子类 服务员类*/public class FuWuYuan extends YuanGong implements VIP &#123; public FuWuYuan() &#123; super(); &#125; public FuWuYuan(String xingMing, String gongHao) &#123; super(xingMing, gongHao); &#125; @Override public void work() &#123; System.out.println("亲，全身心为您服务，记得给好评哦"); &#125; @Override public void server() &#123; System.out.println("给顾客倒酒"); &#125;&#125;  经理 1234567891011121314151617181920212223242526/** 经理在员工的基础上，添加了奖金成员*/public class JingLi extends YuanGong &#123; private double jiangJin; public JingLi() &#123; super(); &#125; public JingLi(String xingMing, String gongHao, double jiangJin) &#123; super(xingMing, gongHao); this.jiangJin = jiangJin; &#125; public double getJiangJin() &#123; return jiangJin; &#125; public void setJiangJin(double jiangJin) &#123; this.jiangJin = jiangJin; &#125; @Override public void work() &#123; System.out.println("哪个员工让顾客不满意，我扣谁钱"); &#125;;&#125;  厨师 1234567891011121314151617181920/** 定义员工的子类 厨师类*/public class ChuShi extends YuanGong implements VIP&#123; public ChuShi() &#123; super(); &#125; public ChuShi(String xingMing, String gongHao) &#123; super(xingMing, gongHao); &#125; @Override public void work() &#123; System.out.println("我做饭，放心吃吧，包您满意"); &#125; @Override public void server() &#123; System.out.println("做菜加量加料"); &#125;&#125; 参数数量可变的方法（“变参”方法）1234567891011121314151617181920212223242526272829303132333435现在的版本提供了可以用可变的参数数量调用的方法（有时称为“ 变参” 方法。)printf方法是这样定义的：public class PrintStream&#123; public PrintStream printf(String fmt , Object ... args) &#123; return format(fmt, args); &#125;&#125;这里的省略号 . . . 是 Java 代码的一部分，它表明这个方法可以接收任意数量的对象（除 format参数之外。)———————————————————————————————————————————————————————————————————————————————————————————实际上，printf 方法接收"两个参数"， 一个是"格式字符串"， 另一个是 "Object [] 数组"， "Object [] 数组" 保存着所有的参数（"如果调用者提供的是【整型数组或者其他基本类型】的值， 【自动装箱】功能将【把它们】【转换成对象】 )。现在将扫描format 字符串， 并将第 i 个格式说明符与 args[i] 的值匹配起来"=&gt;&gt; "Object… 参数类型与 Object[ ] 完全一样"———————————————————————————————————————————————————————————————————————————————————————————编译器需要对 printf 的每次调用进行转换， 以便将参数绑定到数组上， 并在必要的时候进行自动装箱：System.out.printf("%d %s", new Object [] &#123; new Integer(n), "widgets" &#125; );"用户自己也可以定义可变参数的方法， 并将参数指定为【任意类型】， 【甚至】是【基本类型】"———————————————————————————————————————————————————————————————————————————————————————————public class Demo &#123; public static void main(String[] args) &#123; func("How ","are ","you"); &#125; public static void func(String ... args)&#123;//等效于 args -&gt; new String []&#123;"How ","are ","you"&#125;; for(String value : args)&#123; System.out.println(value); &#125; &#125;&#125;编译器将 new String []&#123;"How ","are ","you"&#125; 传递给 args甚至可以将 main 方法声明为下列形式：public static void main(String... args) Comparable 接口 &amp;&amp; Comparator 接口123456789101112131415### 总结``` java不同修饰符的使用类，最常使用public修饰成员变量，最常使用private修饰成员方法，最常使用public修饰自定义数据类型的使用"【类】作为【方法参数】时，说明要向方法中传入【该类的对象】""【类】作为【方法返回值】时，说明该方法要返回一个【该类的对象】。""【抽象类】作为【方法参数】时，说明要传入一个实现【抽象类】【所有抽象方法】的【子类对象】。""【抽象类】作为【方法返回值】时，说明需要返回一个实现【抽象类】【所有抽象方法】的【子类对象】。""【接口】作为【方法参数】时，说明该方法要传入一个【接口】【实现类对象】。""【接口】作为【方法返回值】时，说明该方法需要返回一个【接口】【实现类对象】。"]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础11(final、static，内部类，包，代码块)]]></title>
    <url>%2F2016%2F10%2F15%2Fday13%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、final 关键字2、static 关键字3、匿名对象4、内部类5、包的声明与访问6、访问修饰符7、代码块 01final关键字概念* A: 概述 12345继承的出现提高了代码的复用性，并方便开发。但随之也有问题，有些类在描述完之后，不想被继承，或者有些类中的部分方法功能是固定的，不想让子类重写。可是当子类继承了这些特殊类之后，就可以对其中的方法进行重写，那怎么解决呢？要解决上述的这些问题，需要使用到一个关键字final，final的意思为最终，不可变。final是个修饰符，它可以用来修饰类，类的成员，以及局部变量。 02final修饰类义* A: final 修饰类 12345 final修饰类"【不可以】【被继承】，但是【可以继承】其他类"。* B: 案例 class Yy &#123;&#125; final class Fu extends Yy&#123;&#125; //可以继承Yy类 class Zi extends Fu&#123;&#125; //不能继承Fu类 03final修饰方法* A: final修饰方法 1234567891011  final修饰的方法"不可以被覆盖","但如果父类中【没有】被final修饰方法，子类【覆盖】"后可以加final。* B: 案例 class Fu &#123; // final修饰的方法，不可以被覆盖，但可以继承使用 public final void method1()&#123;&#125; public void method2()&#123;&#125; &#125; class Zi extends Fu &#123; //重写method2方法 public final void method2()&#123;&#125; &#125; 04final修饰局部变量* A:修饰基本数据类型变量 1234567891011121314151617final修饰的变量称为常量，这些变量只能赋值一次 * B:案例1 final int i = 20; i = 30; //赋值报错，final修饰的变量只能赋值一次 * C: 修饰引用数据类型 "【引用类型】的变量值为【对象地址值】，地址值【不能更改】， 但是【地址内的对象属性值可以修改】"* D: 修饰引用数据类型 final Person p = new Person(); Person p2 = new Person(); p = p2; //final修饰的变量p，所记录的地址值不能改变 p.name = "小明";//可以更改p对象中name属性值 p不能为别的对象，而p对象中的name或age属性值可更改。 05final修饰成员变量* A: 修饰成员变量 123456789101112131415 "修饰成员变量，需要在【创建对象】前赋值，否则报错。(当没有显式赋值时，如有多个构造方法，则均需要为其赋值。)"* B: 案例 class Demo &#123; //直接赋值 final int m = 100; //final修饰的成员变量，需要在创建对象前赋值，否则报错。 final int n; public Demo()&#123; //可以在创建对象时所调用的构造方法中，为变量n赋值 n = 2016; &#125; &#125; 06static的概念* A：概念 1234当在定义类的时候，类中都会有相应的属性和方法。而属性和方法都是通过创建本类对象调用的。"当在调用对象的某个方法时，但是这个方法【没有】访问到对象的【特有数据】时，方法创建这个对象有些多余。"可是不创建对象，方法又调用不了，这时就会想，那么我们能不能不创建对象，就可以调用方法呢？"可以的，我们可以通过static关键字来实现。static它是静态修饰符，一般用来修饰类中的成员。" 07static修饰的对象特有数据* A：特点1: 12345678910111213141516171819202122被 static "修饰的成员变量" "【属于类】"，"【不属于】这个类的某个对象"。（也就是说，多个对象在访问或修改static修饰的成员变量时，其中一个对象将static成员变量值进行了修改，其他对象中的static成员变量值跟着改变，即"多个对象共享同一个" static 成员变量）" 被静态修饰的成员，可以被 【类名】 【直接调用】""对象的【特有数据】： （非静态修饰）=&gt; 【调用者只能是New 对象】对象的【共享数据】： （静态修饰） =&gt; 【调用者是类名，也可以是New 对象(不建议这样用)】"* B: 代码演示 class Demo &#123; public static int num = 100; &#125; class Test &#123; public static void main(String[] args) &#123; Demo d1 = new Demo(); Demo d2 = new Demo(); d1.num = 200; System.out.println(d1.num); //结果为200 System.out.println(d2.num); //结果为200 &#125; &#125; 08static的内存图 09static注意事项_【静态不能直接调用非静态】* A: 注意事项 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108 被static修饰的成员可以并且"建议通过类名直接访问"。 * B: 访问静态成员的格式：" 类名.静态成员变量名 类名.静态成员方法名(参数)" 对象名.静态成员变量名 ------不建议使用该方式，会出现警告 对象名.静态成员方法名(参数) ------不建议使用该方式，会出现警告 * C: 代码演示 class Demo &#123; //静态成员变量 public static int num = 100; //静态方法 public static void method()&#123; System.out.println("静态方法"); &#125; &#125; class Test &#123; public static void main(String[] args) &#123; System.out.println(Demo.num); Demo.method(); &#125; &#125;————————————————————————————————————————————————————————————————————————————————————————*"【静态内容】是优先于【对象】存在，【只能访问静态】"，"不能"使用this/super。"静态修饰的内容存于静态区"。class Demo &#123; //成员变量 public int num = 100; //静态方法 public static void method()&#123; //this.num; 不能使用this/super。 System.out.println(this.num); &#125;&#125;————————————————————————————————————————————————————————————————————————————————————————*"同一个类中，静态成员【只能】访问静态成员"class Demo &#123; //成员变量 public int num = 100; //静态成员变量 public static int count = 200; //静态方法 public static void method()&#123; //System.out.println(num); 静态方法中，只能访问静态成员变量或静态成员方法 System.out.println(count); &#125;&#125;————————————————————————————————————————————————————————————————————————————————————————*"【非静态内容】 【只能】 通过 创建【本类对象】，再通过【 对象.成员变量 】 OR 【 对象.成员方法(参数) 】的方式调用"class Demo &#123; //成员变量 public int num = 100; //静态成员变量 public static int count = 200; //非静态方法 public void function()&#123; System.out.println("这是非静态方法 function"); &#125; //静态方法 public static void method()&#123; //System.out.println(num); // 静态方法中，只能访问静态成员变量或静态成员方法 System.out.println(count); //【非静态内容】 【只能】 通过 创建【本类对象】， // 再通过【 对象.成员变量 】 OR 【 对象.成员方法(参数) 】的方式调用 Demo d = new Demo(); System.out.println(d.num); d.function(); &#125;&#125;————————————————————————————————————————————————————————————————————————————————————————*"main方法为静态方法仅仅为程序执行入口，它【不属于任何一个对象】，可以定义在任意类中。"————————————————————————————————————————————————————————————————————————————————————————举例：class Test&#123; public static void hello()&#123; System.out.println("hello"); &#125; &#125;public class TTTss &#123; public static void main(String[] args) &#123; Test tt = null; tt.hello(); &#125;&#125;运行结果：能编译通过，并能正常运行，打印：hello。注意：Test类中的方法 hello() 是静态static 的，因此，"hello()方法归类所有，与对象无关。当实例化Test类的时候，【静态成员】会被【优先加载】而且【只加载一次】，所以【不受】【实例化对象】 new Test();影响"，"只要是用到了Test类，都会加载静态 hello()方法。"此外，在【其他类】的【静态方法】中也能调用public的静态hello()方法。—————————————————————————————————————————————————————————总结： "静态方法【不受】实例化对象的影响"，即使Test tt = null; 这是只要调用了Test类，就会加载静态方法，tt中包含了Test类的初始化数据。 此外，如果hello()是【非静态的方法】，那就会报NullPointerException异常。 10static静态的使用场景* A: 使用场景 1234567static可以修饰"【成员变量】"和"【成员方法】"。 什么时候使用static修饰"成员变量"？ 加static修饰成员的时候，"这个成员会被类的所有对象所共享。一般我们把【共性数据】定义为静态的变量。"————————————————————————————————————————————————————————————————————————————————————————什么时候使用static修饰"成员方法"？ "静态的方法【只能】访问静态的成员"，" 如果静态方法中引用到了静态的其他成员，那么这个方法需要声明为静态的方法。" "方法中【没有】调用【非静态成员变量】，则将方法定义为【静态】" 11对象中的静态调用* A: 对象的静态调用 123456789101112131415"在多态中，无论是【静态成员变量】 还是【非静态成员变量】，【都看父类】"————————————————————————————————————————————————————————————————————————————————————————" 在多态中，【非静态成员方法】【编译】【看父类】，【运行】【看子类】，【父类没有】则编译失败。"————————————————————————————————————————————————————————————————————————————————————————" 但多态中的【静态成员方法】,【编译看父类】,【运行仍然看父类】。因为【静态和对象没有关系】，属于【静态绑定】。"————————————————————————————————————————————————————————————————————————————————————————即："【只有】【非静态成员方法】 运行看 【子类】,其他看父类"————————————————————————————————————————————————————————————————————————————————————————* B: 举例public class Test&#123; public static void main(String[] args)&#123; Fu f = new Zi(); f.show(); //父类的引用和父类的方法绑定,和对象无关,不会在运行时动态的执行子类特有的方法。 &#125;&#125; 12定义静态常量* A: 静态常量 123456789101112131415161718192021222324252627开发中，我们想在类中定义一个静态常量，通常使用public static final修饰的变量来完成定义。"此时变量名用【全部大写】，多个单词使用下划线连接。"* B: 定义格式： public static final 数据类型 变量名 = 值; * C: 如下演示： class Company &#123; public static final String COMPANY_NAME = "传智播客"; public static void method()&#123; System.out.println("一个静态方法"); &#125; &#125; "当我们想使用类的静态成员时，【不需要创建对象】，【直接使用类名】来访问即可。" System.out.println(Company.COMPANY_NAME); //打印传智播客 Company.method(); // 调用一个静态方法* D: 注意： "接口中的每个【成员变量】都默认使用" public static final修饰。 "所有【接口】中的【成员变量】【必须是静态常量】，由于【接口】【没有】【构造方法】， 所以【必须显示赋值】。可以【直接】用【接口名】访问" interface Inter &#123; public static final int COUNT = 100; &#125; " 访问接口中的静态变量 ": Inter.COUNT&#125; 13匿名对象* A:匿名对象的概述 12345678910111213141516171819202122232425262728293031323334353637383940414243444546* 匿名对象是指创建对象时，只有创建对象的语句，却没有把对象地址值赋值给某个变量。* B:案例public class Person&#123; public void eat()&#123; System.out.println();&#125;&#125;创建一个普通对象Person p = new Person();"创建一个匿名对象"new Person();* C: 匿名对象的特点a:"创建匿名对象【直接使用】，【没有变量名】"。 new Person().eat() //"eat方法被一个没有名字的Person对象调用了"。b:"【匿名对象】在【没有指定】其【引用变量】时，【只能】【使用一次】，第二次使用则【重新】创建了【新的匿名对象】"。 new Person().eat(); 创建一个匿名对象，调用eat方法 new Person().eat(); 想再次调用eat方法，重新创建了一个匿名对象 c:"【匿名对象】可以作为【方法接收的参数】、【方法返回值】使用" class Demo &#123; public static Person getPerson()&#123; //普通方式 //Person p = new Person(); //return p; //匿名对象作为方法返回值 return new Person(); &#125; public static void method(Person p)&#123;&#125; &#125; class Test &#123; public static void main(String[] args) &#123; //调用getPerson方法，得到一个Person对象 Person person = Demo.getPerson(); //调用method方法 Demo.method(person); //匿名对象作为方法接收的参数 Demo.method(new Person()); &#125; &#125; 14内部类及其特点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869" 将类写在其他类的【内部】，可以写在其他类的【成员位置】和【局部位置】，这时写在其他类内部的类就称为【内部类】。其他类也称为外部类 "。* B: 什么时候使用内部类 在描述事物时，若一个事物内部还包含其他可能包含的事物，比如在描述汽车时，汽车中还包含这发动机， 这时发动机就可以使用内部类来描述。 class 汽车 &#123; //外部类 class 发动机 &#123; //内部类 &#125; &#125;* C: 内部类的分类 注意：(1) "外部类 修饰符 【只能】使用 public 和 【省略访问控制符】" —————————————————————————————————————————————— "内部类 修饰符 可以使用：public protected private static 和 【省略访问控制符】"解释： 外部类的上一级程序单元是包，所以它只有2个作用域:"同一个包内和任何位置"。因此只需2种访问权限:"包访问权限和公开访问权限"，正好对应"省略访问控制符和public访问控制符"。省略访问控制符是包访问权限，即同一包中的其他类可以访问省略访问控制符的成员。因此，如果一个外部类不使用任何访问控制符修饰，则只能被同一个包中其他类访问。而内部类的上一级程序单元是外部类，它就具有4个作用域:同一个类、同一个包、父子类和任何位置，因此可以使用4种访问控制权限————————————————————————————————————————————————————————————————————————————————————————(2) "【非静态成员内部类】【不能】拥有【静态成员变量】" 根据静态成员不能直接访非静态成员的规则， "外部类的【静态方法】、静态代码块【不能直接】访问【非静态内部类】， 包括不能直接使用非静态内部类定义变量、创建实例等。" 总之，【不允许】在外部类的【静态成员】中直接使用【非静 态内部类】但是：静态常量的【这里要注意静态常量一定拥有一个编译期常量的】如： private static final double PI=3.14;分析：首先要明白以下三点：1、static类型的属性和方法，"在类加载的时候就会存在于内存中"。2、要想使用某个类的static属性和方法，那么"这个类必须要加载到虚拟机中"。3、"非静态内部类【并不随】外部类一起加载"，"只有在【实例化外部类之后】才会加载"。现在考虑这个情况："在外部类并没有实例化，内部类还没有加载，这时候如果调用内部类的静态成员或方法，内部类还没有加载，却试图在内存中创建该内部类的静态成员，这明显是矛盾的。"所以非静态内部类不能有静态成员变量或静态方法。public class Outer &#123; private static int t1; private int r1; public class Inner&#123; private static int t1;//error private static final double PI=3.14; public void func()&#123; int e = r1; e=t1; e=new Outer().r1;; e=Outer.t1; &#125; &#125;&#125;——————————————————————————————————————————————《 非静态方法可以调用静态成员方法和静态成员变量 》———————————————————————————————————————————————————————————————————————————————————————— "内部类分为【成员内部类】与【局部内部类】"。———————————————————————————————————————————————————————————————————————————————————————— "我们【定义】【内部类】时，就是一个【正常定义类】的过程， 【同样】【包含】各种【修饰符】、【继承】与【实现关系】等"。———————————————————————————————————————————————————————————————————————————————————————— "在【内部类】中可以【直接】访问【外部类】的【所有成员】"。 小结1.为什么使用内部类?使用内部类最吸引人的原因是：每个内部类都能独立地继承一个（接口的）实现，所以无论外围类是否已经继承了某个（接口的）实现，对于内部类都没有影响1.1.使用内部类最大的优点就在于它能够非常好的解决多重继承的问题,使用内部类还能够为我们带来如下特性:(1)、内部类可以用多个实例，每个实例都有自己的状态信息，并且与其他外围对象的信息相互独立。(2)、在单个外围类中，可以让多个内部类以不同的方式实现同一个接口，或者继承同一个类。(3)、创建内部类对象的时刻并不依赖于外围类对象的创建。(4)、内部类并没有令人迷惑的“is-a”关系，他就是一个独立的实体。(5)、内部类提供了更好的封装，除了该外围类，其他类都不能访问。2.内部类分类: (一).成员内部类:1234567891011121314151617181920public class Outer&#123; private int age = 99; String name = "Coco"; public class Inner&#123; String name = "Jayden"; public void show()&#123; System.out.println(Outer.this.name); System.out.println(name); System.out.println(age); &#125; &#125; public Inner getInnerClass()&#123; return new Inner(); &#125; public static void main(String[] args)&#123; Outer o = new Outer(); Inner in = o.new Inner(); in.show(); &#125; &#125; 1.Inner 类定义在 Outer 类的内部，相当于 Outer 类的一个成员变量的位置，Inner 类可以使用任意访问控制符，如 public 、 protected 、 private 等2.Inner 类中定义的 show() 方法可以直接访问 Outer 类中的数据，而不受访问控制符的影响，如直接访问 Outer 类中的私有属性age3.定义了成员内部类后，必须使用外部类对象来创建内部类对象，而不能直接去 new 一个内部类对象，即：内部类 对象名 = 外部类对象.new 内部类( );4.编译上面的程序后，会发现产生了两个 .class 文件: Outer.class,Outer$Inner.class{}5.非静态成员内部类中不能存在任何 static 的变量和方法,可以定义常量:(1).因为非静态内部类是要依赖于外部类的实例,而静态变量和方法是不依赖于对象的,仅与类相关,简而言之:在加载静态域时,根本没有外部类,所在在非静态内部类中不能定义静态域或方法,编译不通过;非静态内部类的作用域是实例级别(2).常量是在编译器就确定的,放到所谓的常量池了★★友情提示:1.外部类是不能直接使用内部类的成员和方法的，可先创建内部类的对象，然后通过内部类的对象来访问其成员变量和方法;2.如果外部类和内部类具有相同的成员变量或方法，内部类默认访问自己的成员变量或方法，如果要访问外部类的成员变量，可以使用 this 关键字,如:Outer.this.name (二).静态内部类: 是 static 修饰的内部类,1.静态内部类不能直接访问外部类的非静态成员，但可以通过 new 外部类().成员 的方式访问 2.如果外部类的静态成员与内部类的成员名称相同，可通过“类名.静态成员”访问外部类的静态成员；如果外部类的静态成员与内部类的成员名称不相同，则可通过“成员名”直接调用外部类的静态成员3.创建静态内部类的对象时，不需要外部类的对象，可以直接创建 内部类 对象名 = new 内部类(); 123456789101112131415public class Outer&#123; private int age = 99; static String name = "Coco"; public static class Inner&#123; String name = "Jayden"; public void show()&#123; System.out.println(Outer.name); System.out.println(name); &#125; &#125; public static void main(String[] args)&#123; Inner i = new Inner(); i.show(); &#125; &#125; (三).局部内部类：其作用域仅限于方法内，方法外部无法访问该内部类(1).局部内部类就像是方法里面的一个局部变量一样，是不能有 public、protected、private 以及 static 修饰符的(2).只能访问方法中定义的 final 类型的局部变量,因为:当方法被调用运行完毕之后，局部变量就已消亡了。但内部类对象可能还存在,直到没有被引用时才会消亡。此时就会出现一种情况，就是内部类要访问一个不存在的局部变量;==&gt;使用final修饰符不仅会保持对象的引用不会改变,而且编译器还会持续维护这个对象在回调方法中的生命周期.局部内部类并不是直接调用方法传进来的参数，而是内部类将传进来的参数通过自己的构造器备份到了自己的内部，自己内部的方法调用的实际是自己的属性而不是外部类方法的参数;防止被篡改数据,而导致内部类得到的值不一致 1234567891011121314151617181920212223242526/*使用的形参为何要为 final??? 在内部类中的属性和外部方法的参数两者从外表上看是同一个东西，但实际上却不是，所以他们两者是可以任意变化的， 也就是说在内部类中我对属性的改变并不会影响到外部的形参，而然这从程序员的角度来看这是不可行的， 毕竟站在程序的角度来看这两个根本就是同一个，如果内部类该变了，而外部方法的形参却没有改变这是难以理解 和不可接受的，所以为了保持参数的一致性，就规定使用 final 来避免形参的不改变 */ public class Outer&#123; public void Show()&#123; final int a = 25; int b = 13; class Inner&#123; int c = 2; public void print()&#123; System.out.println("访问外部类:" + a); System.out.println("访问内部类:" + c); &#125; &#125; Inner i = new Inner(); i.print(); &#125; public static void main(String[] args)&#123; Outer o = new Outer(); o.show(); &#125; &#125; . (3).注意:在JDK8版本之中,方法内部类中调用方法中的局部变量,可以不需要修饰为 final,匿名内部类也是一样的，主要是JDK8之后增加了 Effectively final 功能http://docs.oracle.com/javase/tutorial/java/javaOO/localclasses.html反编译jdk8编译之后的class文件,发现内部类引用外部的局部变量都是 final 修饰的 (四).匿名内部类:(1).匿名内部类是直接使用 new 来生成一个对象的引用;(2).对于匿名内部类的使用它是存在一个缺陷的，就是它仅能被使用一次，创建匿名内部类时它会立即创建一个该类的实例，该类的定义会立即消失，所以匿名内部类是不能够被重复使用;(3).使用匿名内部类时，我们必须是继承一个类或者实现一个接口，但是两者不可兼得，同时也只能继承一个类或者实现一个接口;(4).匿名内部类中是不能定义构造函数的,匿名内部类中不能存在任何的静态成员变量和静态方法;(5).匿名内部类中不能存在任何的静态成员变量和静态方法,匿名内部类不能是抽象的,它必须要实现继承的类或者实现的接口的所有抽象方法(6).匿名内部类初始化:使用构造代码块！利用构造代码块能够达到为匿名内部类创建一个构造器的效果 123456789101112131415161718public class OuterClass &#123; public InnerClass getInnerClass(final int num,String str2)&#123; return new InnerClass()&#123; int number = num + 3; public int getNumber()&#123; return number; &#125; &#125;; /* 注意：分号不能省 */ &#125; public static void main(String[] args) &#123; OuterClass out = new OuterClass(); InnerClass inner = out.getInnerClass(2, "chenssy"); System.out.println(inner.getNumber()); &#125; &#125; interface InnerClass &#123; int getNumber(); &#125; 15成员内部类的调用格式* A: 格式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157"【成员内部类】，定义在【外部类】中的【成员位置】。与类中的成员变量【相似】，可通过【外部类】【对象】进行访问"* B: 定义格式class 外部类 &#123; 修饰符 class 内部类 &#123; //其他代码 &#125;&#125;* C: 访问方式————————————————————————————————————————————————————————————————————————————————————————外部类名.内部类名 变量名 = new 外部类名().new 内部类名();Outer.this.成员 &gt;&gt;&gt; "表示内部类对外部类的成员引用"this.成员 &gt;&gt;&gt; "表示内部类对自己成员的调用"————————————————————————————————————————————————————————————————————————————————————————注：其他类调用内部类的成员：（一）访问"【非静态成员内部类】"："——————————————————————————————————————————————————————————"外部类名.内部类名 变量名 = new 外部类名().new 内部类名();"——————————————————————————————————————————————————————————"*************************************************************************************************"【非静态内部类】【不能】 定义【 静态方法、静态成员变量、静态初始化块】"*************************************************************************************************"需要在外部类中创建 内部类对象 ==&gt;&gt;&gt;调用方法"： 根据静态成员不能直接访非静态成员的规则， "外部类的【静态方法】、静态代码块【不能直接】访问【非静态内部类】， 包括不能直接使用非静态内部类定义变量、创建实例等。" 总之，【不允许】在中直接使用【非静 态内部类】举例：public class Outer_0 &#123; //非静态内部类 public class Inner_0&#123; &#125; //外部类的【静态方法】 public static void static_method()&#123; new Inner_0();//error,不允许在外部类的【静态成员】中【直接使用】非静态静内部类 "正确调用方式" new Outer_0().new Inner_0(); &#125;&#125;访问"【非静态成员内部类】"：（1）在【外部类】的"【非静态方法】"中访问： "【new 内部类名()" OR "【 new 外部类名().new 内部类名() 】" （2）在【外部类以外】的"【非静态方法】"中访问： "【只能】【 new 外部类名().new 内部类名() 】"（3）在【外部类】及 【外部类以外】的"【静态方法】"中访问：" 【只能】通过【 new 外部类名().new 内部类名() 】" 方式访问————————————————————————————————————————————————————————————————————————————————————————（二）访问"【静态成员内部类】"："——————————————————————————————————————————————————————————"（1）在【外部类】中使用静态内部类new 静态内部类名();调用静态内部类的"【非静态方法】"：new 外部类名.静态内部类名()调用静态内部类的"【静态方法】"： 静态内部类名.静态方法名(); （2）在【外部类以外】使用静态内部类 因为【静态内部类】是外部类"类相关"的，"因此创建静态内部类对象时【无须】创建外部类对象"。在【外部类以外】的地方创建静态内部类实例的语法："***************************************************************************************"外部类名.内部类名 变量名 = new 外部类名.静态内部类名();"***************************************************************************************" A:【调用非静态方法】： 变量名.静态方法名() OR new 外部类名.静态内部类名().静态方法名()"——————————————————————————————————————————————————————————" B:【调用静态方法】："在【外部类以外】：访问方式无需创建对象，利用 【 外部类名.静态内部类名.内部类静态方法 】访问内部类【静态方法】"————————————————————————————————————————————————————————————————————————————————————————* D: 成员内部类代码演示class Body &#123;//外部类，身体 private boolean life= true; //生命状态 public class Heart &#123; //内部类，心脏 public void jump() &#123; System.out.println("心脏噗通噗通的跳") System.out.println("生命状态" + life); //访问外部类成员变量 &#125; &#125;&#125;访问内部类public static void main(String[] args) &#123; //创建内部类对象 Body.Heart bh = new Body().new Heart(); //调用内部类中的方法 bh.jump();&#125;*Fpublic class Outer &#123; private int num; public Outer(int num)&#123; this.num = num; &#125; public void ff() &#123; // 【静态内部类】 也可以创建对象 // 对内部类的方法进行调用 new LLei_static().hanshu(); &#125; //非静态成员内部类 public class Inner&#123; private int num =93; public void func()&#123; int num=18; System.out.println("成员内部类 Inner 的方法 func &gt;&gt; num: "+ num);//18,就近原则 System.out.println("成员内部类 Inner 的方法 func &gt;&gt; this.num: "+ this.num);//视为 访问 内部类对象（this）的成员变量，用this System.out.println("成员内部类 Inner 的方法 func &gt;&gt; Outer.this.num: "+ Outer.this.num);//视为 访问 外部类对象(Outer.this)的成员变量，用Outer.this &#125; &#125; //静态成员内部类 public static class LLei_static&#123; public void hanshu()&#123; int num=232; System.out.println("成员内部类 LLei_static 的方法 hanshu &gt;&gt; num: "+ new Outer(89565).num); &#125; &#125;&#125;public class TSET &#123; public static void main(String[] args) &#123; Outer.Inner in1 = new Outer(274).new Inner(); in1.func(); System.out.println("————————————————————————————————————1:"); Outer out =new Outer(2365); Outer.Inner in2 = out.new Inner(); in2.func(); Outer static_out =new Outer(4345); System.out.println("————————————————————————————————————2:"); //此时 将【静态成员内部类】理解为 一个成员变量 Outer.LLei_static static_in = new Outer.LLei_static(); static_in.hanshu(); &#125;&#125; 16成员内部类的同名变量调用* A: 代码实现 1234567891011121314151617181920212223242526272829当在"【非静态内部类】"的"方法内"访问某个变量时，(1)系统优先在该"方法内"查找是否存在该名字的"局部变量"，如果存在就使用该变量;"方法内"的"局部变量"：直接用变量名 调用(2)如果不存在，则到该方法所在的"内部类"中查找是否存在该名字的成员变量，如果存在则使用该"成员变量";"内部类"中的"成员变量"：this.成员变量名 调用(3)如果不存在，则到该内部类所在的"外部类"中查找是否存在该名字的"成员变量"，如果存在则使用该成员变量;"外部类"中的"成员变量"：外部类名.this.成员变量名 调用如果依然不存在，系统将出现编译错误:提示找不到该变量。public class Outer &#123; int num = 1; class Inner &#123; int num = 2; public void inner()&#123; int num = 3; //18,就近原则 System.out.println("成员内部类 Inner 的方法 func &gt;&gt; num: "+ num); //视为 访问 内部类对象（this）的成员变量，用this System.out.println("成员内部类 Inner 的方法 func &gt;&gt; this.num: "+ this.num); //视为 访问 外部类对象(Outer.this)的成员变量，用Outer.this System.out.println("成员内部类 Inner 的方法 func &gt;&gt; Outer.this.num: "+ Outer.this.num); &#125; &#125;&#125; 17 局部内部类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687* A "局部内部类"，定义在"【外部类方法】"中的"局部位置"。"与访问方法中的【局部变量】【相似】，* 可通过【调用方法】【进行访问】".* 局部类 "【不能】" 用 public或 private "修饰符进行声明，它的作用域被限定在所声明的【局部类的块】中。"* B 定义格式 class 【外部类】 &#123; 修饰符 返回值类型 【方法名(参数)】 &#123; class 【内部类】 &#123; //其他代码 &#125; &#125; &#125;* C 访问方式 "在【外部类方法】中，创建【内部类】【对象】，进行访问"* D 局部内部类代码演示 定义类 class Party &#123;//外部类，聚会 public void puffBall()&#123;// 吹气球方法 class Ball &#123;// 内部类，气球 public void puff()&#123; System.out.println("气球膨胀了"); &#125; &#125; //创建内部类对象，调用puff方法 new Ball().puff(); &#125; &#125; 访问内部类 public static void main(String[] args) &#123; //创建外部类对象 Party p = new Party(); //调用外部类中的puffBall方法 p.puffBall(); &#125;————————————————————————————————————————————————————————————————————————————————————————举例：//局部内部类public class Outer &#123; private int num =380; public void method()&#123; final int TYU =56; System.out.println("外部类 Outer 的方法"); &#125; public int outer_func( String s)&#123; int num = 200; // num是局部变量 int yu=90; int [] arr = new int[1]; //局部内部类 class Inner&#123; int num =567; //如何调用 局部内部类 中的 方法？ public void inner_func()&#123; int num = 45456; // s = "dvd"; // yu =56; // yu++; //ERROR arr[0]++; arr[0]++;//通过引用数据类型，实现【局部内部类】中的 计数器 this.num++;// 该this指向【局部内部类 Inner 】【对象】的【成员属性】：567+1=568 System.out.println("局部内部类 Inner 的方法: " + this.num+ " "+ yu + s); System.out.println("局部内部类 Inner 的方法:调用局部变量 " + arr[0]); Outer.this.method(); &#125; public int inner_return()&#123; return this.num;//568 &#125; &#125; // 需要在【外部类】的【方法】中，创建【内部类】【对象】，进行访问 Inner in = new Inner(); in.inner_func(); System.out.println("this.num "+ this.num);// 该this指向 【外部类 Outer】【对象】的【成员属性】:380 return in.inner_return() + this.num + num;// num是局部变量：200 &#125;&#125; 18匿名内部类* A: 概述 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102 内部类是为了应对更为复杂的类间关系。查看源代码中会涉及到，而在日常业务中很难遇到，这里不做赘述。 最常用到的内部类就是匿名内部类，它是局部内部类的一种。 定义的【匿名内部类】有两个含义： "临时定义某一指定类型的子类" "定义后【即刻】创建刚刚定义的这个【子类】的【对象】"* B: 本质 "【匿名内部类】的【本质】是一个实现了【接口】或继承了某个【父类】的【子类匿名对象】".1 匿名内部类"不能有构造方法"。2 匿名内部类"不能定义任何静态成员、方法和类"。3 匿名内部类"不能"是public,protected,private,static。4 "只能"创建匿名内部类的"一个实例"。5 一个匿名内部类"一定是在new的后面"，用其隐含实现一个接口或实现一个类。6 因匿名内部类为"局部内部类"，所以局部内部类的所有限制都对其生效。public class test &#123; public static void main(String[] args) &#123; ////使用匿名内部类 new Drink()&#123; public Drink()&#123;"//error "不能有构造方法"" &#125; private int er; private static int rt;"//error "不能定义任何静态成员、方法和类"" public void func()&#123; System.out.println("这是一个匿名内部类的 方法 func"); &#125; &#125;; System.out.println("————————————————————————————————————2:"); new Drink()&#123; public void func()&#123; System.out.println("这是一个匿名内部类的 方法 func"); &#125; &#125;.func(); System.out.println("————————————————————————————————————3:"); //创建匿名内部类 对象 dd Drink dd = new Drink()&#123; public void func()&#123; System.out.println("这是一个匿名内部类的 方法 func"); &#125; &#125;; //再通过 对象 调用 匿名内部类 的 func 方法 dd.func(); &#125;&#125;* C: 案例public interface Smoking &#123; public abstract void smoking(); &#125; /*【回顾之前采用的方式】 * 实现类,实现接口 重写接口抽象方法,创建实现类对象 * class XXX implements Smoking&#123; * public void smoking()&#123; * * &#125; * &#125; * XXX x = new XXX(); * x.smoking(); * Smoking s = new XXX(); * s.smoking(); * * 匿名内部类,简化问题: 定义实现类,重写方法,建立实现类对象,合为一步完成 */测试类:public class Test &#123; public static void main(String[] args) &#123; "//使用匿名内部类 /* * 定义实现类,重写方法,创建实现类对象,一步搞定 * 格式:" —————————————————————————————————————————————————————— new 接口或者父类()&#123; 重写抽象方法 &#125;; —————————————————————————————————————————————————————— "* 从 new开始,到分号结束 * 创建了接口的实现类的对象 */" new Smoking()&#123; public void smoking()&#123; System.out.println("人在吸烟"); &#125; &#125;.smoking(); &#125;&#125; 19匿名内部类_2* A: 匿名内部类案例演示 1234567891011121314151617181920212223242526272829303132333435 public abstract class Animal &#123; public abstract void eat(); public abstract void sleep(); &#125;测试代码/* * new Animal()&#123; public void eat()&#123; System.out.println("在吃饭"); &#125; public void sleep()&#123; System.out.println("在睡觉"); &#125; &#125;;*/ "以上代码,就是Animal的子类的对象 利用多态性, 父类引用 = 子类的对象"public class Test2 &#123; public static void main(String[] args) &#123; Animal a= new Animal()&#123; public void eat()&#123; System.out.println("在吃饭"); &#125; public void sleep()&#123; System.out.println("在睡觉"); &#125; &#125;; a.eat(); a.sleep(); &#125;&#125; 20包的概念* A: 概念 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354java的包，其实就是我们电脑系统中的文件夹，包里存放的是"类文件（.java 或者 .class 文件）"。当类文件很多的时候，通常我们会采用多个包进行存放管理他们，这种方式称为"分包管理"。在项目中，我们将相同功能的类放到一个包中，方便管理。并且日常项目的分工也是"以包作为边界"。"类中声明的包必须与实际class文件所在的文件夹情况【相一致】，即类声明在a包下，则生成的.class文件必须在a文件夹下，否则，程序运行时会找不到类"。"————————————————————————————————————————————————————————————————————————————————————————"* B 声明格式通常使用公司网址反写，"可以有【多层包】，包名采用【全部小写字母】，【多层包】之间用【”.”】连接" 类中包的声明格式： —————————————————————————————— package 包名.包名.包名…; —————————————————————————————— 如：网址itheima.com那么网址反写就为com.itheima itcast.cn 那么网址反写就为 cn.itcast "注意：声明包的语句，必须写在程序【有效代码】的【第一行】（注释不算）" 代码演示： package cn.itcast; //包的声明，必须在有效代码的第一行 import java.util.Scanner; import java.util.Random; public class Demo &#123;&#125;"————————————————————————————————————————————————————————————————————————————————————————"* C: 包的访问在访问类时，为了能够找到该类，"必须使用含有包名的【类全名】（包名.类名）"。即："包名.包名….类名"如： java.util.Scanner java.util.Random cn.itcast.Demo——————————————————————————————————————————————————————————带有包的类，创建对象格式：包名.类名 变量名 = new 包名.类名();——————————————————————————————————————————————————————————如： cn.itcast.Demo d = new cn.itcast.Demo(); 前提：包的访问与访问权限密切相关，这里以一般情况来说，即类用public修饰的情况。"————————————————————————————————————————————————————————————————————————————————————————"*D:类的简化访问——————————————————————————————————————————————————————————当我们要使用一个类时，这个类与当前程序在"同一个包中（即同一个文件夹中）"，或者"这个类是【java.lang】包中的类"时通常"【可以省略】掉【包名】"，直接使用该类。——————————————————————————————————————————————————————————如：cn.itcast包中有两个类，PersonTest类，与Person类。我们在PersonTest类中，访问Person类时，由于是同一个包下，访问时可以省略包名，即直接通过类名访问 Person。—————————————————————————————————————————————————————————— 类名 变量名 = new类名(); Person p = new Person(); 当我们要使用的类，与当前程序"【不在】同一个包中（即【不同】文件夹中）"，要访问的类"必须"用public"修饰才可访问"。 package cn.itcst02; public class Person &#123;&#125; 22导入包* A:导入包 12345678910111213141516171819202122我们每次使用类时，都需要写很长的包名。很麻烦，我们可以通过import导包的方式来简化。可以通过导包的方式使用该类，可以避免使用全类名编写（即，包类.类名）。导包的格式：import 包名.类名; 当程序导入指定的包后，使用类时，就可以简化了。演示如下//导入包前的方式//创建对象java.util.Random r1 = new java.util.Random();java.util.Random r2 = new java.util.Random();java.util.Scanner sc1 = new java.util.Scanner(System.in);java.util.Scanner sc2 = new java.util.Scanner(System.in);//导入包后的方式import java.util.Random;import java.util.Scanner;//创建对象Random r1 = new Random();Random r2 = new Random();Scanner sc1 = new Scanner(System.in);Scanner sc2 = new Scanner(System.in);import导包代码书写的位置：在声明包package后，定义所有类class前，使用导包import包名.包名.类名; 23权限修饰符* A 权限修饰符有哪些 12345678910111213141516171819202122232425262728293031 在Java中提供了四种访问权限，使用不同的访问权限时，被修饰的内容会有不同的访问权限， 以下表来说明不同权限的访问能力： public protected default private———————————————————————————————————————————————————————————————————————————————————————— "同一【类】中" √ √ √ √———————————————————————————————————————————————————————————————————————————————————————— "同一包中(子类与无关类)" √ √ √ ———————————————————————————————————————————————————————————————————————————————————————— "不同包的子类" √ √———————————————————————————————————————————————————————————————————————————————————————— "不同包中的无关类" √ ———————————————————————————————————————————————————————————————————————————————————————— * B: 小结归纳一下：在日常开发过程中，编写的类、方法、成员变量的访问———————————————————————————————————————————————————————————————————————————————————————— private:要想"【仅能在本类中】"访问使用private修饰；———————————————————————————————————————————————————————————————————————————————————————— default:要想"【本包】"中的类都可以访问"【不加修饰符】"即可；———————————————————————————————————————————————————————————————————————————————————————— protected:要想"【本包】中的类与【其他包中的【子类】】"可以访问使用protected修饰注意： protected 修饰符 在"【跨包】调用成员"时： "【只能】在 【子类的内部】【进行调用】：&#123; 直接用 【成员名】 OR 【super.成员名】 调用&#125;并且【不能】在【子类中】 通过 【创建对象】 【进行调用】"———————————————————————————————————————————————————————————————————————————————————————— public:要想"【所有包】中的【所有类】"都可以访问使用public修饰。———————————————————————————————————————————————————————————————————————————————————————— 注意：如果类用public修饰，"则【类名】必须与【文件名】相同"。"一个文件中【只能】有一个" public修饰的类。———————————————————————————————————————————————————————————————————————————————————————— 24代码块12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788* A: 概述:程序中用"【大括号括起来】"的代码叫"代码块"———————————————————————————————————————————————————————————————————————————————————————— * B: 分类"局部代码块" "构造代码块" "静态代码块" "同步代码块"———————————————————————————————————————————————————————————————————————————————————————— * C "局部代码块":"【局部代码块】是定义在【方法】或【语句】中"特点： "以”&#123;&#125;”划定的代码区域，此时只需要关注【作用域】的不同即可" "【方法】和【类】都是以【代码块】的方式【划定边界】的"———————————————————————————————————————————————————————————————————————————————————————— class Demo&#123; public static void main(String[] args) &#123; //局部代码块 &#123; int x = 1; System.out.println("局部代码块" + x); &#125; //局部变量作用域 int x = 99; System.out.println("代码块之外" + x); &#125;&#125; 结果： 普通代码块1 代码块之外99 "【局部代码块】作用:可以【限定变量】的【声明周期】".———————————————————————————————————————————————————————————————————————————————————————— * D: "构造代码块""【构造代码块】是定义在【类】中【成员位置】的代码块"特点： "【优先于】【构造方法】执行，构造代码块用于执行【所有对象】【均需要】的【初始化动作】" "每【创建一个】对象均会【执行一次】构造代码块"。public class Person &#123; private String name; private int age; //构造代码块 &#123; System.out.println("构造代码块执行了"); &#125; Person()&#123; System.out.println("Person无参数的构造函数执行"); &#125; Person(int age)&#123; this.age = age; System.out.println("Person（age）参数的构造函数执行"); &#125;&#125;class PersonDemo&#123; public static void main(String[] args) &#123; Person p = new Person(); Person p1 = new Person(23); &#125;&#125;结果： 构造代码块执行了 Person无参数的构造函数执行 构造代码块执行了 Person（age）参数的构造函数执行———————————————————————————————————————————————————————————————————————————————————————— * E: "静态代码块""【静态代码块】是定义在【成员位置】"，使用static "修饰的代码块"。特点： "它【优先于】【主方法】执行、【优先于】【构造代码块】执行， 当以任意形式【第一次使用到该类】时执行"。 "【该类】【不管创建多少对象】，【静态代码块】【只执行一次】"。 "可用于给【静态变量赋值】，用来给【类进行初始化】"。 public class Person &#123; private String name; private int age; //静态代码块 static&#123; System.out.println("静态代码块执行了"); &#125; &#125;———————————————————————————————————————————————————————————————————————————————————————— * F: "同步代码块"(多线程学习) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071————————————————————————————————————————————————————————————————————————————————————————举例：class Person &#123; public Person()&#123; System.out.println("Class Person 构造方法"); &#125; &#123; System.out.println("Class Person 构造代码块 "); &#125; static &#123; System.out.println("Class Person 【静态】代码块 "); &#125;&#125;class Student extends Person &#123; public Student() &#123; System.out.println(" Student 构造方法"); &#125; static &#123; System.out.println(" Student 【静态】代码块"); &#125; &#123; System.out.println(" Student 构造代码块"); &#125; &#125;public class Test &#123; public static void main(String[] args) &#123; new Student(); System.out.println("————————————————————————————"); new Student(); &#125;&#125;————————————————————————————————————————————————————————————————————————————————————————运行结果：Class Person 【静态】代码块 Student 【静态】代码块Class Person 构造代码块 Class Person 构造方法 Student 构造代码块 Student 构造方法————————————————————————————Class Person 构造代码块 Class Person 构造方法 Student 构造代码块 Student 构造方法———————————————————————————————————————————————————————————————————————————————————————结论："【静态代码块】【只执行一次】执行顺序：* 静态代码块 &gt; 构造代码块（初始化块） &gt; 构造方法（构造器）* 父类 &gt; 子类结合下来的顺序： 【父类】静态代码块 【子类】静态代码块 父类构造代码块 父类构造方法 子类构造代码块 子类构造方法" 25总结12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final：关键字，最终的意思 final修饰的类：最终的类，不能被继承 final修饰的变量： 相当于是一个常量, 在编译生产.class文件后，该变量变为常量值 final修饰的方法： 最终的方法，子类不能重写，可以继承过来使用————————————————————————————————————————————————————————————————————————————————————————static : 关键字， 静态的意思 可以用来修饰类中的成员(成员变量，成员方法) 注意： 也可以用来修饰成员内部类特点： 被静态所修饰的成员，会被所有的对象所共享 被静态所修饰的成员，可以通过类名直接调用，方便 Person.country = "中国"; Person.method();注意事项： 静态的成员，随着类的加载而加载，优先于对象存在 在静态方法中，没有this关键字 静态方法中，只能调用静态的成员(静态成员变量，静态成员方法————————————————————————————————————————————————————————————————————————————————————————匿名对象：一个没有名字的对象特点：创建匿名对象直接使用，没有变量名匿名对象在没有指定其引用变量时，只能使用一次匿名对象可以作为方法接收的参数、方法返回值使用————————————————————————————————————————————————————————————————————————————————————————内部类：在一个类中，定义了一个新类，这个新的类就是内部类 class A &#123;//外部类 class B&#123;// 内部类 &#125; &#125;特点： 内部类可以直接访问外部类的成员，包含私有的成员————————————————————————————————————————————————————————————————————————————————————————包的声明与访问类中包的声明格式： package 包名.包名.包名…;带有包的类，创建对象格式：包名.类名 变量名 = new包名.类名();cn.itcast.Demo d = new cn.itcast.Demo();导包的格式：import 包名.类名;————————————————————————————————————————————————————————————————————————————————————————权限修饰符 public : 公共的 protected: 受保护的 default: 默认的（可省略） private : 私有的 public protected default private———————————————————————————————————————————————————————————————————————————————————————— "同一【类】中" √ √ √ √———————————————————————————————————————————————————————————————————————————————————————— "同一包中(子类与无关类)" √ √ √ ———————————————————————————————————————————————————————————————————————————————————————— "不同包的子类" √ √———————————————————————————————————————————————————————————————————————————————————————— "不同包中的无关类" √ ———————————————————————————————————————————————————————————————————————————————————————— 代码块： 局部代码块：定义在方法中的，用来限制变量的作用范围 构造代码块：定义在类中方法外，用来给对象中的成员初始化赋值 静态代码块：定义在类中方法外，用来给类的静态成员初始化赋值———————————————————————————————————————————————————————————————————————————————————————— 以下代码的输出结果是？12345678910111213141516public class B&#123; public static B t1 = new B(); public static B t2 = new B(); &#123; System.out.println("构造块"); &#125; static &#123; System.out.println("静态块"); &#125; public static void main(String[] args) &#123; B t = new B(); &#125;&#125; 答案： 构造块 构造块 静态块 构造块 开始时JVM加载B.class，对所有的静态成员进行声明，t1 t2被初始化为默认值，为null，又因为t1 t2需要被显式初始化，所以对t1进行显式初始化，初始化代码块→构造函数（没有就是调用默认的构造函数），咦！静态代码块咋不初始化？因为在开始时已经对static部分进行了初始化，虽然只对static变量进行了初始化，但在初始化t1时也不会再执行static块了，因为JVM认为这是第二次加载类B了，所以static会在t1初始化时被忽略掉，所以直接初始化非static部分，也就是构造块部分（输出’’构造块’’）接着构造函数（无输出）。接着对t2进行初始化过程同t1相同（输出’构造块’），此时就对所有的static变量都完成了初始化，接着就执行static块部分（输出’静态块’），接着执行，main方法，同样也，new了对象，调用构造函数输出（’构造块’） 并不是静态块最先初始化,而是静态域.而静态域中包含静态变量、静态块和静态方法,其中需要初始化的是静态变量和静态块.而他们两个的初始化顺序是靠他们俩的位置决定的!So！初始化顺序是 t1 t2 静态块]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础10(构造方法，this，super)]]></title>
    <url>%2F2016%2F10%2F13%2Fday12%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、构造方法2、this关键字3、super关键字4、综合案例 01构造方法引入* A:构造方法的引入 在开发中经常需要在创建对象的同时明确对象的属性值，比如员工入职公司就要明确他的姓名、年龄等属性信息。 那么，创建对象就要明确属性值，那怎么解决呢？也就是在创建对象的时候就要做的事情，当使用new关键字创建对象时，怎么给对象的属性初始化值呢？ 这就要学习Java另外一门小技术，构造方法。 * B: 那什么是构造方法呢？ 从字面上理解即为构建创造时用的方法，即就是对象创建时要执行的方法。既然是对象创建时要执行的方法，那么只要在new对象时， 知道其执行的构造方法是什么，就可以在执行这个方法的时候给对象进行属性赋值。 02构造方法作用* A: 构造方法的作用: 在new的同时给成员变量赋值,给对象属性进行初始化。 * B: 举例: Perons p = new Person(&quot;张三&quot;,23); 在new 的时候给p对象的name属性和age属性进行赋值,使这个对象的属性有值。 03构造方法的定义和运行特点* A: 构造方法定义 构造方法的格式： 修饰符 构造方法名(参数列表) { } * B: 构造方法的体现： 构造方法没有返回值类型。也不需要写返回值。因为它是为构建对象的，对象创建完，方法就执行结束。 构造方法名称必须和类型保持一致。 构造方法没有具体的返回值。 构造方法的代码体现： * C: 构造方法举例 123456789101112131415 class Person &#123; // Person的成员属性age和name private int age; private String name; // Person的构造方法，拥有参数列表 Person(int a, String nm) &#123; // 接受到创建对象时传递进来的值，将值赋给成员属性 age = a; name = nm; &#125; &#125;* D: 构造方法运行特点: 在new 对象的时候自动调用执行。 04默认添加的构造方法* A: 每一class类都必须有一个构造方法，构造方法不写也有。 编译的时候，javac，系统会自动检查类中是否有构造方法，如果没有编译器就会自动添加一个构造方法 比如Person类， 编译器添加一个无参构造 public Person(){} 05构造方法的调用赋值* A: 理解构造方法的格式和基本功能之后，现在就要研究构造方法是怎么执行的呢？在创建对象的时候是如何初始化的呢？ 构造方法是专门用来创建对象的，也就是在new对象时要调用构造方法。现在来看看如何调用构造方法。 * B: 案例 1234567891011121314151617181920212223242526 class Person &#123; // Person的成员属性age和name private int age; private String name; // Person的构造方法，拥有参数列表 Person(int a, String nm) &#123; // 接受到创建对象时传递进来的值，将值赋给成员属性 age = a; name = nm; &#125; public void speak() &#123; System.out.println("name=" + name + ",age=" + age); &#125; &#125; class PersonDemo &#123; public static void main(String[] args) &#123; // 创建Person对象，并明确对象的年龄和姓名 Person p2 = new Person(23, "张三"); p2.speak(); &#125; &#125;上述代码演示了创建对象时构造方法的调用。即在创建对象时，会调用与参数列表对应的构造方法 06构造方法的内存A:内存加载的过程 有一个Person类, 创建Person 对象new Person() 1、首先会将main方法压入栈中，执行main方法中的 new Person(23,”张三”); 2、在堆内存中分配一片区域，用来存放创建的Person对象，这片内存区域会有属于自己的内存地址（0x88）。 然后给成员变量进行默认初始化（name=null，age=0）。 3、执行构造方法中的代码（age = a ; name = nm;）,将变量a对应的23赋值给age， 将变量nm对应的”张三赋值给name，这段代码执行结束后，成员变量age和name的值已经改变。 执行结束之后构造方法弹栈，Person对象创建完成。将Person对象的内存地址0x88赋值给p2。 07构造方法的重载* A：当在描述事物时，要不要在类中写构造方法呢？这时要根据描述事物的特点来确定， * 当描述的事物在创建其对象时就要明确属性的值，这时就需要在定义类的时候书写带参数的构造方法。 * 若创建对象时不需要明确具体的数据，这时可以不用书写构造方法（不书写也有默认的构造方法）。 12345678910111213141516171819202122 构造方法的细节： 1、一个类中可以有多个构造方法，多个构造方法是以重载的形式存在的 2、构造方法是可以被private修饰的，作用：其他程序无法创建该类的对象。* B: 举例 class Person &#123; private int age; private String name; // 私有无参数的构造方法，即外界不能通过new Person();语句创建本类对象 private Person() &#123; &#125; // 多个构造方法是以重载的形式存在 Person(int a) &#123; age = a; &#125; Person(String nm, int a) &#123; name = nm; age = a; &#125; &#125; 08构造方法和一般方法区别* A: 目前为止，学习两种方法，分别为构造方法和一般方法，那么他们之间有什么异同呢？ 12345678910111213141.格式不同 构造方法 : 修饰符 类名(参数类型 参数 ...)&#123; 初始化成员变量&#125;一般方法: 需要有返回值类型2.作用不同构造方法一般用来给成员变量初始化;一般方法根据需求而定;3.调用方式不同构造方法创建对象时调用, 或者this() super() 语句调用普通方法需要对象调用或者静态方法直接调用静态方法.4.执行不同构造方法在对象创建时就执行了，而且只执行一次。一般方法是在对象创建后，需要使用时才被对象调用，并可以被多次调用。 09this在构造方法之间的调用* A: 在之前学习方法之间调用时，可以通过方法名进行调用。可是针对构造方法，无法通过构造方法名来相互调用。 12345678910111213141516171819202122232425262728 构造方法之间的调用，可以通过this关键字来完成。 构造方法调用格式： this(参数列表);* B:调用构造方法的案例 class Person &#123; // Person的成员属性 private int age; private String name; // 无参数的构造方法 Person() &#123; &#125; // 给姓名初始化的构造方法 Person(String nm) &#123; name = nm; &#125; // 给姓名和年龄初始化的构造方法 Person(String nm, int a) &#123; // 由于已经存在给姓名进行初始化的构造方法 name = nm;因此只需要调用即可 // 调用其他构造方法，需要通过this关键字来调用 this(nm); // 给年龄初始化 age = a; &#125; &#125; 10this在构造方法调用的内存图* A: 被加载的代码 123456789101112131415161718192021222324252627282930313233343536373839404142class Person &#123; private int age; private String name; Person() &#123; &#125; Person(String nm) &#123; name = nm; &#125; Person(String nm, int a) &#123; this(nm); age = a; &#125;&#125;class PersonDemo &#123; public static void main(String[] args) &#123; Person p = new Person("张三", 23); &#125;&#125;* B: 构造方法调用的原理图* 1、先执行main方法，main方法压栈，执行其中的new Person(“张三”,23);2、堆内存中开辟空间，并为其分配内存地址0x33，，紧接着成员变量默认初始化（name=null age = 0）；3、拥有两个参数的构造方法（Person（String nm , int a））压栈，在这个构造方法中有一个隐式的this，因为构造方法是给对象初始化的，哪个对象调用到这个构造方法，this就指向堆中的哪个对象。4、由于Person（String nm , int a）构造方法中使用了this(nm);构造方法Person(String nm)就会压栈，并将“张三”传递给nm。在Person（String nm , int a）构造方法中同样也有隐式的this，this的值同样也为0x33，这时会执行其中name = nm，即把“张三”赋值给成员的name。当赋值结束后Person（String nm , int a）构造方法弹栈。5、程序继续执行构造方法（Person（String nm , int a）中的age = a；这时会将23赋值给成员属性age。赋值结束构造方法（Person（String nm , int a）弹栈。6、当构造方法（Person（String nm , int a）弹栈结束后，Person对象在内存中创建完成，并将0x33赋值给main方法中的p引用变量。注意：this到底代表什么呢？this代表的是对象，具体代表哪个对象呢？哪个对象调用了this所在的方法，this就代表哪个对象。调用其他构造方法的语句必须定义在构造方法的第一行，原因是初始化动作要最先执行。 11this简易应用* A: 当在方法中出现了局部变量和成员变量同名的时候，那么在方法中怎么区别局部变量成员变量呢？可以在成员变量名前面加上this.来区别成员变量和局部变量 * B: 举例1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Person &#123; private int age; private String name; // 给姓名和年龄初始化的构造方法 Person(String name, int age) &#123; // 当需要访问成员变量是，只需要在成员变量前面加上this.即可 this.name = name; this.age = age; &#125; public void speak() &#123; System.out.println("name=" + this.name + ",age=" + this.age); &#125;&#125;class PersonDemo &#123; public static void main(String[] args) &#123; Person p = new Person("张三", 23); p.speak(); &#125;&#125;* C: 举例2学习完了构造方法、this的用法之后，现在做个小小的练习。需求：在Person类中定义功能，判断两个人是否是同龄人class Person &#123; private int age; private String name; // 给姓名和年龄初始化的构造方法 Person(String name, int age) &#123; // 当需要访问成员变量是，只需要在成员变量前面加上this.即可 this.name = name; this.age = age; &#125; public void speak() &#123; System.out.println("name=" + this.name + ",age=" + this.age); &#125; // 判断是否为同龄人 public boolean equalsAge(Person p) &#123; // 使用当前调用该equalsAge方法对象的age和传递进来p的age进行比较 // 由于无法确定具体是哪一个对象调用equalsAge方法，这里就可以使用this来代替 /* * if(this.age == p.age) &#123; return true; &#125; return false; */ return this.age == p.age; &#125;&#125; 12super关键字_1* A: 子父类中构造方法的调用 12345678 在创建子类对象时，父类的构造方法会先执行，因为子类中所有构造方法的第一行有默认的隐式super();语句。* B: 格式： 调用本类中的构造方法 this(实参列表); 调用父类中的空参数构造方法 super(); 调用父类中的有参数构造方法 super(实参列表); 13super关键字_2* A:子类构造方法,有一个默认添加的构造方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Student extends Person &#123; public Student()&#123; super(); &#125;&#125;* B :为什么子类对象创建都要访问父类中的构造方法？因为子类继承了父类的内容， 所以创建对象时，必须要先看父类是如何对其内容进行初始化的，看如下程序public class Test &#123; public static void main(String[] args) &#123; new Zi(); &#125; &#125;class Fu&#123; int num ; Fu()&#123; System.out.println("Fu构造方法"+num); num = 4; &#125;&#125;class Zi extends Fu&#123; Zi()&#123; //super(); 调用父类空参数构造方法 System.out.println("Zi构造方法"+num); &#125;&#125;执行结果： Fu构造方法0 Zi构造方法4通过结果发现，子类空参数构造方法执行时中，调用了父类空参数构造方法，这说明，子类空参数构造方法中有一句super()。@A: "【子类】中的【空参数构造方法】会有一句【隐式】的" super()原因：子类会继承父类中的内容，所以子类在初始化时，必须先到父类中去执行父类的初始化动作。这样，才可以使用父类中的内容。——————————————————————————————————————————————————————————————————————————————————————@B: "当父类中【没有】【空参数构造方法】时，子类的构造方法【必须】有【显示】的【super(参数)语句】， 指定要访问的父类【有参数】【构造方法】。否则报错！！！"public class Parent &#123; public Parent(String s)&#123; System.out.println("Parent"); &#125;&#125;public class Child extends Parent &#123; public Child(String s)&#123; super(s);//父类中【没有】【空参数构造方法】时，子类的构造方法【必须】有【显示】的【super(参数)语句】 System.out.println("Child"); &#125;&#125; 14子类父类的内存图 15super关键字_3* A: 创建子类对象的时候会必须调用父类的构造方法。 &quot;子类默认会调用父类的【无参构造】， 但如果父类【没有无参构造】，子类的构造方法继续调用父类的无参构造就会报错。&quot; &quot;因此子类构造方法的第一行需要调用父类的构造方法，既可以调用父类的无参构造，也可以调用父类的有参构造，这样语法上就不会报错。&quot; 16super关键字_41234567* A: 构造方法第一行,写this()还是super()* " this() 是调用本类的构造方法,super()是调用父类的构造方法, 且两条语句不能同时存在 "* " 保证子类的所有构造方法调用到父类的构造方法即可 "* B: 小结:*" 无论如何,子类的所有构造方法,直接或间接必须调用到父类构造方法;"* "子类的构造方法什么都不写,默认的构造方法第一行是super() ，即默认调用父类的空参数构造方法" 17创建子类对象过程的细节1234567891011121314* A 创建子类对象过程的细节* 如果子类的构造方法第一行写了this调用了本类其他构造方法，那么super调用父类的语句还有吗？* 这时是没有的，"因为this()或者super(),只能定义在构造方法的第一行，因为初始化动作要先执行。"* 父类构造方法中是否有隐式的super呢？* 也是有的。记住：只要是构造方法默认第一行都是super();* 父类的父类是谁呢？super调用的到底是谁的构造方法呢？* Java体系在设计，定义了一个所有对象的父类Object* 注意：* "类中的构造方法默认第一行都有【隐式】的super()语句，访问父类中的【空参数构造方法】。所以父类的构造方法既可以给自己的对象初始化，也可以给自己的子类对象初始化。如果默认的隐式super()语句在父类中【没有】对应的构造方法，那么必须在构造方法中通过 this(参数) 或者 super(参数) 的形式明确要调用的构造方法。" 18super的应用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152* A: 练习：描述学生和工人这两个类，将他们的共性name和age抽取出来存放在父类中，并提供相应的get和set方法，同时需要在创建学生和工人对象就必须明确姓名和年龄* 案例://定义Person类，将Student和Worker共性抽取出来class Person &#123; private String name; private int age; public Person(String name, int age) &#123; // super(); this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125;class Student extends Person &#123; // Student类的构造方法 Student(String name, int age) &#123; // 使用super关键字调用父类构造方法，进行相应的初始化动作 super(name, age); &#125; public void study() &#123;// Studnet中特有的方法 System.out.println(this.getName() + "同学在学习"); &#125;&#125;class Worker extends Person &#123; Worker(String name, int age) &#123; // 使用super关键字调用父类构造方法，进行相应的初始化动作 super(name, age); &#125; public void work() &#123;// Worker 中特有的方法 System.out.println(this.getName() + "工人在工作"); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; Student stu = new Student("小明",23);stu.study(); Worker w = new Worker("小李",45);w.work(); &#125;&#125; 19总结123456789101112131415161718192021222324252627282930313233343536373839404142434445this关键字this关键字，本类对象的引用this是在方法中使用的，哪个对象调用了该方法，那么，this就代表调用该方法的对象引用this什么时候存在的？当创建对象的时候，this存在的this的作用：用来区别同名的成员变量与局部变量（this.成员变量） public void setName(String name) &#123; this.name = name; &#125;————————————————————————————————————————————————————————————————————————————"构造方法"： "用来给类的成员进行初始化操作"格式： 修饰符 类名 (参数列表) &#123; ...&#125;构造方法的特点：1, 方法名与类名相同2，【"没有返回值】，也【没有】【返回值类型】"，连void也没有构造方法什么时候会被调用执行？ "【只有】在创建对象的时候才可以被调用"————————————————————————————————————————————————————————————————————————————super: 指的是父类的存储空间(理解为"【父类的引用】") "调用父类的【成员变量】"： super.成员变量; "调用父类的【构造方法】": super(参数); "调用父类的【成员方法】": super.成员方法();继承中的构造方法注意事项：1，"如果我们【手动给出了构造方法】，编译器【不会】再给我们提供【默认】的【空参数构造方法】如果我们【没写】任何的构造方法，编译器提供给我们【一个隐式空参数构造方法】"2, 在构造方法中，【默认】的第一条语句为 super();它是用来访问父类中的【空参数构造方法】，进行父类成员的初始化操作3, 当父类中【没有】【空参数构造方法】的时候，怎么办？ a: 通过 super(参数) "访问【父类】【有参数的构造方法】" b: 通过 this(参数) "访问【本类】中其他构造方法" 注意:"【本类】中的其他构造方法应满足已经能够正常访问【父类构造方法】， 即本类其他构造方法（含有super(参数)）"4, "super(参数) 与 this(参数) 【不能】同时在构造方法中存在" 20完整员工案例分析 * A: 项目介绍 某IT公司有多名员工，按照员工负责的工作不同，进行了部门的划分（研发部员工、维护部员工）。研发部根据所需研发的内容不同，又分为JavaEE工程师、Android工程师；维护部根据所需维护的内容不同，又分为网络维护工程师、硬件维护工程师。 公司的每名员工都有他们自己的员工编号、姓名，并要做它们所负责的工作。 工作内容 JavaEE工程师：员工号为xxx的 xxx员工，正在研发淘宝网站 Android工程师：员工号为xxx的 xxx员工，正在研发淘宝手机客户端软件 网络维护工程师：员工号为xxx的 xxx员工，正在检查网络是否畅通 硬件维护工程师：员工号为xxx的 xxx员工，正在修复打印机 请根据描述，完成员工体系中所有类的定义，并指定类之间的继承关系。进行XX工程师类的对象创建，完成工作方法的调用。 * B: 案例分析 根据上述部门的描述，得出如下的员工体系图 根据员工信息的描述，确定每个员工都有员工编号、姓名、要进行工作。则，把这些共同的属性与功能抽取到父类中（员工类），关于工作的内容由具体的工程师来进行指定。 工作内容 JavaEE工程师：员工号为xxx的 xxx员工，正在研发淘宝网站 Android工程师：员工号为xxx的 xxx员工，正在研发淘宝手机客户端软件 网络维护工程师：员工号为xxx的 xxx员工，正在检查网络是否畅通 硬件维护工程师：员工号为xxx的 xxx员工，正在修复打印机 创建JavaEE工程师对象，完成工作方法的调用 21案例代码实现* A:定义员工类(抽象类) 1234567891011121314151617181920212223242526272829public abstract class Employee &#123; private String id;// 员工编号 private String name; // 员工姓名 //空参数构造方法 public Employee() &#123; super(); &#125; //有参数构造方法 public Employee(String id, String name) &#123; super(); this.id = id; this.name = name; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; //工作方法（抽象方法） public abstract void work(); &#125; * B : 定义研发部员工类Developer 继承 员工类Employee 12345678910public abstract class Developer extends Employee &#123; //空参数构造方法 public Developer() &#123; super(); &#125; //有参数构造方法 public Developer(String id, String name) &#123; super(id, name); &#125;&#125; * C: 定义维护部员工类Maintainer 继承 员工类 1234567891011Employeepublic abstract class Maintainer extends Employee &#123; //空参数构造方法 public Maintainer() &#123; super(); &#125; //有参数构造方法 public Maintainer(String id, String name) &#123; super(id, name); &#125;&#125; * D: 定义JavaEE工程师 继承 研发部员工类，重写工作方法 public class JavaEE extends Developer { //空参数构造方法 public JavaEE() { super(); } //有参数构造方法 public JavaEE(String id, String name) { super(id, name); } @Override public void work() { System.out.println("员工号为 " + getId() + " 的 " + getName() + " 员工，正在研发淘宝网站"); } } * E: 定义Android工程师 继承 研发部员工类，重写工作方法 public class Android extends Developer { //空参数构造方法 public Android() { super(); } //有参数构造方法 public Android(String id, String name) { super(id, name); } @Override public void work() { System.out.println("员工号为 " + getId() + " 的 " + getName() + " 员工，正在研发淘宝手机客户端软件"); } } * F: 定义Network网络维护工程师 继承 维护部员工类，重写工作方法 public class Network extends Maintainer { //空参数构造方法 public Network() { super(); } //有参数构造方法 public Network(String id, String name) { super(id, name); } @Override public void work() { System.out.println("员工号为 " + getId() + " 的 " + getName() + " 员工，正在检查网络是否畅通"); } } * G: 定义Hardware硬件维护工程师 继承 维护部员工类，重写工作方法 public class Hardware extends Maintainer { //空参数构造方法 public Hardware() { super(); } //有参数构造方法 public Hardware(String id, String name) { super(id, name); } @Override public void work() { System.out.println("员工号为 " + getId() + " 的 " + getName() + " 员工，正在修复打印机"); } } * H: 在测试类中，创建JavaEE工程师对象，完成工作方法的调用 public class Test { public static void main(String[] args) { //创建JavaEE工程师员工对象，该员工的编号000015，员工的姓名 小明 JavaEE ee = new JavaEE("000015", "小明"); //调用该员工的工作方法 ee.work(); } }]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础9(接口，多态)]]></title>
    <url>%2F2016%2F10%2F12%2Fday11%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、接口2、多态 Java中引用数据类型只有三种，分别是类(class)、接口(interface)、数组。 Java把内存分成两种，一种叫做栈内存，一种叫做堆内存。在函数中定义的一些【基本类型的变量】和【对象的引用变量】都是在函数的【栈内存】中分配。 当在一段代码块中定义一个变量时，java就在栈中为这个变量分配内存空间，当超过变量的作用域后，java会自动释放掉为该变量分配的内存空间，该内存空间可以立刻被另作他用。 【堆内存用于存放由new创建的对象或数组】。在堆中分配的内存，由java虚拟机自动垃圾回收器来管理。在堆中产生了一个数组或者对象后，还可以在栈中定义一个特殊的变量，这个变量的取值等于【数组或者对象在堆内存中的首地址】，在栈中的这个特殊的变量就变成了数组或者对象的引用变量，以后就可以在程序中使用栈内存中的引用变量来访问堆中的数组或者对象，引用变量相当于为数组或者对象起的一个别名。 【引用变量是普通变量，定义时在栈中分配内存，引用变量在程序运行到作用域外释放。】而数组＆对象本身在堆中分配，即使程序运行到使用new产生数组和对象的语句所在地代码块之外，数组和对象本身占用的堆内存也不会被释放，【数组和对象在没有引用变量指向它的时候，才变成垃圾】，不能再被使用，但是仍然占着内存，在随后的一个不确定的时间被垃圾回收器释放掉。这个也是java比较占内存的主要原因，实际上，栈中的变量指向堆内存中的变量，这就是 Java 中的指针! 01接口的概念* A:接口的概念 接口是功能的集合，同样可看做是一种数据类型，是比抽象类更为抽象的”类”。 接口只描述所应该具备的方法，并没有具体实现，具体的实现由接口的实现类(相当于接口的子类)来完成。这样将功能的定义与实现分离，优化了程序设计。 请记住：一切事物均有功能，即一切事物均有接口。 02接口的定义123456789101112131415161718192021* A: 接口的定义 与定义类的class不同，接口定义时需要使用interface关键字。 定义接口所在的仍为.java文件，虽然声明时使用的为interface关键字的编译后仍然会产生.class文件。 这点可以让我们将接口看做是一种只包含了功能声明的特殊类。 * B : 定义格式 public interface 接口名 &#123; 抽象方法1; 抽象方法2; 抽象方法3;&#125;* C: 定义步骤 使用interface代替了原来的class，其他步骤与定义类相同： "接口中的方法均为【公共】访问的抽象方法": 定义为： public abstract 返回值类型 方法名(参数列表); 接口中无法定义普通的成员变量： public static final int NUM = 3;// NUM的值不能改变 03接口的实现类* A: 类与接口的关系 123456789101112131415"类与接口的关系为实现关系，即类实现接口"。实现的动作类似继承，只是关键字不同，"实现使用 implements "其他类(实现类)实现接口后，就相当于声明：”我应该具备这个接口中的功能”。实现类仍然需要重写方法以实现具体的功能。* B: 类实现接口的格式class 类 implements 接口 &#123; 重写接口中方法&#125; * C:注意事项"在类实现接口后，该类就会将接口中的抽象方法继承过来，此时该类需要重写该抽象方法，完成具体的逻辑。"接口中定义功能，当需要具有该功能时，可以让类实现该接口，只声明了应该具备该方法，是功能的声明。在具体实现类中重写方法，实现功能，是方法的具体实现。 04接口中成员变量的特点1234567891011A:成员变量特点* a 接口中可以定义变量，但是变量"必须有固定的修饰符修饰" public static final 所以"接口中的变量也称之为常量，其值不能改变"。后面我们会讲解static与final关键字* B:案例interface Demo &#123; ///定义一个名称为Demo的接口。 public static final int NUM = 3;// NUM的值不能改变 //可以省略不写修饰符public static final，接口默认是public static final int NUMBER = 5;&#125; 05接口中成员方法的特点12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455* A: 成员方法特点 * a 接口中可以定义方法，"方法也有固定的修饰符"，public abstract 同样，"可以省略不写"修饰符public abstract ，接口的成员方法"默认"是public abstract 但是，"在【实现类】中【重写】【接口中的方法】 【必须有】" public————————————————————————————————————————————————————————————————————————————————————————此外，注意： @1 接口中可以定义"静态方法"（static method）：public interface MyInterface &#123; public abstract void func(); public static void static_func()&#123; System.out.println("接口中可以定义\"静态方法\" "); &#125;&#125;"调用方式： 接口名.静态方法名(); MyInterface.static_func();"——————————————————————————————————————————————————————————@2 接口中可以定义"默认方法"（default method）:通过default修饰符标记该方法。public interface MyInterface &#123; public abstract void func(); default void method()&#123; System.out.println("接口中可以定义\"默认方法\" "); &#125;&#125;———————————————————————————————————————————————————————————————————————————————————————— * b "子类必须覆盖掉接口中【所有的抽象方法】后，子类才可以实例化。否则子类是一个抽象类。" * "所有接口中的成员变量【必须是静态常量】，由于【接口】【没有】【构造方法】， * 所以【必须显示赋值】。可以【直接】用【接口名】访问" * " 访问接口中的静态变量 ": * "接口名.变量名" Inter.COUNT* B: 案例interface Demo &#123; ///定义一个名称为Demo的接口。 public abstract void show1(); public abstract void show2(); void show3();&#125;//定义子类去覆盖接口中的方法。类与接口之间的关系是 实现。通过 关键字 implementsclass DemoImpl implements Demo &#123; //子类实现Demo接口。 //重写接口中的方法。 public void show1()&#123;&#125; public void show2()&#123;&#125; public void show3()&#123;&#125;&#125; 06实现类还是一个抽象类A: 接口的实现类 一个类如果实现类接口,有两种操作方法: 第一:实现类是【非抽象类】,就需要【重写接口中所有】的抽象方法. ———————————————————————————————————————————————————————————————————————————————————————— 第二:实现类也声明为【抽象类】,那么实现类【可以不重写】接口中的抽象方法。 07类和接口的多实现* A：接口的多实现 了解了接口的特点后，那么想想为什么要定义接口，使用抽象类描述也没有问题，接口到底有啥用呢？ 接口最重要的体现：解决多继承的弊端。将多继承这种机制在java中通过多实现完成了。 * B 多实现的优点 * 怎么解决多继承的弊端呢？ * 弊端：多继承时，当多个父类中有相同功能时，子类调用会产生不确定性。 * 其实核心原因就是在于多继承父类中功能有主体，而导致调用运行时，不确定运行哪个主体内容。 * 为什么多实现能解决了呢？ * 因为接口中的功能都没有方法体，由子类来明确。 C :案例演示 interface Fu1 { void show1(); } interface Fu2{ void show2(); } class Zi implements Fu1,Fu2 { // 多实现。同时实现多个接口。 public void show1(){} public void show2(){} } 08类在继承类的同时实现多接口A: 继承的同时实现接口 * 接口和类之间可以通过实现产生关系，同时也学习了类与类之间可以通过继承产生关系。当一个类已经继承了一个父类，它又需要扩展额外的功能，这时接口就派上用场了。 * 子类通过继承父类扩展功能，通过继承扩展的功能都是子类应该具备的基础功能。如果子类想要继续扩展其他类中的功能呢？这时通过实现接口来完成。 * 接口的出现避免了单继承的局限性。父类中定义的事物的基本功能。接口中定义的事物的扩展功能。 B: 代码演示1234567891011121314151617181920212223//父类：抽象类abstract class Fu &#123; public abstract void show();&#125;//接口interface Inter &#123; pulbic abstract void show1();&#125;//接口interface kock &#123; pulbic abstract void show1();&#125;//类Zi在继承父类Fu的同时实现多接口(Inter,kock) class Zi extends Fu implements Inter,kock &#123; //重写接口的抽象方法 public void show1() &#123; &#125; //重写父类的抽象方法 public void show()&#123; &#125;&#125;接口的出现避免了单继承的局限性。父类中定义的事物的基本功能。接口中定义的事物的扩展功能。 09接口的多继承* A: 接口的多继承 * 学习类的时候，知道类与类之间可以通过继承产生关系，接口和类之间可以通过实现产生关系，那么接口与接口之间会有什么关系。 ———————————————————————————————————————————————————————————————————————————————————————— * 【多个接口】之间可以使用【 extends 】进行【多继承】。 ———————————————————————————————————————————————————————————————————————————————————————— * 【类】【没有】【多继承】 ———————————————————————————————————————————————————————————————————————————————————————— * 【接口】【有】【多继承】 B 代码演示12345678910111213141516171819202122232425262728293031323334 interface AA&#123; void fun_A();&#125;interface BB&#123; void fun_B();&#125;interface CC&#123; void fun_C();&#125;//接口DD 多继承 AA,BB,CCinterface DD extends AA,BB,CC&#123; void fun_D();&#125;//EE类实现接口DDpublic class EE implements DD&#123;//EE类实现接口DD，需要重写DD以及DD多继承接口的全部抽象方法 public void fun_D()&#123; System.out.println("重写fun_D"); &#125; public void func_A()&#123; System.out.println("重写fun_A"); &#125; public void func_B()&#123; System.out.println("重写fun_B"); &#125; public void func_C()&#123; System.out.println("重写fun_C"); &#125;&#125;在开发中如果多个接口中存在相同方法，这时若有个类实现了这些接口，那么就要实现接口中的方法，由于接口中的方法是抽象方法，子类实现后也不会发生调用的不确定性。 10接口思想* A:接口的思想 * 前面学习了接口的代码体现，现在来学习接口的思想，接下里从生活中的例子进行说明。 * 举例：我们都知道电脑上留有很多个插口，而这些插口可以插入相应的设备，这些设备为什么能插在上面呢？ * 主要原因是这些设备在生产的时候符合了这个插口的使用规则，否则将无法插入接口中，更无法使用。发现这个插口的出现让我们使用更多的设备。 ———————————————————————————————————————————————————————————————————————————————————————— * B: 接口的好处 * 总结：接口在开发中的它好处 * 1、接口的出现扩展了功能。 * 2、接口其实就是暴漏出来的规则。 * 3、接口的出现【降低】了【耦合性】，即设备与设备之间实现了【解耦】。 * 接口的出现方便后期使用和维护，一方是在使用接口（如电脑），一方在实现接口（插在插口上的设备）。例如：笔记本使用这个规则（接口），电脑外围设备实现这个规则（接口）。 11接口和抽象类的区别* A: 明白了接口思想和接口的用法后，接口和抽象类的区别是什么呢？接口在生活体现也基本掌握，那在程序中接口是如何体现的呢？ 通过实例进行分析和代码演示抽象类和接口的用法。 * B: 举例： * 犬： 行为： 吼叫； 吃饭； * 缉毒犬： 行为： 吼叫； 吃饭； 缉毒； * C:思考： * 由于犬分为很多种类，他们吼叫和吃饭的方式不一样，在描述的时候不能具体化，也就是吼叫和吃饭的行为不能明确。 * 当描述行为时，行为的具体动作不能明确，这时，可以将这个行为写为抽象行为，那么这个类也就是抽象类。 * 可是当缉毒犬有其他额外功能时，而这个功能并不在这个事物的体系中。这时可以让缉毒犬具备犬科自身特点的同时也有其他额外功能，可以将这个额外功能定义接口中。 * D: 代码演示 1234567891011121314151617181920212223interface 缉毒&#123; public abstract void 缉毒();&#125;//定义犬科的共性功能abstract class 犬科&#123; public abstract void 吃饭(); public abstract void 吼叫();&#125;// 缉毒犬属于犬科一种，让其继承犬科，获取的犬科的特性，//由于缉毒犬具有缉毒功能，那么它只要实现缉毒接口即可，这样即保证缉毒犬具备犬科的特性，也拥有了缉毒的功能class 缉毒犬 extends 犬科 implements 缉毒&#123; public void 缉毒() &#123; &#125; void 吃饭() &#123; &#125; void 吼叫() &#123; &#125;&#125;class 缉毒猪 implements 缉毒&#123; public void 缉毒() &#123; &#125;&#125; * E: 接口和抽象类区别总结 123456789101112131415 相同点: 都位于继承的顶端,用于被其他类实现或继承; "【都不能】直接实例化对象"; "都包含抽象方法,其子类都必须覆写这些抽象方法才能实例化";区别: "抽象类为部分方法提供实现,避免子类重复实现这些方法,提高代码重用性;" "【抽象类】【可以】【不包含】 【抽象方法】" "【接口】【只能】【含有】【抽象方法】"; " 一个类只能继承一个直接父类(可能是抽象类),却可以实现多个接口;(接口弥补了Java的单继承) " 抽象类是这个事物中"应该具备的内容", 继承体系是一种 is..a关系 接口是这个事物中的"【额外内容】",继承体系是一种 like..a关系二者的选用: " 优先选用接口,尽量少用抽象类; " 需要定义子类的行为,又要为子类提供共性功能时才选用抽象类; 12多态概述* A: 多态概述 1234567891011121314151617多态是继封装、继承之后，面向对象的第三大特性。现实事物经常会体现出多种形态，如学生，学生是人的一种，则一个具体的同学张三既是学生也是人，即出现两种形态。 Java作为面向对象的语言，同样可以描述一个事物的多种形态。如Student类继承了Person类，一个Student的对象便既是Student，又是Person。**************************************************************" Java中多态的代码体现在一个子类对象(实现类对象)既可以给这个子类(实现类对象)引用变量赋值，又可以给这个子类(实现类对象)的父类(接口)变量赋值。"**************************************************************如Student类可以为Person类的子类。那么一个Student对象既可以赋值给一个Student类型的引用，也可以赋值给一个Person类型的引用。**************************************************************" 最终多态体现为父类引用变量可以指向子类对象。多态的前提是必须有子父类关系或者类实现接口关系，否则无法完成多态。 "**************************************************************" 在使用多态后的【父类引用变量】【调用方法】时，会调用【子类】【重写】后的方法。"**************************************************************【多态的缺点】："【父类】【不能】调用【子类】的【特有内容】，需要【向下转型】调用子类的【特有内容】" 13多态调用的三种格式123456789101112131415161718192021222324252627282930313233343536373839404142434445* A:"多态的定义格式"： * 就是父类的引用变量指向子类对象 父类类型 变量名 = new 子类类型(); 变量名.方法名();* B: "普通类多态定义的格式" 父类 变量名 = new 子类(); 举例： class Fu &#123;&#125; class Zi extends Fu &#123;&#125; //类的多态使用 Fu f = new Zi();* C: "抽象类多态定义格式" 抽象类 变量名 = new 抽象类子类(); 举例： abstract class Fu &#123; public abstract void method(); &#125; class Zi extends Fu &#123; public void method()&#123; System.out.println("重写父类抽象方法"); &#125; &#125; //类的多态使用 Fu fu= new Zi();* D: "接口多态定义的格式" 接口 变量名 = new 接口实现类(); 如： interface Fu &#123; public abstract void method(); &#125; class Zi implements Fu &#123; public void method()&#123; System.out.println("重写接口抽象方法"); &#125; &#125; //接口的多态使用 Fu fu = new Zi();* E: "注意事项" "同一个父类的方法会被不同的子类重写。在调用方法时，调用的为各个子类重写后的方法。" 如 Person p1 = new Student(); Person p2 = new Teacher(); p1.work(); //p1会调用Student类中重写的work方法 p2.work(); //p2会调用Teacher类中重写的work方法 当变量名指向不同的子类对象时，由于每个子类重写父类方法的内容不同，所以会调用不同的方法。 14多态成员方法的特点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253* A: 掌握了多态的基本使用后，那么多态出现后类的成员有啥变化呢？* 前面学习继承时，我们知道子父类之间成员变量有了自己的特定变化， * 那么当多态出现后，成员变量在使用上有没有变化呢？ * 多态出现后会导致子父类中的成员变量有微弱的变化* B: 代码演示 class Fu &#123; int num = 4; &#125; class Zi extends Fu &#123; int num = 5; &#125; class Demo &#123; public static void main(String[] args) &#123; Fu f = new Zi(); System.out.println(f.num);//4 Zi z = new Zi(); System.out.println(z.num);//5 &#125; &#125;* C: "多态成员变量"* " &lt;&lt;参考基础11.[12]&gt;&gt;" "当子父类中出现同名的成员变量时，多态调用该变量时： 编译时期：参考的是引用型变量所属的类中是否有被调用的成员变量。没有，编译失败。 运行时期：也是调用引用型变量所属的类中的成员变量。" "简单记：编译和运行都参考等号的左边。编译运行看左边。"* D: 多态出现后会导致子父类中的成员方法有微弱的变化。看如下代码 class Fu &#123; int num = 4; void show() &#123; System.out.println("Fu show num"); &#125; &#125; class Zi extends Fu &#123; int num = 5; void show() &#123; System.out.println("Zi show num"); &#125; &#125; class Demo &#123; public static void main(String[] args) &#123; Fu f = new Zi(); f.show(); &#125; &#125;* E: "多态成员方法" "编译时期：参考引用变量所属的类，如果没有类中没有调用的方法，编译失败。 运行时期：参考引用变量所指的对象所属的类，并运行对象所属类中的成员方法。 简而言之：编译看左边，运行看右边。" 1234567891011121314151617181920212223242526public class Base&#123; private String baseName = "base"; public Base() &#123; callName(); &#125; public void callName() &#123; System. out. println(baseName); &#125; static class Sub extends Base &#123; private String baseName = "sub"; public void callName() &#123; System. out. println (baseName) ; &#125; &#125; public static void main(String[] args) &#123; Base b = new Sub(); &#125;&#125; A.首先，需要明白类的加载顺序。(1) 父类静态代码块(包括静态初始化块，静态属性，但不包括静态方法)(2) 子类静态代码块(包括静态初始化块，静态属性，但不包括静态方法 )(3) 父类非静态代码块( 包括非静态初始化块，非静态属性 )(4) 父类构造函数(5) 子类非静态代码块 ( 包括非静态初始化块，非静态属性 )(6) 子类构造函数其中：类中静态块按照声明顺序执行，并且(1)和(2)不需要调用new类实例的时候就执行了(意思就是在类加载到方法区的时候执行的) B.其次，需要理解子类覆盖父类方法的问题，也就是方法重写实现多态问题。Base b = new Sub();它为多态的一种表现形式，声明是Base,实现是Sub类， 理解为 b 编译时表现为Base类特性，运行时表现为Sub类特性。当子类覆盖了父类的方法后，意思是父类的方法已经被重写，题中 父类初始化调用的方法为子类实现的方法，子类实现的方法中调用的baseName为子类中的私有属性。由A.可知，此时只执行到步骤4.,子类非静态代码块和初始化步骤还没有到，子类中的baseName还没有被初始化。所以此时 baseName为空。 所以为null。 15instanceof关键字12345678910* A: 作用 可以通过instanceof关键字来判断某个对象是否属于某种数据类型。如学生的对象属于学生类，学生的对象也属于人类* 格式: boolean b = 对象 instanceof 数据类型;* 举例: Person p1 = new Student(); // 前提条件，学生类已经继承了人类 boolean flag = p1 instanceof Student; //flag结果为true boolean flag2 = p1 instanceof Teacher; //flag2结果为false 16多态-向上转型* A: 多态的转型分为向上转型与向下转型两种： * B: 向上转型(自动类型转换)： * 当有子类对象赋值给一个父类引用时，便是向上转型，多态本身就是向上转型的过程。 123使用格式：父类类型 变量名 = new 子类类型();如：Person p = new Student(); 17多态-向下转型* A: 向下转型(强制类型转换)： 1234567891011* 一个已经向上转型的子类对象可以使用强制类型转换的格式，* "将【父类引用类型】强制转为【子类引用类型】，这个过程是向下转型。"* "好处：可以调用子类特有的方法"* "如果是直接创建父类对象，是无法向下转型的！" 使用格式： Person p = new Student();————————————————————————————————————————————————————————————————" 子类类型 变量名 = (子类类型) 父类类型的变量; " 如:Student stu = (Student) p; //变量p 实际上指向Student对象———————————————————————————————————————————————————————————————— 18多态的好处和弊端1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950* A: 多态的好处和弊端 * 当父类的引用指向子类对象时，就发生了向上转型，即把子类类型对象转成了父类类型。 向上转型的好处是隐藏了子类类型，提高了代码的扩展性。 * "但向上转型也有弊端，只能使用【父类共性】的内容，而【无法】使用【子类特有功能】，功能有限制"。 * B: 看如下代码 //描述动物类，并抽取共性eat方法 abstract class Animal &#123; abstract void eat(); &#125; // 描述狗类，继承动物类，重写eat方法，增加lookHome方法 class Dog extends Animal &#123; void eat() &#123; System.out.println("啃骨头"); &#125; void lookHome() &#123; System.out.println("看家"); &#125; &#125; // 描述猫类，继承动物类，重写eat方法，增加catchMouse方法 class Cat extends Animal &#123; void eat() &#123; System.out.println("吃鱼"); &#125; void catchMouse() &#123; System.out.println("抓老鼠"); &#125; &#125; public class Test &#123; public static void main(String[] args) &#123; Animal a = new Dog(); //多态形式，创建一个狗对象 a.eat(); // 调用对象中的方法，会执行狗类中的eat方法 // a.lookHome();//使用Dog类特有的方法，需要向下转型，不能直接使用 // 为了使用狗类的lookHome方法，需要向下转型 // 向下转型过程中，可能会发生类型转换的错误，即ClassCastException异常 // 那么，在转之前需要做健壮性判断 if( !a instanceof Dog)&#123; // 判断当前对象是否是Dog类型 System.out.println("类型不匹配，不能转换"); return; &#125; Dog d = (Dog) a; //向下转型 d.lookHome();//调用狗类的lookHome方法 &#125; &#125; 123456789101112131415* C 多态总结:"什么时候使用向上转型： 当【不需要】面对子类类型时，通过提高扩展性，或者使用父类的功能就能完成相应的操作，这时就可以使用向上转型。" 如： Animal a = new Dog(); a.eat();"什么时候使用向下转型 当要使用【子类特有功能】时，就需要使用【向下转型】。" 如：Dog d = (Dog) a; //向下转型 d.lookHome();//调用狗类的lookHome方法 "向下转型的好处：可以使用子类特有功能。" "弊端是：需要面对具体的【子类对象】；在向下转型时容易发生 ClassCastException 类型转换异常。 在转换之前必须做类型判断。"如：if( !a instanceof Dog)&#123;…&#125; 19多态举例12345678910111213141516171819202122232425262728293031323334353637383940* A: 刘老师和刘大爷的故事* 案例: /* 描述刘老师和刘大爷， 刘老师拥有讲课和看电影功能 刘大爷拥有讲课和钓鱼功能 */ class 刘大爷 &#123; void 讲课() &#123; System.out.println("语文"); &#125; void 钓鱼() &#123; System.out.println("钓鱼"); &#125; &#125; // 刘老师继承了刘大爷，就有拥有了刘大爷的讲课和钓鱼的功能， // 但刘老师和刘大爷的讲课内容不一样，因此刘老师要覆盖刘大爷的讲课功能 class 刘老师 extends 刘大爷 &#123; void 讲课() &#123; System.out.println("Java"); &#125; void 看电影() &#123; System.out.println("看电影"); &#125; &#125; public class Test &#123; public static void main(String[] args) &#123; // 多态形式 刘大爷 a = new 刘老师(); // 向上转型 a.讲课(); // 这里表象是刘大爷，其实真正讲课的仍然是刘老师，因此调用的也是刘老师的讲课功能 a.钓鱼(); // 这里表象是刘大爷，但对象其实是刘老师，而刘老师继承了刘大爷，即刘老师也具有钓鱼功能 // 当要调用刘老师特有的看电影功能时，就必须进行类型转换 刘老师 b = (刘老师) a; // 向下转型 b.看电影(); &#125; 20笔记本电脑案例 * A:案例介绍 * 定义USB接口（具备开启功能、关闭功能），笔记本要使用USB设备，即笔记本在生产时需要预留可以插入USB设备的USB接口，即就是笔记本具备使用USB设备的功能， * 但具体是什么USB设备，笔记本并不关心，只要符合USB规格的设备都可以。鼠标和键盘要想能在电脑上使用，那么鼠标和键盘也必须遵守USB规范，不然鼠标和键盘的生产出来无法使用 * 进行描述笔记本类，实现笔记本使用USB鼠标、USB键盘 USB接口，包含开启功能、关闭功能 笔记本类，包含运行功能、关机功能、使用USB设备功能 鼠标类，要符合USB接口 键盘类，要符合USB接口 * B: 案例分析 * 阶段一： 使用笔记本，笔记本有运行功能，需要笔记本对象来运行这个功能 * 阶段二： 想使用一个鼠标，又有一个功能使用鼠标，并多了一个鼠标对象。 * 阶段三： 还想使用一个键盘 ，又要多一个功能和一个对象 * 问题：每多一个功能就需要在笔记本对象中定义一个方法，不爽，程序扩展性极差。 降低鼠标、键盘等外围设备和笔记本电脑的耦合性。 21笔记本电脑案例代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172* A: 代码实现定义鼠标、键盘，笔记本三者之间应该遵守的规则interface USB &#123; void open();// 开启功能 void close();// 关闭功能&#125; 鼠标实现USB规则class Mouse implements USB &#123; public void open() &#123; System.out.println("鼠标开启"); &#125; public void close() &#123; System.out.println("鼠标关闭"); &#125;&#125; 键盘实现USB规则class KeyBoard implements USB &#123; public void open() &#123; System.out.println("键盘开启"); &#125; public void close() &#123; System.out.println("键盘关闭"); &#125;&#125; 定义笔记本class NoteBook &#123; // 笔记本开启运行功能 public void run() &#123; System.out.println("笔记本运行"); &#125; // 笔记本使用usb设备，这时当笔记本对象调用这个功能时，必须给其传递一个符合USB规则的USB设备 public void useUSB(USB usb) &#123; // 判断是否有USB设备 if (usb != null) &#123; usb.open(); usb.close(); &#125; &#125; public void shutDown() &#123; System.out.println("笔记本关闭"); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; // 创建笔记本实体对象 NoteBook nb = new NoteBook(); // 笔记本开启 nb.run(); // 创建鼠标实体对象 Mouse m = new Mouse(); // 笔记本使用鼠标 nb.useUSB(m); // 创建键盘实体对象 KeyBoard kb = new KeyBoard(); // 笔记本使用键盘 nb.useUSB(kb); // 笔记本关闭 nb.shutDown(); &#125;&#125; 22小结接口：理解为是一个特殊的抽象类，但它不是类，是一个接口——————————————————————————————————————————————————————————接口的特点：1234561，定义一个接口用interface关键字 interface Inter&#123;&#125; 2，一个类实现一个接口，实现implements关键字 class Demo implements Inter&#123;&#125; 3, 接口不能直接创建对象 通过多态的方式，由子类来创建对象，接口多态 ——————————————————————————————————————————————————————————接口中的成员特点：12345678成员变量： 只能是final 修饰的常量 默认修饰符： public static final构造方法： 无成员方法： 只能是抽象方法 默认修饰符: public abstract ——————————————————————————————————————————————————————————类与类，类与接口，接口与接口之间的关系 类与类之间：继承关系，单继承，可以是多层继承 类与接口之间: 实现关系，单实现，也可以多实现 接口与接口之间：继承关系，单继承，也可以是多继承 Java中的类可以继承一个父类的同时，实现多个接口 ——————————————————————————————————————————————————————————多态：理解为同一种物质的多种形态多态使用的前提： 1，有继承或者实现关系 2，要方法重写 3，父类引用指向子类对象 —————————————————————————————————————————————————————————— 多态的成员访问特点： 方法的运行看右边，其他都看左边 多态的好处： 提高了程序的扩展性 —————————————————————————————————————————————————————————— 多态的弊端： 不能访问子类的特有功能 —————————————————————————————————————————————————————————— 多态的分类 ——————————————————————————————————————————————————————————类的多态1234567891011abstract class Fu &#123; public abstract void method();&#125;class Zi extends Fu &#123; public void method()&#123; System.out.println(“重写父类抽象方法”);&#125;&#125;//类的多态使用Fu fu= new Zi(); ——————————————————————————————————————————————————————————接口的多态12345678910interface Fu &#123; public abstract void method();&#125;class Zi implements Fu &#123; public void method()&#123; System.out.println(“重写接口抽象方法”);&#125;&#125;//接口的多态使用Fu fu = new Zi(); ——————————————————————————————————————————————————————————instanceof 关键字 格式： 对象名 instanceof 类名 返回值： true, false 作用： 判断指定的对象 是否为 给定类创建的对象]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础8(继承，抽象类)]]></title>
    <url>%2F2016%2F10%2F11%2Fday10%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、继承2、抽象类3、综合案例—员工类系列定义 01继承的概述*A:继承的概念 *a:继承描述的是事物之间的所属关系，通过继承可以使多种事物之间形成一种关系体系 *b:在Java中，类的继承是指在一个现有类的基础上去构建一个新的类， 构建出来的新类被称作子类，现有类被称作父类 *B:继承关系的子类特点 *a:子类会自动拥有父类所有非private修饰的属性和方法 02继承的定义格式和使用123456789101112131415161718192021222324252627282930313233343536373839*A:继承的格式 class 子类 extends 父类 &#123;&#125;*B:雇员(Employee)与研发部员工(Developer)案例: *cn.itcast.demo01包下: *Employee.java: /* * 定义员工类Employee */ class Employee &#123; String name; // 定义name属性 public void work() &#123;// 定义员工的工作方法 System.out.println("尽心尽力地工作"); &#125; &#125; *Developer.java: /* * 定义研发部员工类Developer 继承 员工类Employee * 继承了父类中所有非private修饰的成员变量 */ class Developer extends Employee &#123; // 定义一个打印name的方法 public void printName() &#123; System.out.println("name=" + name); &#125; &#125; *测试员工类与研发部员工类: /* * 定义测试类 */ public class Example01 &#123; public static void main(String[] args) &#123; Developer d = new Developer(); // 创建一个研发部员工类对象 d.name = "小明"; // 为该员工类的name属性进行赋值 d.printName(); // 调用该员工的printName()方法 d.work(); // 调用Developer类继承来的work()方法 &#125; &#125; *通过子类对象既可以调用自身的非private修饰的成员,也可以调用父类的非private修饰的成员 03继承的好处*A:继承的好处： *1、继承的出现提高了代码的复用性，提高软件开发效率。 *2、继承的出现让类与类之间产生了关系，提供了多态的前提。 04继承的注意事项1234567891011121314151617181920212223242526272829303132333435363738394041424344 *A:继承的注意事项 *a:在Java中，类只支持单继承，不允许多继承，也就是说一个类只能有一个直接父类，例如下面这种情况是不合法的。 class A&#123;&#125; class B&#123;&#125; class C extends A,B&#123;&#125; // C类不可以同时继承A类和B类 假如支持多继承例如: class A&#123; int a=3; public void method()&#123; &#125; &#125; class B&#123; int a=5; public void method()&#123; &#125; &#125; class C extends A,B&#123; &#125; class Demo&#123; public static void main(String[] args)&#123; C c=new C(); System.out.println(c.a);//到底是调用A的还是B的成员变量??无法确定 c.method();//到底是调用A的还是B的成员方法??无法确定 &#125; &#125; *b:多个类可以继承一个父类，例如下面这种情况是允许的(就像你爹可以多个儿子,但是这些儿子都只有一个爹) class A&#123;&#125; class B extends A&#123;&#125; class C extends A&#123;&#125; // 类B和类C都可以继承类A *c:在Java中，多层继承是可以的， 即一个类的父类可以再去继承另外的父类， 例如C类继承自B类，而B类又可以去继承A类，这时，C类也可称作A类的子类。下面这种情况是允许的。 class A&#123;&#125; class B extends A&#123;&#125; // 类B继承类A，类B是类A的子类 class C extends B&#123;&#125; // 类C继承类B，类C是类B的子类，同时也是类A的子类 *d:在Java中，子类和父类是一种相对概念， 也就是说一个类是某个类父类的同时，也可以是另一个类的子类。 例如上面的这种情况中，B类是A类的子类，同时又是C类的父类。 05继承的体系 *A:继承的体系: 动物(吃) | ------------------------- | | 猫科动物(吃,胎生) 爬行动物(吃,卵生) | | ------------------------------- ----------------- | | | | 猫(吃,抓老鼠,胎生) 虎(吃,领地,胎生) 蛇(吃,冬眠,卵生) 鳄鱼(吃,潜水,卵生) *a:动物体系是对每个具体事物共性的抽取,子类的共性抽取形成父类 *b:父类:具有所有子类的共性内容 子类:不但有共性还有自身特有的内容 *c:整个继承体系,越向上越抽象,越向下越具体 06继承后子类父类成员变量的特点123456789101112131415161718192021222324252627A:继承后子类父类成员变量的特点 a:子类的对象调用成员变量的时候,子类自己有,使用子类,子类自己没有调用的父类 class Fu&#123; //Fu中的成员变量。 int num = 5; &#125; class Zi extends Fu&#123; //Zi中的成员变量 int num2 = 6; //Zi中的成员方法 public void show() &#123; //访问父类中的num System.out.println("Fu num="+num); //访问子类中的num2 System.out.println("Zi num2="+num2); &#125; &#125; class Demo&#123; public static void main(String[] args) &#123; Zi z = new Zi(); //创建子类对象 z.show(); //调用子类中的show方法 &#125; &#125; 12345678910111213141516171819202122232425262728293031323334 b:当子父类中出现了同名成员变量 class Fu&#123; //Fu中的成员变量。 int num = 5;&#125;class Zi extends Fu&#123; //Zi中的成员变量 int num = 6; void show()&#123; //子类的局部变量 int num=7 //直接访问,遵循就近查找原则 System.out.println(num);//7 //子父类中出现了同名的成员变量时 //在子类中需要访问父类中非私有成员变量时，需要使用super关键字 //访问父类中的num System.out.println("Fu num="+super.num);//5 //访问子类中的num2 System.out.println("Zi num2="+this.num);//6 &#125;&#125;class Demo5 &#123; public static void main(String[] args) &#123; Zi z = new Zi(); //创建子类对象 z.show(); //调用子类中的show方法 &#125;&#125; 07继承后子类父类成员方法的特性_子类重写父类方法12345678910111213141516171819A:继承后子类父类成员方法的特性 a:子类的对象调用方法的时候,子类自己有,使用子类,子类自己没有调用的父类 class Fu&#123; public void show()&#123; System.out.println("Fu类中的show方法执行"); &#125; &#125; class Zi extends Fu&#123; public void show2()&#123; System.out.println("Zi类中的show2方法执行"); &#125; &#125; public class Test&#123; public static void main(String[] args) &#123; Zi z = new Zi(); z.show(); //子类中没有show方法，但是可以找到父类方法去执行 z.show2(); &#125; &#125; 12345678910111213b:为什么要有重写? class Fu&#123; public void method()&#123; //上千行代码 //Fu类中的方法最先存在,那么如果项目需求变了,该方法 //功能不能够满足我们的需求,此时我们也不会去改这个方法 //因为项目中可能有大量的功能已经使用到该方法,如果随意修改可能使调用该方法的功能出现问题 //所以使用重写方式基于原有功能提供更强的功能 &#125; &#125; class Zi extends Fu&#123; &#125; 12345678910111213141516171819 c:子类中出现与父类一模一样的方法时，会出现覆盖操作，也称为override重写、复写或者覆盖 class Fu&#123; public void show()&#123; System.out.println("Fu show"); &#125; &#125; class Zi extends Fu&#123; //子类复写了父类的show方法 public void show()&#123; System.out.println("Zi show"); &#125;&#125; public class Test&#123; public static void main(String[] args) &#123; Zi z = new Zi(); z.show(); //Zi show 子类有直接使用子类 &#125;&#125; 08方法覆盖的需求A:方法覆盖的需求 a:案例:比如手机，当描述一个手机时，它具有发短信，打电话，显示来电号码功能， 后期由于手机需要在来电显示功能中增加显示姓名和头像， 这时可以重新定义一个类描述智能手机，并继承原有描述手机的类。 并在新定义的类中覆盖来电显示功能，在其中增加显示姓名和头像功能 b:分析:我们不改装(破坏)原来的手机,而是再买一个新的智能手机,不但有原有的功能,而且还有特有功能 例:厂商发布新手机都是基于原有手机的升级,不会拿着原有的手机在卖,新产一款 1:分析类的构建: 手机类 属性(成员变量):无 行为(成员方法): 发短信 打电话 来电显示:显示来电号码 智能手机类: 属性(成员变量):无 行为(成员方法): 发短信 打电话 来电显示:显示来电号码,显示姓名和头像 手机类和智能手机类有共性内容: 发短信 打电话 显示来电号码 2:继承关系分析: 对于发短信和打电话功能,让智能手机直接沿用(继承)手机的就可以 但是在智能手机中的来电显示不但实现号码,还显示姓名和头像,同样的都是来电显示功能,智能手机的来电显示比手机的功能更加强大,我们考虑使用重写 09方法覆盖的手机案例实现12345678910111213141516171819202122232425262728293031323334353637//手机类class Phone&#123; public void sendMessage()&#123; System.out.println("发短信"); &#125; public void call()&#123; System.out.println("打电话"); &#125; public void showNum()&#123; System.out.println("来电显示号码"); &#125;&#125;//智能手机类class NewPhone extends Phone&#123; //覆盖父类的来电显示号码功能，并增加自己的显示姓名和图片功能 //从现实生活角度考虑沿用原有的showNum方法名便于用户更快熟悉和接受,而不是再起个新的名字 //用户还需要花费大量时间慢慢接受 public void showNum()&#123; //调用父类已经存在的功能使用super //如果不加super这是调用子类自身的showNum(),自己调用自己,递归 //方法不断入栈导致内存溢出 super.showNum(); //增加自己特有显示姓名和图片功能 System.out.println("显示来电姓名"); System.out.println("显示头像"); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; new NewPhone().showNum();//来电显示 显示来电姓名 显示头像 &#125;&#125; 10方法覆盖的注意事项1234567891011121314151617181920A:方法覆盖的注意事项 a:"权限:【子类方法】覆盖【父类方法】，【必须要保证】子类权限【大于等于】父类权限"。 四大权限:public&gt;默认=protected&gt;private class Fu&#123; void show()&#123;&#125;public void method()&#123;&#125; &#125; class Zi() extends Fu&#123;public void show()&#123;//编译运行没问题&#125; void method()&#123;//编译错误 &#125; &#125; 1234567891011121314151617181920212223242526272829303132 b:方法定义:子类方法和要重写的父类的方法:"方法的方法名和参数列表都要一样。" 关于方法的返回值:"如果是【基本数据类型】,子类的方法和重写的父类的方法【返回值类型】【必须相同】"" 如果是【引用数据类型】,子类的方法和重写的父类的方法【返回值类型】【可以相同】 或者【子类方法的返回值类型】是父类方法返回值类型的【子类】""【父类方法返回值类型】&gt;= 【子类方法的返回值类型】" class Fu&#123; int show()&#123; &#125; public Fu method()&#123; &#125; public Fu method2()&#123; &#125; &#125; class Zi() extends Fu&#123; public int show()&#123;//返回值为基本类型的重写 &#125; public Fu method()&#123;//子类的方法和重写的父类的方法返回值类型可以相同 &#125; public Zi method2()&#123;//子类方法的返回值类型是父类方法返回值类型的子类 &#125; &#125; 123456789101112131415161718192021222324252627 c:重载与重写对比: 重载: 权限修饰符(public private 默认):无关 方法名:重载的两个方法的方法名必须相同 形参列表: "形参类型的顺序不同 形参的个数不同 形参的类型不同 三者至少满足一个" 返回值类型: "重载与返回值类型无关"重写: 权限修饰符(public private 默认): "子类方法的权限&gt;=父类的方法的权限" 方法名: "子类方法和父类方法必须相同" 形参列表: "子类方法和父类方法的形参列表必须相同" 返回值类型: "基本类数据类型: 必须相同" "引用数据类型: 子类方法的返回值类型和父类方法的返回值类型相同 或者 子类方法的返回值类型是父类方法的返回值类型的 子类" "【父类方法返回值类型】⊇【子类方法的返回值类型】" 11抽象类的产生A:抽象类的产生 a:分析事物时，发现了共性内容，就出现向上抽取。会有这样一种特殊情况，就是方法功能声明相同，但方法功能主体不同。那么这时也可以抽取，但只抽取方法声明，不抽取方法主体。那么此方法就是一个抽象方法。 12抽象类的定义格式A:抽象方法定义的格式： 123456789101112131415161718192021222324 a:public abstract 返回值类型 方法名(参数); 抽象类定义的格式：abstract class 类名 &#123; &#125; b:抽象类示例代码： /* * 定义类开发工程师类 * EE开发工程师 : 工作 * Android开发工程师 : 工作 * * 根据共性进行抽取,然后形成一个父类Develop * 定义方法,工作: 怎么工作,具体干什么呀 * * 抽象类,不能实例化对象, 不能new的 * 不能创建对象的原因: 如果真的让你new了, 对象.调用抽象方法,抽象方法没有主体,根本就不能运行 * 抽象类使用: 定义类继承抽象类,将抽象方法进行重写,创建子类的对象 */public abstract class Develop &#123; //定义方法工作方法,但是怎么工作,说不清楚了,讲不明白 //就不说, 方法没有主体的方法,必须使用关键字abstract修饰 //抽象的方法,必须存在于抽象的类中,类也必须用abstract修饰 public abstract void work();&#125; 13抽象类的使用方式123456789101112131415161718192021222324252627282930313233343536 A:抽象类的使用方式 /* * 定义类,JavaEE的开发人员 * 继承抽象类Develop,重写抽象的方法 */public class JavaEE extends Develop&#123; //重写父类的抽象方法 //去掉abstract修饰符,加上方法主体 public void work()&#123; System.out.println("JavaEE工程师在开发B/S 软件"); &#125;&#125;/* * 定义Android类,继承开发人员类 * 重写抽象方法 */public class Android extends Develop&#123; public void work()&#123; System.out.println("Android工程师开发手机软件"); &#125;&#125;/* * 测试抽象类 * 创建他的子类的对象,使用子类的对象调用方法 */public class Test &#123; public static void main(String[] args) &#123; JavaEE ee = new JavaEE(); ee.work();//"JavaEE工程师在开发B/S 软件" Android and = new Android(); and.work();//"Android工程师开发手机软件" &#125;&#125; 14抽象类特点 A:抽象类的特点a:抽象类和抽象方法都需要被abstract修饰。抽象方法一定要定义在抽象类中。b:抽象类不可以直接创建对象，原因：调用抽象方法没有意义。c:【只有覆盖了抽象类中所有的抽象方法后】，其子类才可以创建对象。【否则该子类还是一个抽象类】。之所以继承抽象类，更多的是在思想，是面对共性类型操作会更简单。12345678910111213141516abstract class A&#123; public abstract void func(); public abstract void func2();&#125;class A2 extends A&#123;//A2把A中的两个抽象方法都重写掉了 //A2类不再是抽象类 public void func()&#123;&#125; public void func2()&#123;&#125;&#125;abstract class A3 extends A&#123;//含有抽象方法的类一定是抽象类 public void func()&#123; &#125; //public abstract void func2();//func2相当于被继承下来&#125; 15抽象类的设计思想A:抽象类的设计思想 a:抽象类的作用:继承的体系抽象类,强制子类重写抽象的方法 抽象员工: 规定一个方法,work工作 EE员工,Android员工 Develop类 抽象类 abstract work(); | ------------- | | EE Android //是我开发的一员必须工作 work(){} work(){} 16抽象类的细节 A:抽象类的细节 a:抽象类一定是个父类？ 是的，因为不断抽取而来的。 b:抽象类中是否可以不定义抽象方法?1234567891011121314151617181920212223 是可以的，那这个抽象类的存在到底有什么意义呢？不让该类创建对象,方法可以直接让子类去使用 (适配器设计模式) /* * "抽象类,可以没有抽象方法,可以定义带有方法体的方法" * 让子类继承后,可以直接使用 */public abstract class Animal &#123; public void sleep()&#123; System.out.println("动物睡觉"); &#125; &#125;public class Cat extends Animal&#123; &#125; public class Test &#123; public static void main(String[] args) &#123; //Cat c = new Cat(); new Cat().sleep();//不让该类创建对象,方法可以直接让子类去使用 &#125; &#125; c:抽象关键字abstract不可以和哪些关键字共存？ 1234567891011121314151617181:private：私有的方法子类是无法继承到的，也不存在覆盖， 而abstract和private一起使用修饰方法，abstract既要子类去实现这个方法, 而private修饰子类根本无法得到父类这个方法。互相矛盾。 /* * 抽象类,可以没有抽象方法,可以定义带有方法体的方法 * 让子类继承后,可以直接使用 */public abstract class Animal &#123; // private abstract void show(); //抽象方法,需要子类重写, 如果父类方法是私有的,子类继承不了,也就没有了重写&#125;2:final，，后面学3:static，后面学 17员工案例分析A:员工案例分析: a:需求描述: 某IT公司有多名员工，按照员工负责的工作不同，进行了部门的划分（研发部员工、维护部员工）。 研发部根据所需研发的内容不同，又分为JavaEE工程师、Android工程师； 维护部根据所需维护的内容不同，又分为网络维护工程师、硬件维护工程师。 公司的每名员工都有他们自己的员工编号、姓名，并要做它们所负责的工作。  工作内容  JavaEE工程师：员工号为xxx的 xxx员工，正在研发淘宝网站  Android工程师：员工号为xxx的 xxx员工，正在研发淘宝手机客户端软件  网络维护工程师：员工号为xxx的 xxx员工，正在检查网络是否畅通  硬件维护工程师：员工号为xxx的 xxx员工，正在修复打印机 b:继承体系: 员工 | -------------------------------------------- | | 研发部员工 维护部员工 | | ------------- ----------- | | | | JavaEE工程师 Android工程师 网络维护工程师 硬件维护工程师 c:详细描述:  根据员工信息的描述，确定每个员工都有员工编号、姓名、要进行工作。 则，把这些共同的属性与功能抽取到父类中（员工类）， 关于工作的内容由具体的工程师来进行指定。  工作内容  JavaEE工程师：员工号为xxx的 xxx员工，正在研发淘宝网站  Android工程师：员工号为xxx的 xxx员工，正在研发淘宝手机客户端软件  网络维护工程师：员工号为xxx的 xxx员工，正在检查网络是否畅通  硬件维护工程师：员工号为xxx的 xxx员工，正在修复打印机  创建JavaEE工程师对象，完成工作方法的调用 18员工案例Employee类的编写12345678910111213141516171819202122232425262728 A:员工案例Employee类的编写:按照分析的继承体系来逐个实现 /* * 定义员工类 * 内容,都是所有子类的共性抽取 * 属性: 姓名,工号 * 方法: 工作 */ public abstract class Employee &#123; private String id;// 员工编号 private String name; // 员工姓名 public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; //工作方法（抽象方法） public abstract void work(); &#125; 19员工案例的子类的编写123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263 B:员工案例的子类的编写: /* * 定义研发员工类 * 属于员工中的一种, 继承员工类 * 抽象类Develop 给自己的员工定义自己有的属性 */public abstract class Develop extends Employee&#123;&#125;/* * 描述JavaEE开发工程师类 * 工号,姓名 工作方法 * 其他的员工,也具备这些共性,抽取到父类中,自己就不需要定义了 * 是研发部员工的一种,继承研发部类 */public class JavaEE extends Develop&#123; //重写他父类的父类的抽象方法 public void work()&#123; //调用父类的get方法,获取name,id值 System.out.println("JavaEE的工程师开发淘宝"+ super.getName()+".."+super.getId()); &#125;&#125; /* *定义Android工程师 继承 研发部员工类，重写工作方法 */ public class Android extends Developer &#123; @Override public void work() &#123; System.out.println("员工号为 " + getId() + " 的 " + getName() + " 员工，正在研发淘宝手机客户端软件"); &#125; &#125; /* * 定义维护员工类,属于员工中的一种 * 继承员工类 * 抽象类Maintainer 给自己的员工定义自己有的属性 */public abstract class Maintainer extends Employee&#123;&#125; /* * 描述的是网络维护工程师 * 属于维护部的员工,继承维护部类 */public class Network extends Maintainer&#123; public void work()&#123; System.out.println("网络工程师在检查网络是否畅通"+super.getName()+"..."+super.getId()); &#125;&#125; /* *定义Hardware硬件维护工程师 继承 维护部员工类，重写工作方法 */public class Hardware extends Maintainer &#123; @Override public void work() &#123; System.out.println("员工号为 " + getId() + " 的 " + getName() + " 员工，正在修复打印机"); &#125;&#125; 20小结（1） 继承：是指在一个现有类的基础上去构建一个新的类，构建出来的新类被称作子类，现有类被称作父类，子类会自动拥有父类所有继承的好处：可继承的属性和方法。 提高了代表的可维护性 提高了代码的复用性 让类与类之间产生了继承关系 继承的弊端： 类与类之间的耦合度过高 继承特点： java中类只能够单继承，不能多继承，可以多层继承 class Yy extends Object {} class Fu extends Yy{} class Zi extends Fu {} 所有的类都直接或者间接的继承了 Object类，Object类称为祖宗类 继承的注意事项： 1，使用关键字 extends 让类与类之间 产生继承关系 2, 父类私有的成员，子类不能继承，因为根本看不到 3，不能为了继承某个功能而随意进行继承操作， 必须要符合 is a 的关系 苹果 is a 水果 男人 is a 人 狗 is a 人 ， 这种情况就不能继承了 继承中的成员变量关系： 不同名的变量： 子类直接继承使用 同名的变量： 默认访问的是子类自己的成员变量(this.成员变量), 想访问父类中的同名变量，请使用 (super.成员变量); 继承中的成员方法关系：1234567891011不同名的方法：子类直接继承使用同名的方法：默认访问的是子类自己的成员方法，想访问父类中的同名方法，请使用 super.成员方法();super:用来表示当前对象中包含的父类对象空间的引用调用父类的成员变量：super.成员变量;调用方法的成员方法:super.成员方法(); (2)方法重写(override)：指 在子父类中，出现了方法声明相同的情况，也叫做方法覆盖，方法复写方法重写的注意事项：1231，子类的方法声明要与父类相同2, 子类要重写方法的方法，方法的权限修饰符不能比父类的更低3, 父类私有的方法，子类不能够进行方法重写 (3)方法重载(overload)：指 在同一个类中，多个方法名称相同，它们的参数列表不同(个数不同，数据类型不同) (4)抽象123抽象方法： 方法只有声明部分，没有方法体,即 public abstract void method();抽象类： 包含抽象方法的类，一定是抽象类 使用 abstract 修饰的类，是抽象类 抽象类的特点：1234561，抽象类与抽象方法都必须使用 abstract来修饰 2，抽象类不能直接创建对象 3，抽象类中可以有抽象方法，也可以没有抽象方法 4，抽象类的子类 a，实现了抽象方法的具体类 b，抽象类 抽象类面试题： 1，抽象类中是否可以没有抽象方法？如果可以，那么，该类还定义成抽象类有意义吗？为什么？ 可以没有抽象方法，有意义，不会让其他人直接创建该类对象]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础7(类与对象，成员变量，封装)]]></title>
    <url>%2F2016%2F10%2F10%2Fday09%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、面向对象思想2、类与对象的关系3、局部变量和成员变量的关系4、封装思想5、private,this关键字6、随机点名器 面向对象思想面向对象和面向过程的思想* A: 面向过程与面向对象都是我们编程中，编写程序的一种思维方式 * a: 面向过程的程序设计方式，是遇到一件事时，思考“我该怎么做”，然后一步步实现的过程。 * b: 面向对象的程序设计方式，是遇到一件事时，思考“我该让谁来做”，然后那个“谁”就是对象，他要怎么做这件事是他自己的事，反正最后一群对象合力能把事就好就行了。 面向对象的思想的生活案例* A: 买电脑（组装机） * a: 面向过程：自己该怎么做 * b: 面向对象：找人帮我们做 面向对象好处* A: 面向对象好处 * a: 面向对象思维方式是一种更符合人们思考习惯的思想 * b: 面向过程思维方式中更多的体现的是执行者（自己做事情），面向对象中更多的体现是指挥者（指挥对象做事情）。 * c: 面向对象思维方式将复杂的问题简单化。 大象装进冰箱的代码案例* A: 需求：把大象装冰箱里 * a: 面向过程 * 自己打开冰箱门 * 自己将大象装进去 * 自己关闭冰箱门 * b: 面向对象 * 分析发现打开、装、关闭都是冰箱的功能。即冰箱对象具 备如下功能 * 冰箱打开 * 冰箱存储 * 冰箱关闭 * B: 通过伪代码描述大象和冰箱 * 描述大象： class 大象 { } * 描述冰箱 class冰箱 { void 打开(){} void 存储(大象){} void 关闭(){} } * C: 使用对象： * 1、创建冰箱的对象 * 冰箱 bx = new 冰箱(); * 2、调用冰箱的功能 * 对象.功能()； * bx.打开(); * bx.存储(new 大象()); * bx.关闭(); * D：总结： * 1、先按照名词提炼问题领域中的对象 * 2、对对象进行描述，其实就是在明确对象中应该具备的属性和功能 * 3、通过new的方式就可以创建该事物的具体对象 * 4、通过该对象调用它以后的功能。 类与对象的关系定义小汽车类* A: 分析小汽车的属性和功能 * 属性 * 颜色 * 轮胎个数 * 功能 * 运行 * B: 通过伪代码描述小汽车 * 小汽车{ * 颜色 * 轮胎个数 * 运行(){} * } * C：通过JAVA代码描述小汽车 12345678* public class Car &#123; * String color; * int number; * void run() &#123; * System.out.println(color + ":" + number); * &#125;* &#125; 测试汽车类* A: 创见对象的格式 * a: 类名 变量名 = new 类名(); * B: 测试汽车类 1234567891011121314public class CarDemo &#123; public static void main(String[] args) &#123; /* 测试：Car类中的run方法。 */ // 1,创建Car的对象。给对象起个名字。 Car c = new Car();// c是类类型的变量。c指向了一个具体的Car类型的对象。 // 2,通过已有的对象调用该对象的功能。格式：对象.对象成员; // 3,可以该对象的属性赋值。 c.color = "red"; c.number = 4; c.run(); &#125;&#125; 对象的内存图 类和对象的关系* A: 类和对象的关系 * 类是对某一类事物的抽象描述，而对象用于表示现实中该类事物的个体 * B: 举例 * 可以将玩具模型看作是一个类，将一个个玩具看作对象，从玩具模型和玩具之间的关系便可以看出类与对象之间的关系 局部变量和成员变量的关系成员变量和局部变量的区别123456789101112* 区别一：定义的位置不同 * 定义在【类】中的变量是【成员变量】 * 定义在【方法】中或者&#123;&#125;语句里面的变量是【局部变量】* 区别二：在内存中的位置不同 * 【成员变量】存储在【堆内存】的对象中 * 【局部变量】存储在【栈内存】的方法中（局部变量跟随方法进栈）* 区别三：声明周期不同 * 成员变量随着对象的出现而出现在堆中，随着对象的消失而从堆中消失 * 局部变量随着方法的运行而出现在栈中，随着方法的弹栈而消失* 区别四：初始化不同 * 【成员变量】因为在堆内存中，【所有默认的初始化值】 * 【局部变量】【没有默认】的初始化值，必须手动的给其赋值才可以使用。 封装思想01方法参数是基本数据类型和引用数据类型* A.基本类型 123456789101112131415class Demo&#123; public static void main(String[] args) &#123; int x = 4; show(x); System.out.println("x="+x); &#125; public static void show(int x) &#123; x = 5; &#125;&#125; 基本类型作为参数传递时，其实就是将基本类型变量x空间中的值复制了一份传递给调用的方法show()，当在show()方法中x接受到了复制的值，再在show()方法中对x变量进行操作，这时只会影响到show中的x。当show方法执行完成，弹栈后，程序又回到main方法执行，main方法中的x值还是原来的值。 * B.引用类型 12345678910111213141516171819202122class Demo &#123; int x ; public static void main(String[] args) &#123; Demo d = new Demo(); d.x = 5; show(d); System.out.println("x="+d.x); &#125; public static void show(Demo d) &#123; d.x = 6; &#125;&#125; 当引用变量作为参数传递时，这时其实是将引用变量空间中的内存地址(引用)复制了一份传递给了show方法的d引用变量。这时会有两个引用同时指向堆中的同一个对象。当执行show方法中的d.x=6时，会根据d所持有的引用找到堆中的对象，并将其x属性的值改为6.show方法弹栈。由于是两个引用指向同一个对象，不管是哪一个引用改变了引用的所指向的对象的中的值，其他引用再次使用都是改变后的值。* C.结论* 对于基本类型形式参数改变不会影响到实际参数* 对于引用类型形式参数改变会影响到实际参数 02封装的概述* A.面向对象三大特征 * 封装、继承、多态 * B.封装表现 * 1、方法就是一个最基本封装体 * 2、类其实也是一个封装体 * C.封装的好处 * 1、提高了代码的复用性 * 2、隐藏了实现细节，还要对外提供可以访问的方式。便于调用者的使用。这是核心之一，也可以理解为就是封装的概念 * 3、提高了安全性 03封装的生活中的举例* A.封装的生活中的举例 机箱： 一台电脑，它是由CPU、主板、显卡、内存、硬盘、电源等部件组长，其实我们将这些部件组装在一起就可以使用电脑了，但是发现这些部件都散落在外面，很容造成不安全因素，于是，使用机箱壳子，把这些部件都装在里面，并在机箱壳上留下一些插口等，若不留插口，大家想想会是什么情况。 总结：机箱其实就是隐藏了办卡设备的细节，对外提供了插口以及开关等访问内部细节的方式。 * B.总结 * 机箱其实就是隐藏了办卡设备的细节，对外提供了插口以及开关等访问内部细节的方式 private,this关键字private关键字1234567891011121314* A.private概述 * private可以修饰成员内容包括成员方法和成员变量 * 被private修饰的内容不能在其他类访问* B.使用步骤 * 1、通过private修饰属性* C.完整代码 class Person &#123; private int age; private String name; public void show() &#123; System.out.println("age=" + age + ",name" + name); &#125; &#125; get和set方法* A.get和set方法 * 年龄已被私有，错误的值无法赋值，可是正确的值也赋值不了，这样还是不行，那肿么办呢？按照之前所学习的封装的原理，隐藏后，还需要提供访问方式。只要对外提供可以访问的方法，让其他程序访问这些方法。同时在方法中可以对数据进行验证。 一般对成员属性的访问动作：赋值(设置 set)，取值(获取 get)，因此对私有的变量访问的方式可以提供对应的 setXxx或者getXxx的方法。12345678910111213141516171819202122232425class Person &#123; // 私有成员变量 private int age; private String name; // 对外提供设置成员变量的方法 public void setAge(int a) &#123; // 由于是设置成员变量的值，这里可以加入数据的验证 if (a &lt; 0 || a &gt; 130) &#123; System.out.println(a + "不符合年龄的数据范围"); return; &#125; age = a; &#125; // 对外提供访问成员变量的方法 public void getAge() &#123; return age; &#125;&#125;* 总结 * 类中不需要对外提供的内容都私有化，包括属性和方法。以后再描述事物，属性都私有化，并提供setXxx getXxx方法对其进行访问* 注意 * 私有仅仅是封装的体现形式而已 私有化Person类带get,set* 标准代码 12345678910111213141516171819202122232425262728293031323334353637383940414243package cn.itcast.demo05;/* * 类描述人: * 属性: 姓名和年龄 * 方法: 说话 * * 私有化所有的属性 (成员变量) ,必须写对应的get/set方法 * 凡是自定义的类,自定义成员变量,应该私有化,提供get/set * * this关键字: * 区分成员变量和局部变量同名情况 * 方法中,方位成员变量,写this. */public class Person &#123; private String name; private int age; // set方法,变量name,age赋值 public void setAge(int age) &#123; this.age = age; &#125; public void setName(String name) &#123; this.name = name; &#125; // get方法,变量name,age获取值 public int getAge() &#123; return age; &#125; public String getName() &#123; return name; &#125; public void speak() &#123; String name = "哈哈"; int age = 16; System.out.println("人在说话 " + this.name + "..." + this.age); &#125;&#125; * 标准测试代码 12345678910111213141516package cn.itcast.demo05;public class PersonTest &#123; public static void main(String[] args) &#123; Person p = new Person(); //调用set方法,对成员变量赋值 p.setAge(18); p.setName("旺财"); p.speak(); //调用get方法,获取成员变量的值// System.out.println(p.getName());// System.out.println(p.getAge()); &#125;&#125; this关键字_区分成员变量和局部变量的同名* A.什么时候用 * 当类中存在成员变量和局部变量同名的时候为了区分，就需要使用this关键字 * B.代码 class Person { private int age; private String name; public void speak() { this.name = &quot;小强&quot;; this.age = 18; System.out.println(&quot;name=&quot; + this.name + &quot;,age=&quot; + this.age); } } class PersonDemo { public static void main(String[] args) { Person p = new Person(); p.speak(); } } this内存图* A.this内存图 this的年龄比较* A.需求：在Person类中定义功能，判断两个人是否是同龄人 * B.代码 12345678910111213141516171819202122232425262728293031323334class Person &#123; private int age; private String name; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public void speak() &#123; System.out.println("name=" + this.name + ",age=" + this.age); &#125; // 判断是否为同龄人 public boolean equalsAge(Person p) &#123; // 使用当前调用该equalsAge方法对象的age和传递进来p的age进行比较 // 由于无法确定具体是哪一个对象调用equalsAge方法，这里就可以使用this来代替 /* * if(this.age == p.age) &#123; return true; &#125; return false; */ return this.age == p.age; &#125;&#125; 随机点名器随机点名器案例重构* A.需求：随机点名器，即在全班同学中随机的找出一名同学，打印这名同学的个人信息 它具备以下3个内容： 存储所有同学姓名 总览全班同学姓名 随机点名其中一人，打印到控制台 * B.代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import java.util.ArrayList;import java.util.Random;import java.util.Scanner;/** * 思路： * 第一步：存储全班同学信息 * 第二步：打印全班同学每一个人的信息 * 第三部：随机对学生点名，打印学生信息 */public class Test &#123; public static void main(String[] args) &#123; ArrayList&lt;Student&gt; list = new ArrayList&lt;Student&gt;(); //1.1创建一个可以存储多个同学名字的容器 //1.存储全班同学信息 addStudent(list); //2.打印全班同学每一个人的信息（姓名、年龄） printStudent(list); //3.随机对学生点名，打印学生信息 randomStudent(list); &#125; public static void addStudent(ArrayList&lt;Student&gt; list) &#123; //键盘输入多个同学名字存储到容器中 Scanner sc = new Scanner(System.in); for (int i = 0; i &lt; 3; i++) &#123; //创建学生 Student s = new Student(); System.out.println("存储第"+i+"个学生姓名："); String name = sc.next(); s.setName(name); System.out.println("存储第"+i+"个学生年龄："); int age = sc.nextInt(); s.setAge(age); //添加学生到集合 list.add(s); &#125; &#125; /** 2.打印全班同学每一个人的信息（姓名、年龄） */ public static void printStudent (ArrayList&lt;Student&gt; list) &#123; for (int i = 0; i &lt; list.size(); i++) &#123; Student s = list.get(i); System.out.println("姓名："+s.getName() +",年龄："+s.getAge()); &#125; &#125; /** 3.随机对学生点名，打印学生信息 */ public static void randomStudent (ArrayList&lt;Student&gt; list) &#123; //在班级总人数范围内，随机产生一个随机数 int index = new Random().nextInt(list.size()); //在容器（ArrayList集合）中，查找该随机数所对应的同学信息（姓名、年龄） Student s = list.get(index); System.out.println("被随机点名的同学："+s.getName() + "，年龄:" + s.getAge()); &#125;&#125; 1234567891011121314151617181920212223/** * 学生信息类 */public class Student &#123; private String name; // 姓名 private int age; // 年龄 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 总结123456789101112131415161718192021222324252627282930313233343536* A.类与对象 * 类，用于描述多个对象的共同特征，它是对象的模板。 * 对象，用于描述现实中的个体，它是类的实例。 * 类的定义：使用关键字class来定义java中的类 * 格式： * class 类名 &#123; * //属性 * 数据类型 变量名; * … * //方法 * 修饰符 返回值类型 方法名(参数)&#123; &#125; * … * &#125; * * B.创建对象： * 格式： * 类名 对象名 = new 类名();* C.封装（private关键字） * 封装，把对象的属性与方法的实现细节隐藏，仅对外提供一些公共的访问方式 * 封装的体现： * 变量:使用 private 修饰，这就是变量的封装 * 方法:也是一种封装，封装了多条代码 * 类： 也是一种封装，封装了多个方法* D.private关键字，私有的意思 * 它可以用来修饰类中的成员(成员变量，成员方法) * private的特点： * private修饰的成员只能在当前类中访问，其他类中无法直接访问* E.this关键字 * this关键字，本类对象的引用 * this是在方法中使用的，哪个对象调用了该方法，那么，this就代表调用该方法的对象引用 * this什么时候存在的？当创建对象的时候，this存在的 * this的作用：用来区别同名的成员变量与局部变量（this.成员变量） * public void setName(String name) &#123; * this.name = name; * &#125;]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础6(自定义类，ArrayList)]]></title>
    <url>%2F2016%2F10%2F09%2Fday06%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、自定义类型的定义及使用2、自定义类的内存图3、ArrayList集合的基本功能4、随机点名器案例及库存案例代码优化 01引用数据类型_类* A: 数据类型 * a: java中的数据类型分为：基本类型和引用类型 * B: 引用类型的分类 * a: Java为我们提供好的类，比如说：Scanner,Random等。 * b: 我们自己创建的类，按照类的定义标准，可以在类中包含多个方法与属性，来供我们使用。 02自定义类的概述* A: 自定义类的概述 * java代码映射成现实事物的过程就是定义类的过程。 * 举例： 我们就拿一部手机进行分析，它能用来做什么呢？它可以打电话，上网，聊微信等，这些就是手机所提供的功能，也就是方法；手机也有它的特征，如颜色、尺寸大小、品牌型号等，这些就是手机的特征，也就是属性 * 目前，我们只关注类中的属性，类中的方法在面向对象部分再进行学习。 03自定义类的格式* A: 自定义类的格式 * a: 使用类的形式,对现实中的事物进行描述。 * b: 事物由方法和属性两部分组成。 * 方法: 这个事物具备的功能。 * 属性: 这个事物具备的特征。 * c: 格式 123456789public class 类名&#123; 属性定义 修饰符 数据类型 变量名 = 值 方法定义 修饰符 返回值类型 方法名(参数列表)&#123; &#125;&#125; 04自定义的手机类* A: 自定义的手机类 123456789* a: 案例代码 public class Phone&#123; /* 定义手机的属性 */ String color ; String brand ; double size ; &#125; 05测试手机类导包：我们将所有的类放到同一个文件夹下，可以避免导包。 创建对象：数据类型 变量名 = new 数据类型(); 调用方法：目前我们定义的自定义类不涉及方法，只是属性（自定义类中的方法部分在面向对象部分讲解）访问属性：变量名.属性 (这是当前的方式，后期会采取调用方法的方式替代掉直接访问的方式来完成对属性的访问。)1234567891011121314151617181920212223* A: 调用方法执行流程* a: 实现引用类型的步骤 * 1: 导入包 , 类都是在同一个文件夹,不需要导入包 * 2: 创建引用类型的变量 * 3: 变量.类型中的功能* b: 案例代码 public class TestPhone&#123; public static void main(String[] args)&#123; // 2: 创建引用类型的变量 Phone p = new Phone(); //System.out.println(p); //输出内存的地址 //3: 变量.类型中的功能 //变量 p.的方式,调用类中的属性 //属性就是变量 , 赋值和获取值 p.color = "土豪金"; p.brand = "爱立信"; p.size = 5.0; //获取属性值 System.out.println(p.color+" "+p.brand+" "+p.size); &#125; &#125; 06自定义类的内存图_1* A: 自定义类的内存图_1 07自定义类的内存图_2* A: 自定义类的内存图_1 08两个引用类型变量内存图* A: 自定义类的内存图_1 09自定义类的练习* A: 实体类的代码 1234567891011121314151617181920212223242526272829303132333435363738/* 电饭锅，包含属性（品牌、容量大小、颜色等） 定义类,描述事物,电饭锅 属性: 品牌,大小 ,颜色 定义类,类名字,电饭锅 类的范围,定义三个属性*/public class DianFanGuo&#123; //定义三个属性 String brand ; double size ; String color ;&#125;/* 汽车，包含属性（品牌、排量、类型等） 定义类,类名 Car 属性 品牌 排量 类型 */public class Car&#123; //定义汽车三个属性 String brand ; double paiLiang ; String type;&#125; /* 学生，包含属性（姓名，年龄，性别等） 定义类,类名Student 三个属性: 姓名,年龄,性别 (char)*/public class Student&#123; String name; int age ; char sex ;&#125; * B: 测试类的代码 1234567891011121314151617181920212223242526272829303132/* 定义的测试类 同时测试,电饭锅,汽车,学生*/public class Test&#123; public static void main(String[] args)&#123; //创建电饭锅引用类型 DianFanGuo dfg = new DianFanGuo(); dfg.brand = "特斯拉"; dfg.color = "红色"; dfg.size = 30; System.out.println(dfg.brand+" "+dfg.color+" "+dfg.size); //创建汽车引用类型 Car c = new Car(); c.brand = "巨力"; c.type = "拖拉机"; c.paiLiang = 0.5; System.out.println(c.brand+" "+c.type+" "+c.paiLiang); //创建学生引用类型 Student stu = new Student(); stu.name = "张三"; stu.age = 20; stu.sex = '男'; System.out.println(stu.name+" "+stu.age+" "+stu.sex); &#125;&#125; 10ArrayList创建变量的步骤为了保存这些数目不确定的元素，JDK中提供了一系列特殊的类，这些类可以存储任意类型的元素，并且长度可变，统称为集合。在这里，我们先介绍ArrayList集合.导包：import java.util.ArrayList; 创建对象：与其他普通的引用数据类型创建方式完全相同，但是要指定容器中存储的数据类型： 1ArrayList&lt;要存储元素的数据类型&gt; 变量名 = new ArrayList&lt;要存储元素的数据类型&gt;(); * A: ArrayList创建变量的步骤 * a: 导入包 java.util包中 * b: 创建引用类型的变量 数据类型&lt; 集合存储的数据类型&gt; 变量名 = new 数据类型&lt;集合存储的数据类型&gt;(); 集合存储的数据类型: 要将数据存储到集合的容器中 创建集合引用变量的时候,必须要指定好,存储的类型是什么 * c: 变量名.方法 注意: 集合存储的数据,8个基本类型对应8个引用类型 存储引用类型,不存储基本类型 “&lt;要存储元素的数据类型&gt;”中的数据类型必须是【引用数据类型】，不能是基本数据类型；下面给出8种基本数据类型所对应的引用数据类型表示形式: 基本数据类型 对应的引用数据类型表示形式 12345678byte Byteshort ShortInt Integerlong Longfloat Floatdouble Doublechar Characterboolean Boolean 11ArrayList创建变量举例* A: ArrayList创建变量的示例代码 1234567891011121314import java.util.ArrayList;public class ArrayListDemo&#123; public static void main(String[] args)&#123; //创建集合容器,指定存储的数据类型 //存储字符串 ArrayList&lt;String&gt; array = new ArrayList&lt;String&gt;(); //创建集合容器,存储整数 ArrayList&lt;Integer&gt; array2 = new ArrayList&lt;Integer&gt;(); //创建集合容器,存储手机类型 ArrayList&lt;Phone&gt; array3 = new ArrayList&lt;Phone&gt;(); &#125;&#125; 12ArrayList的常见方法* A: ArrayList的常见方法 123* a: add(参数) 向集合中添加元素* b: get(int index) 取出集合中的元素,get方法的参数,写入索引* c: size() 返回集合的长度, 集合存储元素的个数 * B: 案例代码 1234567891011121314151617181920212223242526import java.util.ArrayList;public class ArrayListDemo_1&#123; public static void main(String[] args)&#123; //定义集合,存储字符串元素 ArrayList&lt;String&gt; array = new ArrayList&lt;String&gt;(); //调用集合方法add存储元素 array.add("abc"); array.add("itcast"); array.add("love"); array.add("java"); //输出集合的长度,调用集合方法size, size方法的返回值类型 int int size = array.size(); System.out.println(size); //获取出集合中的一个元素,获取1索引的元素 //集合的方法get, 获取元素后结果数据类型 String s = array.get(1); System.out.println(s); System.out.println(array.get(0)); System.out.println(array.get(1)); System.out.println(array.get(2)); System.out.println(array.get(3)); &#125;&#125; 13ArrayList集合的遍历* A: 案例代码 1234567891011121314151617181920212223/* 集合的遍历 实现思想也是索引思想 集合的索引从0开始,到 size()-1 方法get(int index)*/import java.util.ArrayList;public class ArrayListDemo_2&#123; public static void main(String[] args)&#123; ArrayList&lt;Integer&gt; array = new ArrayList&lt;Integer&gt;(); array.add(121); array.add(125); array.add(123); array.add(120); array.add(128); //对集合进行遍历 //使用方法 size+get组合进行遍历 for(int i = 0 ; i &lt; array.size(); i++)&#123; System.out.println( array.get(i) ); &#125; &#125;&#125; 14ArrayList补充方法* A: ArrayList补充方法 1234* a: add(int 索引,存储的元素) 将元素添加到指定的索引上* b: set(int 索引,修改后的元素) 将指定索引的元素,进行修改* c: remove(int 索引) 删除指定索引上的元素* d: clear() 清空集合中的所有元素 * B: 案例代码 import java.util.ArrayList; public class ArrayListDemo_3{ public static void main(String[] args){ ArrayList&lt;Integer&gt; array = new ArrayList&lt;Integer&gt;(); array.add(1); array.add(2); array.add(3); array.add(4); //在索引2上,添加元素7 array.add(2,7); //将0索引上的元素,修改成10 array.set(0,10); //将4索引上的元素,删除 array.remove(4); array.clear(); //使用方法 size+get组合进行遍历 for(int i = 0 ; i &lt; array.size(); i++){ System.out.println( array.get(i) ); } } } 15随机点名器案例分析* A: 随机点名器案例分析 全班同学中随机的找出一名同学，打印这名同学的个人信息。 我们对本案例进行分析，得出如下分析结果： 1.存储全班同学信息（姓名、年龄） 将容器换成集合，集合中存的是Student类型 2.打印全班同学每一个人的信息（姓名、年龄） 遍历集合 3.在班级总人数范围内，随机产生一个随机数，查找该随机数所对应的同学信息（姓名、年龄） 随机点名器明确地分为了三个功能。如果将多个独立功能的代码写到一起，则代码相对冗长，我们可以针对不同的功能可以将其封装到一个方法中，将完整独立的功能分离出来。 而在存储同学姓名时，如果对每一个同学都定义一个变量进行姓名存储，则会出现过多孤立的变量，很难一次性将全部数据持有。此时，我们采用ArrayList集合来解决多个学生信息的存储问题 16随机点名器代码实现* A: 随机点名器案例代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/* 随机点名器,集合改进 (学生的姓名和年龄) 现实中有学生这个事物,使用定义类的形式,描述学生事物 属性: 姓名,年龄 姓名存储了数组, 将容器换成是集合 String[] s = &#123;"",""&#125;; 集合中,存储的是学生的姓名吗? 应该存储Student类型 存储学生: 学生类型,存储到集合中 总览: 遍历集合 随机: 随机数,作为索引,到集合中找到元素 三个功能,共享的数据,集合容器, 定义三个方法,必须参数传递集合*/import java.util.ArrayList;import java.util.Random;public class CallName&#123; public static void main(String[] args)&#123; //定义集合,存储的是StudentName类型变量 ArrayList &lt;StudentName&gt; array = new ArrayList&lt;StudentName&gt;(); //调用添加方法 add (array); //调用遍历集合 printArrayList(array); randomStudentName(array); &#125; /* 随机数,当作集合的索引,到集合中找到元素 */ public static void randomStudentName(ArrayList&lt;StudentName&gt; array )&#123; Random r = new Random(); int number = r.nextInt( array.size()); //随机数,索引,到集合中get StudentName s = array.get(number); System.out.println( s.name +" "+s.age); &#125; /* 总览学生的信息,遍历集合 */ public static void printArrayList(ArrayList&lt;StudentName&gt; array)&#123; for(int i = 0 ; i &lt; array.size();i++)&#123; //存储集合的时候, 集合.add(sn1) sn1 是StudentName类型变量 //获取的时候,集合.get方法,获取出来的是什么, 还是StudentName类型变量 StudentName s = array.get(i); System.out.println(s.name+" "+s.age); &#125; &#125; /* 定义方法,实现存储学生的姓名和年龄 创建StudentName类型变量,存储到集合中 */ public static void add (ArrayList&lt;StudentName&gt; array)&#123; //创建StudentName类型变量 StudentName sn1 = new StudentName(); StudentName sn2 = new StudentName(); StudentName sn3 = new StudentName(); StudentName sn4 = new StudentName(); StudentName sn5 = new StudentName(); sn1.name = "张三1"; sn1.age = 201; sn2.name = "张三2"; sn2.age = 202; sn3.name = "张三3"; sn3.age = 203; sn4.name = "张三4"; sn4.age = 204; sn5.name = "张三5"; sn5.age = 205; //将StudentName变量,存储到集合中 array.add(sn1); array.add(sn2); array.add(sn3); array.add(sn4); array.add(sn5); &#125;&#125; 17库存案例分析加入集合* A: 库存案例分析加入集合 * a: 参见\day06\day06(面向对象\day06_source\对象内存图.JPG 18库存案例添加商品信息* A: 案例代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/* 定义,.描述商品的类 商品 4个属性 商品名字 大小 价格 库存 String double double int 定义类,类名Goods 这个类型的变量,存储到集合中*/public class Goods&#123; //定义商品名字 String brand ; //大小属性 double size ; // 价格属性 double price ; //库存属性 int count ;&#125;/* 实现库存管理案例: 1.存储商品信息 存储商品类型变量 将商品类型的变量,存储到集合中*///import java.util.ArrayList;import java.util.*;public class Shopp&#123; public static void main(String[] args)&#123; //创建ArrayList集合,存储Goods类型 ArrayList&lt;Goods&gt; array = new ArrayList&lt;Goods&gt;(); //调用添加商品信息的方法 addGoods(array); &#125; /* 定义方法,将商品的信息存储到集合中 集合是所有方法的共享数据,参数传递 */ public static void addGoods (ArrayList&lt;Goods&gt; array)&#123; //创建商品类型变量 Goods类型的变量 Goods g1 = new Goods(); Goods g2 = new Goods(); g1.brand = "MacBook"; g1.size = 13.3; g1.price = 9999.99; g1.count = 3; g2.brand = "Thinkpad"; g2.size = 15.6; g2.price = 7999.99; g2.count = 1; //Goods类型的变量,存储到集合中 array.add(g1); array.add(g2); &#125;&#125; 19库存案例查看库存清单* A: 案例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/* 实现库存管理案例: 1.存储商品信息 存储商品类型变量 将商品类型的变量,存储到集合中 2.查看库存清单 将集合进行遍历, 获取出集合中存储的Goods类型变量 输出每一个Goods类型的属性 计算求和: 总库存,总金额*///import java.util.ArrayList;import java.util.*;public class Shopp&#123; public static void main(String[] args)&#123; //创建ArrayList集合,存储Goods类型 ArrayList&lt;Goods&gt; array = new ArrayList&lt;Goods&gt;(); //调用添加商品信息的方法 addGoods(array); &#125; /* 定义方法,查看库存清单,遍历集合 */ public static void printStore(ArrayList&lt;Goods&gt; array)&#123; //输出表头 System.out.println("----------商场库存清单----------"); System.out.println("品牌型号 尺寸 价格 库存数"); //定义变量,保存总库存数,和总金额 int totalCount = 0 ; double totalMoney = 0; //遍历集合 for(int i = 0 ; i &lt; array.size(); i++)&#123; //get(索引)获取出集合中的元素,存储的是Goods类,获取的也是Goods类型 //使用Goods类型变量,接受get方法结果 Goods g = array.get(i); System.out.println(g.brand+" "+g.size+" "+g.price+" "+g.count); totalCount = totalCount+g.count; totalMoney = totalMoney + g.count*g.price; &#125; System.out.println("总库存数: "+totalCount); System.out.println("商品库存总金额: "+totalMoney); &#125; /* 定义方法,将商品的信息存储到集合中 集合是所有方法的共享数据,参数传递 */ public static void addGoods (ArrayList&lt;Goods&gt; array)&#123; //创建商品类型变量 Goods类型的变量 Goods g1 = new Goods(); Goods g2 = new Goods(); g1.brand = "MacBook"; g1.size = 13.3; g1.price = 9999.99; g1.count = 3; g2.brand = "Thinkpad"; g2.size = 15.6; g2.price = 7999.99; g2.count = 1; //Goods类型的变量,存储到集合中 array.add(g1); array.add(g2); &#125;&#125; 20库存案例修改库存清单及测试代码的实现* A: 案例代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123/* 实现库存管理案例: 1.存储商品信息 存储商品类型变量 将商品类型的变量,存储到集合中 2.查看库存清单 将集合进行遍历, 获取出集合中存储的Goods类型变量 输出每一个Goods类型的属性 计算求和: 总库存,总金额 3.修改商品的库存 集合遍历 ,获取出集合中存储的Goods类型变量 变量调用Goods类的属性count,值进行修改 (键盘输入)*///import java.util.ArrayList;import java.util.*;public class Shopp&#123; public static void main(String[] args)&#123; //创建ArrayList集合,存储Goods类型 ArrayList&lt;Goods&gt; array = new ArrayList&lt;Goods&gt;(); //调用添加商品信息的方法 addGoods(array); //进入死循环中 while(true)&#123; //调用选择功能的方法,获取到用户输入的功能序号 int number = chooseFunction(); //对序号判断,如果=1 进入查看库存功能 = 2 进入修改库存功能 =3 结束 switch(number)&#123; case 1: //进入查看库存,调用查看库存的方法,传递存储商品信息的集合 printStore(array); break; case 2: //进入修改库存功能,调用修改库存的方法,传递集合 update(array); break; case 3: return ; default: System.out.println("无此功能"); break; &#125; &#125; &#125; /* 方法定义,修改库存 键盘的输入,将Goods中的属性值,修改 */ public static void update(ArrayList&lt;Goods&gt; array)&#123; Scanner sc = new Scanner(System.in); //遍历集合,获取集合中的每个元素 for(int i = 0 ; i &lt; array.size(); i++)&#123; //集合方法get获取的是集合的元素,元素类型Goods Goods g = array.get(i); System.out.println("请输入"+g.brand+"的库存数"); //Goods属性,count进行修改 g.count = sc.nextInt(); &#125; &#125; /* 定义方法,实现选择菜单,用户根据功能选择菜单 */ public static int chooseFunction()&#123; System.out.println("-------------库存管理------------"); System.out.println("1.查看库存清单"); System.out.println("2.修改商品库存数量"); System.out.println("3.退出"); System.out.println("请输入要执行的操作序号："); Scanner sc = new Scanner(System.in); int number = sc.nextInt(); return number; &#125; /* 定义方法,查看库存清单,遍历集合 */ public static void printStore(ArrayList&lt;Goods&gt; array)&#123; //输出表头 System.out.println("----------商场库存清单----------"); System.out.println("品牌型号 尺寸 价格 库存数"); //定义变量,保存总库存数,和总金额 int totalCount = 0 ; double totalMoney = 0; //遍历集合 for(int i = 0 ; i &lt; array.size(); i++)&#123; //get(索引)获取出集合中的元素,存储的是Goods类,获取的也是Goods类型 //使用Goods类型变量,接受get方法结果 Goods g = array.get(i); System.out.println(g.brand+" "+g.size+" "+g.price+" "+g.count); totalCount = totalCount+g.count; totalMoney = totalMoney + g.count*g.price; &#125; System.out.println("总库存数: "+totalCount); System.out.println("商品库存总金额: "+totalMoney); &#125; /* 定义方法,将商品的信息存储到集合中 集合是所有方法的共享数据,参数传递 */ public static void addGoods (ArrayList&lt;Goods&gt; array)&#123; //创建商品类型变量 Goods类型的变量 Goods g1 = new Goods(); Goods g2 = new Goods(); g1.brand = "MacBook"; g1.size = 13.3; g1.price = 9999.99; g1.count = 3; g2.brand = "Thinkpad"; g2.size = 15.6; g2.price = 7999.99; g2.count = 1; //Goods类型的变量,存储到集合中 array.add(g1); array.add(g2); &#125;&#125;]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础5(方法)]]></title>
    <url>%2F2016%2F10%2F08%2Fday05%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、方法基础知识2、方法高级内容3、方法案例 01方法的概述* A: 为什么要有方法 * 提高代码的复用性 * B: 什么是方法 * 完成特定功能的代码块。 02方法的定义格式* A: 方法的格式 * 修饰符 返回值类型 方法名(参数类型 参数名1,参数类型 参数名2...) { 方法体语句; return 返回值; } * B: 方法的格式说明 * 修饰符：目前就用 public static。后面我们再详细的讲解其他的修饰符。 * 返回值类型：就是功能结果的数据类型。 * 方法名：符合命名规则即可。方便我们的调用。 * 参数： * 实际参数：就是实际参与运算的。 * 形式参数；就是方法定义上的，用于接收实际参数的。 * 参数类型：就是参数的数据类型 * 参数名：就是变量名 * 方法体语句：就是完成功能的代码。 * return：结束方法的。 * 返回值：就是功能的结果，由return带给调用者。 03定义方法计算面积* A: 定义方法计算面积 123456789101112131415161718192021222324public class MethodDemo&#123; public static void main(String[] args)&#123; //调用方法, 方法执行起来 // 在方法main中,调用方法 getArea int area = getArea(5,6); System.out.println("面积是: "+area); &#125; /* 要求: 计算一个长方形的面积 定义方法解决这个要求 分析方法定义过程: 1.明确方法计算后的结果的数据类型 int 定义格式对应的就是返回值类型 2.方法计算过程中,有没有未知的数据, 宽和长, 未知数据的数据类型 int 未知数的变量,定义在方法的小括号内 */ public static int getArea(int w, int h)&#123; //实现方法的功能主体 //int area = w * h; return w * h; &#125;&#125; 04调用方法* A: 调用方法 * a: 在main函数中调用方法，让方法执行起来 * b: 方法的形参 * 方法要什么参数我们就给什么类型的参数。 * c: 方法的返回值 * 方法返回什么类型的值我们就用对应的数据类型的变量来接收 05调用方法执行流程* A: 调用方法执行流程 * a: 方法的定义是没有顺序的，写在main函数的上边或者下边都可以。 * b: 方法的执行，是把实参传递给形参，从而来执行的。 * c: 方法只有被调用才会执行。 06方法调用的内存图 A: 方法调用的内存图 07方法调用的练习* A: 案例代码 12345678910111213141516171819202122/* 方法的定义练习*/import java.util.Scanner;public class MethodDemo_1&#123; public static void main(String[] args)&#123; //printRect(); //int number = getNumber(); //System.out.println(getNumber()); //printRect2(3,5); double avg = getAvg(2,2,3); System.out.println(avg); &#125; /* 定义有返回值有参数方法，如求三个数的平均值 明确方法计算后的数据类型, 返回值类型 double 明确方法未知数, 三个未知的整数 */ public static double getAvg(double a, double b,double c)&#123; return (a+b+c)/3; &#125; 12345678910111213/* 定义无返回值有参数方法，如打印指定M行，每行N个*号的矩形 明确方法计算后结果,控制台输出图形,没有返回值的 方法中有没有未知数,图形行数,和列数,是未知的, 数据类型整数int */ public static void printRect2(int m,int n)&#123; for(int i = 0 ; i &lt; m ; i++)&#123; for(int j = 0 ; j &lt; n ; j++)&#123; System.out.print("*"); &#125; System.out.println(); &#125; &#125; 12345678910/* 定义有返回值无参数方法，如键盘录入得到一个整数 明确方法计算后结果的数据类型 int 明确有没有未知数,没 */ public static int getNumber()&#123; Scanner sc = new Scanner(System.in); //int number = sc.nextInt(); return sc.nextInt(); &#125; 123456789101112131415/* 定义无返回值无参数方法，如打印3行，每行3个*号的矩形 为什么没有返回值: 打印矩形 ,输出效果,不需要将结果返回 明确未知数: 不需要未知数 */ public static void printRect()&#123; for(int i = 0 ; i &lt; 3 ; i++)&#123; for(int j = 0 ; j &lt; 3 ;j++)&#123; System.out.print("*"); &#125; System.out.println(); &#125; &#125; &#125; 08方法的定义和使用的注意事项* A: 方法的定义和使用的注意事项 12345678* a: 方法不能定义在另一个方法的里面* b: 写错方法名字* c: 写错了参数列表* d: 方法返回值是void,方法中可以省略return 不写 return 下面不能有代码* e 方法返回值类型,和return 后面数据类型必须匹配* f: 方法重复定义问题* g: 调用方法的时候,返回值是void, 不能写在输出语句中 09方法的重载* A: 方法的重载 1234567891011121314151617181920 * 在同一个类中，方法名相同，参数列表不同。与返回值类型无关。 * 参数列表不同： * A:参数个数不同 * B:参数类型不同 * C:参数的顺序不同(算重载,但是在开发中不用)* B: 案例代码 public static int getSum(int a,int b)&#123; System.out.println("两个int参数"); return a+b; &#125; public static int getSum(int a,int b,int c)&#123; System.out.println("三个int参数"); return a+b+c; &#125; public static double getSum(double a,double b)&#123; System.out.println("两个double参数"); return a+b; &#125; 10方法重载注意事项* A: 方法重载注意事项 * a: 参数列表必须不同 * b: 重载和参数变量名无关 * c: 重载和返回值类型无关 * d: 重载和修饰符无关 * e: 技巧: 重载看方法名和参数列表 11方法参数是基本数据类型* A: 方法参数是基本数据类型 * a: 方法参数是基本类型时，传递的是值。 12方法参数是引用数据类型* A: 方法参数是引用数据类型 * a: 方法参数是引用类型时，传递的是内存地址值。 13随机点名器* A: 案例代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/* 实现随机点名器 1.存储所有学生姓名 2.预览所有学生姓名,遍历数组 3.随机数作为索引,到数组中找元素 将功能独立出来, 作成方法,调用方法即可 定义三个功能, 用到同一个姓名数据 姓名存储到数组中,三个方法,使用一个数组中的数据, 方法传递参数*/import java.util.Random;public class CallName&#123; public static void main(String[] args)&#123; //定义数组,存储学生姓名 String[] names = new String[8]; //调用添加姓名方法 addStudent(names); //调用遍历数组方法 printStudentName(names); //调用随机姓名的方法 String name = randomStudentName(names); System.out.println(name); &#125; /* 定义方法,随机数,做索引,数组中找到学生姓名 返回值? 学生姓名 参数? 数组 */ public static String randomStudentName(String[] names)&#123; Random ran = new Random(); int index = ran.nextInt(names.length); return names[index]; &#125; /* 定义方法,遍历数组 返回值? 没有 参数? 数组 */ public static void printStudentName(String[] names)&#123; for(int i = 0 ; i &lt; names.length ;i++)&#123; System.out.println(names[i]); &#125; &#125; /* 定义方法,实现向数组中添加学生姓名 返回值? 没有, 参数? 参数就是数组 */ public static void addStudent(String[] names)&#123; names[0] = "张三"; names[1] = "李四"; names[2] = "王五"; names[3] = "李蕾"; names[4] = "韩梅梅"; names[5] = "小名"; names[6] = "老王"; names[7] = "小华"; &#125;&#125; 14库存案例代码实现_1* A: 案例代码 /* 实现商品的库存管理 功能: 1.展示用户选择功能清单 2.根据选择的功能编号,进行不同的操作 A. 展示所有库存 B. 修改库存数量 分析: 1.展示用户清单: 输出语句, 用户输入, 选择功能序号 2.根据选择,调用不同的方法 switch语句 case 1 2 3 A 展示库存 将存储商品的数组,遍历 B 修改库存 修改所有的库存数量 */ import java.util.Scanner; public class Shopp{ public static void main(String[] args){ } /* 定义方法,展示所有的库存清单,遍历 返回值,没有 参数, 数组 */ public static void printStore(String[] brand,double[] size,double[] price,int[] count){ System.out.println(&quot;----------商场库存清单----------&quot;); System.out.println(&quot;品牌型号 尺寸 价格 库存数&quot;); //定义变量,计算总库存数,和总价格 int totalCount = 0; int totalMoney = 0; //遍历数组,将数组中所有的商品信息打印出来 for(int i = 0 ; i &lt; brand.length ; i++){ System.out.println(brand[i]+&quot; &quot;+size[i]+&quot; &quot;+price[i]+&quot; &quot;+count[i]); totalCount += count[i]; totalMoney += count[i]*price[i]; } System.out.println(&quot;总库存数: &quot;+totalCount); System.out.println(&quot;商品库存总金额: &quot;+totalMoney); } /* 定义方法,实现用户的选择功能,功能的需要返回来 返回值, int 参数, 没有 */ public static int chooseFunction(){ System.out.println(&quot;-------------库存管理------------&quot;); System.out.println(&quot;1.查看库存清单&quot;); System.out.println(&quot;2.修改商品库存数量&quot;); System.out.println(&quot;3.退出&quot;); System.out.println(&quot;请输入要执行的操作序号：&quot;); //接受键盘输入 Scanner sc = new Scanner(System.in); int chooseNumber = sc.nextInt(); return chooseNumber; } } 15库存案例代码实现_2* A: 案例代码 /* 定义方法,修改所有商品的库存 用户输入1个,修改1个 返回值,没有 参数, 库存数的数组, 品名数组 */ public static void update(String[] brand, int[] count){ //遍历数组,遍历到一个,修改一个 //接受键盘输入 Scanner sc = new Scanner(System.in); //遍历数组 for(int i = 0; i &lt; brand.length ; i++){ System.out.println(&quot;请输入&quot;+brand[i]+&quot;的库存数&quot;); //键盘输入,录入库存, 存储到库存的数组中 int newCount = sc.nextInt(); count[i] = newCount; } //int chooseNumber = sc.nextInt(); } 16库存案例代码测试* A: 案例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109/* 实现商品的库存管理 功能: 1.展示用户选择功能清单 2.根据选择的功能编号,进行不同的操作 A. 展示所有库存 B. 修改库存数量 分析: 1.展示用户清单: 输出语句, 用户输入, 选择功能序号 2.根据选择,调用不同的方法 switch语句 case 1 2 3 A 展示库存 将存储商品的数组,遍历 B 修改库存 修改所有的库存数量*/import java.util.Scanner;public class Shopp&#123; public static void main(String[] args)&#123; //使用数组,保存商品的信息 //品名,尺寸,价格,库存数, 定义5个数组 String[] brand = &#123;"MacBookAir","ThinkpadT450"&#125;; double[] size = &#123;13.3,15.6&#125;; double[] price = &#123;9998.97,6789.56&#125;; int[] count = &#123;0,0&#125;; while(true)&#123; int choose = chooseFunction(); switch(choose)&#123; case 1: //调用查看库存清单方法 printStore(brand,size,price,count); break; case 2: //调用修改库存的方法 update(brand,count); break; case 3: return ; default: System.out.println("没有这个功能"); break; &#125; &#125; &#125; /* 定义方法,修改所有商品的库存 用户输入1个,修改1个 返回值,没有 参数, 库存数的数组, 品名数组 */ public static void update(String[] brand, int[] count)&#123; //遍历数组,遍历到一个,修改一个 //接受键盘输入 Scanner sc = new Scanner(System.in); //遍历数组 for(int i = 0; i &lt; brand.length ; i++)&#123; System.out.println("请输入"+brand[i]+"的库存数"); //键盘输入,录入库存, 存储到库存的数组中 int newCount = sc.nextInt(); count[i] = newCount; &#125; //int chooseNumber = sc.nextInt(); &#125; /* 定义方法,展示所有的库存清单,遍历 返回值,没有 参数, 数组 */ public static void printStore(String[] brand,double[] size,double[] price,int[] count)&#123; System.out.println("----------商场库存清单----------"); System.out.println("品牌型号 尺寸 价格 库存数"); //定义变量,计算总库存数,和总价格 int totalCount = 0; int totalMoney = 0; //遍历数组,将数组中所有的商品信息打印出来 for(int i = 0 ; i &lt; brand.length ; i++)&#123; System.out.println(brand[i]+" "+size[i]+" "+price[i]+" "+count[i]); totalCount += count[i]; totalMoney += count[i]*price[i]; &#125; System.out.println("总库存数: "+totalCount); System.out.println("商品库存总金额: "+totalMoney); &#125; /* 定义方法,实现用户的选择功能,功能的需要返回来 返回值, int 参数, 没有 */ public static int chooseFunction()&#123; System.out.println("-------------库存管理------------"); System.out.println("1.查看库存清单"); System.out.println("2.修改商品库存数量"); System.out.println("3.退出"); System.out.println("请输入要执行的操作序号："); //接受键盘输入 Scanner sc = new Scanner(System.in); int chooseNumber = sc.nextInt(); return chooseNumber; &#125;&#125;]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础4(switch，数组)]]></title>
    <url>%2F2016%2F10%2F04%2Fday04%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、流程控制语句switch2、数组3、随机点名器案例 01switch语句解构* A:switch语句解构 * a:switch只能针对某个表达式的值作出判断，从而决定程序执行哪一段代码。 1234567891011121314151617* b:格式如下: swtich(表达式)&#123; case 常量1 : 要执行的语句; break; case 常量2 : 要执行的语句; break; case 常量3 : 要执行的语句; break; default: 要执行的语句; break; 123456789101112* c: 执行流程: 表达式,和case后面的常量进行比较和哪个case后的常量相同,就执行哪个case后面的程序,遇到break,就全结束* d: 关键字: switch case default break * e:举例 如果等于1，则输出星期一 如果等于2，则输出星期二 如果等于3，则输出星期三 如果等于4，则输出星期四 如果等于5，则输出星期五 如果等于6，则输出星期六 如果等于7，则输出星期天 02switch语句的星期判断* A: switch语句的星期判断 123456789101112131415161718192021222324252627282930313233343536* a: 明确需求 需求:初始化int类型变量(1-7)代表星期几,使用switch语句进行判断,并打印出该整数对应的星期. * b: 代码实现public class SwitchDemo01 &#123; public static void main(String[] args) &#123; int week = 5; switch (week) &#123; case 1: System.out.println("星期一"); break; case 2: System.out.println("星期二"); break; case 3: System.out.println("星期三"); break; case 4: System.out.println("星期四"); break; case 5: System.out.println("星期五"); break; case 6: System.out.println("星期六"); break; case 7: System.out.println("星期天"); break; default: System.out.println("输入的数字不正确..."); break; &#125; &#125;&#125; 03switch语句接受的数据类型* A: switch语句接受的数据类型 * a:注意事项 switch语句中的表达式的数据类型,是有要求的 JDK1.0 - 1.4 数据类型接受 byte short int char JDK1.5 数据类型接受 byte short int char enum(枚举) JDK1.7 数据类型接受 byte short int char enum(枚举), String 04case穿透* A:case穿透 123* a: 在使用switch语句的过程中，如果多个case条件后面的执行语句是一样的，则该执行语句只需书写一次即可，这是一种简写的方式。* b: 例如，要判断一周中的某一天是否为工作日，同样使用数字1~7来表示星期一到星期天，当输入的数字为1、2、3、4、5时就视为工作日，否则就视为休息日。* 注意：case 语句后面 没有break 就会一直穿透下去。 05数组的概述* A: 数组的概述 * a:数组的需求 现在需要统计某公司员工的工资情况，例如计算平均工资、最高工资等。假设该公司有50名员工，用前面所学的知识完成， 那么程序首先需要声明50个变量来分别记住每位员工的工资，这样做会显得很麻烦. * b:数组的概述 数组是指一组数据的集合，数组中的每个数据被称作元素。在数组中可以存放任意类型的元素，但同一个数组里存放的元素类型必须一致。 06数组的定义* A：数组的定义 123456789101112131415161718192021222324* b:格式: 数据类型[] 数组名 = new 数据类型[元素个数或数组长度]; * c:举例: int[] x = new int[100];* c:要点说明 1)数据类型: 数组中存储元素的数据类型 2) [] 表示数组的意思 3) 变量名 自定义标识符 4) new 创建容器关键字 5)数据类型: 数组中存储元素的数据类型 6)[] 表示数组的意思 7)元素个数,就是数组中,可以存储多少个数据 (恒定, 定长) 数组是一个容器: 存储到数组中的每个元素,都有自己的自动编号 自动编号,最小值是0, 最大值,长度-1 自动编号专业名次, 索引(index), 下标, 角标 访问数组存储的元素,必须依赖于索引, 公式 数组名[索引] Java提供一个属性,操作索引的 数组的一个属性,就是数组的长度, 属性的名字 length 使用属性: 数组名.length 数据类型 int 数组的最小索引是0, 最大索引数组.length-1 07JVM内存划分* A：内存划分 * JVM对自己的内存划分为5个区域 * a: 寄存器:内存和CUP之间 * b: 本地方法栈: JVM调用了系统中的功能 * c: 方法和数据共享: 运行时期class文件进入的地方 * d: 方法栈:所有的方法运行的时候进入内存 * e: 堆:存储的是容器和对象 08数组的内存1234567* A: 数组的内存* int[] x; // 声明一个int[]类型的变量* x = new int[100]; // 创建一个长度为100的数组* 接下来，通过两张内存图来详细地说明数组在创建过程中内存的分配情况。* 第一行代码 int[] x; 声明了一个变量x，该变量的类型为int[]，即一个int类型的数组。变量x会占用一块内存单元，它没有被分配初始值* 第二行代码 x = new int[100]; 创建了一个数组，将数组的地址赋值给变量x。在程序运行期间可以使用变量x来引用数组，这时内存中的状态会发生变化* 引用数据类型 存的是变量的地址 09使用索引访问数组的元素* A: 使用索引访问数组的元素 * 组中有100个元素，初始值都为0。数组中的每个元素都有一个索引(也可称为角标)，要想访问数组中的元素可以通过“x[0]、x[1]、……、x[98]、x[99]”的形式。 * 需要注意的是，数组中最小的索引是0，最大的索引是“数组的长度-1” 10数组的length属性* A: lenth属性 123456789101112* a 在Java中，为了方便我们获得数组的长度，提供了一个length属性，在程序中可以通过“数组名.length”的方式来获得数组的长度，即元素的个数。* b 求数组的长度public class ArrayDemo01 &#123; public static void main(String[] args) &#123; int[] arr; // 声明变量 arr = new int[3]; // 创建数组对象 System.out.println("arr[0]=" + arr[0]); // 访问数组中的第一个元素 System.out.println("arr[1]=" + arr[1]); // 访问数组中的第二个元素 System.out.println("arr[2]=" + arr[2]); // 访问数组中的第三个元素 System.out.println("数组的长度是：" + arr.length); // 打印数组长度 &#125;&#125; 11为数组的元素赋值* A: 为数组的元素赋值 * a: 如果在使用数组时，不想使用这些默认初始值，也可以显式地为这些元素赋值。 * 赋值过的元素已经变为新的数值,没有赋值的元素默认初始化的数值 * b: 案例 123456789101112public class ArrayDemo02 &#123; public static void main(String[] args) &#123; int[] arr = new int[4]; // 定义可以存储4个整数的数组 arr[0] = 1; // 为第1个元素赋值1 arr[1] = 2; // 为第2个元素赋值2 // 下面的代码是打印数组中每个元素的值 System.out.println("arr[0]=" + arr[0]); System.out.println("arr[1]=" + arr[1]); System.out.println("arr[2]=" + arr[2]); System.out.println("arr[3]=" + arr[3]); &#125;&#125; 12数组的定义_2* A: 定义数组格式2 1234567891011121314* a: 数组初始化动态初始化 : 在定义数组时只指定数组的长度，由系统自动为元素赋初值的方式称作动态初始化。 1、类型[] 数组名 = new 类型[长度]; int[] arr = new int[4]; 静态初始化: 在初始化数组时还有一种方式叫做静态初始化，就是在定义数组的同时就为数组的每个元素赋值。 2、类型[] 数组名 = new 类型[]&#123;元素，元素，……&#125;; int[] arr = new int[]&#123;1,2,3,4&#125;; 使用这种语法形式可以在不创建新变量的情况下重新初始化一个数组。 例如： arr = new int[] &#123; 17, 19, 23, 29, 31, 37 &#125;; 3、类型[] 数组名 = &#123;元素，元素，元素，……&#125;; int[] arr = &#123; 1, 2, 3, 4 &#125;;* 数组拷贝 int[] smallPrimes = &#123; 2, 3, 5, 7, 11, 13 &#125;; int[] luckyNumbers = smallPrimes; 如果希望将一个数组的所有值拷贝到一个新的数组中去，就要使用 Arrays 类的 copyOf方法： 123int[] copiedLuckyNumbers = Arrays.copyOf(luckyNumbers, luckyNumbers.length) ;//第 2 个参数是新数组的长度。这个方法通常用来增加数组的大小luckyNumbers = Arrays.copyOf(luckyNumbers, 2 * luckyNumbers.length); 如果数组元素是数值型，那么多余的元素将被赋值为 0 ; 如果数组元素是布尔型， 则将赋值为 false。相反， 如果长度小于原始数组的长度，则只拷贝最前面的数据元素。 13遍历数组* A:遍历数组 * 在操作数组时，经常需要依次访问数组中的每个元素，这种操作称作数组的遍历 * B:练习 12345678910111213141516public class ArrayDemo04 &#123; public static void main(String[] args) &#123; int[] arr = &#123; 1, 2, 3, 4, 5 &#125;; // 定义数组 // 使用for循环遍历数组的元素 for (int i = 0; i &lt; arr.length; i++) &#123; System.out.println(arr[i]); // 通过索引访问元素 &#125; &#125;&#125;上述代码中，定义一个长度为5的数组arr，数组的角标为0~4。由于for循环中定义的变量i的值在循环过程中为0~4，因此可以作为索引，依次去访问数组中的元素，并将元素的值打印出来for each 循环 =&gt; 遍历数组for (variable : collection) &#123;statement&#125;例如: for(int element : a) System.out.println(element); 提示：有个更加简单的方式打印数组中的所有值， 即利用 Arrays 类的 toString 方法。 调用 Arrays.toString(a), 返回一个包含数组元素的字符串， 这些元素被放置在括号内， 并用逗号分隔， 例如，“ [2, 3, 5,7，11 ，13]”、 要想打印数组， 可以调用System.out.println(Arrays.toString(a)); 14数组中常见的异常* A: 数组操作中,常见的两个异常 数组的索引越界异常 空指针异常 * B: 练习 1234567891011121314public class ArrayDemo_4&#123; public static void main(String[] args)&#123; //数组的索引越界异常 //int[] arr = &#123;5,2,1&#125;; //数组中3个元素,索引 0,1,2 //System.out.println(arr[3]);//java.lang.ArrayIndexOutOfBoundsException: 3 //空指针异常 int[] arr2 = &#123;1,5,8&#125;; System.out.println(arr2[2]); arr2 = null; // arr2 不在保存数组的地址了 System.out.println(arr2[2]);//java.lang.NullPointerException &#125;&#125; 15数组最值和排序* A: 数组获取最值的原理思想 * 定义数组的第一个元素arr[0]为最大值;循环arr数组,判断如果有比arr[0] 大的就交换,直到arr数组遍历完毕,那么arr[0]中就保存了最大的元素 * B: 数组排序 * 要想对数值型数组进行排序， 可以使用 Arrays 类中的 sort 方法： int[] a = new int[10000]; Arrays.sort(a) 16数组获取最值代码实现* A: 代码实现 12345678910111213public class ArrayDemo05 &#123; public static void main(String[] args) &#123; int[] arr = &#123; 4, 1, 6, 3, 9, 8 &#125;; // 定义一个数组 int max = arr[0]; // 定义变量max用于记住最大数，首先假设第一个元素为最大值 // 下面通过一个for循环遍历数组中的元素 for (int x = 1; x &lt; arr.length; x++) &#123; if (arr[x] &gt; max) &#123; // 比较 arr[x]的值是否大于max max = arr[x]; // 条件成立，将arr[x]的值赋给max &#125; &#125; System.out.println("max=" + max); // 打印最大值 &#125;&#125; 17二维数组的定义* A 二维数组的作用 * 要统计一个学校各个班级学生的考试成绩，又该如何实现呢？ * 这时就需要用到多维数组，多维数组可以简单地理解为在数组中嵌套数组。 * B 定义格式 123456789* a 第一种定义格式: * int[][] arr = new int[3][4]; * 上面的代码相当于定义了一个3*4的二维数组，即二维数组的长度为3，二维数组中的每个元素又是一个长度为4的数组* b 第二种定义格式 * int[][] arr = new int[3][]; * 第二种方式和第一种类似，只是数组中每个元素的长度不确定* c 第三种定义格式 * int[][] arr = &#123;&#123;1,2&#125;,&#123;3,4,5,6&#125;,&#123;7,8,9&#125;&#125;; * 二维数组中定义了三个元素，这三个元素都是数组，分别为&#123;1,2&#125;、&#123;3,4,5,6&#125;、&#123;7,8,9&#125; 18二维数组元素的访问* A: 二维数组的访问 * 案例: 12345678910111213141516171819202122232425262728293031class ArrayDemo08 &#123; public static void main(String[] args)&#123; //定义二维数组的方式 int[][] arr = new int[3][4]; System.out.println( arr ); System.out.println("二维数组的长度: " + arr.length); //获取二维数组的3个元素 System.out.println( arr[0] ); System.out.println( arr[1] ); System.out.println( arr[2] ); System.out.println("打印第一个一维数组的元素值"); System.out.println( arr[0][0] ); System.out.println( arr[0][1] );//访问的为二维数组中第1个一维数组的第2个元素 System.out.println( arr[0][2] ); System.out.println( arr[0][3] ); System.out.println("打印第二个一维数组的元素值"); System.out.println( arr[1][0] ); System.out.println( arr[1][1] ); System.out.println( arr[1][2] ); System.out.println( arr[1][3] ); System.out.println("打印第三个一维数组的元素值"); System.out.println( arr[2][0] ); System.out.println( arr[2][1] ); System.out.println( arr[2][2] ); System.out.println( arr[2][3] ); &#125;&#125; 19二维数组内存图* A: 二维数组内存图 * 举例:int[][] arr = new int[3][2]; * 外层数组长在内存开辟连续的3个大的内存空间,每一个内存空间都对应的有地址值 * 每一个大内存空间里又开辟连续的两个小的内存空间. 20二维数组的定义和访问1234567891011* A: 二维数组的定义和访问 * 格式1: * int[][] arr = new int[3][]; 不推荐 * 格式2 * int[][] arr = &#123;&#123;1,2,4&#125;,&#123;4,7&#125;,&#123;0,9,3&#125;&#125;; * * B: 二维数组的访问 举例:int[][] arr = &#123;&#123;1,2,4&#125;,&#123;5,8,7&#125;,&#123;0,9,3&#125;&#125;; 想要打印数组中7这个元素需要先找到大的元素索引&#123;5,7&#125; 索引为2 ,在找7在&#123;5,7&#125;中的索引2 那么结果为 arr[2][2] 第一个[2]代表大数组中&#123;5,8,7&#125;这个元素索引 第二个[2]代表&#123;5,8,7&#125;中7元素的索引 21二维数组的遍历* A:二维数组遍历 123456789101112131415161718 int[][] arr = &#123;&#123;1,2,4&#125;,&#123;4,7&#125;,&#123;0,9,3&#125;&#125;; 先使用for循环遍历arr这个二维数组,得到每一个元素为arr[i]为一维数组 再外层for循环中嵌套一个for循环遍历每一个一维数组arr[i],得到每一元素 * B:举例:遍历二维数组public class ArrayArrayDemo_2&#123; public static void main(String[] args)&#123; int[][] arr = &#123; &#123;1,2,3&#125;,&#123;4,5&#125;,&#123;6,7,8,9&#125;,&#123;0&#125; &#125;; //外循环,遍历二维数组 for(int i = 0 ; i &lt; arr.length ;i++)&#123; //内循环,遍历每个一维数组 arr[0] arr[1] arr[i] for(int j = 0 ; j &lt; arr[i].length; j++)&#123; System.out.print(arr[i][j]); &#125; System.out.println(); &#125; &#125; * C:二维数组累加求和 12345678910111213 class ArrayDemo09 &#123; public static void main(String[] args)&#123; int[][] arr2 = &#123; &#123;1,2&#125;,&#123;3,4,5&#125;,&#123;6,7,8,9,10&#125; &#125;; int sum2 = 0; for (int i=0; i&lt;arr2.length; i++) &#123; for (int j=0; j&lt;arr2[i].length; j++) &#123; //System.out.println(arr2[i][j]) sum2 += arr2[i][j]; &#125; &#125; System.out.println("sum2= "+ sum2); &#125;&#125; for each 循环语句不能自动处理二维数组的每一个元素。它是按照行， 也就是一维数组处理的要想访问二维教组 a 的所有元素， 需要使用两个嵌套的循环， 如下所示： 1234for (double [] row : a) for (double value : row) //do something with value System.out.println(value); 提示： 要想快速地打印一个二维数组的数据元素列表， 可以调用：System.out.println(Arrays.deepToString(a)) ;输出格式为：[[16, B, 2, 13], [5, 10, 11, 8], [9, 6, 7, 12], [4, 15, 14, 1]] 22二维数组的求和练习* A 例如要统计一个公司三个销售小组中每个小组的总销售额以及整个公司的销售额。如下所示 * 第一小组销售额为{11, 12}万元 * 第二小组销售额为{21, 22, 23}万元 * 第三小组销售额为{31, 32, 33, 34}万元。 * B 代码实现 123456789101112131415161718public class ArrayDemo10 &#123; public static void main(String[] args) &#123; int[][] arr = new int[3][]; // 定义一个长度为3的二维数组 arr[0] = new int[] &#123; 11, 12 &#125;; // 为数组的元素赋值 arr[1] = new int[] &#123; 21, 22, 23 &#125;; arr[2] = new int[] &#123; 31, 32, 33, 34 &#125;; int sum = 0; // 定义变量记录总销售额 for (int i = 0; i &lt; arr.length; i++) &#123; // 遍历数组元素 int groupSum = 0; // 定义变量记录小组销售总额 for (int j = 0; j &lt; arr[i].length; j++) &#123; // 遍历小组内每个人的销售额 groupSum = groupSum + arr[i][j]; &#125; sum = sum + groupSum; // 累加小组销售额 System.out.println("第" + (i + 1) + "小组销售额为：" + groupSum + " 万元"); &#125; System.out.println("总销售额为: " + sum + " 万元"); &#125;&#125; 23随机点名器案例分析* A 随机点名器案例分析 * B: 需求 * 随机点名器，即在全班同学中随机的打印出一名同学名字。 * C:分析: * 1)定义数组存数全班同学 * 2)生成随机数范围0 到 数组长度-1 * 3)根据这个索引找到数组中的同学名称 24随机点名器代码实现* A: 分析 随机点名器: 1 存储姓名 2. 预览所有人的姓名 3. 随机出一个人的姓名 * B 代码实现 123456789101112131415161718192021import java.util.Random;public class CallName&#123; public static void main(String[] args)&#123; //存储姓名,姓名存储到数组中 //数组存储姓名,姓名的数据类型,String String[] names = &#123;"张三","李四","王五","李蕾","韩梅梅","小名","老王","小华","约翰逊","爱丽丝"&#125;; //预览: 遍历数组,打印所有姓名 for(int i = 0 ; i &lt; names.length ; i++)&#123; System.out.println(names[i]); &#125; System.out.println("============="); //随机出一个人的名 //利用随机数,生成一个整数,作为索引,到数组中找到对应的元素 Random ran = new Random(); //随机数,范围必须是0-数组的最大索引 int index = ran.nextInt(names.length);//index 就是随机数,作为索引 System.out.println(names[index]); &#125;&#125; 25随机点名器代码实现_2* A 代码优化: 1234567import java.util.Random;public class CallName&#123; public static void main(String[] args)&#123; String[] names = &#123;"张三","李四","王五","李蕾","韩梅梅","小名","老王","小华","约翰逊","爱丽丝"&#125;; System.out.println(names[new Random().nextInt(names.length)]); &#125;&#125;]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础3(引用类型，if，while)]]></title>
    <url>%2F2016%2F10%2F04%2Fday03%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、引用类型变量的创建及使用2、流程控制语句之选择语句3、流程控制语句之循环语句4、循环高级 01创建引用类型变量公式 A: 创建引用类型变量公式 a: 我们要学的Scanner类是属于引用数据类型，我们先了解下引用数据类型。 b: 引用数据类型的定义格式 与定义基本数据类型变量不同，引用数据类型的变量定义及赋值有一个相对固定的步骤或格式。 数据类型 变量名 = new 数据类型(); c: 引用数据类型的使用 每种引用数据类型都有其功能，我们可以调用该类型实例的功能。 变量名.方法名(); 02Scanner类的使用* A: Scanner类的使用 123456* a: 导包import java.util.Scanner;* b：创建键盘录入对象 Scanner sc = new Scanner(System.in);* c: 读取键盘录入的一个整数 * int enterNumber = sc.nextInt();* d: 读取键盘录入的字符串 * String enterString = sc.next(); * B: 案例代码 import java.util.Scanner; public class Demo05Scanner{ public static void main(String[] args) { Scanner sc = new Scanner(System.in); int enterNumber = sc.nextInt(); System.out.println(&quot;用户输入的整数为&quot;+enterNumber); String enterString = sc.next(); System.out.println(&quot;用户输入的字符串为&quot;+enterString); } } 03Random随机数类的使用_1* A: Random随机数类的使用_1 123456789101112131415161718192021222324252627* a: 功能 * 生成随机数需要使用到引用类型随机数Random类* b: 使用方式 * import导包：所属包java.util. Random * 创建实例格式：Random random = new Random (); * 调用方法 * nextInt(int maxValue) 产生[0,maxValue)范围的随机数,包含0不包含maxValue * nextDouble() 产生[0,1)范围的随机数 如： Random random = new Random (); int myNumber = random.nextInt(100);//结果为0-99的一个数* B: 案例代码 import java.util.Random; public class RandomDemo&#123; public static void main(String[] args)&#123; Random ran = new Random(); // Random类中的,产生随机数的功能 int i = ran.nextInt(100); System.out.println(i); //问题? 产生随机数,范围 1-100之间 // nextInt(100) 0-99 + 1 &#125; &#125; 04Random随机数类的使用_2* A: Random随机数类的使用_2 12345* a: 调用方法 * nextDouble() 产生[0,1)范围的随机数 如： Random random = new Random (); int myNumber = random.nextDouble();//结果为0.0-1.0之间的数(包括0.0不包括1.0) 05if语句格式第一种* A: if语句格式第一种 12345678* a: 书写格式 if(比较表达式) &#123; 语句体; &#125;* b：执行流程： * 先计算比较表达式的值，看其返回值是true还是false。 * 如果是true，就执行语句体； * 如果是false，就不执行语句体； 12345678910111213* B: 案例代码 public class IfDemo&#123; public static void main(String[] args)&#123; int i = 5 ; //对变量i进行if判断 if(i &gt; 5)&#123; System.out.println("if中的条件是true"); i++; &#125; System.out.println(i); &#125; &#125; 06if语句格式第二种* A: if语句格式第二种 12345678910* a: 书写格式 if(比较表达式) &#123; 语句体1; &#125;else &#123; 语句体2; &#125;* b：执行流程： * 首先计算比较表达式的值，看其返回值是true还是false。 * 如果是true，就执行语句体1； * 如果是false，就执行语句体2； 123456789101112* B: 案例代码 public class IfElseDemo&#123; public static void main(String[] args)&#123; int i = 16 ; //判断变量,是奇偶数, 除以2,看余数是0还是1 if( i % 2 == 0 )&#123; System.out.println(i+" 是偶数"); &#125;else&#123; System.out.println(i+" 是奇数"); &#125; &#125; &#125; 07if语句格式第三种* A: if语句格式第三种 123456789101112131415161718192021* a: 书写格式 if(比较表达式1) &#123; 语句体1; &#125;else if(比较表达式2) &#123; 语句体2; &#125;else if(比较表达式3) &#123; 语句体3; &#125; ... else &#123; 语句体n+1; &#125;* b：执行流程： * 首先计算比较表达式1看其返回值是true还是false， * 如果是true，就执行语句体1，if语句结束。 * 如果是false，接着计算比较表达式2看其返回值是true还是false， * 如果是true，就执行语句体2，if语句结束。 * 如果是false，接着计算比较表达式3看其返回值是true还是false， * 如果都是false，就执行语句体n+1。 12345678910111213141516171819* B: 案例代码 public class IfElseIfDemo&#123; public static void main(String[] args)&#123; //成绩判断要求 ,成绩&gt;80 成绩&gt;70 成绩&gt;60 不及格 //定义变量,保存成绩 int grade = 75; //使用if else if 语句对成绩判断 if( grade &gt; 80 )&#123; System.out.println(grade+" 成绩是优"); &#125;else if ( grade &gt; 70)&#123; System.out.println(grade+" 成绩是良"); &#125;else if ( grade &gt; 60)&#123; System.out.println(grade+" 成绩是中"); &#125;else&#123; System.out.println(grade+" 成绩是差"); &#125; &#125; &#125; 08if语句和三元运算符的互换* A: 三元运算符 12345678* a: 概念 * 用来完成简单的选择逻辑，即根据条件判断，从两个选择中选择一种执行* b: 使用格式 * (条件表达式)？表达式1：表达式2；* c: 运算规则 * 1: 判断条件表达式，结果为一个布尔值 * 2: true，运算结果为表达式1 * 3: false，运算结果为表达式2 123456789101112131415161718192021* B: 案例代码 public class IfElseDemo_1&#123; public static void main(String[] args)&#123; int j = 6; int i = 15; //使用if语句,判断出最大值 if(i&gt;j)&#123; int j = 6; System.out.println(i+" 是最大值"); &#125;else&#123; System.out.println(j+" 是最大值"); &#125; //使用三元运算实现 int k = i&gt;j ? i : j; System.out.println(k+" 是最大值"); &#125; &#125;* C: 使用if语句还是三元表达式 * 判断条件多,使用if * 三元,必须有结果的, if 可以没有结果的 09while循环* A: while循环结构 123456789* a: 使用格式 初始化表达式； while(条件)&#123; 循环体 &#125;* b: 执行顺序 当条件是true,就执行循环体,执行完循环体后 程序再次执行while中的条件,如果条件还是true,继续执行循环体 直到条件是false的时候,循环就结束 123456789101112* B: 案例代码 public class WhileDemo&#123; public static void main(String[] args)&#123; //输出 1-4之间的整数 //定义变量,整数类型, 循环的条件 int i = 1; while( i &lt; 5 )&#123; System.out.println(i); i++; &#125; &#125; &#125; 10for循环_1* A: for循环_1 123456789101112131415161718 * a: 使用格式 for(初始化变量 ; 条件 ; 增量)&#123; 循环体; &#125; * b: 各模块解释 初始化变量: 定义变量,作用是用来控制循环的次数 条件: 当条件是true,执行循环体,条件是false,结束循环 增量: 变量自增情况 * B: 案例代码 public class ForDemo&#123; public static void main(String[] args)&#123; //for循环,输出0-10 for(int i = 0 ; i &lt; 11 ; i++)&#123; System.out.println(i); &#125; &#125; &#125; 11for循环_2* A: for循环的执行流程 for（①1 ; ②2 ; ③3）{ ④4 } 第一步，执行①1 第二步，执行②2，如果判断结果为true，执行第三步，如果判断结果为false，执行第五步 第三步，执行④4 第四步，执行③3，然后重复执行第二步 第五步，退出循环 12for循环_3* A: 案例 * a: 利用for循环,计算1+4的结果 * B: 案例代码 123456789101112public class ForDemo_1&#123; public static void main(String[] args)&#123; // 定义变量,记录求和后的数据 int sum = 0; // 利用循环,将变量从1变化到4 for(int i = 1 ; i &lt;= 4 ; i++)&#123; //对变量进行求和 sum = sum + i; &#125; System.out.println(sum); &#125;&#125; 13do_while循环* A: do_while循环 12345678910111213141516171819* a: 使用格式 do&#123; 循环体; &#125;while(条件);* b: 执行顺序 先执行一次循环体，然后再判断条件，如果条件为true，继续执行循环体， 如果条件为false，循环结束。* c: 特点 * 无条件先执行一次* B: 案例代码public class DoWhileDemo&#123; public static void main(String[] args)&#123; int i = 0; do&#123; System.out.println(i); i++; &#125;while( i &lt; 5); &#125;&#125; 14死循环* A: 死循环概述 * 无限循环存在的原因是并不知道循环多少次，而是根据某些条件，来控制循环 * B: 死循环格式 * while(true){} * for(;;){} 15嵌套for循环_1* A: 嵌套循环的概述 123* 嵌套循环是指在一个循环语句的循环体中再定义一个循环语句的语法结构。* while、do…while、for循环语句都可以进行嵌套，并且它们之间也可以互相嵌套，* 如最常见的在for循环中嵌套for循环。 * B: 嵌套循环的格式 12345678for(初始化表达式; 循环条件; 操作表达式) &#123; ……… for(初始化表达式; 循环条件; 操作表达式) &#123; 执行语句 ……… &#125; ………&#125; * C: 各模块解释 12345* 总的循环次数 = 内循环次数 * 外循环的次数* 内循环,是外循环的循环体 * 外循环,控制的是行数* 内循环,控制的是每行的个数 16嵌套for循环_2* A: 案例 * a: 打印正三角形 * B: 案例代码 12345678910public class ForForDemo&#123; public static void main(String[] args)&#123; for(int i = 0 ; i &lt; 9 ; i++)&#123; for(int j = 0; j &lt; i+1 ;j++)&#123; System.out.print("* "); &#125; System.out.println(); &#125; &#125;&#125; 17break语句* A: break语句 123456789101112* a: 作用 * 跳出所在的循环体* b: 书写位置 * 必须出现在循环或选择结构内* c: 举例 for(int i=0; i&lt;10; i++) &#123; if(i&gt;5) &#123; break; &#125; System.out.println(“我爱Java”+i); &#125; //会从0-5输出6次“我爱Java” * B: break详细解释 123456789* a: 作用 * 在loop/switch选择或者循环过程中，我们总是满足布尔表达条件才能执行对应的代码，然而在这些逻辑过程中， 可以使用一些关键字直接跳出正在执行的代码，去执行后边或者指定位置的代码， 这些关键字一旦出现就可以跳转语句执行顺序。* b: 使用方式 * 无法单独使用，必须将break关键字置于switch或循环语句中* c: 运行规律 * 不需要判断任何条件，只要遇到break变直接跳出执行后续代码。会完全跳出选择或者循环结构 * 只能跳出最近的代码块，不能跨越多级代码块 * C：循环标号 123456789* a: 为什么使用循环标号 * 当在双层循环或者循环内有switch选择语句时，我们发现，使用break或者continue所作用的对象均是内层语句，无法直接跳出外层循环，这时就需要使用标号语句跳转了.* b: 使用方式 * 在外层循环外的某行前边，使用后边跟有冒号”:”的标识符，即定义完毕。 使用时当在内层循环使用break或continue时后边紧跟之前定义的标号即可* c: 运行规律 * 当外层循环外定义了标号 * 内层使用break，终止内外双层循环。 * 内层使用continue，终止内层循环，继续外层循环。 18continue语句* A: continue语句 12345678910111213141516171819* a: 作用 * 提前结束本次循环，继续进行下次循环* b: 使用方式 * 无法单独使用，必须将continue关键字置于循环语句中* c：运行规律 * 不需要判断任何条件，只要遇到continue变直接跳出本轮循环进行下次循环* d：案例代码 public class ContinueDemo&#123; public static void main(String[] args)&#123; for(int i = 0 ; i &lt; 10 ; i++)&#123; if(i%2==0)&#123; continue; &#125; System.out.println(i); &#125; &#125; &#125; //会把0-9之间所有的奇数打印到控制台上 19猜数字小游戏* A: 猜数字小游戏 * a: 分析 * 用户给的数可能大于、小于、或等于被猜的数，这样就会出现三种情况，用前面讲的三元运算符可以实现， 但是得用三元运算符的嵌套，比较麻烦！可以用更简单的方式if条件判断，可以有三个以上的条件 * b: 需求分析 * 后台预先生成一个随机数1-100，用户键盘录入猜数字 * 如果猜对了，打印“恭喜您，答对了” * 如果猜错了 * 猜大了：打印“sorry，您猜大了!” * 猜小了：打印“sorry，您猜小了!” 直到数字猜到为止 最多只能猜5次，否则提示“sorry，您没有机会了!” * B: 案例代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/* 猜数字小游戏 完成猜数字小游戏： 1、产生随机数 后台预先生成一个随机数1-100，用户键盘录入猜数字 2、通过if语句对用户猜的数与随机数进行比较 如果猜对了，打印“恭喜您，答对了” 如果猜错了 猜大了：打印“sorry，您猜大了!” 猜小了：打印“sorry，您猜小了!” 3、通过for循环完成用户猜数的循环 直到数字猜到为止 最多只能猜5次，否则提示“sorry，您没有机会了!”*/import java.util.Random;import java.util.Scanner;//通过*的方式可以一次导入该包下所有的类，但是不建议使用。建议使用哪个导哪个。//import java.util.*;public class GuessNumber&#123; public static void main(String[] args) &#123; //1、产生随机数 //后台预先生成一个随机数1-100，用户键盘录入猜数字 //创建随机数对象 Random random = new Random(); //产生一个1-100的随机数 int randomNumber = random.nextInt(100)+1; //System.out.println("我产生的随机数是："+randomNumber+"你猜猜是多少？"); 作弊专用 //产生控制台录入的Scanner对象 Scanner sc = new Scanner(System.in); //3、通过for循环完成用户猜数的循环 //通过for循环完成猜数字逻辑 for(int i=1; i&lt;=5; i++)&#123; //提示用户输入要猜的数，用变量接收 System.out.println(); System.out.println("请您输入一个1-100的数："); int guessNumber = sc.nextInt(); //2、通过if语句对用户猜的数与随机数进行比较 //如果猜对了 if(guessNumber==randomNumber) &#123; //打印猜对后的提示 System.out.println("恭喜您，猜对了！"); //跳出循环，不用再猜了 break; &#125;else &#123;//如果猜错了 //如果猜大了 if(guessNumber&gt;randomNumber) &#123; System.out.println("sorry，您猜大了!"); &#125;else &#123;//如果猜小了 System.out.println("sorry，您猜小了!"); &#125; &#125; //如果猜到了最后的第5次仍然没有猜对就跳出循环 if(i==5) &#123; System.out.println("对不起，点太背，下次再来吧！"); break; &#125; //每次猜错后，都提示还有多少次机会 System.out.println("请注意，您还有"+(5-i)+"次机会，请慎重作答！"); &#125; &#125;&#125;]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AS环境配置踩坑经历]]></title>
    <url>%2F2016%2F10%2F03%2FAS%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E8%B8%A9%E5%9D%91%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[遇到的bugUnable to resolve dependency for &apos;:app@debug/compileClasspath&apos; 这是由于配置文件的依赖是通过Google下载的，然而该下载被墙了！[解决办法]： 在整个工程的build.gradle中添加以下框内代码：1234maven &#123; url 'http://maven.aliyun.com/nexus/content/groups/public/' &#125;maven &#123; url 'http://repo1.maven.org/maven2' &#125; app下的build.gradle配置如下:buildToolsVersion 需要和你的sdk安装目录 ~\sdk\build-tools文件里面已有的版本对应123456789101112131415161718android &#123; compileSdkVersion 26 buildToolsVersion '27.0.3' defaultConfig &#123; applicationId "com.example.administrator.myapplication" minSdkVersion 19 targetSdkVersion 22 versionCode 1 versionName "1.0" testInstrumentationRunner "android.support.test.runner.AndroidJUnitRunner" &#125; buildTypes &#123; release &#123; minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro' &#125; &#125;&#125; implementation ‘com.android.support:appcompat-v7:26.+’ 中v7:26.+表示使用的sdk版本123456789101112dependencies &#123; implementation fileTree(dir: 'libs', include: ['*.jar']) implementation 'com.android.support:appcompat-v7:26.+' implementation 'com.android.support.constraint:constraint-layout:1.0.2' testImplementation 'junit:junit:4.12' androidTestImplementation 'com.android.support.test:runner:0.4' androidTestImplementation 'com.android.support.test.espresso:espresso-core:2.2.2'// androidTestImplementation 'com.android.support.test:runner:1.0.1'// androidTestImplementation 'com.android.support.test.espresso:espresso-core:3.0.1'&#125; 若配置后还没解决问题，依然报错打开 C:/Users/(用户名)/.gradle/gradle.properties把http代理的配置注释掉，例如： ## For more details on how to configure your build environment visit # http://www.gradle.org/docs/current/userguide/build_environment.html # # Specifies the JVM arguments used for the daemon process. # The setting is particularly useful for tweaking memory settings. # Default value: -Xmx1024m -XX:MaxPermSize=256m # org.gradle.jvmargs=-Xmx2048m -XX:MaxPermSize=512m -XX:+HeapDumpOnOutOfMemoryError -Dfile.encoding=UTF-8 # # When configured, Gradle will run in incubating parallel mode. # This option should only be used with decoupled projects. More details, visit # http://www.gradle.org/docs/current/userguide/multi_project_builds.html#sec:decoupled_projects # org.gradle.parallel=true #Sat Sep 29 23:37:12 CST 2018 #systemProp.http.proxyHost=mirrors.neusoft.edu.cn #systemProp.https.proxyPort=80 #systemProp.https.proxyHost=mirrors.neusoft.edu.cn #systemProp.http.proxyPort=80 More info: 参考该问题的csdn博客]]></content>
      <categories>
        <category>软件安装</category>
      </categories>
      <tags>
        <tag>AS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习笔记——基础1(变量，运算符)]]></title>
    <url>%2F2016%2F10%2F02%2Fjava%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[1、变量2、运算符 第一个Java程序Java代码Java程序是大小写敏感的 对格式没有严格要求，但用空格或Tab键缩进会比较好看 Hello.java12345public class Hello &#123; public static void main(String[] args) &#123; System.out.println("Hello, world!");&#125;&#125; 文件名必须是Hello.java，文件名也要注意大小写，必须与程序的类名完全一致，扩展名是.java。 编译切换到Hello.java所在目录：1javac Hello.java 无任何输出表示成功，可查看编译出的Hello.class文件。 执行1java Hello 代码格式：public 和 static 是修饰符static表示静态方法 12345678910public class 类名 &#123; public static void 方法名(参数) &#123; //单行注释 你的程序代码; /* 多行注释 */&#125;&#125;//class定义结束 变量变量概述A: 什么是变量? 12a: 变量是一个内存中的小盒子（小容器），容器是什么？生活中也有很多容器，例如水杯是容器，用来装载水；你家里的大衣柜是容器，用来装载衣裤；饭盒是容器，用来装载饭菜。那么变量是装载什么的呢？答案是数据！结论：变量是内存中装载数据的小盒子，你只能用它来存数据和取数据。 计算机存储单元A: 计算机中储存和运算的最小单位是?123456789a: 一个字节,也就是一个byte. win+r--cmd--回车 b: 常用储存单位 *1B（字节） = 8bit *1KB = 1024B *1MB = 1024KB *1GB = 1024MB *1TB = 1024GB *1PB = 1024TB Java中数据类型四类八种 A: 数据类型四类八种123456789*四类 八种 字节数 数据表示范围*整型 byte 1 -128～127 short 2 -32768～32767 int 4 -2147483648～2147483648 long 8 -263～263-1*浮点型 float 4 -3.403E38～3.403E38 double 8 -1.798E308～1.798E308*字符型 char 2 表示一个字符，如('a'，'A'，'0'，'家')*布尔型 boolean 1 只有两个值true与false 常量和数据类型 A:常量的定义1234* a: 整形常量默认是int类型* b: 小数常量默认是double类型* c: 定义长整形数据如果值超过int取值范围后面要+"L"* d: 定义float类型的数据后面要+"f" 否则默认是double 变量创建的三要素A: 定义变量的语法格式：1234567891011121314数据类型 变量名 = 变量值;* int a = 100; * B:代码:public class Variable &#123; public static void main(String[] args) &#123; int a = 10; double b = 3.14; char c = 'z'; String s = "i love java"; a = 20; System.out.println(a); &#125;&#125; 定义所有的基本数据类型变量 A: 案例演示 a: 八种基本类型数据的创建 定义字符串变量 A：案例演示 创建字符串数据类型变量 String 是引用数据类型变量定义使用注意事项 A：变量使用的注意事项12345678910111213141516* a: 变量定义后可以不赋值，使用时再赋值。不赋值不能使用。 public static void main(String[] args) &#123; int x; x = 20; //为x赋值20 System.out.println(x);//读取x变量中的值，再打印 &#125; * c: 变量使用时有作用域的限制。 public static void main(String[] args) &#123; int x = 20; &#123; int y = 20; &#125; System.out.println(x);//读取x变量中的值，再打印 System.out.println(y);//读取y变量中的值失败，失败原因，找不到y变量，因为超出了y变量作用范围，所以不能使用y变量 &#125; 数据类型转换_自动转换 A:  自动类型转换12345678* a:表示范围小的数据类型转换成范围大的数据类型，这种方式称为自动类型转换 自动类型转换格式： 范围大的数据类型 变量 = 范围小的数据类型值； 如： double d = 1000; 或 int i = 100; double d2 = i; 数据类型转换_强制转换 A: 强制类型转换12345678*a: 表示范围大的数据类型转换成范围小的数据类型，这种方式称为强制类型转换*b: 强制类型转换格式：范围小的数据类型 变量 = (范围小的数据类型) 范围大的数据类型值;如：int i = (int)6.718; //i的值为6或double d = 3.14;int i2 = (int)d; //i2的值为3 运算符算数运算符_1 A: 常见操作 1234567891011运算符 运算规则 范例 结果+ 正号 +3 3+ 加 2+3 5+ 连接字符串 “中”+“国” “中国”- 负号 int a=3;-a -3- 减 3-1 2* 乘 2*3 6/ 除 5/2 2% 取模 5/2 1++ 自增 int a=1;a++/++a 2-- 自减 int b=3;a--/--a 2 B: 注意事项 12345*a:加法运算符在连接字符串时要注意，只有直接与字符串相加才会转成字符串。*b:除法“/”当两边为整数时，取整数部分，舍余数。当其中一边为浮点型时，按正常规则相除。 *c:“%”为整除取余符号，小数取余没有意义。结果符号与被取余符号相同。*d:整数做被除数，0不能做除数，否则报错。*e:小数做被除数，整除0结果为Infinity，对0取模结果为NaN C:代码演示 1234567891011121314151617181920public class OperatorDemo1 &#123; public static void main(String[] args) &#123; /* * 常量使用算数运算符 */ System.out.println(10+20); /* * 变量使用算数运算符 */ int x = 10; int y = 20; //"+"作为加法运算使用 int z = x + y; //"+"作为连接字符串使用 System.out.println("x="+x); System.out.println("y="+y); System.out.println("z="+z);&#125;&#125; 算数运算符_2 算数运算符++、–* A:算数运算符++、--的使用 * a: ++运算符，会在原有值的基础上自增1 * b: --运算符，会在原有值的基础上自减1。 * B:++ -- 位置的使用 * a:++,--运算符后置时，先使用变量a原有值参与运算操作，运算操作完成后，变量a的值自增1或者自减1； * b:++，--运算符前置时，先将变量a的值自增1或者自减1，然后使用更新后的新值参与运算操作。 赋值运算符 A: 赋值运算符的使用 1234567运算符 运算规则 范例 结果= 赋值 int a=2 2+= 加后赋值 int a=2，a+=2 4-= 减后赋值 int a=2，a-=2 0*= 乘后赋值 int a=2，a*=2 4/= 整除后赋值 int a=2，a/=2 1%= 取模后赋值 int a=2，a%=2 0 B：案例演示 123456789101112 * 赋值运算符 * +=, -=, *=, /=, %= ： * 上面的运算符作用：将等号左右两边计算，会将结果自动强转成等号左边的数据类型,再赋值给等号左边的 * 注意：赋值运算符左边必须是变量public class OperatorDemo2 &#123; public static void main(String[] args) &#123; byte x = 10; x += 20;// 相当于 x = (byte)(x+20); System.out.println(x); &#125;&#125; 比较运算符 A:比较运算符的使用 1234567运算符 运算规则 范例 结果== 相等于 4==3 False!= 不等于 4!=3 True&lt; 小于 4&lt;3 False&gt; 大于 4&gt;3 True&lt;= 小于等于 4&lt;=3 False&gt;= 大于等于 4&gt;=3 True 逻辑运算符A: 逻辑运算符的使用 123456789101112运算符 运算规则 范例 结果&amp; 与 false&amp;true False| 或 false|true True^ 异或 true^flase True! 非 !true Flase&amp;&amp; 短路与 false&amp;&amp;true False|| 短路或 false||true True规律小结: 短路与&amp;&amp;:参与运算的两边数据，有false，则运算结果为false； 短路或||:参与运算的两边数据，有true，则运算结果为true； 逻辑非! : 参与运算的数据，原先是true则变成false，原先是false则变成true。 三元运算符A: 格式: (条件表达式)？表达式1：表达式2； B: 代码案例 方式一： System.out.println( 3&gt;2 ? “正确” : “错误” ); // 三元运算符运算后的结果为true，运算结果为表达式1的值“正确”，然后将结果“正确”，在控制台输出打印 方式二： int a = 3; int b = 4; String result = (a==b) ? “相等” : “不相等”; //三元运算符运算后的结果为false，运算结果为表达式2的值“不相等”，然后将结果赋值给了变量result 方式三： int n = (3&gt;2 &amp;&amp; 4&gt;6) ? 100 : 200; //三元运算符运算后的结果为false，运算结果为表达式2的值200,然后将结果200赋值给了变量n 运算符优先级1234567891011121314151617优先级 描述 运算符1 括号 ()、[]2 正负号 +、-3 自增自减，非 ++、--、!4 乘除，取余 *、/、%5 加减 +、-6 移位运算 &lt;&lt;、&gt;&gt;、&gt;&gt;&gt;7 大小关系 &gt;、&gt;=、&lt;、&lt;=8 相等关系 ==、!=9 按位与 &amp;10 按位异或 ^11 按位或 |12 逻辑与 &amp;&amp;13 逻辑或 ||14 条件运算 ?:15 赋值运算 =、+=、-=、*=、/=、%=16 位赋值运算 &amp;=、|=、&lt;&lt;=、&gt;&gt;=、&gt;&gt;&gt;= 商场库存清单案例A: 案例分析. a:观察清单后，可将清单分解为三个部分（清单顶部、清单中部、清单底部） b:清单顶部为固定的数据，直接打印即可 c:清单中部为商品，为变化的数据，需要记录商品信息后，打印经过观察，我们确定一项商品应该有如下几个属性：品牌型号: 即商品名称，String型尺寸：物品大小，double型价格：物品单价，double型配置：这一项为每种商品的配置信息，String型库存数：这一项为每种商品的库存个数，int型 d:清单底部包含了统计操作，需经过计算后，打印我们发现两个单独的可变化量总库存数：所有商品总个数，int型库存商品总金额：所有商品金额，double型 B: 案例代码实现123456789101112131415161718192021222324252627282930313233343536373839404142//步骤一: 创建Demo01库存清单.java文件，编写main主方法public class Demo01库存清单 &#123; public static void main(String[] args) &#123; &#125;&#125;//步骤二: 记录每种库存商品信息//苹果笔记本电脑String macBrand = "MacBookAir";double macSize = 13.3;double macPrice = 6988.88;int macCount = 5;//联想Thinkpad笔记本电脑String thinkpadBrand = "ThinkpadT450";double thinkpadSize = 14.0;double thinkpadPrice = 5999.99;int thinkpadCount = 10;//华硕ASUS笔记本电脑String ASUSBrand = "ASUS-FL5800";double ASUSSize = 15.6;double ASUSPrice = 4999.50;int ASUSCount = 18;//步骤三: 统计库存总个数、库存总金额int totalCount = macCount + thinkpadCount + ASUSCount;double totalMoney = (macCount * macPrice) + (thinkpadCount * thinkpadPrice) + (ASUSCount * ASUSPrice);//步骤四: 列表顶部System.out.println("------------------------------商城库存清单-----------------------------");System.out.println("品牌型号 尺寸 价格 库存数");步骤四:打印库存清单中部信息//列表中部System.out.println(macBrand+" "+macSize+" "+macPrice+" "+macCount);System.out.println(thinkpadBrand+" "+thinkpadSize+" "+thinkpadPrice+" "+thinkpadCount);System.out.println(ASUSBrand+" "+ASUSSize+" "+ASUSPrice+" "ASUSCount);打印库存清单底部信息//列表底部System.out.println("-----------------------------------------------------------------------");System.out.println("总库存数："+totalCount); System.out.println("库存商品总金额："+totalMoney);]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
</search>
